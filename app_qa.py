import json
import os
import sys
from openai import OpenAI

from config import API_KEY, BASE_URL, MODEL_NAME, is_api_configured

INPUT_FILE = "result.json"  # é»˜è®¤å›¾è°±æ–‡ä»¶ï¼Œå¯é€šè¿‡å‘½ä»¤è¡Œå‚æ•°è¦†ç›–

def load_knowledge_graph(path=None):
    """åŠ è½½çŸ¥è¯†å›¾è°± JSONï¼Œpath ä¸ºç©ºæ—¶ä½¿ç”¨ INPUT_FILEã€‚"""
    path = path or INPUT_FILE
    if not os.path.exists(path):
        return None
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

def _triple_to_fact(triple):
    """å°†å•æ¡ä¸‰å…ƒç»„è½¬ä¸ºè‡ªç„¶è¯­è¨€äº‹å®ï¼›å…¼å®¹ head/tail ä¸ subject/objectã€‚"""
    head = triple.get("head") or triple.get("subject")
    tail = triple.get("tail") or triple.get("object")
    rel = triple.get("relation", "")
    if not head or not tail:
        return None
    if rel == "proposed_model":
        return f"{head} æå‡ºäº†æ¨¡å‹ {tail}ã€‚"
    if rel == "baseline_model":
        return f"{head} å¯¹æ¯”çš„åŸºçº¿æ¨¡å‹æ˜¯ {tail}ã€‚"
    if rel == "evaluated_on":
        return f"{head} åœ¨æ•°æ®é›† {tail} ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚"
    if rel == "uses_metric":
        return f"{head} ä½¿ç”¨çš„è¯„ä¼°æŒ‡æ ‡æ˜¯ {tail}ã€‚"
    if rel == "author_of":
        return f"{head} æ˜¯è®ºæ–‡ã€Š{tail}ã€‹çš„ä½œè€…ã€‚"
    if rel == "cites":
        return f"{head} å¼•ç”¨äº† {tail}ã€‚"
    return f"{head} çš„ {rel} æ˜¯ {tail}ã€‚" if rel else None


def graph_rag_qa(user_query, kg_data):
    """
    å®ç°ä¸€ä¸ªç®€å•çš„ Graph RAG (å›¾è°±å¢å¼ºæ£€ç´¢)
    1. å°†å›¾è°±çš„ä¸‰å…ƒç»„è½¬åŒ–ä¸ºè‡ªç„¶è¯­è¨€ä¸Šä¸‹æ–‡
    2. è®©å¤§æ¨¡å‹ä»…æ ¹æ®è¿™äº›ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼Œé˜²æ­¢å¹»è§‰
    """
    if not is_api_configured():
        return "âŒ è¯·é…ç½® API Keyï¼šå¤åˆ¶ config_local.py.example ä¸º config_local.py å¹¶å¡«å…¥ Keyï¼Œæˆ–è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEYã€‚"
    client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

    # 1. çŸ¥è¯†å›¾è°±æ‰å¹³åŒ– (Flattening)
    paper_meta = kg_data.get("paper_metadata", {})
    paper_title = paper_meta.get("title", "")
    facts = [f"è®ºæ–‡ã€Š{paper_title}ã€‹çš„å…ƒæ•°æ®: {json.dumps(paper_meta, ensure_ascii=False)}"]

    for triple in kg_data.get("knowledge_graph", {}).get("triples", []):
        fact = _triple_to_fact(triple)
        if fact:
            facts.append(fact)

    context_str = "\n".join(facts)
    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªåŸºäºçŸ¥è¯†å›¾è°±çš„æ™ºèƒ½é—®ç­”åŠ©æ‰‹ã€‚ä»…æ ¹æ®æˆ‘æä¾›çš„ã€å·²çŸ¥çŸ¥è¯†å›¾è°±äº‹å®ã€‘å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

ã€å·²çŸ¥çŸ¥è¯†å›¾è°±äº‹å®ã€‘ï¼š
{context_str}

è¦æ±‚ï¼šè‹¥ç­”æ¡ˆåœ¨äº‹å®ä¸­è¯·å‡†ç¡®å›ç­”ï¼›è‹¥ä¸åœ¨è¯·ç›´æ¥è¯´â€œçŸ¥è¯†å›¾è°±ä¸­æœªåŒ…å«æ­¤ä¿¡æ¯â€ï¼Œä¸¥ç¦ç¼–é€ ã€‚å›ç­”ç®€æ´ã€ä¸“ä¸šã€‚"""

    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_query},
            ],
            temperature=0.1,
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"âŒ è°ƒç”¨å¤±è´¥: {e}"

if __name__ == "__main__":
    input_path = (sys.argv[1] if len(sys.argv) > 1 else None) or INPUT_FILE
    kg_data = load_knowledge_graph(input_path)

    if not kg_data:
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {input_path}ï¼Œè¯·å…ˆç”Ÿæˆå›¾è°± (å¦‚ result.json æˆ– top_citations_kg_*.json)")
    else:
        title = kg_data.get("paper_metadata", {}).get("title", "æœªçŸ¥")
        print("==============================================")
        print(f"ğŸ¤– çŸ¥è¯†å›¾è°± QA å·²å¯åŠ¨ (åŸºäº: {title})")
        print("å¯é—®ï¼š'è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä»€ä¹ˆæ¨¡å‹ï¼Ÿ'ã€'ä½¿ç”¨äº†å“ªä¸ªæ•°æ®é›†ï¼Ÿ'ã€'å¼•ç”¨äº†å“ªäº›è®ºæ–‡ï¼Ÿ'")
        print("è¾“å…¥ 'exit' é€€å‡º")
        print("==============================================")

        while True:
            try:
                query = input("\nğŸ™‹ è¯·æé—®: ").strip()
            except (EOFError, KeyboardInterrupt):
                break
            if query.lower() == "exit":
                break
            if not query:
                continue
            print("Thinking...")
            answer = graph_rag_qa(query, kg_data)
            print(f"ğŸ¤– å›ç­”: {answer}")