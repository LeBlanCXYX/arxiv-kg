<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Top Citations KG - Attention Is All You Need</title>
    <script src="echarts.min.js"></script>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        html, body { height: 100%; }
        body { background: #f5f5f5; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; }
        #main { width: 100%; height: 100%; min-height: 400px; }
        .panel {
            position: absolute; background: white; border-radius: 8px;
            box-shadow: 0 2px 12px rgba(0,0,0,0.1); padding: 20px; font-size: 14px; z-index: 999; max-width: 420px;
        }
        .header { top: 20px; left: 20px; }
        .stats { top: 20px; right: 20px; }
        .header h2 { margin-bottom: 10px; color: #333; }
        .header p { color: #666; margin: 5px 0; line-height: 1.5; }
        .stat-item { margin: 8px 0; }
        .stat-label { font-weight: bold; color: #333; }
        .stat-value { color: #0066cc; }
    </style>
</head>
<body>
    <div id="main"></div>
    <div class="panel header">
        <h2>üìÑ Attention Is All You Need</h2>
        <p><strong>‰ΩúËÄÖ:</strong> Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit</p>
        <p><strong>ÂèëË°®Êó•Êúü:</strong> 2017-06-12</p>
        <p><strong>ArXiv ID:</strong> <code>1706.03762</code></p>
    </div>
    <div class="panel stats">
        <div class="stat-item"><span class="stat-label">ËÆ∫ÊñáËäÇÁÇπ:</span> <span class="stat-value">92</span></div>
        <div class="stat-item"><span class="stat-label">Á†îÁ©∂ËÄÖËäÇÁÇπ:</span> <span class="stat-value">450</span></div>
        <div class="stat-item"><span class="stat-label">ÂÖ≥Á≥ªÊï∞:</span> <span class="stat-value">996</span></div>
        <div class="stat-item"><span class="stat-label">ÂºïÁî®ÁöÑËÆ∫Êñá (top N):</span> <span class="stat-value">10</span></div>
        <div class="stat-item"><span class="stat-label">Ë¢´ÂºïÁî®ÁöÑËÆ∫Êñá (top N):</span> <span class="stat-value">10</span></div>
    </div>
    <script type="text/javascript">
        function initChart() {
            if (typeof echarts === 'undefined') {
                document.getElementById('main').innerHTML = '<p style="padding:20px">Êó†Ê≥ïÂä†ËΩΩ EChartsÔºåËØ∑Ê£ÄÊü•ÁΩëÁªúÊàñ CDN„ÄÇ</p>';
                return;
            }
            var chartDom = document.getElementById('main');
            var myChart = echarts.init(chartDom);
            var option = {
                tooltip: { formatter: function(params) {
                    if (params.dataType === 'node') return params.name + ' (' + (params.value || '') + ')';
                    return (params.source && params.source.name) + ' ' + (params.value || '') + ' ' + (params.target && params.target.name);
                }},
                legend: { data: ["Researcher", "AIPaper", "AIModel", "Metric", "Dataset"] },
                series: [{
                    type: 'graph', layout: 'force',
                    data: [{"name": "Attention Is All You Need", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Deep Residual Learning for Image Recognition", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Adam: A Method for Stochastic Optimization", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Long Short-Term Memory", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Dropout: a simple way to prevent neural networks from overfitting", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Rethinking the Inception Architecture for Computer Vision", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Neural Machine Translation by Jointly Learning to Align and Translate", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Sequence to Sequence Learning with Neural Networks", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Xception: Deep Learning with Depthwise Separable Convolutions", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "A comprehensive review of recommender systems: Transitioning from theory to practice", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "CNC-VLM: An RLHF-optimized industrial large vision-language model with multimodal learning for imbalanced CNC fault detection", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "UAV-based quantitative crack measurement for bridges integrating four-point laser metric calibration and mamba segmentation", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "DiffusionEngine: Diffusion model is scalable data engine for object detection", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Enhanced Transformer-BiLSTM Deep Learning Framework for Day-Ahead Energy Price Forecasting", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Conditional Generative Adversarial Network-based framework for multi-feature uncertainty modeling in energy systems", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "CityVLM: Towards sustainable urban development via multi-view coordinated vision\u2013language model", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "FullPerception: Network-Level Collaborative Perception for Eliminating Vehicular Blind Spots", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "A survey of features used for representing black-box single-objective continuous optimization", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "ImageNet classification with deep convolutional neural networks", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Et al", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Microsoft COCO: Common Objects in Context", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Going deeper with convolutions", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "ImageNet Large Scale Visual Recognition Challenge", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Fully convolutional networks for semantic segmentation", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "WarmGait: Thermal Array-Based Gait Recognition for Privacy-Preserving Person Re-ID", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Noise Perception Self-Supervised Learning for Unsupervised Person Re-Identification", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Towards Reliable Tracking: An Uncertainty-Aware Siamese Tracker", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Bridging the gap, not forcing the tie: dual-space alignment and fusion framework for toxic memes detection", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Perturb and restore: Efficient category revocation in federated unlearning", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "DCM-Net: A novel dual-branch CNN-Mamba cross-layer feature fusion network for medical image segmentation", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "AdveDiffNet: adversarial diffusion network for unbalanced melanoma diagnosis", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Auto-Encoding Variational Bayes", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Supporting Online Material for Reducing the Dimensionality of Data with Neural Networks", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Speech recognition with deep recurrent neural networks", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Improving neural networks by preventing co-adaptation of feature detectors", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "ADADELTA: An Adaptive Learning Rate Method", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Learning Word Vectors for Sentiment Analysis", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "On the importance of initialization and momentum in deep learning", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Generating Sequences With Recurrent Neural Networks", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Weakly Supervised Image Dehazing via Physics-Based Decomposition", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "A Machine Learning Approach for Face Mask Detection System with AdamW Optimizer", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Probabilistic hierarchical interpolation and interpretable neural network configurations for flood prediction", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Generating an annual 30\u00a0m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Unveiling cross-modal consistency: Taming inter- and intra-modal noise for robust multi-modal knowledge graph completion", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Low-Resolution Massive MIMO Channel Estimation With LSTM Attention-Based CBDNet", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Quantum solver for single-impurity Anderson models with particle-hole symmetry", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Sentinel-1 SAR-based globally distributed co-seismic landslide detection by deep neural networks", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Increasing resolution and accuracy in sub-seasonal forecasting through 3D U-Net: the western US", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Distilling the Knowledge in a Neural Network", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Visualizing and Understanding Convolutional Networks", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "mHC: Manifold-Constrained Hyper-Connections", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Dataset Purification-Driven Lightweight Deep Learning Model Construction for Empty-Dish Recycling Robot", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Physics-guided deep neural networks for bathymetric mapping using Sentinel-2 multi-spectral imagery", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Spike Memory Transformer: An Energy-Efficient Model in Distributed Learning Framework for Autonomous Depression Detection", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Multi-Perspective Semantic Segmentation of Ground Penetrating Radar Images for Pavement Subsurface Objects", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "A comprehensive review of facial beauty prediction using deep learning techniques", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Seeing Before Reasoning: A Unified Framework for Generalizable and Explainable Fake Image Detection", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "DenseNet Model with Attention Mechanisms for Robust Date Fruit Image Classification", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Evaluation of deep learning models using explainable AI with qualitative and quantitative analysis for rice leaf disease detection", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Wind turbine blade surface defect detection model based on improved you only look once version 10 small and integrated compression", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Attention is All you Need", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "nuScenes: A Multimodal Dataset for Autonomous Driving", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "CARLA: An Open Urban Driving Simulator", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Adding Conditional Control to Text-to-Image Diffusion Models", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Scalable Diffusion Models with Transformers", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Domain randomization for transferring deep neural networks from simulation to the real world", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "The SYNTHIA Dataset: A Large Collection of Synthetic Images for Semantic Segmentation of Urban Scenes", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "OmniNWM: Omniscient Driving Navigation World Models", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "ConsisDrive: Identity-Preserving Driving World Models for Video Generation by Instance Mask", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "View-Consistent Diffusion Representations for 3D-Consistent Video Generation", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Fully Convolutional Networks for Semantic Segmentation", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Speech Recognition with Deep Recurrent Neural Networks", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "nuScenes: A multimodal dataset for autonomous driving", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "Ashish Vaswani", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Noam Shazeer", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Niki Parmar", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jakob Uszkoreit", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Llion Jones", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Aidan N. Gomez", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Lukasz Kaiser", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Illia Polosukhin", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Kaiming He", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Xiangyu Zhang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Shaoqing Ren", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jian Sun", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Diederik P. Kingma", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jimmy Ba", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Sepp Hochreiter", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "J. Schmidhuber", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Nitish Srivastava", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Geoffrey E. Hinton", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "A. Krizhevsky", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "I. Sutskever", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "R. Salakhutdinov", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Christian Szegedy", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Vincent Vanhoucke", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Sergey Ioffe", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jonathon Shlens", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zbigniew Wojna", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Dzmitry Bahdanau", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Kyunghyun Cho", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yoshua Bengio", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Bart van Merrienboer", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Caglar Gulcehre", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Fethi Bougares", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Holger Schwenk", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Ilya Sutskever", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Oriol Vinyals", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Quoc V. Le", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Fran\u00e7ois Chollet", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Junyoung Chung", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "KyungHyun Cho", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Shaina Raza", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Mizanur Rahman", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Safiullah Kamawal", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Armin Toroghi", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Ananya Raval", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "F. Navah", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Amirmohammad Kazemeini", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zhuoran Yang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Xi Guo", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Chenjing Ding", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Chiyu Wang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Wei Wu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yanyong Zhang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zisheng Wang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Junjie Chen", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Chisen Wang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Cong Peng", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jianping Xuan", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Tielin Shi", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Ming J. Zuo", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jinghuan Zhang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Wang Chen", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jian Zhang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Manlin Zhang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jie Wu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yuxi Ren", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jiahong Yang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Ming Li", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Andy J. Ma", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Abdullah Al Ahad Khan", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Md Habib Ullah", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Ruchira Tabassum", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Md Faisal Kabir", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Mojtaba Moradi\u2010Sepahvand", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Junjue Wang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Weihao Xuan", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Heli Qi", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zihang Chen", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Hongruixuan Chen", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zhuo Zheng", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Junshi Xia", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yanfei Zhong", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Naoto Yokoya", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Lin Liang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Guiyang Luo", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yijing Lin", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Lei Deng", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Nan Cheng", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Quan Yuan", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jinglin Li", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Dusit Niyato", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Gjorgjina Cenikj", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Ana Nikolikj", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "G. Petelin", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Niki van Stein", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Carola Doerr", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "T. Eftimov", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Karen Simonyan", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Andrew Zisserman", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "P. Cochat", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "L. Vaucoret", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "J. Sarles", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Ross Girshick", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Tsung-Yi Lin", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Michael Maire", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Serge Belongie", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Lubomir Bourdev", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "James Hays", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Pietro Perona", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Deva Ramanan", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "C. Lawrence Zitnick", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Piotr Doll\u00e1r", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Wei Liu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yangqing Jia", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Pierre Sermanet", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Scott Reed", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Dragomir Anguelov", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Dumitru Erhan", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Andrew Rabinovich", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Olga Russakovsky", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jia Deng", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Hao Su", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jonathan Krause", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Sanjeev Satheesh", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Sean Ma", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zhiheng Huang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Andrej Karpathy", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Aditya Khosla", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Michael Bernstein", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Alexander C. Berg", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Li Fei-Fei", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jonathan Long", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Evan Shelhamer", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Trevor Darrell", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yuqi Cheng", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yunkang Cao", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Haiming Yao", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Wei Luo", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Cheng Jiang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Hui Zhang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Weiming Shen", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Naveen Kumar Srinivasa", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Ajeet Rao Chalamala", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Kumar Singh", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Ieee Krishna Mohan Senior Member", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "K. Naveen", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Srinivasa Rao", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Ajeet Kumar Singh", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Hongbo Jiang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Lei Ye", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jingyang Hu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Xiaotian Chen", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Siyu Chen", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Wei Zhang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Kehua Yang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jingya Wang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jianfeng Wen", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Weiping Ding", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Chunlin Yu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Xiatian Zhu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zhiyong Wang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jie Ma", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Xiangyuan Lan", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Qihua Liang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Guorong Li", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zhiyi Mo", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Bineng Zhong", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yulin Lei", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jin Yang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Huijia Liang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Tianrui Li", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Ning Pang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zou Li", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Pengcheng Wan", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Hongchao Wu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yuchen Bing", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Xiang Zhao", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yanling Liu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Hongmin Deng", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jinghao Fu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yu Fu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Chao Liu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Shaoqiang Wang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Hui Xia", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Diederik P Kingma", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Max Welling", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "John C. Duchi", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Elad Hazan", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Y. Singer", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Alex Graves", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Abdel-rahman Mohamed", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Geoffrey Hinton", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Alex Krizhevsky", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Ruslan R. Salakhutdinov", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Matthew D. Zeiler", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Andrew L. Maas", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Raymond E. Daly", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Peter T. Pham", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Dan Huang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "A. Ng", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Christopher Potts", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "James Martens", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "George E. Dahl", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Nian Wang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zhigao Cui", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yanzhao Su", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yunwei Lan", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yuanliang Xue", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Cong Zhang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Aihua Li", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Leong Kah Meng", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Ho Hooi Yi", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Ng Bo Wei", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Lim Jia Xin", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zailan Arabee Abdul Salam", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Xin Cheng", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Wangding Zeng", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Damai Dai", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Qinyu Chen", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Bingxuan Wang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zhenda Xie", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Kezhao Huang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Xingkai Yu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zhewen Hao", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yukun Li", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Han Zhang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Huishuai Zhang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Dongyan Zhao", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Wenfeng Liang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Mostafa Saberian", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Vidya Samadi", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Ioana Popescu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Husheng Fang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Shunlin Liang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Wenyuan Li", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yongzhe Chen", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Han Ma", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jianglei Xu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yichuan Ma", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Tao He", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Feng Tian", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Fengjiao Zhang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Hui Liang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Bin Chen", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Hanting Shen", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zhangtao Cheng", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Xueting Liu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Ting Zhong", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Fan Zhou", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "I. Helmy", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Wooyeol Choi", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Mariia Karabin", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Tanvir Sohail", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Dmytro Bykov", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Eduardo Antonio Coello P\u00e9rez", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Swarnava Ghosh", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Murali Gopalakrishnan Meena", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Seongmin Kim", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Amir Shehata", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "In-Saeng Suh", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Hanna Terletska", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Markus Eisenbach", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Lorenzo Nava", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "A. Mondini", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Kushanav Bhuyan", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Chengyong Fang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Oriol Monserrat", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "A. Novellino", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Filippo Catani", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jihun Ryu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Hisu Kim", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Simon Wang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jin-Ho Yoon", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Andrew G. Howard", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Menglong Zhu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Bo Chen", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Dmitry Kalenichenko", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Weijun Wang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Tobias Weyand", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Marco Andreetto", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Hartwig Adam", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jeff Dean", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Matthew D Zeiler", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Rob Fergus", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yixuan Wei", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Huanqi Cao", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Chenggang Zhao", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Chengqi Deng", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jiashi Li", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Huazuo Gao", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jiang Chang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Kuai Yu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Liang Zhao", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Shangyan Zhou", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zhean Xu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zhengyan Zhang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Shengding Hu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yuqing Wang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jingyang Yuan", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Lean Wang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yifei Ge", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zhuo Li", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Xuebin Yue", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Hengyi Li", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Lin Meng", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Shuo Qian", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yingying Chen", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Wei Wang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Gaowei Zhang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Lei Li", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zengzhou Hao", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yi Wang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Minqiang Yang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yueze Liu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yongfeng Tao", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Bin Hu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Sibo Huang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Guijie Zhu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jiaming Tang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Weixiong Li", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zhun Fan", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "D. E. Boukhari", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "F. Dornaika", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "A. Chemsa", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Abdelmalik Taleb-Ahmed", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Kaiqing Lin", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zhiyuan Yan", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Ruoxin Chen", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Junyan Ye", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Ke-Yue Zhang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yue Zhou", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Peng Jin", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Bin Li", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Taiping Yao", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Shouhong Ding", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Esraa Hassan", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Sarah Abu Ghazalah", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Nora El-Rashidy", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Tarek Abd El-Hafeez", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Mahmoud Y. Shams", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Hari Kishan Kondaveeti", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Chinna Gopi Simhadri", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Hang Liu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Sheng Liu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zhijian Liu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Ben Niu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jing Xie", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Chi Luo", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zhiyu Shi", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Colin Raffel", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Adam Roberts", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Katherine Lee", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Sharan Narang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Michael Matena", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yanqi Zhou", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Wei Li", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Peter J. Liu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "M. Heusel", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Hubert Ramsauer", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Thomas Unterthiner", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Bernhard Nessler", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Holger Caesar", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Varun Bankiti", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Alex H. Lang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Sourabh Vora", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Venice Erin Liong", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Qiang Xu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Anush Krishnan", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yu Pan", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Giancarlo Baldan", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Oscar Beijbom", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Alexey Dosovitskiy", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "German Ros", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Felipe Codevilla", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Antonio Lopez", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Vladlen Koltun", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Lvmin Zhang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Anyi Rao", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Maneesh Agrawala", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "William Peebles", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Saining Xie", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Dustin Podell", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zion English", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Kyle Lacey", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Andreas Blattmann", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Tim Dockhorn", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jonas M\u00fcller", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Joe Penna", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Robin Rombach", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Josh Tobin", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Rachel Fong", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Alex Ray", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jonas Schneider", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Wojciech Zaremba", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Pieter Abbeel", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "G. Ros", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Laura Sellart", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Joanna Materzynska", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "David V\u00e1zquez", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Antonio M. L\u00f3pez", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Fachrina Dewi Puspitasari", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Chaoning Zhang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Joseph Cho", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Adnan Haider", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Noor Ul Eman", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Omer Amin", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Alexis Mankowski", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Muhammad Umair", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Jingyao Zheng", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Sheng Zheng", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Lik-Hang Lee", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Caiyan Qin", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Tae-Ho Kim", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Choong Seon Hong", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yang Yang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Heng Tao Shen", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Bohan Li", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zhuang Ma", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Dalong Du", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Baorui Peng", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zhujin Liang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zhenqiang Liu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Chao Ma", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yueming Jin", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Hao Zhao", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Wenjun Zeng", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Xin Jin", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Guosheng Zhao", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yaozeng Wang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Xiaofeng Wang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zheng Zhu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Tingdong Yu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Guan Huang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Yongchen Zai", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Ji Jiao", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Changliang Xue", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Xiaole Wang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Zhen Yang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Futang Zhu", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Xingang Wang", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Ahmad Rahimi", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Valentin Gerard", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Eloi Zablocki", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Matthieu Cord", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Alexandre Alahi", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Duolikun Danier", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Ge Gao", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Steven McDonagh", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Changjian Li", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Hakan Bilen", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Oisin Mac Aodha", "category": 0, "symbolSize": 25, "draggable": true, "value": "Researcher"}, {"name": "Transformer", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "WMT 2014 English-to-German translation task", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "WMT 2014 English-to-French translation task", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "BLEU", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "residual learning framework", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "VGG nets", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "ImageNet", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "CIFAR-10", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "COCO object detection dataset", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "error", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "relative improvement", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "Adam", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "AdaMax", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Dropout", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "neural networks", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Inception Architecture", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "ILSVRC 2012 classification challenge validation set", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "top-1 error", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "top-5 error", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "encoder-decoder", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "phrase-based system", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "English-to-French translation", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "translation performance", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "RNN Encoder-Decoder", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "statistical machine translation system", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "log-linear model", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "LSTM", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "phrase-based SMT system", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "WMT'14 dataset", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Xception", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Inception V3", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "larger image classification dataset comprising 350 million images and 17,000 classes", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "long short-term memory (LSTM)", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "gated recurrent unit (GRU)", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "tanh units", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "polyphonic music modeling", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "speech signal modeling", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "InstaDrive", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Instance Flow Guider", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Spatial Geometric Aligner", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "nuScenes", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "CARLA", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "video generation quality", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "safety evaluation", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "CNC-VLM", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "CNC fault detection dataset", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Accuracy", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "F1-score", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "mamba segmentation", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "four-point laser metric calibration", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "DiffusionEngine", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Transformer and Bidirectional Long Short-Term Memory (BiLSTM) model", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "New York Independent System Operator", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "MAE", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "RMSE", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "sMAPE", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "MAPE", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "R\u00b2", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "Conditional Generative Adversarial Network", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "CityVLM", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "FullPerception", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Proactive Conflict-free Scheduling (PCS)", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "single-vehicle systems", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "existing scheduling methods", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "large-scale comprehensive joint simulation experiments", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "perception accuracy", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "deep convolutional neural networks", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "ConvNet models", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "ImageNet Challenge 2014", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "other datasets", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "accuracy", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "Region Proposal Network (RPN)", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "SPPnet", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Fast R-CNN", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "VGG-16", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "PASCAL VOC 2007", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "PASCAL VOC 2012", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "MS COCO", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "ILSVRC", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "COCO 2015", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "object detection accuracy", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "PASCAL", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "SUN", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Deformable Parts Model", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "bounding box detection", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "segmentation detection", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "Inception", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "GoogLeNet", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014)", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Batch Normalization", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "top-5 validation error", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "test error", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "object category classification", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "object detection", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "human accuracy", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "fully convolutional networks", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "AlexNet", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "VGG net", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "PASCAL VOC", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "NYUDv2", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "SIFT Flow", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "mean IU", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "FLOT", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "GTSRB", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "KBTS", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "CIFAR10", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "EMNIST", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "scalability", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "WarmGait", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Taylor Finite Difference (TFD)", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "thermal array sensors", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "average recognition accuracy", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "NPSSL", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Duke dataset", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Unsupervised Domain Adaptation", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Noise Perception Self-Paced Learning", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Uncertainty-Aware Siamese Network", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "VOT2018", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "VOT2019", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "OTB100", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "NFS", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "UAV123", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "LaSOT", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "TrackingNet", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Got-10 k", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "dual-space alignment and fusion framework", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "DCM-Net", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "AdveDiffNet", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "stochastic variational inference and learning algorithm", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "reparameterization of the variational lower bound", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "approximate inference model", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "i.i.d. datasets", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "variational lower bound", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "Recurrent neural networks (RNNs)", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Connectionist Temporal Classification", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Long Short-term Memory RNN", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "deep recurrent neural networks", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "deep Long Short-term Memory RNNs", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "deep feedforward networks", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "TIMIT phoneme recognition benchmark", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "test set error", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "feedforward neural network", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "dropout", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "small training set", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "held-out test data", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "speech recognition", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "object recognition", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "ADADELTA", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "MNIST digit classification task", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "large scale voice dataset", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Word Vectors", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Sentiment Analysis", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Long Short-term Memory recurrent neural networks", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "text", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "online handwriting", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "PBD", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "GAN", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "DWD", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "seven benchmarks", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "reconstruction loss", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "AdamW", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "face mask detection model", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Engram", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Mixture-of-Experts (MoE)", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "MMLU", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "CMMLU", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "BBH", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "ARC-Challenge", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "HumanEval", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "MATH", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Multi-Query NIAH", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Neural Hierarchical Interpolation for Time Series Forecasting (N-HiTS)", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Network-Based Expansion Analysis for Interpretable Time Series Forecasting (N-BEATS)", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "two headwater streams in Georgia and North Carolina, USA", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Multi-Quantile Loss", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "95th percentile prediction uncertainty (95 PPU)", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "Generating an annual 30 m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "category": 1, "symbolSize": 50, "draggable": true, "value": "AIPaper"}, {"name": "NASA-IBM geospatial foundation model", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "harmonized Landsat and Sentinel-2 data", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "LA-CBDNet", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "benchmark approaches", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "comparative methods", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "one-bit received signals", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "varying SNRs", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "different pilot lengths", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "number of users", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "variational quantum eigensolver (VQE)", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Anderson impurity model (AIM)", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "density of states (DOS)", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "quantum-computed moment (QCM)", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "impurity Green's function", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "Deep Neural Networks", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Sentinel-1 backscatter data", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "11 earthquake-induced widespread landslide events", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Haiti (2021) and Sumatra (2022) events", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "3D U-Net", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "NWP models", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "ECMWF ensemble forecasting system", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "PRISM data", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "pattern correlation coefficient", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "MobileNets", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "ensemble of models", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "single model", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "specialist models", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "MNIST", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "acoustic model", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Krizhevsky et al.", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Caltech-101", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Caltech-256", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "ImageNet classification benchmark", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "state-of-the-art results", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "Hyper-Connections (HC)", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Manifold-Constrained Hyper-Connections (mHC)", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "OGNet", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "YOLO-OG", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Dish-10", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Dish-20", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "mean Average Precision (mAP)", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "HybridBathNet", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "UNet", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "physical bathymetry network", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "state-of-the-art methods", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Sentinel-2 multi-spectral imagery", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "diverse island regions", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "bathymetric inversion accuracy", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "generalization capability", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "spike memory transformer (SMT)", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Computation-Oriented Hierarchical Depression Detection Internet of Things (IoT) Framework", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "classical deep learning methods", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "D-Vlog dataset", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "inference power consumption", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "AttnGPRNet", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "multi-view dataset using 3D GPR scans from over 100 kilometers of urban roads", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "mIoU", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "F1 score", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "Forensic-Chat", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "ExplainFake-Bench", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "multimodal large language models (MLLMs)", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "generalization", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "explainability", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "DenseNet with Attention Mechanisms", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Date Fruit Image Dataset", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Classification Accuracy", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "ResNet50", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "InceptionResNetV2", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "DenseNet 201", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "InceptionV3", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "EfficientNetB0", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "VGG16", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Local Interpretable Model-agnostic Explanations (LIME)", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "rice leaf disease detection dataset", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "classification accuracy", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "precision", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "recall", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "Intersection over Union (IoU)", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "Dice Similarity Coefficient (DSC)", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "overfitting ratio", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "improved you only look once version 10 small and integrated compression", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "T5", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Colossal Clean Crawled Corpus", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "summarization", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "question answering", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "text classification", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "Two Time-Scale Update Rule", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "GANs", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "KITTI", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "3D detection and tracking metrics", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "classic modular pipeline", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "end-to-end model trained via imitation learning", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "end-to-end model trained via reinforcement learning", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "metrics provided by CARLA", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "ControlNet", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Stable Diffusion", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "small (<50k) and large (>1m) datasets", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Diffusion Transformers (DiTs)", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "DiT-XL/2", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "U-Net", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "ImageNet 512x512", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "ImageNet 256x256", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "FID", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "Gflops", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "SDXL", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "refinement model", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "deep neural network", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "simulated images", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "real images", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "object localization", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "object detector", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "simulator with non-realistic random textures", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "grasping in a cluttered environment", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "SYNTHIA", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Sora", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "OmniNWM", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Existing models", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "panoramic videos", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "video generation", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "control accuracy", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "long-horizon stability", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "ConsisDrive", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Instance-Masked Attention", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Instance-Masked Loss", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "driving video generation quality", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "UniDriveDreamer", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "LiDAR-specific variational autoencoder (VAE)", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "video VAE", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "diffusion transformer", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Unified Latent Anchoring (ULA)", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "previous state-of-the-art methods", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "multi-camera video", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "LiDAR sequence", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "LiDAR generation", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "MAD-LTX", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "SVD", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "LTX", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "video diffusion models", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "driving world models", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "autonomous driving", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "driving domains", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "structured motion", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "physical and social plausibility", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "compute", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "ViCoDR", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "camera-controlled video diffusion models", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "camera controlled image-to-video, text-to-video, and multi-view generation models", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Fully Convolutional Networks", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "Recurrent neural networks", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "KITTI dataset", "category": 4, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "novel 3D detection and tracking metrics", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}, {"name": "lidar based detection and tracking", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "image based detection and tracking", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "domain randomization", "category": 2, "symbolSize": 25, "draggable": true, "value": "AIModel"}, {"name": "grasping", "category": 3, "symbolSize": 25, "draggable": true, "value": "Metric"}],
                    links: [{"source": "Ashish Vaswani", "target": "Attention Is All You Need", "value": "author_of"}, {"source": "Noam Shazeer", "target": "Attention Is All You Need", "value": "author_of"}, {"source": "Niki Parmar", "target": "Attention Is All You Need", "value": "author_of"}, {"source": "Jakob Uszkoreit", "target": "Attention Is All You Need", "value": "author_of"}, {"source": "Llion Jones", "target": "Attention Is All You Need", "value": "author_of"}, {"source": "Aidan N. Gomez", "target": "Attention Is All You Need", "value": "author_of"}, {"source": "Lukasz Kaiser", "target": "Attention Is All You Need", "value": "author_of"}, {"source": "Illia Polosukhin", "target": "Attention Is All You Need", "value": "author_of"}, {"source": "Kaiming He", "target": "Deep Residual Learning for Image Recognition", "value": "author_of"}, {"source": "Xiangyu Zhang", "target": "Deep Residual Learning for Image Recognition", "value": "author_of"}, {"source": "Shaoqing Ren", "target": "Deep Residual Learning for Image Recognition", "value": "author_of"}, {"source": "Jian Sun", "target": "Deep Residual Learning for Image Recognition", "value": "author_of"}, {"source": "Diederik P. Kingma", "target": "Adam: A Method for Stochastic Optimization", "value": "author_of"}, {"source": "Jimmy Ba", "target": "Adam: A Method for Stochastic Optimization", "value": "author_of"}, {"source": "Sepp Hochreiter", "target": "Long Short-Term Memory", "value": "author_of"}, {"source": "J. Schmidhuber", "target": "Long Short-Term Memory", "value": "author_of"}, {"source": "Nitish Srivastava", "target": "Dropout: a simple way to prevent neural networks from overfitting", "value": "author_of"}, {"source": "Geoffrey E. Hinton", "target": "Dropout: a simple way to prevent neural networks from overfitting", "value": "author_of"}, {"source": "A. Krizhevsky", "target": "Dropout: a simple way to prevent neural networks from overfitting", "value": "author_of"}, {"source": "I. Sutskever", "target": "Dropout: a simple way to prevent neural networks from overfitting", "value": "author_of"}, {"source": "R. Salakhutdinov", "target": "Dropout: a simple way to prevent neural networks from overfitting", "value": "author_of"}, {"source": "Christian Szegedy", "target": "Rethinking the Inception Architecture for Computer Vision", "value": "author_of"}, {"source": "Vincent Vanhoucke", "target": "Rethinking the Inception Architecture for Computer Vision", "value": "author_of"}, {"source": "Sergey Ioffe", "target": "Rethinking the Inception Architecture for Computer Vision", "value": "author_of"}, {"source": "Jonathon Shlens", "target": "Rethinking the Inception Architecture for Computer Vision", "value": "author_of"}, {"source": "Zbigniew Wojna", "target": "Rethinking the Inception Architecture for Computer Vision", "value": "author_of"}, {"source": "Dzmitry Bahdanau", "target": "Neural Machine Translation by Jointly Learning to Align and Translate", "value": "author_of"}, {"source": "Kyunghyun Cho", "target": "Neural Machine Translation by Jointly Learning to Align and Translate", "value": "author_of"}, {"source": "Yoshua Bengio", "target": "Neural Machine Translation by Jointly Learning to Align and Translate", "value": "author_of"}, {"source": "Kyunghyun Cho", "target": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation", "value": "author_of"}, {"source": "Bart van Merrienboer", "target": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation", "value": "author_of"}, {"source": "Caglar Gulcehre", "target": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation", "value": "author_of"}, {"source": "Dzmitry Bahdanau", "target": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation", "value": "author_of"}, {"source": "Fethi Bougares", "target": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation", "value": "author_of"}, {"source": "Holger Schwenk", "target": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation", "value": "author_of"}, {"source": "Yoshua Bengio", "target": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation", "value": "author_of"}, {"source": "Ilya Sutskever", "target": "Sequence to Sequence Learning with Neural Networks", "value": "author_of"}, {"source": "Oriol Vinyals", "target": "Sequence to Sequence Learning with Neural Networks", "value": "author_of"}, {"source": "Quoc V. Le", "target": "Sequence to Sequence Learning with Neural Networks", "value": "author_of"}, {"source": "Fran\u00e7ois Chollet", "target": "Xception: Deep Learning with Depthwise Separable Convolutions", "value": "author_of"}, {"source": "Junyoung Chung", "target": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling", "value": "author_of"}, {"source": "Caglar Gulcehre", "target": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling", "value": "author_of"}, {"source": "KyungHyun Cho", "target": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling", "value": "author_of"}, {"source": "Yoshua Bengio", "target": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling", "value": "author_of"}, {"source": "Shaina Raza", "target": "A comprehensive review of recommender systems: Transitioning from theory to practice", "value": "author_of"}, {"source": "Mizanur Rahman", "target": "A comprehensive review of recommender systems: Transitioning from theory to practice", "value": "author_of"}, {"source": "Safiullah Kamawal", "target": "A comprehensive review of recommender systems: Transitioning from theory to practice", "value": "author_of"}, {"source": "Armin Toroghi", "target": "A comprehensive review of recommender systems: Transitioning from theory to practice", "value": "author_of"}, {"source": "Ananya Raval", "target": "A comprehensive review of recommender systems: Transitioning from theory to practice", "value": "author_of"}, {"source": "F. Navah", "target": "A comprehensive review of recommender systems: Transitioning from theory to practice", "value": "author_of"}, {"source": "Amirmohammad Kazemeini", "target": "A comprehensive review of recommender systems: Transitioning from theory to practice", "value": "author_of"}, {"source": "Zhuoran Yang", "target": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "value": "author_of"}, {"source": "Xi Guo", "target": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "value": "author_of"}, {"source": "Chenjing Ding", "target": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "value": "author_of"}, {"source": "Chiyu Wang", "target": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "value": "author_of"}, {"source": "Wei Wu", "target": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "value": "author_of"}, {"source": "Yanyong Zhang", "target": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "value": "author_of"}, {"source": "Zisheng Wang", "target": "CNC-VLM: An RLHF-optimized industrial large vision-language model with multimodal learning for imbalanced CNC fault detection", "value": "author_of"}, {"source": "Junjie Chen", "target": "CNC-VLM: An RLHF-optimized industrial large vision-language model with multimodal learning for imbalanced CNC fault detection", "value": "author_of"}, {"source": "Chisen Wang", "target": "CNC-VLM: An RLHF-optimized industrial large vision-language model with multimodal learning for imbalanced CNC fault detection", "value": "author_of"}, {"source": "Cong Peng", "target": "CNC-VLM: An RLHF-optimized industrial large vision-language model with multimodal learning for imbalanced CNC fault detection", "value": "author_of"}, {"source": "Jianping Xuan", "target": "CNC-VLM: An RLHF-optimized industrial large vision-language model with multimodal learning for imbalanced CNC fault detection", "value": "author_of"}, {"source": "Tielin Shi", "target": "CNC-VLM: An RLHF-optimized industrial large vision-language model with multimodal learning for imbalanced CNC fault detection", "value": "author_of"}, {"source": "Ming J. Zuo", "target": "CNC-VLM: An RLHF-optimized industrial large vision-language model with multimodal learning for imbalanced CNC fault detection", "value": "author_of"}, {"source": "Jinghuan Zhang", "target": "UAV-based quantitative crack measurement for bridges integrating four-point laser metric calibration and mamba segmentation", "value": "author_of"}, {"source": "Wang Chen", "target": "UAV-based quantitative crack measurement for bridges integrating four-point laser metric calibration and mamba segmentation", "value": "author_of"}, {"source": "Jian Zhang", "target": "UAV-based quantitative crack measurement for bridges integrating four-point laser metric calibration and mamba segmentation", "value": "author_of"}, {"source": "Manlin Zhang", "target": "DiffusionEngine: Diffusion model is scalable data engine for object detection", "value": "author_of"}, {"source": "Jie Wu", "target": "DiffusionEngine: Diffusion model is scalable data engine for object detection", "value": "author_of"}, {"source": "Yuxi Ren", "target": "DiffusionEngine: Diffusion model is scalable data engine for object detection", "value": "author_of"}, {"source": "Jiahong Yang", "target": "DiffusionEngine: Diffusion model is scalable data engine for object detection", "value": "author_of"}, {"source": "Ming Li", "target": "DiffusionEngine: Diffusion model is scalable data engine for object detection", "value": "author_of"}, {"source": "Andy J. Ma", "target": "DiffusionEngine: Diffusion model is scalable data engine for object detection", "value": "author_of"}, {"source": "Abdullah Al Ahad Khan", "target": "Enhanced Transformer-BiLSTM Deep Learning Framework for Day-Ahead Energy Price Forecasting", "value": "author_of"}, {"source": "Md Habib Ullah", "target": "Enhanced Transformer-BiLSTM Deep Learning Framework for Day-Ahead Energy Price Forecasting", "value": "author_of"}, {"source": "Ruchira Tabassum", "target": "Enhanced Transformer-BiLSTM Deep Learning Framework for Day-Ahead Energy Price Forecasting", "value": "author_of"}, {"source": "Md Faisal Kabir", "target": "Enhanced Transformer-BiLSTM Deep Learning Framework for Day-Ahead Energy Price Forecasting", "value": "author_of"}, {"source": "Mojtaba Moradi\u2010Sepahvand", "target": "Conditional Generative Adversarial Network-based framework for multi-feature uncertainty modeling in energy systems", "value": "author_of"}, {"source": "Junjue Wang", "target": "CityVLM: Towards sustainable urban development via multi-view coordinated vision\u2013language model", "value": "author_of"}, {"source": "Weihao Xuan", "target": "CityVLM: Towards sustainable urban development via multi-view coordinated vision\u2013language model", "value": "author_of"}, {"source": "Heli Qi", "target": "CityVLM: Towards sustainable urban development via multi-view coordinated vision\u2013language model", "value": "author_of"}, {"source": "Zihang Chen", "target": "CityVLM: Towards sustainable urban development via multi-view coordinated vision\u2013language model", "value": "author_of"}, {"source": "Hongruixuan Chen", "target": "CityVLM: Towards sustainable urban development via multi-view coordinated vision\u2013language model", "value": "author_of"}, {"source": "Zhuo Zheng", "target": "CityVLM: Towards sustainable urban development via multi-view coordinated vision\u2013language model", "value": "author_of"}, {"source": "Junshi Xia", "target": "CityVLM: Towards sustainable urban development via multi-view coordinated vision\u2013language model", "value": "author_of"}, {"source": "Yanfei Zhong", "target": "CityVLM: Towards sustainable urban development via multi-view coordinated vision\u2013language model", "value": "author_of"}, {"source": "Naoto Yokoya", "target": "CityVLM: Towards sustainable urban development via multi-view coordinated vision\u2013language model", "value": "author_of"}, {"source": "Lin Liang", "target": "FullPerception: Network-Level Collaborative Perception for Eliminating Vehicular Blind Spots", "value": "author_of"}, {"source": "Guiyang Luo", "target": "FullPerception: Network-Level Collaborative Perception for Eliminating Vehicular Blind Spots", "value": "author_of"}, {"source": "Yijing Lin", "target": "FullPerception: Network-Level Collaborative Perception for Eliminating Vehicular Blind Spots", "value": "author_of"}, {"source": "Lei Deng", "target": "FullPerception: Network-Level Collaborative Perception for Eliminating Vehicular Blind Spots", "value": "author_of"}, {"source": "Nan Cheng", "target": "FullPerception: Network-Level Collaborative Perception for Eliminating Vehicular Blind Spots", "value": "author_of"}, {"source": "Quan Yuan", "target": "FullPerception: Network-Level Collaborative Perception for Eliminating Vehicular Blind Spots", "value": "author_of"}, {"source": "Jinglin Li", "target": "FullPerception: Network-Level Collaborative Perception for Eliminating Vehicular Blind Spots", "value": "author_of"}, {"source": "Dusit Niyato", "target": "FullPerception: Network-Level Collaborative Perception for Eliminating Vehicular Blind Spots", "value": "author_of"}, {"source": "Gjorgjina Cenikj", "target": "A survey of features used for representing black-box single-objective continuous optimization", "value": "author_of"}, {"source": "Ana Nikolikj", "target": "A survey of features used for representing black-box single-objective continuous optimization", "value": "author_of"}, {"source": "G. Petelin", "target": "A survey of features used for representing black-box single-objective continuous optimization", "value": "author_of"}, {"source": "Niki van Stein", "target": "A survey of features used for representing black-box single-objective continuous optimization", "value": "author_of"}, {"source": "Carola Doerr", "target": "A survey of features used for representing black-box single-objective continuous optimization", "value": "author_of"}, {"source": "T. Eftimov", "target": "A survey of features used for representing black-box single-objective continuous optimization", "value": "author_of"}, {"source": "A. Krizhevsky", "target": "ImageNet classification with deep convolutional neural networks", "value": "author_of"}, {"source": "I. Sutskever", "target": "ImageNet classification with deep convolutional neural networks", "value": "author_of"}, {"source": "Geoffrey E. Hinton", "target": "ImageNet classification with deep convolutional neural networks", "value": "author_of"}, {"source": "Karen Simonyan", "target": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "value": "author_of"}, {"source": "Andrew Zisserman", "target": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "value": "author_of"}, {"source": "P. Cochat", "target": "Et al", "value": "author_of"}, {"source": "L. Vaucoret", "target": "Et al", "value": "author_of"}, {"source": "J. Sarles", "target": "Et al", "value": "author_of"}, {"source": "Shaoqing Ren", "target": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "value": "author_of"}, {"source": "Kaiming He", "target": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "value": "author_of"}, {"source": "Ross Girshick", "target": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "value": "author_of"}, {"source": "Jian Sun", "target": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "value": "author_of"}, {"source": "Tsung-Yi Lin", "target": "Microsoft COCO: Common Objects in Context", "value": "author_of"}, {"source": "Michael Maire", "target": "Microsoft COCO: Common Objects in Context", "value": "author_of"}, {"source": "Serge Belongie", "target": "Microsoft COCO: Common Objects in Context", "value": "author_of"}, {"source": "Lubomir Bourdev", "target": "Microsoft COCO: Common Objects in Context", "value": "author_of"}, {"source": "Ross Girshick", "target": "Microsoft COCO: Common Objects in Context", "value": "author_of"}, {"source": "James Hays", "target": "Microsoft COCO: Common Objects in Context", "value": "author_of"}, {"source": "Pietro Perona", "target": "Microsoft COCO: Common Objects in Context", "value": "author_of"}, {"source": "Deva Ramanan", "target": "Microsoft COCO: Common Objects in Context", "value": "author_of"}, {"source": "C. Lawrence Zitnick", "target": "Microsoft COCO: Common Objects in Context", "value": "author_of"}, {"source": "Piotr Doll\u00e1r", "target": "Microsoft COCO: Common Objects in Context", "value": "author_of"}, {"source": "Christian Szegedy", "target": "Going deeper with convolutions", "value": "author_of"}, {"source": "Wei Liu", "target": "Going deeper with convolutions", "value": "author_of"}, {"source": "Yangqing Jia", "target": "Going deeper with convolutions", "value": "author_of"}, {"source": "Pierre Sermanet", "target": "Going deeper with convolutions", "value": "author_of"}, {"source": "Scott Reed", "target": "Going deeper with convolutions", "value": "author_of"}, {"source": "Dragomir Anguelov", "target": "Going deeper with convolutions", "value": "author_of"}, {"source": "Dumitru Erhan", "target": "Going deeper with convolutions", "value": "author_of"}, {"source": "Vincent Vanhoucke", "target": "Going deeper with convolutions", "value": "author_of"}, {"source": "Andrew Rabinovich", "target": "Going deeper with convolutions", "value": "author_of"}, {"source": "Sergey Ioffe", "target": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "value": "author_of"}, {"source": "Christian Szegedy", "target": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "value": "author_of"}, {"source": "Olga Russakovsky", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "author_of"}, {"source": "Jia Deng", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "author_of"}, {"source": "Hao Su", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "author_of"}, {"source": "Jonathan Krause", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "author_of"}, {"source": "Sanjeev Satheesh", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "author_of"}, {"source": "Sean Ma", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "author_of"}, {"source": "Zhiheng Huang", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "author_of"}, {"source": "Andrej Karpathy", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "author_of"}, {"source": "Aditya Khosla", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "author_of"}, {"source": "Michael Bernstein", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "author_of"}, {"source": "Alexander C. Berg", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "author_of"}, {"source": "Li Fei-Fei", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "author_of"}, {"source": "Jonathan Long", "target": "Fully convolutional networks for semantic segmentation", "value": "author_of"}, {"source": "Evan Shelhamer", "target": "Fully convolutional networks for semantic segmentation", "value": "author_of"}, {"source": "Trevor Darrell", "target": "Fully convolutional networks for semantic segmentation", "value": "author_of"}, {"source": "Yuqi Cheng", "target": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects", "value": "author_of"}, {"source": "Yunkang Cao", "target": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects", "value": "author_of"}, {"source": "Haiming Yao", "target": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects", "value": "author_of"}, {"source": "Wei Luo", "target": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects", "value": "author_of"}, {"source": "Cheng Jiang", "target": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects", "value": "author_of"}, {"source": "Hui Zhang", "target": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects", "value": "author_of"}, {"source": "Weiming Shen", "target": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects", "value": "author_of"}, {"source": "Naveen Kumar Srinivasa", "target": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning", "value": "author_of"}, {"source": "Ajeet Rao Chalamala", "target": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning", "value": "author_of"}, {"source": "Kumar Singh", "target": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning", "value": "author_of"}, {"source": "Ieee Krishna Mohan Senior Member", "target": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning", "value": "author_of"}, {"source": "K. Naveen", "target": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning", "value": "author_of"}, {"source": "Srinivasa Rao", "target": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning", "value": "author_of"}, {"source": "Ajeet Kumar Singh", "target": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning", "value": "author_of"}, {"source": "Hongbo Jiang", "target": "WarmGait: Thermal Array-Based Gait Recognition for Privacy-Preserving Person Re-ID", "value": "author_of"}, {"source": "Lei Ye", "target": "WarmGait: Thermal Array-Based Gait Recognition for Privacy-Preserving Person Re-ID", "value": "author_of"}, {"source": "Jingyang Hu", "target": "WarmGait: Thermal Array-Based Gait Recognition for Privacy-Preserving Person Re-ID", "value": "author_of"}, {"source": "Xiaotian Chen", "target": "WarmGait: Thermal Array-Based Gait Recognition for Privacy-Preserving Person Re-ID", "value": "author_of"}, {"source": "Siyu Chen", "target": "WarmGait: Thermal Array-Based Gait Recognition for Privacy-Preserving Person Re-ID", "value": "author_of"}, {"source": "Wei Zhang", "target": "WarmGait: Thermal Array-Based Gait Recognition for Privacy-Preserving Person Re-ID", "value": "author_of"}, {"source": "Kehua Yang", "target": "WarmGait: Thermal Array-Based Gait Recognition for Privacy-Preserving Person Re-ID", "value": "author_of"}, {"source": "Jingya Wang", "target": "Noise Perception Self-Supervised Learning for Unsupervised Person Re-Identification", "value": "author_of"}, {"source": "Jianfeng Wen", "target": "Noise Perception Self-Supervised Learning for Unsupervised Person Re-Identification", "value": "author_of"}, {"source": "Weiping Ding", "target": "Noise Perception Self-Supervised Learning for Unsupervised Person Re-Identification", "value": "author_of"}, {"source": "Chunlin Yu", "target": "Noise Perception Self-Supervised Learning for Unsupervised Person Re-Identification", "value": "author_of"}, {"source": "Xiatian Zhu", "target": "Noise Perception Self-Supervised Learning for Unsupervised Person Re-Identification", "value": "author_of"}, {"source": "Zhiyong Wang", "target": "Noise Perception Self-Supervised Learning for Unsupervised Person Re-Identification", "value": "author_of"}, {"source": "Jie Ma", "target": "Towards Reliable Tracking: An Uncertainty-Aware Siamese Tracker", "value": "author_of"}, {"source": "Xiangyuan Lan", "target": "Towards Reliable Tracking: An Uncertainty-Aware Siamese Tracker", "value": "author_of"}, {"source": "Qihua Liang", "target": "Towards Reliable Tracking: An Uncertainty-Aware Siamese Tracker", "value": "author_of"}, {"source": "Guorong Li", "target": "Towards Reliable Tracking: An Uncertainty-Aware Siamese Tracker", "value": "author_of"}, {"source": "Zhiyi Mo", "target": "Towards Reliable Tracking: An Uncertainty-Aware Siamese Tracker", "value": "author_of"}, {"source": "Bineng Zhong", "target": "Towards Reliable Tracking: An Uncertainty-Aware Siamese Tracker", "value": "author_of"}, {"source": "Yulin Lei", "target": "Bridging the gap, not forcing the tie: dual-space alignment and fusion framework for toxic memes detection", "value": "author_of"}, {"source": "Jin Yang", "target": "Bridging the gap, not forcing the tie: dual-space alignment and fusion framework for toxic memes detection", "value": "author_of"}, {"source": "Huijia Liang", "target": "Bridging the gap, not forcing the tie: dual-space alignment and fusion framework for toxic memes detection", "value": "author_of"}, {"source": "Tianrui Li", "target": "Bridging the gap, not forcing the tie: dual-space alignment and fusion framework for toxic memes detection", "value": "author_of"}, {"source": "Ning Pang", "target": "Perturb and restore: Efficient category revocation in federated unlearning", "value": "author_of"}, {"source": "Zou Li", "target": "Perturb and restore: Efficient category revocation in federated unlearning", "value": "author_of"}, {"source": "Pengcheng Wan", "target": "Perturb and restore: Efficient category revocation in federated unlearning", "value": "author_of"}, {"source": "Hongchao Wu", "target": "Perturb and restore: Efficient category revocation in federated unlearning", "value": "author_of"}, {"source": "Yuchen Bing", "target": "Perturb and restore: Efficient category revocation in federated unlearning", "value": "author_of"}, {"source": "Xiang Zhao", "target": "Perturb and restore: Efficient category revocation in federated unlearning", "value": "author_of"}, {"source": "Yanling Liu", "target": "DCM-Net: A novel dual-branch CNN-Mamba cross-layer feature fusion network for medical image segmentation", "value": "author_of"}, {"source": "Hongmin Deng", "target": "DCM-Net: A novel dual-branch CNN-Mamba cross-layer feature fusion network for medical image segmentation", "value": "author_of"}, {"source": "Jinghao Fu", "target": "DCM-Net: A novel dual-branch CNN-Mamba cross-layer feature fusion network for medical image segmentation", "value": "author_of"}, {"source": "Yu Fu", "target": "AdveDiffNet: adversarial diffusion network for unbalanced melanoma diagnosis", "value": "author_of"}, {"source": "Chao Liu", "target": "AdveDiffNet: adversarial diffusion network for unbalanced melanoma diagnosis", "value": "author_of"}, {"source": "Shaoqiang Wang", "target": "AdveDiffNet: adversarial diffusion network for unbalanced melanoma diagnosis", "value": "author_of"}, {"source": "Hui Xia", "target": "AdveDiffNet: adversarial diffusion network for unbalanced melanoma diagnosis", "value": "author_of"}, {"source": "Diederik P Kingma", "target": "Auto-Encoding Variational Bayes", "value": "author_of"}, {"source": "Max Welling", "target": "Auto-Encoding Variational Bayes", "value": "author_of"}, {"source": "Geoffrey E. Hinton", "target": "Supporting Online Material for Reducing the Dimensionality of Data with Neural Networks", "value": "author_of"}, {"source": "R. Salakhutdinov", "target": "Supporting Online Material for Reducing the Dimensionality of Data with Neural Networks", "value": "author_of"}, {"source": "John C. Duchi", "target": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization", "value": "author_of"}, {"source": "Elad Hazan", "target": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization", "value": "author_of"}, {"source": "Y. Singer", "target": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization", "value": "author_of"}, {"source": "Alex Graves", "target": "Speech recognition with deep recurrent neural networks", "value": "author_of"}, {"source": "Abdel-rahman Mohamed", "target": "Speech recognition with deep recurrent neural networks", "value": "author_of"}, {"source": "Geoffrey Hinton", "target": "Speech recognition with deep recurrent neural networks", "value": "author_of"}, {"source": "Geoffrey E. Hinton", "target": "Improving neural networks by preventing co-adaptation of feature detectors", "value": "author_of"}, {"source": "Nitish Srivastava", "target": "Improving neural networks by preventing co-adaptation of feature detectors", "value": "author_of"}, {"source": "Alex Krizhevsky", "target": "Improving neural networks by preventing co-adaptation of feature detectors", "value": "author_of"}, {"source": "Ilya Sutskever", "target": "Improving neural networks by preventing co-adaptation of feature detectors", "value": "author_of"}, {"source": "Ruslan R. Salakhutdinov", "target": "Improving neural networks by preventing co-adaptation of feature detectors", "value": "author_of"}, {"source": "Matthew D. Zeiler", "target": "ADADELTA: An Adaptive Learning Rate Method", "value": "author_of"}, {"source": "Andrew L. Maas", "target": "Learning Word Vectors for Sentiment Analysis", "value": "author_of"}, {"source": "Raymond E. Daly", "target": "Learning Word Vectors for Sentiment Analysis", "value": "author_of"}, {"source": "Peter T. Pham", "target": "Learning Word Vectors for Sentiment Analysis", "value": "author_of"}, {"source": "Dan Huang", "target": "Learning Word Vectors for Sentiment Analysis", "value": "author_of"}, {"source": "A. Ng", "target": "Learning Word Vectors for Sentiment Analysis", "value": "author_of"}, {"source": "Christopher Potts", "target": "Learning Word Vectors for Sentiment Analysis", "value": "author_of"}, {"source": "I. Sutskever", "target": "On the importance of initialization and momentum in deep learning", "value": "author_of"}, {"source": "James Martens", "target": "On the importance of initialization and momentum in deep learning", "value": "author_of"}, {"source": "George E. Dahl", "target": "On the importance of initialization and momentum in deep learning", "value": "author_of"}, {"source": "Geoffrey E. Hinton", "target": "On the importance of initialization and momentum in deep learning", "value": "author_of"}, {"source": "Alex Graves", "target": "Generating Sequences With Recurrent Neural Networks", "value": "author_of"}, {"source": "Nian Wang", "target": "Weakly Supervised Image Dehazing via Physics-Based Decomposition", "value": "author_of"}, {"source": "Zhigao Cui", "target": "Weakly Supervised Image Dehazing via Physics-Based Decomposition", "value": "author_of"}, {"source": "Yanzhao Su", "target": "Weakly Supervised Image Dehazing via Physics-Based Decomposition", "value": "author_of"}, {"source": "Yunwei Lan", "target": "Weakly Supervised Image Dehazing via Physics-Based Decomposition", "value": "author_of"}, {"source": "Yuanliang Xue", "target": "Weakly Supervised Image Dehazing via Physics-Based Decomposition", "value": "author_of"}, {"source": "Cong Zhang", "target": "Weakly Supervised Image Dehazing via Physics-Based Decomposition", "value": "author_of"}, {"source": "Aihua Li", "target": "Weakly Supervised Image Dehazing via Physics-Based Decomposition", "value": "author_of"}, {"source": "Leong Kah Meng", "target": "A Machine Learning Approach for Face Mask Detection System with AdamW Optimizer", "value": "author_of"}, {"source": "Ho Hooi Yi", "target": "A Machine Learning Approach for Face Mask Detection System with AdamW Optimizer", "value": "author_of"}, {"source": "Ng Bo Wei", "target": "A Machine Learning Approach for Face Mask Detection System with AdamW Optimizer", "value": "author_of"}, {"source": "Lim Jia Xin", "target": "A Machine Learning Approach for Face Mask Detection System with AdamW Optimizer", "value": "author_of"}, {"source": "Zailan Arabee Abdul Salam", "target": "A Machine Learning Approach for Face Mask Detection System with AdamW Optimizer", "value": "author_of"}, {"source": "Xin Cheng", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Wangding Zeng", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Damai Dai", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Qinyu Chen", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Bingxuan Wang", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Zhenda Xie", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Kezhao Huang", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Xingkai Yu", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Zhewen Hao", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Yukun Li", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Han Zhang", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Huishuai Zhang", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Dongyan Zhao", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Wenfeng Liang", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Mostafa Saberian", "target": "Probabilistic hierarchical interpolation and interpretable neural network configurations for flood prediction", "value": "author_of"}, {"source": "Vidya Samadi", "target": "Probabilistic hierarchical interpolation and interpretable neural network configurations for flood prediction", "value": "author_of"}, {"source": "Ioana Popescu", "target": "Probabilistic hierarchical interpolation and interpretable neural network configurations for flood prediction", "value": "author_of"}, {"source": "Husheng Fang", "target": "Generating an annual 30\u00a0m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "value": "author_of"}, {"source": "Shunlin Liang", "target": "Generating an annual 30\u00a0m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "value": "author_of"}, {"source": "Wenyuan Li", "target": "Generating an annual 30\u00a0m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "value": "author_of"}, {"source": "Yongzhe Chen", "target": "Generating an annual 30\u00a0m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "value": "author_of"}, {"source": "Han Ma", "target": "Generating an annual 30\u00a0m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "value": "author_of"}, {"source": "Jianglei Xu", "target": "Generating an annual 30\u00a0m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "value": "author_of"}, {"source": "Yichuan Ma", "target": "Generating an annual 30\u00a0m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "value": "author_of"}, {"source": "Tao He", "target": "Generating an annual 30\u00a0m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "value": "author_of"}, {"source": "Feng Tian", "target": "Generating an annual 30\u00a0m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "value": "author_of"}, {"source": "Fengjiao Zhang", "target": "Generating an annual 30\u00a0m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "value": "author_of"}, {"source": "Hui Liang", "target": "Generating an annual 30\u00a0m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "value": "author_of"}, {"source": "Bin Chen", "target": "Unveiling cross-modal consistency: Taming inter- and intra-modal noise for robust multi-modal knowledge graph completion", "value": "author_of"}, {"source": "Hanting Shen", "target": "Unveiling cross-modal consistency: Taming inter- and intra-modal noise for robust multi-modal knowledge graph completion", "value": "author_of"}, {"source": "Zhangtao Cheng", "target": "Unveiling cross-modal consistency: Taming inter- and intra-modal noise for robust multi-modal knowledge graph completion", "value": "author_of"}, {"source": "Xueting Liu", "target": "Unveiling cross-modal consistency: Taming inter- and intra-modal noise for robust multi-modal knowledge graph completion", "value": "author_of"}, {"source": "Ting Zhong", "target": "Unveiling cross-modal consistency: Taming inter- and intra-modal noise for robust multi-modal knowledge graph completion", "value": "author_of"}, {"source": "Fan Zhou", "target": "Unveiling cross-modal consistency: Taming inter- and intra-modal noise for robust multi-modal knowledge graph completion", "value": "author_of"}, {"source": "I. Helmy", "target": "Low-Resolution Massive MIMO Channel Estimation With LSTM Attention-Based CBDNet", "value": "author_of"}, {"source": "Wooyeol Choi", "target": "Low-Resolution Massive MIMO Channel Estimation With LSTM Attention-Based CBDNet", "value": "author_of"}, {"source": "Mariia Karabin", "target": "Quantum solver for single-impurity Anderson models with particle-hole symmetry", "value": "author_of"}, {"source": "Tanvir Sohail", "target": "Quantum solver for single-impurity Anderson models with particle-hole symmetry", "value": "author_of"}, {"source": "Dmytro Bykov", "target": "Quantum solver for single-impurity Anderson models with particle-hole symmetry", "value": "author_of"}, {"source": "Eduardo Antonio Coello P\u00e9rez", "target": "Quantum solver for single-impurity Anderson models with particle-hole symmetry", "value": "author_of"}, {"source": "Swarnava Ghosh", "target": "Quantum solver for single-impurity Anderson models with particle-hole symmetry", "value": "author_of"}, {"source": "Murali Gopalakrishnan Meena", "target": "Quantum solver for single-impurity Anderson models with particle-hole symmetry", "value": "author_of"}, {"source": "Seongmin Kim", "target": "Quantum solver for single-impurity Anderson models with particle-hole symmetry", "value": "author_of"}, {"source": "Amir Shehata", "target": "Quantum solver for single-impurity Anderson models with particle-hole symmetry", "value": "author_of"}, {"source": "In-Saeng Suh", "target": "Quantum solver for single-impurity Anderson models with particle-hole symmetry", "value": "author_of"}, {"source": "Hanna Terletska", "target": "Quantum solver for single-impurity Anderson models with particle-hole symmetry", "value": "author_of"}, {"source": "Markus Eisenbach", "target": "Quantum solver for single-impurity Anderson models with particle-hole symmetry", "value": "author_of"}, {"source": "Lorenzo Nava", "target": "Sentinel-1 SAR-based globally distributed co-seismic landslide detection by deep neural networks", "value": "author_of"}, {"source": "A. Mondini", "target": "Sentinel-1 SAR-based globally distributed co-seismic landslide detection by deep neural networks", "value": "author_of"}, {"source": "Kushanav Bhuyan", "target": "Sentinel-1 SAR-based globally distributed co-seismic landslide detection by deep neural networks", "value": "author_of"}, {"source": "Chengyong Fang", "target": "Sentinel-1 SAR-based globally distributed co-seismic landslide detection by deep neural networks", "value": "author_of"}, {"source": "Oriol Monserrat", "target": "Sentinel-1 SAR-based globally distributed co-seismic landslide detection by deep neural networks", "value": "author_of"}, {"source": "A. Novellino", "target": "Sentinel-1 SAR-based globally distributed co-seismic landslide detection by deep neural networks", "value": "author_of"}, {"source": "Filippo Catani", "target": "Sentinel-1 SAR-based globally distributed co-seismic landslide detection by deep neural networks", "value": "author_of"}, {"source": "Jihun Ryu", "target": "Increasing resolution and accuracy in sub-seasonal forecasting through 3D U-Net: the western US", "value": "author_of"}, {"source": "Hisu Kim", "target": "Increasing resolution and accuracy in sub-seasonal forecasting through 3D U-Net: the western US", "value": "author_of"}, {"source": "Simon Wang", "target": "Increasing resolution and accuracy in sub-seasonal forecasting through 3D U-Net: the western US", "value": "author_of"}, {"source": "Jin-Ho Yoon", "target": "Increasing resolution and accuracy in sub-seasonal forecasting through 3D U-Net: the western US", "value": "author_of"}, {"source": "Andrew G. Howard", "target": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications", "value": "author_of"}, {"source": "Menglong Zhu", "target": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications", "value": "author_of"}, {"source": "Bo Chen", "target": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications", "value": "author_of"}, {"source": "Dmitry Kalenichenko", "target": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications", "value": "author_of"}, {"source": "Weijun Wang", "target": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications", "value": "author_of"}, {"source": "Tobias Weyand", "target": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications", "value": "author_of"}, {"source": "Marco Andreetto", "target": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications", "value": "author_of"}, {"source": "Hartwig Adam", "target": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications", "value": "author_of"}, {"source": "Geoffrey Hinton", "target": "Distilling the Knowledge in a Neural Network", "value": "author_of"}, {"source": "Oriol Vinyals", "target": "Distilling the Knowledge in a Neural Network", "value": "author_of"}, {"source": "Jeff Dean", "target": "Distilling the Knowledge in a Neural Network", "value": "author_of"}, {"source": "Matthew D Zeiler", "target": "Visualizing and Understanding Convolutional Networks", "value": "author_of"}, {"source": "Rob Fergus", "target": "Visualizing and Understanding Convolutional Networks", "value": "author_of"}, {"source": "Zhenda Xie", "target": "mHC: Manifold-Constrained Hyper-Connections", "value": "author_of"}, {"source": "Yixuan Wei", "target": "mHC: Manifold-Constrained Hyper-Connections", "value": "author_of"}, {"source": "Huanqi Cao", "target": "mHC: Manifold-Constrained Hyper-Connections", "value": "author_of"}, {"source": "Chenggang Zhao", "target": "mHC: Manifold-Constrained Hyper-Connections", "value": "author_of"}, {"source": "Chengqi Deng", "target": "mHC: Manifold-Constrained Hyper-Connections", "value": "author_of"}, {"source": "Jiashi Li", "target": "mHC: Manifold-Constrained Hyper-Connections", "value": "author_of"}, {"source": "Damai Dai", "target": "mHC: Manifold-Constrained Hyper-Connections", "value": "author_of"}, {"source": "Huazuo Gao", "target": "mHC: Manifold-Constrained Hyper-Connections", "value": "author_of"}, {"source": "Jiang Chang", "target": "mHC: Manifold-Constrained Hyper-Connections", "value": "author_of"}, {"source": "Kuai Yu", "target": "mHC: Manifold-Constrained Hyper-Connections", "value": "author_of"}, {"source": "Liang Zhao", "target": "mHC: Manifold-Constrained Hyper-Connections", "value": "author_of"}, {"source": "Shangyan Zhou", "target": "mHC: Manifold-Constrained Hyper-Connections", "value": "author_of"}, {"source": "Zhean Xu", "target": "mHC: Manifold-Constrained Hyper-Connections", "value": "author_of"}, {"source": "Zhengyan Zhang", "target": "mHC: Manifold-Constrained Hyper-Connections", "value": "author_of"}, {"source": "Wangding Zeng", "target": "mHC: Manifold-Constrained Hyper-Connections", "value": "author_of"}, {"source": "Shengding Hu", "target": "mHC: Manifold-Constrained Hyper-Connections", "value": "author_of"}, {"source": "Yuqing Wang", "target": "mHC: Manifold-Constrained Hyper-Connections", "value": "author_of"}, {"source": "Jingyang Yuan", "target": "mHC: Manifold-Constrained Hyper-Connections", "value": "author_of"}, {"source": "Lean Wang", "target": "mHC: Manifold-Constrained Hyper-Connections", "value": "author_of"}, {"source": "Wenfeng Liang", "target": "mHC: Manifold-Constrained Hyper-Connections", "value": "author_of"}, {"source": "Yifei Ge", "target": "Dataset Purification-Driven Lightweight Deep Learning Model Construction for Empty-Dish Recycling Robot", "value": "author_of"}, {"source": "Zhuo Li", "target": "Dataset Purification-Driven Lightweight Deep Learning Model Construction for Empty-Dish Recycling Robot", "value": "author_of"}, {"source": "Xuebin Yue", "target": "Dataset Purification-Driven Lightweight Deep Learning Model Construction for Empty-Dish Recycling Robot", "value": "author_of"}, {"source": "Hengyi Li", "target": "Dataset Purification-Driven Lightweight Deep Learning Model Construction for Empty-Dish Recycling Robot", "value": "author_of"}, {"source": "Lin Meng", "target": "Dataset Purification-Driven Lightweight Deep Learning Model Construction for Empty-Dish Recycling Robot", "value": "author_of"}, {"source": "Shuo Qian", "target": "Physics-guided deep neural networks for bathymetric mapping using Sentinel-2 multi-spectral imagery", "value": "author_of"}, {"source": "Yingying Chen", "target": "Physics-guided deep neural networks for bathymetric mapping using Sentinel-2 multi-spectral imagery", "value": "author_of"}, {"source": "Wei Wang", "target": "Physics-guided deep neural networks for bathymetric mapping using Sentinel-2 multi-spectral imagery", "value": "author_of"}, {"source": "Gaowei Zhang", "target": "Physics-guided deep neural networks for bathymetric mapping using Sentinel-2 multi-spectral imagery", "value": "author_of"}, {"source": "Lei Li", "target": "Physics-guided deep neural networks for bathymetric mapping using Sentinel-2 multi-spectral imagery", "value": "author_of"}, {"source": "Zengzhou Hao", "target": "Physics-guided deep neural networks for bathymetric mapping using Sentinel-2 multi-spectral imagery", "value": "author_of"}, {"source": "Yi Wang", "target": "Physics-guided deep neural networks for bathymetric mapping using Sentinel-2 multi-spectral imagery", "value": "author_of"}, {"source": "Minqiang Yang", "target": "Spike Memory Transformer: An Energy-Efficient Model in Distributed Learning Framework for Autonomous Depression Detection", "value": "author_of"}, {"source": "Yueze Liu", "target": "Spike Memory Transformer: An Energy-Efficient Model in Distributed Learning Framework for Autonomous Depression Detection", "value": "author_of"}, {"source": "Yongfeng Tao", "target": "Spike Memory Transformer: An Energy-Efficient Model in Distributed Learning Framework for Autonomous Depression Detection", "value": "author_of"}, {"source": "Bin Hu", "target": "Spike Memory Transformer: An Energy-Efficient Model in Distributed Learning Framework for Autonomous Depression Detection", "value": "author_of"}, {"source": "Sibo Huang", "target": "Multi-Perspective Semantic Segmentation of Ground Penetrating Radar Images for Pavement Subsurface Objects", "value": "author_of"}, {"source": "Guijie Zhu", "target": "Multi-Perspective Semantic Segmentation of Ground Penetrating Radar Images for Pavement Subsurface Objects", "value": "author_of"}, {"source": "Jiaming Tang", "target": "Multi-Perspective Semantic Segmentation of Ground Penetrating Radar Images for Pavement Subsurface Objects", "value": "author_of"}, {"source": "Weixiong Li", "target": "Multi-Perspective Semantic Segmentation of Ground Penetrating Radar Images for Pavement Subsurface Objects", "value": "author_of"}, {"source": "Zhun Fan", "target": "Multi-Perspective Semantic Segmentation of Ground Penetrating Radar Images for Pavement Subsurface Objects", "value": "author_of"}, {"source": "D. E. Boukhari", "target": "A comprehensive review of facial beauty prediction using deep learning techniques", "value": "author_of"}, {"source": "F. Dornaika", "target": "A comprehensive review of facial beauty prediction using deep learning techniques", "value": "author_of"}, {"source": "A. Chemsa", "target": "A comprehensive review of facial beauty prediction using deep learning techniques", "value": "author_of"}, {"source": "Abdelmalik Taleb-Ahmed", "target": "A comprehensive review of facial beauty prediction using deep learning techniques", "value": "author_of"}, {"source": "Kaiqing Lin", "target": "Seeing Before Reasoning: A Unified Framework for Generalizable and Explainable Fake Image Detection", "value": "author_of"}, {"source": "Zhiyuan Yan", "target": "Seeing Before Reasoning: A Unified Framework for Generalizable and Explainable Fake Image Detection", "value": "author_of"}, {"source": "Ruoxin Chen", "target": "Seeing Before Reasoning: A Unified Framework for Generalizable and Explainable Fake Image Detection", "value": "author_of"}, {"source": "Junyan Ye", "target": "Seeing Before Reasoning: A Unified Framework for Generalizable and Explainable Fake Image Detection", "value": "author_of"}, {"source": "Ke-Yue Zhang", "target": "Seeing Before Reasoning: A Unified Framework for Generalizable and Explainable Fake Image Detection", "value": "author_of"}, {"source": "Yue Zhou", "target": "Seeing Before Reasoning: A Unified Framework for Generalizable and Explainable Fake Image Detection", "value": "author_of"}, {"source": "Peng Jin", "target": "Seeing Before Reasoning: A Unified Framework for Generalizable and Explainable Fake Image Detection", "value": "author_of"}, {"source": "Bin Li", "target": "Seeing Before Reasoning: A Unified Framework for Generalizable and Explainable Fake Image Detection", "value": "author_of"}, {"source": "Taiping Yao", "target": "Seeing Before Reasoning: A Unified Framework for Generalizable and Explainable Fake Image Detection", "value": "author_of"}, {"source": "Shouhong Ding", "target": "Seeing Before Reasoning: A Unified Framework for Generalizable and Explainable Fake Image Detection", "value": "author_of"}, {"source": "Esraa Hassan", "target": "DenseNet Model with Attention Mechanisms for Robust Date Fruit Image Classification", "value": "author_of"}, {"source": "Sarah Abu Ghazalah", "target": "DenseNet Model with Attention Mechanisms for Robust Date Fruit Image Classification", "value": "author_of"}, {"source": "Nora El-Rashidy", "target": "DenseNet Model with Attention Mechanisms for Robust Date Fruit Image Classification", "value": "author_of"}, {"source": "Tarek Abd El-Hafeez", "target": "DenseNet Model with Attention Mechanisms for Robust Date Fruit Image Classification", "value": "author_of"}, {"source": "Mahmoud Y. Shams", "target": "DenseNet Model with Attention Mechanisms for Robust Date Fruit Image Classification", "value": "author_of"}, {"source": "Hari Kishan Kondaveeti", "target": "Evaluation of deep learning models using explainable AI with qualitative and quantitative analysis for rice leaf disease detection", "value": "author_of"}, {"source": "Chinna Gopi Simhadri", "target": "Evaluation of deep learning models using explainable AI with qualitative and quantitative analysis for rice leaf disease detection", "value": "author_of"}, {"source": "Hang Liu", "target": "Wind turbine blade surface defect detection model based on improved you only look once version 10 small and integrated compression", "value": "author_of"}, {"source": "Sheng Liu", "target": "Wind turbine blade surface defect detection model based on improved you only look once version 10 small and integrated compression", "value": "author_of"}, {"source": "Zhijian Liu", "target": "Wind turbine blade surface defect detection model based on improved you only look once version 10 small and integrated compression", "value": "author_of"}, {"source": "Ben Niu", "target": "Wind turbine blade surface defect detection model based on improved you only look once version 10 small and integrated compression", "value": "author_of"}, {"source": "Jing Xie", "target": "Wind turbine blade surface defect detection model based on improved you only look once version 10 small and integrated compression", "value": "author_of"}, {"source": "Chi Luo", "target": "Wind turbine blade surface defect detection model based on improved you only look once version 10 small and integrated compression", "value": "author_of"}, {"source": "Zhiyu Shi", "target": "Wind turbine blade surface defect detection model based on improved you only look once version 10 small and integrated compression", "value": "author_of"}, {"source": "Ashish Vaswani", "target": "Attention is All you Need", "value": "author_of"}, {"source": "Noam Shazeer", "target": "Attention is All you Need", "value": "author_of"}, {"source": "Niki Parmar", "target": "Attention is All you Need", "value": "author_of"}, {"source": "Jakob Uszkoreit", "target": "Attention is All you Need", "value": "author_of"}, {"source": "Llion Jones", "target": "Attention is All you Need", "value": "author_of"}, {"source": "Aidan N. Gomez", "target": "Attention is All you Need", "value": "author_of"}, {"source": "Lukasz Kaiser", "target": "Attention is All you Need", "value": "author_of"}, {"source": "Illia Polosukhin", "target": "Attention is All you Need", "value": "author_of"}, {"source": "Colin Raffel", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "author_of"}, {"source": "Noam Shazeer", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "author_of"}, {"source": "Adam Roberts", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "author_of"}, {"source": "Katherine Lee", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "author_of"}, {"source": "Sharan Narang", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "author_of"}, {"source": "Michael Matena", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "author_of"}, {"source": "Yanqi Zhou", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "author_of"}, {"source": "Wei Li", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "author_of"}, {"source": "Peter J. Liu", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "author_of"}, {"source": "M. Heusel", "target": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium", "value": "author_of"}, {"source": "Hubert Ramsauer", "target": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium", "value": "author_of"}, {"source": "Thomas Unterthiner", "target": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium", "value": "author_of"}, {"source": "Bernhard Nessler", "target": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium", "value": "author_of"}, {"source": "Sepp Hochreiter", "target": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium", "value": "author_of"}, {"source": "Holger Caesar", "target": "nuScenes: A Multimodal Dataset for Autonomous Driving", "value": "author_of"}, {"source": "Varun Bankiti", "target": "nuScenes: A Multimodal Dataset for Autonomous Driving", "value": "author_of"}, {"source": "Alex H. Lang", "target": "nuScenes: A Multimodal Dataset for Autonomous Driving", "value": "author_of"}, {"source": "Sourabh Vora", "target": "nuScenes: A Multimodal Dataset for Autonomous Driving", "value": "author_of"}, {"source": "Venice Erin Liong", "target": "nuScenes: A Multimodal Dataset for Autonomous Driving", "value": "author_of"}, {"source": "Qiang Xu", "target": "nuScenes: A Multimodal Dataset for Autonomous Driving", "value": "author_of"}, {"source": "Anush Krishnan", "target": "nuScenes: A Multimodal Dataset for Autonomous Driving", "value": "author_of"}, {"source": "Yu Pan", "target": "nuScenes: A Multimodal Dataset for Autonomous Driving", "value": "author_of"}, {"source": "Giancarlo Baldan", "target": "nuScenes: A Multimodal Dataset for Autonomous Driving", "value": "author_of"}, {"source": "Oscar Beijbom", "target": "nuScenes: A Multimodal Dataset for Autonomous Driving", "value": "author_of"}, {"source": "Alexey Dosovitskiy", "target": "CARLA: An Open Urban Driving Simulator", "value": "author_of"}, {"source": "German Ros", "target": "CARLA: An Open Urban Driving Simulator", "value": "author_of"}, {"source": "Felipe Codevilla", "target": "CARLA: An Open Urban Driving Simulator", "value": "author_of"}, {"source": "Antonio Lopez", "target": "CARLA: An Open Urban Driving Simulator", "value": "author_of"}, {"source": "Vladlen Koltun", "target": "CARLA: An Open Urban Driving Simulator", "value": "author_of"}, {"source": "Lvmin Zhang", "target": "Adding Conditional Control to Text-to-Image Diffusion Models", "value": "author_of"}, {"source": "Anyi Rao", "target": "Adding Conditional Control to Text-to-Image Diffusion Models", "value": "author_of"}, {"source": "Maneesh Agrawala", "target": "Adding Conditional Control to Text-to-Image Diffusion Models", "value": "author_of"}, {"source": "William Peebles", "target": "Scalable Diffusion Models with Transformers", "value": "author_of"}, {"source": "Saining Xie", "target": "Scalable Diffusion Models with Transformers", "value": "author_of"}, {"source": "Dustin Podell", "target": "SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis", "value": "author_of"}, {"source": "Zion English", "target": "SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis", "value": "author_of"}, {"source": "Kyle Lacey", "target": "SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis", "value": "author_of"}, {"source": "Andreas Blattmann", "target": "SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis", "value": "author_of"}, {"source": "Tim Dockhorn", "target": "SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis", "value": "author_of"}, {"source": "Jonas M\u00fcller", "target": "SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis", "value": "author_of"}, {"source": "Joe Penna", "target": "SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis", "value": "author_of"}, {"source": "Robin Rombach", "target": "SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis", "value": "author_of"}, {"source": "Josh Tobin", "target": "Domain randomization for transferring deep neural networks from simulation to the real world", "value": "author_of"}, {"source": "Rachel Fong", "target": "Domain randomization for transferring deep neural networks from simulation to the real world", "value": "author_of"}, {"source": "Alex Ray", "target": "Domain randomization for transferring deep neural networks from simulation to the real world", "value": "author_of"}, {"source": "Jonas Schneider", "target": "Domain randomization for transferring deep neural networks from simulation to the real world", "value": "author_of"}, {"source": "Wojciech Zaremba", "target": "Domain randomization for transferring deep neural networks from simulation to the real world", "value": "author_of"}, {"source": "Pieter Abbeel", "target": "Domain randomization for transferring deep neural networks from simulation to the real world", "value": "author_of"}, {"source": "G. Ros", "target": "The SYNTHIA Dataset: A Large Collection of Synthetic Images for Semantic Segmentation of Urban Scenes", "value": "author_of"}, {"source": "Laura Sellart", "target": "The SYNTHIA Dataset: A Large Collection of Synthetic Images for Semantic Segmentation of Urban Scenes", "value": "author_of"}, {"source": "Joanna Materzynska", "target": "The SYNTHIA Dataset: A Large Collection of Synthetic Images for Semantic Segmentation of Urban Scenes", "value": "author_of"}, {"source": "David V\u00e1zquez", "target": "The SYNTHIA Dataset: A Large Collection of Synthetic Images for Semantic Segmentation of Urban Scenes", "value": "author_of"}, {"source": "Antonio M. L\u00f3pez", "target": "The SYNTHIA Dataset: A Large Collection of Synthetic Images for Semantic Segmentation of Urban Scenes", "value": "author_of"}, {"source": "Fachrina Dewi Puspitasari", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Chaoning Zhang", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Joseph Cho", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Adnan Haider", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Noor Ul Eman", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Omer Amin", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Alexis Mankowski", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Muhammad Umair", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Jingyao Zheng", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Sheng Zheng", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Lik-Hang Lee", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Caiyan Qin", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Tae-Ho Kim", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Choong Seon Hong", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Yang Yang", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Heng Tao Shen", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Bohan Li", "target": "OmniNWM: Omniscient Driving Navigation World Models", "value": "author_of"}, {"source": "Zhuang Ma", "target": "OmniNWM: Omniscient Driving Navigation World Models", "value": "author_of"}, {"source": "Dalong Du", "target": "OmniNWM: Omniscient Driving Navigation World Models", "value": "author_of"}, {"source": "Baorui Peng", "target": "OmniNWM: Omniscient Driving Navigation World Models", "value": "author_of"}, {"source": "Zhujin Liang", "target": "OmniNWM: Omniscient Driving Navigation World Models", "value": "author_of"}, {"source": "Zhenqiang Liu", "target": "OmniNWM: Omniscient Driving Navigation World Models", "value": "author_of"}, {"source": "Chao Ma", "target": "OmniNWM: Omniscient Driving Navigation World Models", "value": "author_of"}, {"source": "Yueming Jin", "target": "OmniNWM: Omniscient Driving Navigation World Models", "value": "author_of"}, {"source": "Hao Zhao", "target": "OmniNWM: Omniscient Driving Navigation World Models", "value": "author_of"}, {"source": "Wenjun Zeng", "target": "OmniNWM: Omniscient Driving Navigation World Models", "value": "author_of"}, {"source": "Xin Jin", "target": "OmniNWM: Omniscient Driving Navigation World Models", "value": "author_of"}, {"source": "Zhuoran Yang", "target": "ConsisDrive: Identity-Preserving Driving World Models for Video Generation by Instance Mask", "value": "author_of"}, {"source": "Yanyong Zhang", "target": "ConsisDrive: Identity-Preserving Driving World Models for Video Generation by Instance Mask", "value": "author_of"}, {"source": "Guosheng Zhao", "target": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "value": "author_of"}, {"source": "Yaozeng Wang", "target": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "value": "author_of"}, {"source": "Xiaofeng Wang", "target": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "value": "author_of"}, {"source": "Zheng Zhu", "target": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "value": "author_of"}, {"source": "Tingdong Yu", "target": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "value": "author_of"}, {"source": "Guan Huang", "target": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "value": "author_of"}, {"source": "Yongchen Zai", "target": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "value": "author_of"}, {"source": "Ji Jiao", "target": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "value": "author_of"}, {"source": "Changliang Xue", "target": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "value": "author_of"}, {"source": "Xiaole Wang", "target": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "value": "author_of"}, {"source": "Zhen Yang", "target": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "value": "author_of"}, {"source": "Futang Zhu", "target": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "value": "author_of"}, {"source": "Xingang Wang", "target": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "value": "author_of"}, {"source": "Ahmad Rahimi", "target": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "value": "author_of"}, {"source": "Valentin Gerard", "target": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "value": "author_of"}, {"source": "Eloi Zablocki", "target": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "value": "author_of"}, {"source": "Matthieu Cord", "target": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "value": "author_of"}, {"source": "Alexandre Alahi", "target": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "value": "author_of"}, {"source": "Duolikun Danier", "target": "View-Consistent Diffusion Representations for 3D-Consistent Video Generation", "value": "author_of"}, {"source": "Ge Gao", "target": "View-Consistent Diffusion Representations for 3D-Consistent Video Generation", "value": "author_of"}, {"source": "Steven McDonagh", "target": "View-Consistent Diffusion Representations for 3D-Consistent Video Generation", "value": "author_of"}, {"source": "Changjian Li", "target": "View-Consistent Diffusion Representations for 3D-Consistent Video Generation", "value": "author_of"}, {"source": "Hakan Bilen", "target": "View-Consistent Diffusion Representations for 3D-Consistent Video Generation", "value": "author_of"}, {"source": "Oisin Mac Aodha", "target": "View-Consistent Diffusion Representations for 3D-Consistent Video Generation", "value": "author_of"}, {"source": "Jonathan Long", "target": "Fully Convolutional Networks for Semantic Segmentation", "value": "author_of"}, {"source": "Evan Shelhamer", "target": "Fully Convolutional Networks for Semantic Segmentation", "value": "author_of"}, {"source": "Trevor Darrell", "target": "Fully Convolutional Networks for Semantic Segmentation", "value": "author_of"}, {"source": "Alex Graves", "target": "Speech Recognition with Deep Recurrent Neural Networks", "value": "author_of"}, {"source": "Abdel-rahman Mohamed", "target": "Speech Recognition with Deep Recurrent Neural Networks", "value": "author_of"}, {"source": "Geoffrey Hinton", "target": "Speech Recognition with Deep Recurrent Neural Networks", "value": "author_of"}, {"source": "Holger Caesar", "target": "nuScenes: A multimodal dataset for autonomous driving", "value": "author_of"}, {"source": "Varun Bankiti", "target": "nuScenes: A multimodal dataset for autonomous driving", "value": "author_of"}, {"source": "Alex H. Lang", "target": "nuScenes: A multimodal dataset for autonomous driving", "value": "author_of"}, {"source": "Sourabh Vora", "target": "nuScenes: A multimodal dataset for autonomous driving", "value": "author_of"}, {"source": "Venice Erin Liong", "target": "nuScenes: A multimodal dataset for autonomous driving", "value": "author_of"}, {"source": "Qiang Xu", "target": "nuScenes: A multimodal dataset for autonomous driving", "value": "author_of"}, {"source": "Anush Krishnan", "target": "nuScenes: A multimodal dataset for autonomous driving", "value": "author_of"}, {"source": "Yu Pan", "target": "nuScenes: A multimodal dataset for autonomous driving", "value": "author_of"}, {"source": "Giancarlo Baldan", "target": "nuScenes: A multimodal dataset for autonomous driving", "value": "author_of"}, {"source": "Oscar Beijbom", "target": "nuScenes: A multimodal dataset for autonomous driving", "value": "author_of"}, {"source": "Josh Tobin", "target": "Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World", "value": "author_of"}, {"source": "Rachel Fong", "target": "Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World", "value": "author_of"}, {"source": "Alex Ray", "target": "Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World", "value": "author_of"}, {"source": "Jonas Schneider", "target": "Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World", "value": "author_of"}, {"source": "Wojciech Zaremba", "target": "Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World", "value": "author_of"}, {"source": "Pieter Abbeel", "target": "Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World", "value": "author_of"}, {"source": "Attention Is All You Need", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "Attention Is All You Need", "target": "Adam: A Method for Stochastic Optimization", "value": "cites"}, {"source": "Attention Is All You Need", "target": "Long Short-Term Memory", "value": "cites"}, {"source": "Attention Is All You Need", "target": "Dropout: a simple way to prevent neural networks from overfitting", "value": "cites"}, {"source": "Attention Is All You Need", "target": "Rethinking the Inception Architecture for Computer Vision", "value": "cites"}, {"source": "Attention Is All You Need", "target": "Neural Machine Translation by Jointly Learning to Align and Translate", "value": "cites"}, {"source": "Attention Is All You Need", "target": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation", "value": "cites"}, {"source": "Attention Is All You Need", "target": "Sequence to Sequence Learning with Neural Networks", "value": "cites"}, {"source": "Attention Is All You Need", "target": "Xception: Deep Learning with Depthwise Separable Convolutions", "value": "cites"}, {"source": "Attention Is All You Need", "target": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling", "value": "cites"}, {"source": "A comprehensive review of recommender systems: Transitioning from theory to practice", "target": "Attention Is All You Need", "value": "cites"}, {"source": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "target": "Attention Is All You Need", "value": "cites"}, {"source": "CNC-VLM: An RLHF-optimized industrial large vision-language model with multimodal learning for imbalanced CNC fault detection", "target": "Attention Is All You Need", "value": "cites"}, {"source": "UAV-based quantitative crack measurement for bridges integrating four-point laser metric calibration and mamba segmentation", "target": "Attention Is All You Need", "value": "cites"}, {"source": "DiffusionEngine: Diffusion model is scalable data engine for object detection", "target": "Attention Is All You Need", "value": "cites"}, {"source": "Enhanced Transformer-BiLSTM Deep Learning Framework for Day-Ahead Energy Price Forecasting", "target": "Attention Is All You Need", "value": "cites"}, {"source": "Conditional Generative Adversarial Network-based framework for multi-feature uncertainty modeling in energy systems", "target": "Attention Is All You Need", "value": "cites"}, {"source": "CityVLM: Towards sustainable urban development via multi-view coordinated vision\u2013language model", "target": "Attention Is All You Need", "value": "cites"}, {"source": "FullPerception: Network-Level Collaborative Perception for Eliminating Vehicular Blind Spots", "target": "Attention Is All You Need", "value": "cites"}, {"source": "A survey of features used for representing black-box single-objective continuous optimization", "target": "Attention Is All You Need", "value": "cites"}, {"source": "Deep Residual Learning for Image Recognition", "target": "ImageNet classification with deep convolutional neural networks", "value": "cites"}, {"source": "Deep Residual Learning for Image Recognition", "target": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "value": "cites"}, {"source": "Deep Residual Learning for Image Recognition", "target": "Long Short-Term Memory", "value": "cites"}, {"source": "Deep Residual Learning for Image Recognition", "target": "Et al", "value": "cites"}, {"source": "Deep Residual Learning for Image Recognition", "target": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "value": "cites"}, {"source": "Deep Residual Learning for Image Recognition", "target": "Microsoft COCO: Common Objects in Context", "value": "cites"}, {"source": "Deep Residual Learning for Image Recognition", "target": "Going deeper with convolutions", "value": "cites"}, {"source": "Deep Residual Learning for Image Recognition", "target": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "value": "cites"}, {"source": "Deep Residual Learning for Image Recognition", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "cites"}, {"source": "Deep Residual Learning for Image Recognition", "target": "Fully convolutional networks for semantic segmentation", "value": "cites"}, {"source": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "DiffusionEngine: Diffusion model is scalable data engine for object detection", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "WarmGait: Thermal Array-Based Gait Recognition for Privacy-Preserving Person Re-ID", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "Noise Perception Self-Supervised Learning for Unsupervised Person Re-Identification", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "Towards Reliable Tracking: An Uncertainty-Aware Siamese Tracker", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "Bridging the gap, not forcing the tie: dual-space alignment and fusion framework for toxic memes detection", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "Perturb and restore: Efficient category revocation in federated unlearning", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "DCM-Net: A novel dual-branch CNN-Mamba cross-layer feature fusion network for medical image segmentation", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "AdveDiffNet: adversarial diffusion network for unbalanced melanoma diagnosis", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "Adam: A Method for Stochastic Optimization", "target": "ImageNet classification with deep convolutional neural networks", "value": "cites"}, {"source": "Adam: A Method for Stochastic Optimization", "target": "Auto-Encoding Variational Bayes", "value": "cites"}, {"source": "Adam: A Method for Stochastic Optimization", "target": "Supporting Online Material for Reducing the Dimensionality of Data with Neural Networks", "value": "cites"}, {"source": "Adam: A Method for Stochastic Optimization", "target": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization", "value": "cites"}, {"source": "Adam: A Method for Stochastic Optimization", "target": "Speech recognition with deep recurrent neural networks", "value": "cites"}, {"source": "Adam: A Method for Stochastic Optimization", "target": "Improving neural networks by preventing co-adaptation of feature detectors", "value": "cites"}, {"source": "Adam: A Method for Stochastic Optimization", "target": "ADADELTA: An Adaptive Learning Rate Method", "value": "cites"}, {"source": "Adam: A Method for Stochastic Optimization", "target": "Learning Word Vectors for Sentiment Analysis", "value": "cites"}, {"source": "Adam: A Method for Stochastic Optimization", "target": "On the importance of initialization and momentum in deep learning", "value": "cites"}, {"source": "Adam: A Method for Stochastic Optimization", "target": "Generating Sequences With Recurrent Neural Networks", "value": "cites"}, {"source": "Weakly Supervised Image Dehazing via Physics-Based Decomposition", "target": "Adam: A Method for Stochastic Optimization", "value": "cites"}, {"source": "A Machine Learning Approach for Face Mask Detection System with AdamW Optimizer", "target": "Adam: A Method for Stochastic Optimization", "value": "cites"}, {"source": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "target": "Adam: A Method for Stochastic Optimization", "value": "cites"}, {"source": "Probabilistic hierarchical interpolation and interpretable neural network configurations for flood prediction", "target": "Adam: A Method for Stochastic Optimization", "value": "cites"}, {"source": "Generating an annual 30\u00a0m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "target": "Adam: A Method for Stochastic Optimization", "value": "cites"}, {"source": "Unveiling cross-modal consistency: Taming inter- and intra-modal noise for robust multi-modal knowledge graph completion", "target": "Adam: A Method for Stochastic Optimization", "value": "cites"}, {"source": "Low-Resolution Massive MIMO Channel Estimation With LSTM Attention-Based CBDNet", "target": "Adam: A Method for Stochastic Optimization", "value": "cites"}, {"source": "Quantum solver for single-impurity Anderson models with particle-hole symmetry", "target": "Adam: A Method for Stochastic Optimization", "value": "cites"}, {"source": "Sentinel-1 SAR-based globally distributed co-seismic landslide detection by deep neural networks", "target": "Adam: A Method for Stochastic Optimization", "value": "cites"}, {"source": "Increasing resolution and accuracy in sub-seasonal forecasting through 3D U-Net: the western US", "target": "Adam: A Method for Stochastic Optimization", "value": "cites"}, {"source": "Xception: Deep Learning with Depthwise Separable Convolutions", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "Xception: Deep Learning with Depthwise Separable Convolutions", "target": "ImageNet classification with deep convolutional neural networks", "value": "cites"}, {"source": "Xception: Deep Learning with Depthwise Separable Convolutions", "target": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "value": "cites"}, {"source": "Xception: Deep Learning with Depthwise Separable Convolutions", "target": "Going deeper with convolutions", "value": "cites"}, {"source": "Xception: Deep Learning with Depthwise Separable Convolutions", "target": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "value": "cites"}, {"source": "Xception: Deep Learning with Depthwise Separable Convolutions", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "cites"}, {"source": "Xception: Deep Learning with Depthwise Separable Convolutions", "target": "Rethinking the Inception Architecture for Computer Vision", "value": "cites"}, {"source": "Xception: Deep Learning with Depthwise Separable Convolutions", "target": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications", "value": "cites"}, {"source": "Xception: Deep Learning with Depthwise Separable Convolutions", "target": "Distilling the Knowledge in a Neural Network", "value": "cites"}, {"source": "Xception: Deep Learning with Depthwise Separable Convolutions", "target": "Visualizing and Understanding Convolutional Networks", "value": "cites"}, {"source": "mHC: Manifold-Constrained Hyper-Connections", "target": "Xception: Deep Learning with Depthwise Separable Convolutions", "value": "cites"}, {"source": "Dataset Purification-Driven Lightweight Deep Learning Model Construction for Empty-Dish Recycling Robot", "target": "Xception: Deep Learning with Depthwise Separable Convolutions", "value": "cites"}, {"source": "Physics-guided deep neural networks for bathymetric mapping using Sentinel-2 multi-spectral imagery", "target": "Xception: Deep Learning with Depthwise Separable Convolutions", "value": "cites"}, {"source": "Spike Memory Transformer: An Energy-Efficient Model in Distributed Learning Framework for Autonomous Depression Detection", "target": "Xception: Deep Learning with Depthwise Separable Convolutions", "value": "cites"}, {"source": "Multi-Perspective Semantic Segmentation of Ground Penetrating Radar Images for Pavement Subsurface Objects", "target": "Xception: Deep Learning with Depthwise Separable Convolutions", "value": "cites"}, {"source": "A comprehensive review of facial beauty prediction using deep learning techniques", "target": "Xception: Deep Learning with Depthwise Separable Convolutions", "value": "cites"}, {"source": "Seeing Before Reasoning: A Unified Framework for Generalizable and Explainable Fake Image Detection", "target": "Xception: Deep Learning with Depthwise Separable Convolutions", "value": "cites"}, {"source": "DenseNet Model with Attention Mechanisms for Robust Date Fruit Image Classification", "target": "Xception: Deep Learning with Depthwise Separable Convolutions", "value": "cites"}, {"source": "Evaluation of deep learning models using explainable AI with qualitative and quantitative analysis for rice leaf disease detection", "target": "Xception: Deep Learning with Depthwise Separable Convolutions", "value": "cites"}, {"source": "Wind turbine blade surface defect detection model based on improved you only look once version 10 small and integrated compression", "target": "Xception: Deep Learning with Depthwise Separable Convolutions", "value": "cites"}, {"source": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "target": "Attention is All you Need", "value": "cites"}, {"source": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "cites"}, {"source": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "target": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium", "value": "cites"}, {"source": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "target": "nuScenes: A Multimodal Dataset for Autonomous Driving", "value": "cites"}, {"source": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "target": "CARLA: An Open Urban Driving Simulator", "value": "cites"}, {"source": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "target": "Adding Conditional Control to Text-to-Image Diffusion Models", "value": "cites"}, {"source": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "target": "Scalable Diffusion Models with Transformers", "value": "cites"}, {"source": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "target": "SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis", "value": "cites"}, {"source": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "target": "Domain randomization for transferring deep neural networks from simulation to the real world", "value": "cites"}, {"source": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "target": "The SYNTHIA Dataset: A Large Collection of Synthetic Images for Semantic Segmentation of Urban Scenes", "value": "cites"}, {"source": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "target": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "value": "cites"}, {"source": "OmniNWM: Omniscient Driving Navigation World Models", "target": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "value": "cites"}, {"source": "ConsisDrive: Identity-Preserving Driving World Models for Video Generation by Instance Mask", "target": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "value": "cites"}, {"source": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "target": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "value": "cites"}, {"source": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "target": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "value": "cites"}, {"source": "View-Consistent Diffusion Representations for 3D-Consistent Video Generation", "target": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "value": "cites"}, {"source": "Attention Is All You Need", "target": "Transformer", "value": "proposed_model"}, {"source": "Transformer", "target": "WMT 2014 English-to-German translation task", "value": "evaluated_on"}, {"source": "Transformer", "target": "WMT 2014 English-to-French translation task", "value": "evaluated_on"}, {"source": "Transformer", "target": "BLEU", "value": "uses_metric"}, {"source": "Deep Residual Learning for Image Recognition", "target": "residual learning framework", "value": "proposed_model"}, {"source": "Deep Residual Learning for Image Recognition", "target": "VGG nets", "value": "baseline_model"}, {"source": "Deep Residual Learning for Image Recognition", "target": "ImageNet", "value": "evaluated_on"}, {"source": "Deep Residual Learning for Image Recognition", "target": "CIFAR-10", "value": "evaluated_on"}, {"source": "Deep Residual Learning for Image Recognition", "target": "COCO object detection dataset", "value": "evaluated_on"}, {"source": "Deep Residual Learning for Image Recognition", "target": "error", "value": "uses_metric"}, {"source": "Deep Residual Learning for Image Recognition", "target": "relative improvement", "value": "uses_metric"}, {"source": "Adam: A Method for Stochastic Optimization", "target": "Adam", "value": "proposed_model"}, {"source": "Adam: A Method for Stochastic Optimization", "target": "AdaMax", "value": "proposed_model"}, {"source": "Long Short-Term Memory", "target": "Long Short-Term Memory", "value": "proposed_model"}, {"source": "Dropout: a simple way to prevent neural networks from overfitting", "target": "Dropout", "value": "proposed_model"}, {"source": "Dropout", "target": "neural networks", "value": "baseline_model"}, {"source": "Rethinking the Inception Architecture for Computer Vision", "target": "Inception Architecture", "value": "proposed_model"}, {"source": "Rethinking the Inception Architecture for Computer Vision", "target": "ILSVRC 2012 classification challenge validation set", "value": "evaluated_on"}, {"source": "Rethinking the Inception Architecture for Computer Vision", "target": "top-1 error", "value": "uses_metric"}, {"source": "Rethinking the Inception Architecture for Computer Vision", "target": "top-5 error", "value": "uses_metric"}, {"source": "Neural Machine Translation by Jointly Learning to Align and Translate", "target": "encoder-decoder", "value": "proposed_model"}, {"source": "Neural Machine Translation by Jointly Learning to Align and Translate", "target": "phrase-based system", "value": "baseline_model"}, {"source": "Neural Machine Translation by Jointly Learning to Align and Translate", "target": "English-to-French translation", "value": "evaluated_on"}, {"source": "Neural Machine Translation by Jointly Learning to Align and Translate", "target": "translation performance", "value": "uses_metric"}, {"source": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation", "target": "RNN Encoder-Decoder", "value": "proposed_model"}, {"source": "RNN Encoder-Decoder", "target": "statistical machine translation system", "value": "baseline_model"}, {"source": "RNN Encoder-Decoder", "target": "statistical machine translation system", "value": "evaluated_on"}, {"source": "statistical machine translation system", "target": "log-linear model", "value": "uses_metric"}, {"source": "Sequence to Sequence Learning with Neural Networks", "target": "LSTM", "value": "proposed_model"}, {"source": "Sequence to Sequence Learning with Neural Networks", "target": "phrase-based SMT system", "value": "baseline_model"}, {"source": "Sequence to Sequence Learning with Neural Networks", "target": "WMT'14 dataset", "value": "evaluated_on"}, {"source": "LSTM", "target": "BLEU", "value": "uses_metric"}, {"source": "phrase-based SMT system", "target": "BLEU", "value": "uses_metric"}, {"source": "Xception: Deep Learning with Depthwise Separable Convolutions", "target": "Xception", "value": "proposed_model"}, {"source": "Xception: Deep Learning with Depthwise Separable Convolutions", "target": "Inception V3", "value": "baseline_model"}, {"source": "Xception", "target": "ImageNet", "value": "evaluated_on"}, {"source": "Xception", "target": "larger image classification dataset comprising 350 million images and 17,000 classes", "value": "evaluated_on"}, {"source": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling", "target": "gated recurrent unit (GRU)", "value": "proposed_model"}, {"source": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling", "target": "long short-term memory (LSTM)", "value": "baseline_model"}, {"source": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling", "target": "tanh units", "value": "baseline_model"}, {"source": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling", "target": "polyphonic music modeling", "value": "evaluated_on"}, {"source": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling", "target": "speech signal modeling", "value": "evaluated_on"}, {"source": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "target": "InstaDrive", "value": "proposed_model"}, {"source": "InstaDrive", "target": "nuScenes", "value": "evaluated_on"}, {"source": "InstaDrive", "target": "CARLA", "value": "evaluated_on"}, {"source": "InstaDrive", "target": "video generation quality", "value": "uses_metric"}, {"source": "InstaDrive", "target": "safety evaluation", "value": "uses_metric"}, {"source": "CNC-VLM: An RLHF-optimized industrial large vision-language model with multimodal learning for imbalanced CNC fault detection", "target": "CNC-VLM", "value": "proposed_model"}, {"source": "CNC-VLM", "target": "CNC fault detection dataset", "value": "evaluated_on"}, {"source": "CNC-VLM", "target": "Accuracy", "value": "uses_metric"}, {"source": "CNC-VLM", "target": "F1-score", "value": "uses_metric"}, {"source": "UAV-based quantitative crack measurement for bridges integrating four-point laser metric calibration and mamba segmentation", "target": "mamba segmentation", "value": "proposed_model"}, {"source": "UAV-based quantitative crack measurement for bridges integrating four-point laser metric calibration and mamba segmentation", "target": "four-point laser metric calibration", "value": "uses_metric"}, {"source": "DiffusionEngine: Diffusion model is scalable data engine for object detection", "target": "DiffusionEngine", "value": "proposed_model"}, {"source": "Enhanced Transformer-BiLSTM Deep Learning Framework for Day-Ahead Energy Price Forecasting", "target": "Transformer and Bidirectional Long Short-Term Memory (BiLSTM) model", "value": "proposed_model"}, {"source": "Enhanced Transformer-BiLSTM Deep Learning Framework for Day-Ahead Energy Price Forecasting", "target": "New York Independent System Operator", "value": "evaluated_on"}, {"source": "Enhanced Transformer-BiLSTM Deep Learning Framework for Day-Ahead Energy Price Forecasting", "target": "MAE", "value": "uses_metric"}, {"source": "Enhanced Transformer-BiLSTM Deep Learning Framework for Day-Ahead Energy Price Forecasting", "target": "RMSE", "value": "uses_metric"}, {"source": "Enhanced Transformer-BiLSTM Deep Learning Framework for Day-Ahead Energy Price Forecasting", "target": "sMAPE", "value": "uses_metric"}, {"source": "Enhanced Transformer-BiLSTM Deep Learning Framework for Day-Ahead Energy Price Forecasting", "target": "MAPE", "value": "uses_metric"}, {"source": "Enhanced Transformer-BiLSTM Deep Learning Framework for Day-Ahead Energy Price Forecasting", "target": "R\u00b2", "value": "uses_metric"}, {"source": "Conditional Generative Adversarial Network-based framework for multi-feature uncertainty modeling in energy systems", "target": "Conditional Generative Adversarial Network", "value": "proposed_model"}, {"source": "CityVLM: Towards sustainable urban development via multi-view coordinated vision\u2013language model", "target": "CityVLM", "value": "proposed_model"}, {"source": "FullPerception: Network-Level Collaborative Perception for Eliminating Vehicular Blind Spots", "target": "FullPerception", "value": "proposed_model"}, {"source": "FullPerception: Network-Level Collaborative Perception for Eliminating Vehicular Blind Spots", "target": "Proactive Conflict-free Scheduling (PCS)", "value": "proposed_model"}, {"source": "FullPerception", "target": "single-vehicle systems", "value": "baseline_model"}, {"source": "FullPerception", "target": "existing scheduling methods", "value": "baseline_model"}, {"source": "FullPerception", "target": "large-scale comprehensive joint simulation experiments", "value": "evaluated_on"}, {"source": "FullPerception", "target": "perception accuracy", "value": "uses_metric"}, {"source": "ImageNet classification with deep convolutional neural networks", "target": "deep convolutional neural networks", "value": "proposed_model"}, {"source": "ImageNet classification with deep convolutional neural networks", "target": "ImageNet", "value": "evaluated_on"}, {"source": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "target": "ConvNet models", "value": "proposed_model"}, {"source": "ConvNet models", "target": "ImageNet Challenge 2014", "value": "evaluated_on"}, {"source": "ConvNet models", "target": "other datasets", "value": "evaluated_on"}, {"source": "ConvNet models", "target": "accuracy", "value": "uses_metric"}, {"source": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "target": "Region Proposal Network (RPN)", "value": "proposed_model"}, {"source": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "target": "SPPnet", "value": "baseline_model"}, {"source": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "target": "Fast R-CNN", "value": "baseline_model"}, {"source": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "target": "PASCAL VOC 2007", "value": "evaluated_on"}, {"source": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "target": "PASCAL VOC 2012", "value": "evaluated_on"}, {"source": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "target": "MS COCO", "value": "evaluated_on"}, {"source": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "target": "ILSVRC", "value": "evaluated_on"}, {"source": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "target": "COCO 2015", "value": "evaluated_on"}, {"source": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "target": "object detection accuracy", "value": "uses_metric"}, {"source": "Microsoft COCO: Common Objects in Context", "target": "Deformable Parts Model", "value": "baseline_model"}, {"source": "Microsoft COCO: Common Objects in Context", "target": "PASCAL", "value": "evaluated_on"}, {"source": "Microsoft COCO: Common Objects in Context", "target": "ImageNet", "value": "evaluated_on"}, {"source": "Microsoft COCO: Common Objects in Context", "target": "SUN", "value": "evaluated_on"}, {"source": "Deformable Parts Model", "target": "bounding box detection", "value": "uses_metric"}, {"source": "Deformable Parts Model", "target": "segmentation detection", "value": "uses_metric"}, {"source": "Going deeper with convolutions", "target": "Inception", "value": "proposed_model"}, {"source": "Going deeper with convolutions", "target": "GoogLeNet", "value": "proposed_model"}, {"source": "Inception", "target": "ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014)", "value": "evaluated_on"}, {"source": "GoogLeNet", "target": "ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014)", "value": "evaluated_on"}, {"source": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "target": "Batch Normalization", "value": "proposed_model"}, {"source": "Batch Normalization", "target": "ImageNet", "value": "evaluated_on"}, {"source": "Batch Normalization", "target": "top-5 validation error", "value": "uses_metric"}, {"source": "Batch Normalization", "target": "test error", "value": "uses_metric"}, {"source": "ImageNet Large Scale Visual Recognition Challenge", "target": "ImageNet", "value": "evaluated_on"}, {"source": "ImageNet Large Scale Visual Recognition Challenge", "target": "object category classification", "value": "uses_metric"}, {"source": "ImageNet Large Scale Visual Recognition Challenge", "target": "object detection", "value": "uses_metric"}, {"source": "ImageNet Large Scale Visual Recognition Challenge", "target": "human accuracy", "value": "uses_metric"}, {"source": "Fully convolutional networks for semantic segmentation", "target": "fully convolutional networks", "value": "proposed_model"}, {"source": "fully convolutional networks", "target": "AlexNet", "value": "baseline_model"}, {"source": "fully convolutional networks", "target": "VGG net", "value": "baseline_model"}, {"source": "fully convolutional networks", "target": "GoogLeNet", "value": "baseline_model"}, {"source": "fully convolutional networks", "target": "PASCAL VOC", "value": "evaluated_on"}, {"source": "fully convolutional networks", "target": "NYUDv2", "value": "evaluated_on"}, {"source": "fully convolutional networks", "target": "SIFT Flow", "value": "evaluated_on"}, {"source": "fully convolutional networks", "target": "mean IU", "value": "uses_metric"}, {"source": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning", "target": "FLOT", "value": "proposed_model"}, {"source": "FLOT", "target": "GTSRB", "value": "evaluated_on"}, {"source": "FLOT", "target": "KBTS", "value": "evaluated_on"}, {"source": "FLOT", "target": "CIFAR10", "value": "evaluated_on"}, {"source": "FLOT", "target": "EMNIST", "value": "evaluated_on"}, {"source": "FLOT", "target": "accuracy", "value": "uses_metric"}, {"source": "FLOT", "target": "scalability", "value": "uses_metric"}, {"source": "WarmGait: Thermal Array-Based Gait Recognition for Privacy-Preserving Person Re-ID", "target": "WarmGait", "value": "proposed_model"}, {"source": "WarmGait", "target": "thermal array sensors", "value": "evaluated_on"}, {"source": "WarmGait", "target": "average recognition accuracy", "value": "uses_metric"}, {"source": "Noise Perception Self-Supervised Learning for Unsupervised Person Re-Identification", "target": "NPSSL", "value": "proposed_model"}, {"source": "NPSSL", "target": "Duke dataset", "value": "evaluated_on"}, {"source": "Noise Perception Self-Supervised Learning for Unsupervised Person Re-Identification", "target": "Unsupervised Domain Adaptation", "value": "baseline_model"}, {"source": "NPSSL", "target": "Noise Perception Self-Paced Learning", "value": "uses_metric"}, {"source": "Towards Reliable Tracking: An Uncertainty-Aware Siamese Tracker", "target": "Uncertainty-Aware Siamese Network", "value": "proposed_model"}, {"source": "Towards Reliable Tracking: An Uncertainty-Aware Siamese Tracker", "target": "VOT2018", "value": "evaluated_on"}, {"source": "Towards Reliable Tracking: An Uncertainty-Aware Siamese Tracker", "target": "VOT2019", "value": "evaluated_on"}, {"source": "Towards Reliable Tracking: An Uncertainty-Aware Siamese Tracker", "target": "OTB100", "value": "evaluated_on"}, {"source": "Towards Reliable Tracking: An Uncertainty-Aware Siamese Tracker", "target": "NFS", "value": "evaluated_on"}, {"source": "Towards Reliable Tracking: An Uncertainty-Aware Siamese Tracker", "target": "UAV123", "value": "evaluated_on"}, {"source": "Towards Reliable Tracking: An Uncertainty-Aware Siamese Tracker", "target": "LaSOT", "value": "evaluated_on"}, {"source": "Towards Reliable Tracking: An Uncertainty-Aware Siamese Tracker", "target": "TrackingNet", "value": "evaluated_on"}, {"source": "Towards Reliable Tracking: An Uncertainty-Aware Siamese Tracker", "target": "Got-10 k", "value": "evaluated_on"}, {"source": "Bridging the gap, not forcing the tie: dual-space alignment and fusion framework for toxic memes detection", "target": "dual-space alignment and fusion framework", "value": "proposed_model"}, {"source": "DCM-Net: A novel dual-branch CNN-Mamba cross-layer feature fusion network for medical image segmentation", "target": "DCM-Net", "value": "proposed_model"}, {"source": "Auto-Encoding Variational Bayes", "target": "stochastic variational inference and learning algorithm", "value": "proposed_model"}, {"source": "Auto-Encoding Variational Bayes", "target": "reparameterization of the variational lower bound", "value": "proposed_model"}, {"source": "Auto-Encoding Variational Bayes", "target": "approximate inference model", "value": "proposed_model"}, {"source": "stochastic variational inference and learning algorithm", "target": "i.i.d. datasets", "value": "evaluated_on"}, {"source": "reparameterization of the variational lower bound", "target": "variational lower bound", "value": "uses_metric"}, {"source": "approximate inference model", "target": "i.i.d. datasets", "value": "evaluated_on"}, {"source": "Speech recognition with deep recurrent neural networks", "target": "deep recurrent neural networks", "value": "proposed_model"}, {"source": "Speech recognition with deep recurrent neural networks", "target": "deep Long Short-term Memory RNNs", "value": "proposed_model"}, {"source": "Speech recognition with deep recurrent neural networks", "target": "deep feedforward networks", "value": "baseline_model"}, {"source": "deep Long Short-term Memory RNNs", "target": "TIMIT phoneme recognition benchmark", "value": "evaluated_on"}, {"source": "deep Long Short-term Memory RNNs", "target": "test set error", "value": "uses_metric"}, {"source": "Improving neural networks by preventing co-adaptation of feature detectors", "target": "dropout", "value": "proposed_model"}, {"source": "dropout", "target": "feedforward neural network", "value": "baseline_model"}, {"source": "dropout", "target": "small training set", "value": "evaluated_on"}, {"source": "dropout", "target": "held-out test data", "value": "evaluated_on"}, {"source": "dropout", "target": "speech recognition", "value": "uses_metric"}, {"source": "dropout", "target": "object recognition", "value": "uses_metric"}, {"source": "ADADELTA: An Adaptive Learning Rate Method", "target": "ADADELTA", "value": "proposed_model"}, {"source": "ADADELTA: An Adaptive Learning Rate Method", "target": "MNIST digit classification task", "value": "evaluated_on"}, {"source": "ADADELTA: An Adaptive Learning Rate Method", "target": "large scale voice dataset", "value": "evaluated_on"}, {"source": "Learning Word Vectors for Sentiment Analysis", "target": "Word Vectors", "value": "proposed_model"}, {"source": "Learning Word Vectors for Sentiment Analysis", "target": "Sentiment Analysis", "value": "evaluated_on"}, {"source": "Generating Sequences With Recurrent Neural Networks", "target": "Long Short-term Memory recurrent neural networks", "value": "proposed_model"}, {"source": "Generating Sequences With Recurrent Neural Networks", "target": "text", "value": "evaluated_on"}, {"source": "Generating Sequences With Recurrent Neural Networks", "target": "online handwriting", "value": "evaluated_on"}, {"source": "Weakly Supervised Image Dehazing via Physics-Based Decomposition", "target": "PBD", "value": "proposed_model"}, {"source": "Weakly Supervised Image Dehazing via Physics-Based Decomposition", "target": "GAN", "value": "baseline_model"}, {"source": "PBD", "target": "seven benchmarks", "value": "evaluated_on"}, {"source": "PBD", "target": "reconstruction loss", "value": "uses_metric"}, {"source": "A Machine Learning Approach for Face Mask Detection System with AdamW Optimizer", "target": "AdamW", "value": "proposed_model"}, {"source": "A Machine Learning Approach for Face Mask Detection System with AdamW Optimizer", "target": "Adam", "value": "baseline_model"}, {"source": "A Machine Learning Approach for Face Mask Detection System with AdamW Optimizer", "target": "face mask detection model", "value": "evaluated_on"}, {"source": "A Machine Learning Approach for Face Mask Detection System with AdamW Optimizer", "target": "accuracy", "value": "uses_metric"}, {"source": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "target": "Engram", "value": "proposed_model"}, {"source": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "target": "Mixture-of-Experts (MoE)", "value": "baseline_model"}, {"source": "Engram", "target": "MMLU", "value": "evaluated_on"}, {"source": "Engram", "target": "CMMLU", "value": "evaluated_on"}, {"source": "Engram", "target": "BBH", "value": "evaluated_on"}, {"source": "Engram", "target": "ARC-Challenge", "value": "evaluated_on"}, {"source": "Engram", "target": "HumanEval", "value": "evaluated_on"}, {"source": "Engram", "target": "MATH", "value": "evaluated_on"}, {"source": "Engram", "target": "Multi-Query NIAH", "value": "evaluated_on"}, {"source": "Engram", "target": "MMLU", "value": "uses_metric"}, {"source": "Engram", "target": "CMMLU", "value": "uses_metric"}, {"source": "Engram", "target": "BBH", "value": "uses_metric"}, {"source": "Engram", "target": "ARC-Challenge", "value": "uses_metric"}, {"source": "Engram", "target": "HumanEval", "value": "uses_metric"}, {"source": "Engram", "target": "MATH", "value": "uses_metric"}, {"source": "Engram", "target": "Multi-Query NIAH", "value": "uses_metric"}, {"source": "Probabilistic hierarchical interpolation and interpretable neural network configurations for flood prediction", "target": "Neural Hierarchical Interpolation for Time Series Forecasting (N-HiTS)", "value": "proposed_model"}, {"source": "Probabilistic hierarchical interpolation and interpretable neural network configurations for flood prediction", "target": "Network-Based Expansion Analysis for Interpretable Time Series Forecasting (N-BEATS)", "value": "proposed_model"}, {"source": "Probabilistic hierarchical interpolation and interpretable neural network configurations for flood prediction", "target": "long short-term memory (LSTM)", "value": "baseline_model"}, {"source": "Probabilistic hierarchical interpolation and interpretable neural network configurations for flood prediction", "target": "two headwater streams in Georgia and North Carolina, USA", "value": "evaluated_on"}, {"source": "Neural Hierarchical Interpolation for Time Series Forecasting (N-HiTS)", "target": "Multi-Quantile Loss", "value": "uses_metric"}, {"source": "Network-Based Expansion Analysis for Interpretable Time Series Forecasting (N-BEATS)", "target": "Multi-Quantile Loss", "value": "uses_metric"}, {"source": "Neural Hierarchical Interpolation for Time Series Forecasting (N-HiTS)", "target": "95th percentile prediction uncertainty (95 PPU)", "value": "uses_metric"}, {"source": "Network-Based Expansion Analysis for Interpretable Time Series Forecasting (N-BEATS)", "target": "95th percentile prediction uncertainty (95 PPU)", "value": "uses_metric"}, {"source": "Generating an annual 30 m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "target": "NASA-IBM geospatial foundation model", "value": "proposed_model"}, {"source": "Generating an annual 30 m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "target": "harmonized Landsat and Sentinel-2 data", "value": "evaluated_on"}, {"source": "Low-Resolution Massive MIMO Channel Estimation With LSTM Attention-Based CBDNet", "target": "LA-CBDNet", "value": "proposed_model"}, {"source": "Low-Resolution Massive MIMO Channel Estimation With LSTM Attention-Based CBDNet", "target": "benchmark approaches", "value": "baseline_model"}, {"source": "Low-Resolution Massive MIMO Channel Estimation With LSTM Attention-Based CBDNet", "target": "comparative methods", "value": "baseline_model"}, {"source": "LA-CBDNet", "target": "one-bit received signals", "value": "evaluated_on"}, {"source": "LA-CBDNet", "target": "varying SNRs", "value": "uses_metric"}, {"source": "LA-CBDNet", "target": "different pilot lengths", "value": "uses_metric"}, {"source": "LA-CBDNet", "target": "number of users", "value": "uses_metric"}, {"source": "Quantum solver for single-impurity Anderson models with particle-hole symmetry", "target": "variational quantum eigensolver (VQE)", "value": "proposed_model"}, {"source": "Quantum solver for single-impurity Anderson models with particle-hole symmetry", "target": "Anderson impurity model (AIM)", "value": "evaluated_on"}, {"source": "Quantum solver for single-impurity Anderson models with particle-hole symmetry", "target": "density of states (DOS)", "value": "uses_metric"}, {"source": "Quantum solver for single-impurity Anderson models with particle-hole symmetry", "target": "quantum-computed moment (QCM)", "value": "uses_metric"}, {"source": "Quantum solver for single-impurity Anderson models with particle-hole symmetry", "target": "impurity Green's function", "value": "uses_metric"}, {"source": "Sentinel-1 SAR-based globally distributed co-seismic landslide detection by deep neural networks", "target": "Deep Neural Networks", "value": "proposed_model"}, {"source": "Deep Neural Networks", "target": "11 earthquake-induced widespread landslide events", "value": "evaluated_on"}, {"source": "Deep Neural Networks", "target": "Haiti (2021) and Sumatra (2022) events", "value": "evaluated_on"}, {"source": "Deep Neural Networks", "target": "F1-score", "value": "uses_metric"}, {"source": "Increasing resolution and accuracy in sub-seasonal forecasting through 3D U-Net: the western US", "target": "3D U-Net", "value": "proposed_model"}, {"source": "Increasing resolution and accuracy in sub-seasonal forecasting through 3D U-Net: the western US", "target": "NWP models", "value": "baseline_model"}, {"source": "3D U-Net", "target": "ECMWF ensemble forecasting system", "value": "evaluated_on"}, {"source": "3D U-Net", "target": "PRISM data", "value": "evaluated_on"}, {"source": "3D U-Net", "target": "pattern correlation coefficient", "value": "uses_metric"}, {"source": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications", "target": "MobileNets", "value": "proposed_model"}, {"source": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications", "target": "ImageNet", "value": "evaluated_on"}, {"source": "Distilling the Knowledge in a Neural Network", "target": "single model", "value": "proposed_model"}, {"source": "Distilling the Knowledge in a Neural Network", "target": "specialist models", "value": "proposed_model"}, {"source": "Distilling the Knowledge in a Neural Network", "target": "MNIST", "value": "evaluated_on"}, {"source": "single model", "target": "ensemble of models", "value": "baseline_model"}, {"source": "Visualizing and Understanding Convolutional Networks", "target": "Krizhevsky et al.", "value": "proposed_model"}, {"source": "Visualizing and Understanding Convolutional Networks", "target": "ImageNet", "value": "evaluated_on"}, {"source": "Visualizing and Understanding Convolutional Networks", "target": "Caltech-101", "value": "evaluated_on"}, {"source": "Visualizing and Understanding Convolutional Networks", "target": "Caltech-256", "value": "evaluated_on"}, {"source": "Visualizing and Understanding Convolutional Networks", "target": "ImageNet classification benchmark", "value": "uses_metric"}, {"source": "Visualizing and Understanding Convolutional Networks", "target": "state-of-the-art results", "value": "uses_metric"}, {"source": "mHC: Manifold-Constrained Hyper-Connections", "target": "Manifold-Constrained Hyper-Connections (mHC)", "value": "proposed_model"}, {"source": "mHC: Manifold-Constrained Hyper-Connections", "target": "Hyper-Connections (HC)", "value": "baseline_model"}, {"source": "Dataset Purification-Driven Lightweight Deep Learning Model Construction for Empty-Dish Recycling Robot", "target": "OGNet", "value": "proposed_model"}, {"source": "Dataset Purification-Driven Lightweight Deep Learning Model Construction for Empty-Dish Recycling Robot", "target": "YOLO-OG", "value": "proposed_model"}, {"source": "OGNet", "target": "Dish-10", "value": "evaluated_on"}, {"source": "YOLO-OG", "target": "Dish-10", "value": "evaluated_on"}, {"source": "YOLO-OG", "target": "Dish-20", "value": "evaluated_on"}, {"source": "YOLO-OG", "target": "mean Average Precision (mAP)", "value": "uses_metric"}, {"source": "Physics-guided deep neural networks for bathymetric mapping using Sentinel-2 multi-spectral imagery", "target": "HybridBathNet", "value": "proposed_model"}, {"source": "HybridBathNet", "target": "state-of-the-art methods", "value": "baseline_model"}, {"source": "HybridBathNet", "target": "diverse island regions", "value": "evaluated_on"}, {"source": "HybridBathNet", "target": "bathymetric inversion accuracy", "value": "uses_metric"}, {"source": "HybridBathNet", "target": "accuracy", "value": "uses_metric"}, {"source": "HybridBathNet", "target": "generalization capability", "value": "uses_metric"}, {"source": "Spike Memory Transformer: An Energy-Efficient Model in Distributed Learning Framework for Autonomous Depression Detection", "target": "spike memory transformer (SMT)", "value": "proposed_model"}, {"source": "Spike Memory Transformer: An Energy-Efficient Model in Distributed Learning Framework for Autonomous Depression Detection", "target": "Computation-Oriented Hierarchical Depression Detection Internet of Things (IoT) Framework", "value": "proposed_model"}, {"source": "spike memory transformer (SMT)", "target": "D-Vlog dataset", "value": "evaluated_on"}, {"source": "spike memory transformer (SMT)", "target": "accuracy", "value": "uses_metric"}, {"source": "spike memory transformer (SMT)", "target": "inference power consumption", "value": "uses_metric"}, {"source": "spike memory transformer (SMT)", "target": "classical deep learning methods", "value": "baseline_model"}, {"source": "Multi-Perspective Semantic Segmentation of Ground Penetrating Radar Images for Pavement Subsurface Objects", "target": "AttnGPRNet", "value": "proposed_model"}, {"source": "Multi-Perspective Semantic Segmentation of Ground Penetrating Radar Images for Pavement Subsurface Objects", "target": "multi-view dataset using 3D GPR scans from over 100 kilometers of urban roads", "value": "evaluated_on"}, {"source": "AttnGPRNet", "target": "mIoU", "value": "uses_metric"}, {"source": "AttnGPRNet", "target": "F1 score", "value": "uses_metric"}, {"source": "Seeing Before Reasoning: A Unified Framework for Generalizable and Explainable Fake Image Detection", "target": "Forensic-Chat", "value": "proposed_model"}, {"source": "Seeing Before Reasoning: A Unified Framework for Generalizable and Explainable Fake Image Detection", "target": "ExplainFake-Bench", "value": "proposed_model"}, {"source": "Forensic-Chat", "target": "multimodal large language models (MLLMs)", "value": "baseline_model"}, {"source": "Forensic-Chat", "target": "ExplainFake-Bench", "value": "evaluated_on"}, {"source": "Forensic-Chat", "target": "generalization", "value": "uses_metric"}, {"source": "Forensic-Chat", "target": "explainability", "value": "uses_metric"}, {"source": "DenseNet Model with Attention Mechanisms for Robust Date Fruit Image Classification", "target": "DenseNet with Attention Mechanisms", "value": "proposed_model"}, {"source": "DenseNet Model with Attention Mechanisms for Robust Date Fruit Image Classification", "target": "Date Fruit Image Dataset", "value": "evaluated_on"}, {"source": "DenseNet Model with Attention Mechanisms for Robust Date Fruit Image Classification", "target": "Classification Accuracy", "value": "uses_metric"}, {"source": "Evaluation of deep learning models using explainable AI with qualitative and quantitative analysis for rice leaf disease detection", "target": "ResNet50", "value": "proposed_model"}, {"source": "Evaluation of deep learning models using explainable AI with qualitative and quantitative analysis for rice leaf disease detection", "target": "InceptionResNetV2", "value": "proposed_model"}, {"source": "Evaluation of deep learning models using explainable AI with qualitative and quantitative analysis for rice leaf disease detection", "target": "DenseNet 201", "value": "proposed_model"}, {"source": "Evaluation of deep learning models using explainable AI with qualitative and quantitative analysis for rice leaf disease detection", "target": "InceptionV3", "value": "proposed_model"}, {"source": "Evaluation of deep learning models using explainable AI with qualitative and quantitative analysis for rice leaf disease detection", "target": "EfficientNetB0", "value": "proposed_model"}, {"source": "Evaluation of deep learning models using explainable AI with qualitative and quantitative analysis for rice leaf disease detection", "target": "Xception", "value": "proposed_model"}, {"source": "Evaluation of deep learning models using explainable AI with qualitative and quantitative analysis for rice leaf disease detection", "target": "VGG16", "value": "proposed_model"}, {"source": "Evaluation of deep learning models using explainable AI with qualitative and quantitative analysis for rice leaf disease detection", "target": "AlexNet", "value": "proposed_model"}, {"source": "Evaluation of deep learning models using explainable AI with qualitative and quantitative analysis for rice leaf disease detection", "target": "Local Interpretable Model-agnostic Explanations (LIME)", "value": "baseline_model"}, {"source": "Evaluation of deep learning models using explainable AI with qualitative and quantitative analysis for rice leaf disease detection", "target": "rice leaf disease detection dataset", "value": "evaluated_on"}, {"source": "Evaluation of deep learning models using explainable AI with qualitative and quantitative analysis for rice leaf disease detection", "target": "classification accuracy", "value": "uses_metric"}, {"source": "Evaluation of deep learning models using explainable AI with qualitative and quantitative analysis for rice leaf disease detection", "target": "precision", "value": "uses_metric"}, {"source": "Evaluation of deep learning models using explainable AI with qualitative and quantitative analysis for rice leaf disease detection", "target": "recall", "value": "uses_metric"}, {"source": "Evaluation of deep learning models using explainable AI with qualitative and quantitative analysis for rice leaf disease detection", "target": "Intersection over Union (IoU)", "value": "uses_metric"}, {"source": "Evaluation of deep learning models using explainable AI with qualitative and quantitative analysis for rice leaf disease detection", "target": "Dice Similarity Coefficient (DSC)", "value": "uses_metric"}, {"source": "Evaluation of deep learning models using explainable AI with qualitative and quantitative analysis for rice leaf disease detection", "target": "overfitting ratio", "value": "uses_metric"}, {"source": "Wind turbine blade surface defect detection model based on improved you only look once version 10 small and integrated compression", "target": "improved you only look once version 10 small and integrated compression", "value": "proposed_model"}, {"source": "Attention is All you Need", "target": "Transformer", "value": "proposed_model"}, {"source": "Transformer", "target": "WMT 2014 English-to-German translation task", "value": "evaluated_on"}, {"source": "Transformer", "target": "WMT 2014 English-to-French translation task", "value": "evaluated_on"}, {"source": "Transformer", "target": "BLEU", "value": "uses_metric"}, {"source": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "target": "T5", "value": "proposed_model"}, {"source": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "target": "Colossal Clean Crawled Corpus", "value": "evaluated_on"}, {"source": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "target": "summarization", "value": "uses_metric"}, {"source": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "target": "question answering", "value": "uses_metric"}, {"source": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "target": "text classification", "value": "uses_metric"}, {"source": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium", "target": "Two Time-Scale Update Rule", "value": "proposed_model"}, {"source": "Two Time-Scale Update Rule", "target": "GANs", "value": "baseline_model"}, {"source": "nuScenes: A Multimodal Dataset for Autonomous Driving", "target": "nuScenes", "value": "proposed_model"}, {"source": "nuScenes: A Multimodal Dataset for Autonomous Driving", "target": "KITTI", "value": "baseline_model"}, {"source": "nuScenes: A Multimodal Dataset for Autonomous Driving", "target": "nuScenes", "value": "evaluated_on"}, {"source": "nuScenes: A Multimodal Dataset for Autonomous Driving", "target": "3D detection and tracking metrics", "value": "uses_metric"}, {"source": "CARLA: An Open Urban Driving Simulator", "target": "classic modular pipeline", "value": "proposed_model"}, {"source": "CARLA: An Open Urban Driving Simulator", "target": "end-to-end model trained via imitation learning", "value": "proposed_model"}, {"source": "CARLA: An Open Urban Driving Simulator", "target": "end-to-end model trained via reinforcement learning", "value": "proposed_model"}, {"source": "classic modular pipeline", "target": "end-to-end model trained via imitation learning", "value": "baseline_model"}, {"source": "classic modular pipeline", "target": "end-to-end model trained via reinforcement learning", "value": "baseline_model"}, {"source": "classic modular pipeline", "target": "CARLA", "value": "evaluated_on"}, {"source": "end-to-end model trained via imitation learning", "target": "CARLA", "value": "evaluated_on"}, {"source": "end-to-end model trained via reinforcement learning", "target": "CARLA", "value": "evaluated_on"}, {"source": "classic modular pipeline", "target": "metrics provided by CARLA", "value": "uses_metric"}, {"source": "end-to-end model trained via imitation learning", "target": "metrics provided by CARLA", "value": "uses_metric"}, {"source": "end-to-end model trained via reinforcement learning", "target": "metrics provided by CARLA", "value": "uses_metric"}, {"source": "Adding Conditional Control to Text-to-Image Diffusion Models", "target": "ControlNet", "value": "proposed_model"}, {"source": "ControlNet", "target": "Stable Diffusion", "value": "baseline_model"}, {"source": "ControlNet", "target": "small (<50k) and large (>1m) datasets", "value": "evaluated_on"}, {"source": "Scalable Diffusion Models with Transformers", "target": "Diffusion Transformers (DiTs)", "value": "proposed_model"}, {"source": "Scalable Diffusion Models with Transformers", "target": "DiT-XL/2", "value": "proposed_model"}, {"source": "Scalable Diffusion Models with Transformers", "target": "U-Net", "value": "baseline_model"}, {"source": "Diffusion Transformers (DiTs)", "target": "ImageNet 512x512", "value": "evaluated_on"}, {"source": "Diffusion Transformers (DiTs)", "target": "ImageNet 256x256", "value": "evaluated_on"}, {"source": "DiT-XL/2", "target": "ImageNet 512x512", "value": "evaluated_on"}, {"source": "DiT-XL/2", "target": "ImageNet 256x256", "value": "evaluated_on"}, {"source": "Diffusion Transformers (DiTs)", "target": "FID", "value": "uses_metric"}, {"source": "Diffusion Transformers (DiTs)", "target": "Gflops", "value": "uses_metric"}, {"source": "DiT-XL/2", "target": "FID", "value": "uses_metric"}, {"source": "SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis", "target": "SDXL", "value": "proposed_model"}, {"source": "SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis", "target": "Stable Diffusion", "value": "baseline_model"}, {"source": "SDXL", "target": "refinement model", "value": "proposed_model"}, {"source": "Domain randomization for transferring deep neural networks from simulation to the real world", "target": "deep neural network", "value": "proposed_model"}, {"source": "deep neural network", "target": "simulated images", "value": "evaluated_on"}, {"source": "deep neural network", "target": "real images", "value": "evaluated_on"}, {"source": "deep neural network", "target": "object localization", "value": "uses_metric"}, {"source": "Domain randomization for transferring deep neural networks from simulation to the real world", "target": "object detector", "value": "proposed_model"}, {"source": "object detector", "target": "simulator with non-realistic random textures", "value": "evaluated_on"}, {"source": "object detector", "target": "grasping in a cluttered environment", "value": "uses_metric"}, {"source": "The SYNTHIA Dataset: A Large Collection of Synthetic Images for Semantic Segmentation of Urban Scenes", "target": "SYNTHIA", "value": "proposed_model"}, {"source": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "target": "Sora", "value": "proposed_model"}, {"source": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "target": "MNIST", "value": "baseline_model"}, {"source": "OmniNWM: Omniscient Driving Navigation World Models", "target": "OmniNWM", "value": "proposed_model"}, {"source": "OmniNWM: Omniscient Driving Navigation World Models", "target": "Existing models", "value": "baseline_model"}, {"source": "OmniNWM", "target": "panoramic videos", "value": "evaluated_on"}, {"source": "OmniNWM", "target": "video generation", "value": "uses_metric"}, {"source": "OmniNWM", "target": "control accuracy", "value": "uses_metric"}, {"source": "OmniNWM", "target": "long-horizon stability", "value": "uses_metric"}, {"source": "ConsisDrive: Identity-Preserving Driving World Models for Video Generation by Instance Mask", "target": "ConsisDrive", "value": "proposed_model"}, {"source": "ConsisDrive", "target": "nuScenes", "value": "evaluated_on"}, {"source": "ConsisDrive", "target": "driving video generation quality", "value": "uses_metric"}, {"source": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "target": "UniDriveDreamer", "value": "proposed_model"}, {"source": "UniDriveDreamer", "target": "previous state-of-the-art methods", "value": "baseline_model"}, {"source": "UniDriveDreamer", "target": "multi-camera video", "value": "evaluated_on"}, {"source": "UniDriveDreamer", "target": "LiDAR sequence", "value": "evaluated_on"}, {"source": "UniDriveDreamer", "target": "video generation", "value": "uses_metric"}, {"source": "UniDriveDreamer", "target": "LiDAR generation", "value": "uses_metric"}, {"source": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "target": "MAD-LTX", "value": "proposed_model"}, {"source": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "target": "SVD", "value": "baseline_model"}, {"source": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "target": "LTX", "value": "baseline_model"}, {"source": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "target": "video diffusion models", "value": "baseline_model"}, {"source": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "target": "driving world models", "value": "baseline_model"}, {"source": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "target": "autonomous driving", "value": "evaluated_on"}, {"source": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "target": "driving domains", "value": "evaluated_on"}, {"source": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "target": "structured motion", "value": "uses_metric"}, {"source": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "target": "physical and social plausibility", "value": "uses_metric"}, {"source": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "target": "compute", "value": "uses_metric"}, {"source": "View-Consistent Diffusion Representations for 3D-Consistent Video Generation", "target": "ViCoDR", "value": "proposed_model"}, {"source": "View-Consistent Diffusion Representations for 3D-Consistent Video Generation", "target": "camera-controlled video diffusion models", "value": "baseline_model"}, {"source": "ViCoDR", "target": "camera controlled image-to-video, text-to-video, and multi-view generation models", "value": "evaluated_on"}, {"source": "Fully Convolutional Networks for Semantic Segmentation", "target": "Fully Convolutional Networks", "value": "proposed_model"}, {"source": "Fully Convolutional Networks for Semantic Segmentation", "target": "AlexNet", "value": "baseline_model"}, {"source": "Fully Convolutional Networks for Semantic Segmentation", "target": "VGG net", "value": "baseline_model"}, {"source": "Fully Convolutional Networks for Semantic Segmentation", "target": "GoogLeNet", "value": "baseline_model"}, {"source": "Fully Convolutional Networks", "target": "PASCAL VOC", "value": "evaluated_on"}, {"source": "Fully Convolutional Networks", "target": "NYUDv2", "value": "evaluated_on"}, {"source": "Fully Convolutional Networks", "target": "SIFT Flow", "value": "evaluated_on"}, {"source": "Fully Convolutional Networks", "target": "mean IU", "value": "uses_metric"}, {"source": "Speech Recognition with Deep Recurrent Neural Networks", "target": "deep recurrent neural networks", "value": "proposed_model"}, {"source": "Speech Recognition with Deep Recurrent Neural Networks", "target": "deep Long Short-term Memory RNNs", "value": "proposed_model"}, {"source": "Speech Recognition with Deep Recurrent Neural Networks", "target": "deep feedforward networks", "value": "baseline_model"}, {"source": "Speech Recognition with Deep Recurrent Neural Networks", "target": "TIMIT phoneme recognition benchmark", "value": "evaluated_on"}, {"source": "Speech Recognition with Deep Recurrent Neural Networks", "target": "test set error", "value": "uses_metric"}, {"source": "nuScenes: A multimodal dataset for autonomous driving", "target": "nuScenes", "value": "proposed_model"}, {"source": "nuScenes: A multimodal dataset for autonomous driving", "target": "lidar based detection and tracking", "value": "baseline_model"}, {"source": "nuScenes: A multimodal dataset for autonomous driving", "target": "image based detection and tracking", "value": "baseline_model"}, {"source": "nuScenes: A multimodal dataset for autonomous driving", "target": "nuScenes", "value": "evaluated_on"}, {"source": "nuScenes: A multimodal dataset for autonomous driving", "target": "KITTI dataset", "value": "evaluated_on"}, {"source": "nuScenes: A multimodal dataset for autonomous driving", "target": "novel 3D detection and tracking metrics", "value": "uses_metric"}, {"source": "Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World", "target": "domain randomization", "value": "proposed_model"}, {"source": "domain randomization", "target": "simulated images", "value": "evaluated_on"}, {"source": "domain randomization", "target": "real images", "value": "evaluated_on"}, {"source": "domain randomization", "target": "object localization", "value": "uses_metric"}, {"source": "Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World", "target": "object detector", "value": "proposed_model"}, {"source": "object detector", "target": "grasping", "value": "uses_metric"}],
                    categories: [{"name": "Researcher"}, {"name": "AIPaper"}, {"name": "AIModel"}, {"name": "Metric"}, {"name": "Dataset"}],
                    roam: true,
                    label: { show: true, position: 'right', formatter: '{b}' },
                    edgeLabel: { fontSize: 11, formatter: '{c}' },
                    edgeSymbol: ['none', 'arrow'], edgeSymbolSize: 10,
                    lineStyle: { color: 'source', curveness: 0.3 },
                    force: { repulsion: 1500, edgeLength: 250 },
                    emphasis: { focus: 'adjacency', lineStyle: { width: 4 } }
                }]
            };
            myChart.setOption(option);
            setTimeout(function() { myChart.resize(); }, 100);
            window.addEventListener('resize', function() { myChart.resize(); });
        }
        if (document.readyState === 'loading') {
            document.addEventListener('DOMContentLoaded', initChart);
        } else {
            initChart();
        }
    </script>
</body>
</html>