{
  "paper_metadata": {
    "id": "1706.03762",
    "title": "Attention Is All You Need",
    "abstract": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.",
    "published_date": "2017-06-12",
    "pdf_url": "https://arxiv.org/pdf/1706.03762v7",
    "authors": [
      "Ashish Vaswani",
      "Noam Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "Lukasz Kaiser",
      "Illia Polosukhin"
    ]
  },
  "related_papers_count": {
    "references": 2,
    "citations": 2
  },
  "related_papers": [
    {
      "title": "Deep Residual Learning for Image Recognition",
      "arxiv_id": "",
      "abstract": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers.\n  The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.",
      "authors": [
        "Kaiming He",
        "Xiangyu Zhang",
        "Shaoqing Ren",
        "Jian Sun"
      ],
      "published_date": "2015-12-10",
      "pdf_url": "https://arxiv.org/pdf/1512.03385v1",
      "citation_count": null,
      "year": null
    },
    {
      "title": "Adam: A Method for Stochastic Optimization",
      "arxiv_id": "",
      "abstract": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.",
      "authors": [
        "Diederik P. Kingma",
        "Jimmy Ba"
      ],
      "published_date": "2014-12-22",
      "pdf_url": "https://arxiv.org/pdf/1412.6980v9",
      "citation_count": null,
      "year": null
    },
    {
      "title": "A comprehensive review of recommender systems: Transitioning from theory to practice",
      "arxiv_id": null,
      "abstract": "",
      "authors": [
        "Shaina Raza",
        "Mizanur Rahman",
        "Safiullah Kamawal",
        "Armin Toroghi",
        "Ananya Raval",
        "F. Navah",
        "Amirmohammad Kazemeini"
      ],
      "published_date": "2026",
      "pdf_url": "",
      "citation_count": 7,
      "year": 2026
    },
    {
      "title": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation",
      "arxiv_id": "",
      "abstract": "Autonomous driving relies on robust models trained on high-quality, large-scale multi-view driving videos. While world models offer a cost-effective solution for generating realistic driving videos, they struggle to maintain instance-level temporal consistency and spatial geometric fidelity. To address these challenges, we propose InstaDrive, a novel framework that enhances driving video realism through two key advancements: (1) Instance Flow Guider, which extracts and propagates instance features across frames to enforce temporal consistency, preserving instance identity over time. (2) Spatial Geometric Aligner, which improves spatial reasoning, ensures precise instance positioning, and explicitly models occlusion hierarchies. By incorporating these instance-aware mechanisms, InstaDrive achieves state-of-the-art video generation quality and enhances downstream autonomous driving tasks on the nuScenes dataset. Additionally, we utilize CARLA's autopilot to procedurally and stochastically simulate rare but safety-critical driving scenarios across diverse maps and regions, enabling rigorous safety evaluation for autonomous systems. Our project page is https://shanpoyang654.github.io/InstaDrive/page.html.",
      "authors": [
        "Zhuoran Yang",
        "Xi Guo",
        "Chenjing Ding",
        "Chiyu Wang",
        "Wei Wu",
        "Yanyong Zhang"
      ],
      "published_date": "2026-02-03",
      "pdf_url": "https://arxiv.org/pdf/2602.03242v1",
      "citation_count": null,
      "year": null
    },
    {
      "title": "ImageNet classification with deep convolutional neural networks",
      "arxiv_id": null,
      "abstract": "",
      "authors": [
        "A. Krizhevsky",
        "I. Sutskever",
        "Geoffrey E. Hinton"
      ],
      "published_date": "2012",
      "pdf_url": "",
      "citation_count": 126555,
      "year": 2012
    },
    {
      "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
      "arxiv_id": "1409.1556",
      "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.",
      "authors": [
        "Karen Simonyan",
        "Andrew Zisserman"
      ],
      "published_date": "2014-09-04",
      "pdf_url": "https://arxiv.org/pdf/1409.1556v6",
      "citation_count": 108937,
      "year": 2014
    },
    {
      "title": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects",
      "arxiv_id": null,
      "abstract": "",
      "authors": [
        "Yuqi Cheng",
        "Yunkang Cao",
        "Haiming Yao",
        "Wei Luo",
        "Cheng Jiang",
        "Hui Zhang",
        "Weiming Shen"
      ],
      "published_date": "2026",
      "pdf_url": "",
      "citation_count": 6,
      "year": 2026
    },
    {
      "title": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning",
      "arxiv_id": null,
      "abstract": "Federated learning (FL) has emerged as a promising solution to enable distributed learning without sharing sensitive data. However, FL is vulnerable to data poisoning attacks, where malicious clients inject malicious data during training to compromise the global model. Existing FL defenses suffer from the assumptions of independent and identically distributed (IID) model updates, asymptotic optimal error rate bounds, and strong convexity in the optimization problem. Hence, we propose a novel framework called Federated Learning Optimal Transport (FLOT) that leverages the Wasserstein barycentric technique to obtain a global model from a set of locally trained non-IID models on client devices. In addition, we introduce a loss function-based rejection (LFR) mechanism to suppress malicious updates and a dynamic weighting scheme to optimize the Wasserstein barycentric aggregation function. We provide the theoretical proof of the Byzantine resilience and convergence of FLOT to highlight its efficacy. We evaluate FLOT on four benchmark datasets: GTSRB, KBTS, CIFAR10, and EMNIST. The experimental results underscore the practical significance of FLOT as an effective defense mechanism against data poisoning attacks in FL while maintaining high accuracy and scalability. Also, we observe that FLOT serves as a robust client selection technique under no attack, which demonstrates its effectiveness.",
      "authors": [
        "Naveen Kumar Srinivasa",
        "Ajeet Rao Chalamala",
        "Kumar Singh",
        "Ieee Krishna Mohan Senior Member",
        "K. Naveen",
        "Srinivasa Rao",
        "Ajeet Kumar Singh"
      ],
      "published_date": "2026",
      "pdf_url": "",
      "citation_count": 5,
      "year": 2026
    },
    {
      "title": "Attention is All you Need",
      "arxiv_id": "1706.03762",
      "abstract": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.",
      "authors": [
        "Ashish Vaswani",
        "Noam Shazeer",
        "Niki Parmar",
        "Jakob Uszkoreit",
        "Llion Jones",
        "Aidan N. Gomez",
        "Lukasz Kaiser",
        "Illia Polosukhin"
      ],
      "published_date": "2017-06-12",
      "pdf_url": "https://arxiv.org/pdf/1706.03762v7",
      "citation_count": 164667,
      "year": 2017
    },
    {
      "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
      "arxiv_id": "1910.10683",
      "abstract": "Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts every language problem into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new \"Colossal Clean Crawled Corpus\", we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our dataset, pre-trained models, and code.",
      "authors": [
        "Colin Raffel",
        "Noam Shazeer",
        "Adam Roberts",
        "Katherine Lee",
        "Sharan Narang",
        "Michael Matena",
        "Yanqi Zhou",
        "Wei Li",
        "Peter J. Liu"
      ],
      "published_date": "2019",
      "pdf_url": "",
      "citation_count": 24191,
      "year": 2019
    },
    {
      "title": "Sora as a World Model? A Complete Survey on Text-to-Video Generation",
      "arxiv_id": "",
      "abstract": "The evolution of video generation from text, from animating MNIST to simulating the world with Sora, has progressed at a breakneck speed. Here, we systematically discuss how far text-to-video generation technology supports essential requirements in world modeling. We curate 250+ studies on text-based video synthesis and world modeling. We then observe that recent models increasingly support spatial, action, and strategic intelligences in world modeling through adherence to completeness, consistency, invention, as well as human interaction and control. We conclude that text-to-video generation is adept at world modeling, although homework in several aspects, such as the diversity-consistency trade-offs, remains to be addressed.",
      "authors": [
        "Fachrina Dewi Puspitasari",
        "Chaoning Zhang",
        "Joseph Cho",
        "Adnan Haider",
        "Noor Ul Eman",
        "Omer Amin",
        "Alexis Mankowski",
        "Muhammad Umair",
        "Jingyao Zheng",
        "Sheng Zheng",
        "Lik-Hang Lee",
        "Caiyan Qin",
        "Tae-Ho Kim",
        "Choong Seon Hong",
        "Yang Yang",
        "Heng Tao Shen"
      ],
      "published_date": "2024-03-08",
      "pdf_url": "https://arxiv.org/pdf/2403.05131v3",
      "citation_count": null,
      "year": null
    },
    {
      "title": "OmniNWM: Omniscient Driving Navigation World Models",
      "arxiv_id": "2510.18313",
      "abstract": "Autonomous driving world models are expected to work effectively across three core dimensions: state, action, and reward. Existing models, however, are typically restricted to limited state modalities, short video sequences, imprecise action control, and a lack of reward awareness. In this paper, we introduce OmniNWM, an omniscient panoramic navigation world model that addresses all three dimensions within a unified framework. For state, OmniNWM jointly generates panoramic videos of RGB, semantics, metric depth, and 3D occupancy. A flexible forcing strategy enables high-quality long-horizon auto-regressive generation. For action, we introduce a normalized panoramic Plucker ray-map representation that encodes input trajectories into pixel-level signals, enabling highly precise and generalizable control over panoramic video generation. Regarding reward, we move beyond learning reward functions with external image-based models: instead, we leverage the generated 3D occupancy to directly define rule-based dense rewards for driving compliance and safety. Extensive experiments demonstrate that OmniNWM achieves state-of-the-art performance in video generation, control accuracy, and long-horizon stability, while providing a reliable closed-loop evaluation framework through occupancy-grounded rewards. Project page is available at https://arlo0o.github.io/OmniNWM/.",
      "authors": [
        "Bohan Li",
        "Zhuang Ma",
        "Dalong Du",
        "Bao Peng",
        "Zhujin Liang",
        "Zhenqiang Liu",
        "Chao Ma",
        "Yueming Jin",
        "Hao Zhao",
        "Wenjun Zeng",
        "Xin Jin"
      ],
      "published_date": "2025",
      "pdf_url": "",
      "citation_count": 3,
      "year": 2025
    },
    {
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "arxiv_id": "",
      "abstract": "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications.\n  BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
      "authors": [
        "Jacob Devlin",
        "Ming-Wei Chang",
        "Kenton Lee",
        "Kristina Toutanova"
      ],
      "published_date": "2018-10-11",
      "pdf_url": "https://arxiv.org/pdf/1810.04805v2",
      "citation_count": null,
      "year": null
    },
    {
      "title": "Long Short-Term Memory",
      "arxiv_id": null,
      "abstract": "",
      "authors": [
        "Sepp Hochreiter",
        "J. Schmidhuber"
      ],
      "published_date": "1997",
      "pdf_url": "",
      "citation_count": 100313,
      "year": 1997
    },
    {
      "title": "Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond",
      "arxiv_id": "",
      "abstract": "General world models represent a crucial pathway toward achieving Artificial General Intelligence (AGI), serving as the cornerstone for various applications ranging from virtual environments to decision-making systems. Recently, the emergence of the Sora model has attained significant attention due to its remarkable simulation capabilities, which exhibits an incipient comprehension of physical laws. In this survey, we embark on a comprehensive exploration of the latest advancements in world models. Our analysis navigates through the forefront of generative methodologies in video generation, where world models stand as pivotal constructs facilitating the synthesis of highly realistic visual content. Additionally, we scrutinize the burgeoning field of autonomous-driving world models, meticulously delineating their indispensable role in reshaping transportation and urban mobility. Furthermore, we delve into the intricacies inherent in world models deployed within autonomous agents, shedding light on their profound significance in enabling intelligent interactions within dynamic environmental contexts. At last, we examine challenges and limitations of world models, and discuss their potential future directions. We hope this survey can serve as a foundational reference for the research community and inspire continued innovation. This survey will be regularly updated at: https://github.com/GigaAI-research/General-World-Models-Survey.",
      "authors": [
        "Zheng Zhu",
        "Xiaofeng Wang",
        "Wangbo Zhao",
        "Chen Min",
        "Bohan Li",
        "Nianchen Deng",
        "Min Dou",
        "Yuqi Wang",
        "Botian Shi",
        "Kai Wang",
        "Chi Zhang",
        "Yang You",
        "Zhaoxiang Zhang",
        "Dawei Zhao",
        "Liang Xiao",
        "Jian Zhao",
        "Jiwen Lu",
        "Guan Huang"
      ],
      "published_date": "2024-05-06",
      "pdf_url": "https://arxiv.org/pdf/2405.03520v2",
      "citation_count": null,
      "year": null
    },
    {
      "title": "Understanding World or Predicting Future? A Comprehensive Survey of World Models",
      "arxiv_id": "",
      "abstract": "The concept of world models has garnered significant attention due to advancements in multimodal large language models such as GPT-4 and video generation models such as Sora, which are central to the pursuit of artificial general intelligence. This survey offers a comprehensive review of the literature on world models. Generally, world models are regarded as tools for either understanding the present state of the world or predicting its future dynamics. This review presents a systematic categorization of world models, emphasizing two primary functions: (1) constructing internal representations to understand the mechanisms of the world, and (2) predicting future states to simulate and guide decision-making. Initially, we examine the current progress in these two categories. We then explore the application of world models in key domains, including generative games, autonomous driving, robotics, and social simulacra, with a focus on how each domain utilizes these aspects. Finally, we outline key challenges and provide insights into potential future research directions. We summarize the representative papers along with their code repositories in https://github.com/tsinghua-fib-lab/World-Model.",
      "authors": [
        "Jingtao Ding",
        "Yunke Zhang",
        "Yu Shang",
        "Jie Feng",
        "Yuheng Zhang",
        "Zefang Zong",
        "Yuan Yuan",
        "Hongyuan Su",
        "Nian Li",
        "Jinghua Piao",
        "Yucheng Deng",
        "Nicholas Sukiennik",
        "Chen Gao",
        "Fengli Xu",
        "Yong Li"
      ],
      "published_date": "2024-11-21",
      "pdf_url": "https://arxiv.org/pdf/2411.14499v4",
      "citation_count": null,
      "year": null
    }
  ],
  "top_k": 2,
  "depth": 3,
  "knowledge_graph": {
    "entities": [
      {
        "name": "Attention Is All You Need",
        "type": "AIPaper",
        "arxiv_id": "1706.03762"
      },
      {
        "name": "Deep Residual Learning for Image Recognition",
        "type": "AIPaper",
        "arxiv_id": "1512.03385"
      },
      {
        "name": "Adam: A Method for Stochastic Optimization",
        "type": "AIPaper",
        "arxiv_id": "1412.6980"
      },
      {
        "name": "A comprehensive review of recommender systems: Transitioning from theory to practice",
        "type": "AIPaper",
        "arxiv_id": ""
      },
      {
        "name": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation",
        "type": "AIPaper",
        "arxiv_id": "2602.03242"
      },
      {
        "name": "ImageNet classification with deep convolutional neural networks",
        "type": "AIPaper",
        "arxiv_id": ""
      },
      {
        "name": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
        "type": "AIPaper",
        "arxiv_id": "1409.1556"
      },
      {
        "name": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects",
        "type": "AIPaper",
        "arxiv_id": ""
      },
      {
        "name": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning",
        "type": "AIPaper",
        "arxiv_id": ""
      },
      {
        "name": "Attention is All you Need",
        "type": "AIPaper",
        "arxiv_id": "1706.03762"
      },
      {
        "name": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
        "type": "AIPaper",
        "arxiv_id": "1910.10683"
      },
      {
        "name": "Sora as a World Model? A Complete Survey on Text-to-Video Generation",
        "type": "AIPaper",
        "arxiv_id": "2403.05131"
      },
      {
        "name": "OmniNWM: Omniscient Driving Navigation World Models",
        "type": "AIPaper",
        "arxiv_id": "2510.18313"
      },
      {
        "name": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "type": "AIPaper",
        "arxiv_id": "1810.04805"
      },
      {
        "name": "Long Short-Term Memory",
        "type": "AIPaper",
        "arxiv_id": ""
      },
      {
        "name": "Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond",
        "type": "AIPaper",
        "arxiv_id": "2405.03520"
      },
      {
        "name": "Understanding World or Predicting Future? A Comprehensive Survey of World Models",
        "type": "AIPaper",
        "arxiv_id": "2411.14499"
      },
      {
        "name": "Ashish Vaswani",
        "type": "Researcher"
      },
      {
        "name": "Noam Shazeer",
        "type": "Researcher"
      },
      {
        "name": "Niki Parmar",
        "type": "Researcher"
      },
      {
        "name": "Jakob Uszkoreit",
        "type": "Researcher"
      },
      {
        "name": "Llion Jones",
        "type": "Researcher"
      },
      {
        "name": "Aidan N. Gomez",
        "type": "Researcher"
      },
      {
        "name": "Lukasz Kaiser",
        "type": "Researcher"
      },
      {
        "name": "Illia Polosukhin",
        "type": "Researcher"
      },
      {
        "name": "Kaiming He",
        "type": "Researcher"
      },
      {
        "name": "Xiangyu Zhang",
        "type": "Researcher"
      },
      {
        "name": "Shaoqing Ren",
        "type": "Researcher"
      },
      {
        "name": "Jian Sun",
        "type": "Researcher"
      },
      {
        "name": "Diederik P. Kingma",
        "type": "Researcher"
      },
      {
        "name": "Jimmy Ba",
        "type": "Researcher"
      },
      {
        "name": "Shaina Raza",
        "type": "Researcher"
      },
      {
        "name": "Mizanur Rahman",
        "type": "Researcher"
      },
      {
        "name": "Safiullah Kamawal",
        "type": "Researcher"
      },
      {
        "name": "Armin Toroghi",
        "type": "Researcher"
      },
      {
        "name": "Ananya Raval",
        "type": "Researcher"
      },
      {
        "name": "F. Navah",
        "type": "Researcher"
      },
      {
        "name": "Amirmohammad Kazemeini",
        "type": "Researcher"
      },
      {
        "name": "Zhuoran Yang",
        "type": "Researcher"
      },
      {
        "name": "Xi Guo",
        "type": "Researcher"
      },
      {
        "name": "Chenjing Ding",
        "type": "Researcher"
      },
      {
        "name": "Chiyu Wang",
        "type": "Researcher"
      },
      {
        "name": "Wei Wu",
        "type": "Researcher"
      },
      {
        "name": "Yanyong Zhang",
        "type": "Researcher"
      },
      {
        "name": "A. Krizhevsky",
        "type": "Researcher"
      },
      {
        "name": "I. Sutskever",
        "type": "Researcher"
      },
      {
        "name": "Geoffrey E. Hinton",
        "type": "Researcher"
      },
      {
        "name": "Karen Simonyan",
        "type": "Researcher"
      },
      {
        "name": "Andrew Zisserman",
        "type": "Researcher"
      },
      {
        "name": "Yuqi Cheng",
        "type": "Researcher"
      },
      {
        "name": "Yunkang Cao",
        "type": "Researcher"
      },
      {
        "name": "Haiming Yao",
        "type": "Researcher"
      },
      {
        "name": "Wei Luo",
        "type": "Researcher"
      },
      {
        "name": "Cheng Jiang",
        "type": "Researcher"
      },
      {
        "name": "Hui Zhang",
        "type": "Researcher"
      },
      {
        "name": "Weiming Shen",
        "type": "Researcher"
      },
      {
        "name": "Naveen Kumar Srinivasa",
        "type": "Researcher"
      },
      {
        "name": "Ajeet Rao Chalamala",
        "type": "Researcher"
      },
      {
        "name": "Kumar Singh",
        "type": "Researcher"
      },
      {
        "name": "Ieee Krishna Mohan Senior Member",
        "type": "Researcher"
      },
      {
        "name": "K. Naveen",
        "type": "Researcher"
      },
      {
        "name": "Srinivasa Rao",
        "type": "Researcher"
      },
      {
        "name": "Ajeet Kumar Singh",
        "type": "Researcher"
      },
      {
        "name": "Colin Raffel",
        "type": "Researcher"
      },
      {
        "name": "Adam Roberts",
        "type": "Researcher"
      },
      {
        "name": "Katherine Lee",
        "type": "Researcher"
      },
      {
        "name": "Sharan Narang",
        "type": "Researcher"
      },
      {
        "name": "Michael Matena",
        "type": "Researcher"
      },
      {
        "name": "Yanqi Zhou",
        "type": "Researcher"
      },
      {
        "name": "Wei Li",
        "type": "Researcher"
      },
      {
        "name": "Peter J. Liu",
        "type": "Researcher"
      },
      {
        "name": "Fachrina Dewi Puspitasari",
        "type": "Researcher"
      },
      {
        "name": "Chaoning Zhang",
        "type": "Researcher"
      },
      {
        "name": "Joseph Cho",
        "type": "Researcher"
      },
      {
        "name": "Adnan Haider",
        "type": "Researcher"
      },
      {
        "name": "Noor Ul Eman",
        "type": "Researcher"
      },
      {
        "name": "Omer Amin",
        "type": "Researcher"
      },
      {
        "name": "Alexis Mankowski",
        "type": "Researcher"
      },
      {
        "name": "Muhammad Umair",
        "type": "Researcher"
      },
      {
        "name": "Jingyao Zheng",
        "type": "Researcher"
      },
      {
        "name": "Sheng Zheng",
        "type": "Researcher"
      },
      {
        "name": "Lik-Hang Lee",
        "type": "Researcher"
      },
      {
        "name": "Caiyan Qin",
        "type": "Researcher"
      },
      {
        "name": "Tae-Ho Kim",
        "type": "Researcher"
      },
      {
        "name": "Choong Seon Hong",
        "type": "Researcher"
      },
      {
        "name": "Yang Yang",
        "type": "Researcher"
      },
      {
        "name": "Heng Tao Shen",
        "type": "Researcher"
      },
      {
        "name": "Bohan Li",
        "type": "Researcher"
      },
      {
        "name": "Zhuang Ma",
        "type": "Researcher"
      },
      {
        "name": "Dalong Du",
        "type": "Researcher"
      },
      {
        "name": "Bao Peng",
        "type": "Researcher"
      },
      {
        "name": "Zhujin Liang",
        "type": "Researcher"
      },
      {
        "name": "Zhenqiang Liu",
        "type": "Researcher"
      },
      {
        "name": "Chao Ma",
        "type": "Researcher"
      },
      {
        "name": "Yueming Jin",
        "type": "Researcher"
      },
      {
        "name": "Hao Zhao",
        "type": "Researcher"
      },
      {
        "name": "Wenjun Zeng",
        "type": "Researcher"
      },
      {
        "name": "Xin Jin",
        "type": "Researcher"
      },
      {
        "name": "Jacob Devlin",
        "type": "Researcher"
      },
      {
        "name": "Ming-Wei Chang",
        "type": "Researcher"
      },
      {
        "name": "Kenton Lee",
        "type": "Researcher"
      },
      {
        "name": "Kristina Toutanova",
        "type": "Researcher"
      },
      {
        "name": "Sepp Hochreiter",
        "type": "Researcher"
      },
      {
        "name": "J. Schmidhuber",
        "type": "Researcher"
      },
      {
        "name": "Zheng Zhu",
        "type": "Researcher"
      },
      {
        "name": "Xiaofeng Wang",
        "type": "Researcher"
      },
      {
        "name": "Wangbo Zhao",
        "type": "Researcher"
      },
      {
        "name": "Chen Min",
        "type": "Researcher"
      },
      {
        "name": "Nianchen Deng",
        "type": "Researcher"
      },
      {
        "name": "Min Dou",
        "type": "Researcher"
      },
      {
        "name": "Yuqi Wang",
        "type": "Researcher"
      },
      {
        "name": "Botian Shi",
        "type": "Researcher"
      },
      {
        "name": "Kai Wang",
        "type": "Researcher"
      },
      {
        "name": "Chi Zhang",
        "type": "Researcher"
      },
      {
        "name": "Yang You",
        "type": "Researcher"
      },
      {
        "name": "Zhaoxiang Zhang",
        "type": "Researcher"
      },
      {
        "name": "Dawei Zhao",
        "type": "Researcher"
      },
      {
        "name": "Liang Xiao",
        "type": "Researcher"
      },
      {
        "name": "Jian Zhao",
        "type": "Researcher"
      },
      {
        "name": "Jiwen Lu",
        "type": "Researcher"
      },
      {
        "name": "Guan Huang",
        "type": "Researcher"
      },
      {
        "name": "Jingtao Ding",
        "type": "Researcher"
      },
      {
        "name": "Yunke Zhang",
        "type": "Researcher"
      },
      {
        "name": "Yu Shang",
        "type": "Researcher"
      },
      {
        "name": "Jie Feng",
        "type": "Researcher"
      },
      {
        "name": "Yuheng Zhang",
        "type": "Researcher"
      },
      {
        "name": "Zefang Zong",
        "type": "Researcher"
      },
      {
        "name": "Yuan Yuan",
        "type": "Researcher"
      },
      {
        "name": "Hongyuan Su",
        "type": "Researcher"
      },
      {
        "name": "Nian Li",
        "type": "Researcher"
      },
      {
        "name": "Jinghua Piao",
        "type": "Researcher"
      },
      {
        "name": "Yucheng Deng",
        "type": "Researcher"
      },
      {
        "name": "Nicholas Sukiennik",
        "type": "Researcher"
      },
      {
        "name": "Chen Gao",
        "type": "Researcher"
      },
      {
        "name": "Fengli Xu",
        "type": "Researcher"
      },
      {
        "name": "Yong Li",
        "type": "Researcher"
      },
      {
        "name": "Transformer",
        "type": "AIModel"
      },
      {
        "name": "WMT 2014 English-to-German translation task",
        "type": "Dataset"
      },
      {
        "name": "WMT 2014 English-to-French translation task",
        "type": "Dataset"
      },
      {
        "name": "BLEU",
        "type": "Metric"
      },
      {
        "name": "residual learning framework",
        "type": "AIModel"
      },
      {
        "name": "VGG nets",
        "type": "AIModel"
      },
      {
        "name": "ImageNet",
        "type": "Dataset"
      },
      {
        "name": "CIFAR-10",
        "type": "Dataset"
      },
      {
        "name": "COCO object detection dataset",
        "type": "Dataset"
      },
      {
        "name": "error",
        "type": "Metric"
      },
      {
        "name": "relative improvement",
        "type": "Metric"
      },
      {
        "name": "Adam",
        "type": "AIModel"
      },
      {
        "name": "AdaMax",
        "type": "AIModel"
      },
      {
        "name": "InstaDrive",
        "type": "AIModel"
      },
      {
        "name": "Instance Flow Guider",
        "type": "AIModel"
      },
      {
        "name": "Spatial Geometric Aligner",
        "type": "AIModel"
      },
      {
        "name": "nuScenes",
        "type": "Dataset"
      },
      {
        "name": "CARLA",
        "type": "Dataset"
      },
      {
        "name": "video generation quality",
        "type": "Metric"
      },
      {
        "name": "safety evaluation",
        "type": "Metric"
      },
      {
        "name": "deep convolutional neural networks",
        "type": "AIModel"
      },
      {
        "name": "ConvNet models",
        "type": "AIModel"
      },
      {
        "name": "ImageNet Challenge 2014",
        "type": "Dataset"
      },
      {
        "name": "other datasets",
        "type": "Dataset"
      },
      {
        "name": "accuracy",
        "type": "Metric"
      },
      {
        "name": "FLOT",
        "type": "AIModel"
      },
      {
        "name": "GTSRB",
        "type": "Dataset"
      },
      {
        "name": "KBTS",
        "type": "Dataset"
      },
      {
        "name": "CIFAR10",
        "type": "Dataset"
      },
      {
        "name": "EMNIST",
        "type": "Dataset"
      },
      {
        "name": "scalability",
        "type": "Metric"
      },
      {
        "name": "Unified Text-to-Text Transformer",
        "type": "AIModel"
      },
      {
        "name": "Colossal Clean Crawled Corpus",
        "type": "Dataset"
      },
      {
        "name": "state-of-the-art results",
        "type": "Metric"
      },
      {
        "name": "Sora",
        "type": "AIModel"
      },
      {
        "name": "MNIST",
        "type": "Dataset"
      },
      {
        "name": "text-to-video generation",
        "type": "AIModel"
      },
      {
        "name": "world modeling",
        "type": "Metric"
      },
      {
        "name": "OmniNWM",
        "type": "AIModel"
      },
      {
        "name": "existing models",
        "type": "AIModel"
      },
      {
        "name": "panoramic videos",
        "type": "Dataset"
      },
      {
        "name": "video generation",
        "type": "Metric"
      },
      {
        "name": "control accuracy",
        "type": "Metric"
      },
      {
        "name": "long-horizon stability",
        "type": "Metric"
      },
      {
        "name": "BERT",
        "type": "AIModel"
      },
      {
        "name": "GLUE",
        "type": "Dataset"
      },
      {
        "name": "MultiNLI",
        "type": "Dataset"
      },
      {
        "name": "SQuAD v1.1",
        "type": "Dataset"
      },
      {
        "name": "SQuAD v2.0",
        "type": "Dataset"
      },
      {
        "name": "GLUE score",
        "type": "Metric"
      },
      {
        "name": "MultiNLI accuracy",
        "type": "Metric"
      },
      {
        "name": "SQuAD v1.1 question answering Test F1",
        "type": "Metric"
      },
      {
        "name": "SQuAD v2.0 Test F1",
        "type": "Metric"
      },
      {
        "name": "Sora model",
        "type": "AIModel"
      },
      {
        "name": "autonomous-driving world models",
        "type": "AIModel"
      },
      {
        "name": "autonomous agents",
        "type": "AIModel"
      },
      {
        "name": "GPT-4",
        "type": "AIModel"
      },
      {
        "name": "generative games",
        "type": "Dataset"
      },
      {
        "name": "autonomous driving",
        "type": "Dataset"
      },
      {
        "name": "robotics",
        "type": "Dataset"
      },
      {
        "name": "social simulacra",
        "type": "Dataset"
      }
    ],
    "triples": [
      {
        "head": "Ashish Vaswani",
        "relation": "author_of",
        "tail": "Attention Is All You Need"
      },
      {
        "head": "Noam Shazeer",
        "relation": "author_of",
        "tail": "Attention Is All You Need"
      },
      {
        "head": "Niki Parmar",
        "relation": "author_of",
        "tail": "Attention Is All You Need"
      },
      {
        "head": "Jakob Uszkoreit",
        "relation": "author_of",
        "tail": "Attention Is All You Need"
      },
      {
        "head": "Llion Jones",
        "relation": "author_of",
        "tail": "Attention Is All You Need"
      },
      {
        "head": "Aidan N. Gomez",
        "relation": "author_of",
        "tail": "Attention Is All You Need"
      },
      {
        "head": "Lukasz Kaiser",
        "relation": "author_of",
        "tail": "Attention Is All You Need"
      },
      {
        "head": "Illia Polosukhin",
        "relation": "author_of",
        "tail": "Attention Is All You Need"
      },
      {
        "head": "Kaiming He",
        "relation": "author_of",
        "tail": "Deep Residual Learning for Image Recognition"
      },
      {
        "head": "Xiangyu Zhang",
        "relation": "author_of",
        "tail": "Deep Residual Learning for Image Recognition"
      },
      {
        "head": "Shaoqing Ren",
        "relation": "author_of",
        "tail": "Deep Residual Learning for Image Recognition"
      },
      {
        "head": "Jian Sun",
        "relation": "author_of",
        "tail": "Deep Residual Learning for Image Recognition"
      },
      {
        "head": "Diederik P. Kingma",
        "relation": "author_of",
        "tail": "Adam: A Method for Stochastic Optimization"
      },
      {
        "head": "Jimmy Ba",
        "relation": "author_of",
        "tail": "Adam: A Method for Stochastic Optimization"
      },
      {
        "head": "Shaina Raza",
        "relation": "author_of",
        "tail": "A comprehensive review of recommender systems: Transitioning from theory to practice"
      },
      {
        "head": "Mizanur Rahman",
        "relation": "author_of",
        "tail": "A comprehensive review of recommender systems: Transitioning from theory to practice"
      },
      {
        "head": "Safiullah Kamawal",
        "relation": "author_of",
        "tail": "A comprehensive review of recommender systems: Transitioning from theory to practice"
      },
      {
        "head": "Armin Toroghi",
        "relation": "author_of",
        "tail": "A comprehensive review of recommender systems: Transitioning from theory to practice"
      },
      {
        "head": "Ananya Raval",
        "relation": "author_of",
        "tail": "A comprehensive review of recommender systems: Transitioning from theory to practice"
      },
      {
        "head": "F. Navah",
        "relation": "author_of",
        "tail": "A comprehensive review of recommender systems: Transitioning from theory to practice"
      },
      {
        "head": "Amirmohammad Kazemeini",
        "relation": "author_of",
        "tail": "A comprehensive review of recommender systems: Transitioning from theory to practice"
      },
      {
        "head": "Zhuoran Yang",
        "relation": "author_of",
        "tail": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation"
      },
      {
        "head": "Xi Guo",
        "relation": "author_of",
        "tail": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation"
      },
      {
        "head": "Chenjing Ding",
        "relation": "author_of",
        "tail": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation"
      },
      {
        "head": "Chiyu Wang",
        "relation": "author_of",
        "tail": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation"
      },
      {
        "head": "Wei Wu",
        "relation": "author_of",
        "tail": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation"
      },
      {
        "head": "Yanyong Zhang",
        "relation": "author_of",
        "tail": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation"
      },
      {
        "head": "A. Krizhevsky",
        "relation": "author_of",
        "tail": "ImageNet classification with deep convolutional neural networks"
      },
      {
        "head": "I. Sutskever",
        "relation": "author_of",
        "tail": "ImageNet classification with deep convolutional neural networks"
      },
      {
        "head": "Geoffrey E. Hinton",
        "relation": "author_of",
        "tail": "ImageNet classification with deep convolutional neural networks"
      },
      {
        "head": "Karen Simonyan",
        "relation": "author_of",
        "tail": "Very Deep Convolutional Networks for Large-Scale Image Recognition"
      },
      {
        "head": "Andrew Zisserman",
        "relation": "author_of",
        "tail": "Very Deep Convolutional Networks for Large-Scale Image Recognition"
      },
      {
        "head": "Yuqi Cheng",
        "relation": "author_of",
        "tail": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects"
      },
      {
        "head": "Yunkang Cao",
        "relation": "author_of",
        "tail": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects"
      },
      {
        "head": "Haiming Yao",
        "relation": "author_of",
        "tail": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects"
      },
      {
        "head": "Wei Luo",
        "relation": "author_of",
        "tail": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects"
      },
      {
        "head": "Cheng Jiang",
        "relation": "author_of",
        "tail": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects"
      },
      {
        "head": "Hui Zhang",
        "relation": "author_of",
        "tail": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects"
      },
      {
        "head": "Weiming Shen",
        "relation": "author_of",
        "tail": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects"
      },
      {
        "head": "Naveen Kumar Srinivasa",
        "relation": "author_of",
        "tail": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning"
      },
      {
        "head": "Ajeet Rao Chalamala",
        "relation": "author_of",
        "tail": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning"
      },
      {
        "head": "Kumar Singh",
        "relation": "author_of",
        "tail": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning"
      },
      {
        "head": "Ieee Krishna Mohan Senior Member",
        "relation": "author_of",
        "tail": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning"
      },
      {
        "head": "K. Naveen",
        "relation": "author_of",
        "tail": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning"
      },
      {
        "head": "Srinivasa Rao",
        "relation": "author_of",
        "tail": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning"
      },
      {
        "head": "Ajeet Kumar Singh",
        "relation": "author_of",
        "tail": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning"
      },
      {
        "head": "Ashish Vaswani",
        "relation": "author_of",
        "tail": "Attention is All you Need"
      },
      {
        "head": "Noam Shazeer",
        "relation": "author_of",
        "tail": "Attention is All you Need"
      },
      {
        "head": "Niki Parmar",
        "relation": "author_of",
        "tail": "Attention is All you Need"
      },
      {
        "head": "Jakob Uszkoreit",
        "relation": "author_of",
        "tail": "Attention is All you Need"
      },
      {
        "head": "Llion Jones",
        "relation": "author_of",
        "tail": "Attention is All you Need"
      },
      {
        "head": "Aidan N. Gomez",
        "relation": "author_of",
        "tail": "Attention is All you Need"
      },
      {
        "head": "Lukasz Kaiser",
        "relation": "author_of",
        "tail": "Attention is All you Need"
      },
      {
        "head": "Illia Polosukhin",
        "relation": "author_of",
        "tail": "Attention is All you Need"
      },
      {
        "head": "Colin Raffel",
        "relation": "author_of",
        "tail": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
      },
      {
        "head": "Noam Shazeer",
        "relation": "author_of",
        "tail": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
      },
      {
        "head": "Adam Roberts",
        "relation": "author_of",
        "tail": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
      },
      {
        "head": "Katherine Lee",
        "relation": "author_of",
        "tail": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
      },
      {
        "head": "Sharan Narang",
        "relation": "author_of",
        "tail": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
      },
      {
        "head": "Michael Matena",
        "relation": "author_of",
        "tail": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
      },
      {
        "head": "Yanqi Zhou",
        "relation": "author_of",
        "tail": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
      },
      {
        "head": "Wei Li",
        "relation": "author_of",
        "tail": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
      },
      {
        "head": "Peter J. Liu",
        "relation": "author_of",
        "tail": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
      },
      {
        "head": "Fachrina Dewi Puspitasari",
        "relation": "author_of",
        "tail": "Sora as a World Model? A Complete Survey on Text-to-Video Generation"
      },
      {
        "head": "Chaoning Zhang",
        "relation": "author_of",
        "tail": "Sora as a World Model? A Complete Survey on Text-to-Video Generation"
      },
      {
        "head": "Joseph Cho",
        "relation": "author_of",
        "tail": "Sora as a World Model? A Complete Survey on Text-to-Video Generation"
      },
      {
        "head": "Adnan Haider",
        "relation": "author_of",
        "tail": "Sora as a World Model? A Complete Survey on Text-to-Video Generation"
      },
      {
        "head": "Noor Ul Eman",
        "relation": "author_of",
        "tail": "Sora as a World Model? A Complete Survey on Text-to-Video Generation"
      },
      {
        "head": "Omer Amin",
        "relation": "author_of",
        "tail": "Sora as a World Model? A Complete Survey on Text-to-Video Generation"
      },
      {
        "head": "Alexis Mankowski",
        "relation": "author_of",
        "tail": "Sora as a World Model? A Complete Survey on Text-to-Video Generation"
      },
      {
        "head": "Muhammad Umair",
        "relation": "author_of",
        "tail": "Sora as a World Model? A Complete Survey on Text-to-Video Generation"
      },
      {
        "head": "Jingyao Zheng",
        "relation": "author_of",
        "tail": "Sora as a World Model? A Complete Survey on Text-to-Video Generation"
      },
      {
        "head": "Sheng Zheng",
        "relation": "author_of",
        "tail": "Sora as a World Model? A Complete Survey on Text-to-Video Generation"
      },
      {
        "head": "Lik-Hang Lee",
        "relation": "author_of",
        "tail": "Sora as a World Model? A Complete Survey on Text-to-Video Generation"
      },
      {
        "head": "Caiyan Qin",
        "relation": "author_of",
        "tail": "Sora as a World Model? A Complete Survey on Text-to-Video Generation"
      },
      {
        "head": "Tae-Ho Kim",
        "relation": "author_of",
        "tail": "Sora as a World Model? A Complete Survey on Text-to-Video Generation"
      },
      {
        "head": "Choong Seon Hong",
        "relation": "author_of",
        "tail": "Sora as a World Model? A Complete Survey on Text-to-Video Generation"
      },
      {
        "head": "Yang Yang",
        "relation": "author_of",
        "tail": "Sora as a World Model? A Complete Survey on Text-to-Video Generation"
      },
      {
        "head": "Heng Tao Shen",
        "relation": "author_of",
        "tail": "Sora as a World Model? A Complete Survey on Text-to-Video Generation"
      },
      {
        "head": "Bohan Li",
        "relation": "author_of",
        "tail": "OmniNWM: Omniscient Driving Navigation World Models"
      },
      {
        "head": "Zhuang Ma",
        "relation": "author_of",
        "tail": "OmniNWM: Omniscient Driving Navigation World Models"
      },
      {
        "head": "Dalong Du",
        "relation": "author_of",
        "tail": "OmniNWM: Omniscient Driving Navigation World Models"
      },
      {
        "head": "Bao Peng",
        "relation": "author_of",
        "tail": "OmniNWM: Omniscient Driving Navigation World Models"
      },
      {
        "head": "Zhujin Liang",
        "relation": "author_of",
        "tail": "OmniNWM: Omniscient Driving Navigation World Models"
      },
      {
        "head": "Zhenqiang Liu",
        "relation": "author_of",
        "tail": "OmniNWM: Omniscient Driving Navigation World Models"
      },
      {
        "head": "Chao Ma",
        "relation": "author_of",
        "tail": "OmniNWM: Omniscient Driving Navigation World Models"
      },
      {
        "head": "Yueming Jin",
        "relation": "author_of",
        "tail": "OmniNWM: Omniscient Driving Navigation World Models"
      },
      {
        "head": "Hao Zhao",
        "relation": "author_of",
        "tail": "OmniNWM: Omniscient Driving Navigation World Models"
      },
      {
        "head": "Wenjun Zeng",
        "relation": "author_of",
        "tail": "OmniNWM: Omniscient Driving Navigation World Models"
      },
      {
        "head": "Xin Jin",
        "relation": "author_of",
        "tail": "OmniNWM: Omniscient Driving Navigation World Models"
      },
      {
        "head": "Jacob Devlin",
        "relation": "author_of",
        "tail": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
      },
      {
        "head": "Ming-Wei Chang",
        "relation": "author_of",
        "tail": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
      },
      {
        "head": "Kenton Lee",
        "relation": "author_of",
        "tail": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
      },
      {
        "head": "Kristina Toutanova",
        "relation": "author_of",
        "tail": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
      },
      {
        "head": "Sepp Hochreiter",
        "relation": "author_of",
        "tail": "Long Short-Term Memory"
      },
      {
        "head": "J. Schmidhuber",
        "relation": "author_of",
        "tail": "Long Short-Term Memory"
      },
      {
        "head": "Zheng Zhu",
        "relation": "author_of",
        "tail": "Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond"
      },
      {
        "head": "Xiaofeng Wang",
        "relation": "author_of",
        "tail": "Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond"
      },
      {
        "head": "Wangbo Zhao",
        "relation": "author_of",
        "tail": "Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond"
      },
      {
        "head": "Chen Min",
        "relation": "author_of",
        "tail": "Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond"
      },
      {
        "head": "Bohan Li",
        "relation": "author_of",
        "tail": "Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond"
      },
      {
        "head": "Nianchen Deng",
        "relation": "author_of",
        "tail": "Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond"
      },
      {
        "head": "Min Dou",
        "relation": "author_of",
        "tail": "Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond"
      },
      {
        "head": "Yuqi Wang",
        "relation": "author_of",
        "tail": "Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond"
      },
      {
        "head": "Botian Shi",
        "relation": "author_of",
        "tail": "Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond"
      },
      {
        "head": "Kai Wang",
        "relation": "author_of",
        "tail": "Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond"
      },
      {
        "head": "Chi Zhang",
        "relation": "author_of",
        "tail": "Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond"
      },
      {
        "head": "Yang You",
        "relation": "author_of",
        "tail": "Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond"
      },
      {
        "head": "Zhaoxiang Zhang",
        "relation": "author_of",
        "tail": "Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond"
      },
      {
        "head": "Dawei Zhao",
        "relation": "author_of",
        "tail": "Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond"
      },
      {
        "head": "Liang Xiao",
        "relation": "author_of",
        "tail": "Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond"
      },
      {
        "head": "Jian Zhao",
        "relation": "author_of",
        "tail": "Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond"
      },
      {
        "head": "Jiwen Lu",
        "relation": "author_of",
        "tail": "Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond"
      },
      {
        "head": "Guan Huang",
        "relation": "author_of",
        "tail": "Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond"
      },
      {
        "head": "Jingtao Ding",
        "relation": "author_of",
        "tail": "Understanding World or Predicting Future? A Comprehensive Survey of World Models"
      },
      {
        "head": "Yunke Zhang",
        "relation": "author_of",
        "tail": "Understanding World or Predicting Future? A Comprehensive Survey of World Models"
      },
      {
        "head": "Yu Shang",
        "relation": "author_of",
        "tail": "Understanding World or Predicting Future? A Comprehensive Survey of World Models"
      },
      {
        "head": "Jie Feng",
        "relation": "author_of",
        "tail": "Understanding World or Predicting Future? A Comprehensive Survey of World Models"
      },
      {
        "head": "Yuheng Zhang",
        "relation": "author_of",
        "tail": "Understanding World or Predicting Future? A Comprehensive Survey of World Models"
      },
      {
        "head": "Zefang Zong",
        "relation": "author_of",
        "tail": "Understanding World or Predicting Future? A Comprehensive Survey of World Models"
      },
      {
        "head": "Yuan Yuan",
        "relation": "author_of",
        "tail": "Understanding World or Predicting Future? A Comprehensive Survey of World Models"
      },
      {
        "head": "Hongyuan Su",
        "relation": "author_of",
        "tail": "Understanding World or Predicting Future? A Comprehensive Survey of World Models"
      },
      {
        "head": "Nian Li",
        "relation": "author_of",
        "tail": "Understanding World or Predicting Future? A Comprehensive Survey of World Models"
      },
      {
        "head": "Jinghua Piao",
        "relation": "author_of",
        "tail": "Understanding World or Predicting Future? A Comprehensive Survey of World Models"
      },
      {
        "head": "Yucheng Deng",
        "relation": "author_of",
        "tail": "Understanding World or Predicting Future? A Comprehensive Survey of World Models"
      },
      {
        "head": "Nicholas Sukiennik",
        "relation": "author_of",
        "tail": "Understanding World or Predicting Future? A Comprehensive Survey of World Models"
      },
      {
        "head": "Chen Gao",
        "relation": "author_of",
        "tail": "Understanding World or Predicting Future? A Comprehensive Survey of World Models"
      },
      {
        "head": "Fengli Xu",
        "relation": "author_of",
        "tail": "Understanding World or Predicting Future? A Comprehensive Survey of World Models"
      },
      {
        "head": "Yong Li",
        "relation": "author_of",
        "tail": "Understanding World or Predicting Future? A Comprehensive Survey of World Models"
      },
      {
        "head": "Attention Is All You Need",
        "relation": "cites",
        "tail": "Deep Residual Learning for Image Recognition"
      },
      {
        "head": "Attention Is All You Need",
        "relation": "cites",
        "tail": "Adam: A Method for Stochastic Optimization"
      },
      {
        "head": "A comprehensive review of recommender systems: Transitioning from theory to practice",
        "relation": "cites",
        "tail": "Attention Is All You Need"
      },
      {
        "head": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation",
        "relation": "cites",
        "tail": "Attention Is All You Need"
      },
      {
        "head": "Deep Residual Learning for Image Recognition",
        "relation": "cites",
        "tail": "ImageNet classification with deep convolutional neural networks"
      },
      {
        "head": "Deep Residual Learning for Image Recognition",
        "relation": "cites",
        "tail": "Very Deep Convolutional Networks for Large-Scale Image Recognition"
      },
      {
        "head": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects",
        "relation": "cites",
        "tail": "Deep Residual Learning for Image Recognition"
      },
      {
        "head": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning",
        "relation": "cites",
        "tail": "Deep Residual Learning for Image Recognition"
      },
      {
        "head": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation",
        "relation": "cites",
        "tail": "Attention is All you Need"
      },
      {
        "head": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation",
        "relation": "cites",
        "tail": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
      },
      {
        "head": "Sora as a World Model? A Complete Survey on Text-to-Video Generation",
        "relation": "cites",
        "tail": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation"
      },
      {
        "head": "OmniNWM: Omniscient Driving Navigation World Models",
        "relation": "cites",
        "tail": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation"
      },
      {
        "head": "Sora as a World Model? A Complete Survey on Text-to-Video Generation",
        "relation": "cites",
        "tail": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
      },
      {
        "head": "Sora as a World Model? A Complete Survey on Text-to-Video Generation",
        "relation": "cites",
        "tail": "Long Short-Term Memory"
      },
      {
        "head": "Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond",
        "relation": "cites",
        "tail": "Sora as a World Model? A Complete Survey on Text-to-Video Generation"
      },
      {
        "head": "Understanding World or Predicting Future? A Comprehensive Survey of World Models",
        "relation": "cites",
        "tail": "Sora as a World Model? A Complete Survey on Text-to-Video Generation"
      },
      {
        "head": "Attention Is All You Need",
        "relation": "proposed_model",
        "tail": "Transformer"
      },
      {
        "head": "Transformer",
        "relation": "evaluated_on",
        "tail": "WMT 2014 English-to-German translation task"
      },
      {
        "head": "Transformer",
        "relation": "evaluated_on",
        "tail": "WMT 2014 English-to-French translation task"
      },
      {
        "head": "Transformer",
        "relation": "uses_metric",
        "tail": "BLEU"
      },
      {
        "head": "Deep Residual Learning for Image Recognition",
        "relation": "proposed_model",
        "tail": "residual learning framework"
      },
      {
        "head": "Deep Residual Learning for Image Recognition",
        "relation": "baseline_model",
        "tail": "VGG nets"
      },
      {
        "head": "residual learning framework",
        "relation": "evaluated_on",
        "tail": "ImageNet"
      },
      {
        "head": "residual learning framework",
        "relation": "evaluated_on",
        "tail": "CIFAR-10"
      },
      {
        "head": "residual learning framework",
        "relation": "evaluated_on",
        "tail": "COCO object detection dataset"
      },
      {
        "head": "residual learning framework",
        "relation": "uses_metric",
        "tail": "error"
      },
      {
        "head": "residual learning framework",
        "relation": "uses_metric",
        "tail": "relative improvement"
      },
      {
        "head": "Adam: A Method for Stochastic Optimization",
        "relation": "proposed_model",
        "tail": "Adam"
      },
      {
        "head": "Adam: A Method for Stochastic Optimization",
        "relation": "proposed_model",
        "tail": "AdaMax"
      },
      {
        "head": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation",
        "relation": "proposed_model",
        "tail": "InstaDrive"
      },
      {
        "head": "InstaDrive",
        "relation": "baseline_model",
        "tail": "world models"
      },
      {
        "head": "InstaDrive",
        "relation": "evaluated_on",
        "tail": "nuScenes"
      },
      {
        "head": "InstaDrive",
        "relation": "evaluated_on",
        "tail": "CARLA"
      },
      {
        "head": "InstaDrive",
        "relation": "uses_metric",
        "tail": "video generation quality"
      },
      {
        "head": "InstaDrive",
        "relation": "uses_metric",
        "tail": "safety evaluation"
      },
      {
        "head": "ImageNet classification with deep convolutional neural networks",
        "relation": "proposed_model",
        "tail": "deep convolutional neural networks"
      },
      {
        "head": "ImageNet classification with deep convolutional neural networks",
        "relation": "evaluated_on",
        "tail": "ImageNet"
      },
      {
        "head": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
        "relation": "proposed_model",
        "tail": "ConvNet models"
      },
      {
        "head": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
        "relation": "evaluated_on",
        "tail": "ImageNet Challenge 2014"
      },
      {
        "head": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
        "relation": "evaluated_on",
        "tail": "other datasets"
      },
      {
        "head": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
        "relation": "uses_metric",
        "tail": "accuracy"
      },
      {
        "head": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning",
        "relation": "proposed_model",
        "tail": "FLOT"
      },
      {
        "head": "FLOT",
        "relation": "evaluated_on",
        "tail": "GTSRB"
      },
      {
        "head": "FLOT",
        "relation": "evaluated_on",
        "tail": "KBTS"
      },
      {
        "head": "FLOT",
        "relation": "evaluated_on",
        "tail": "CIFAR10"
      },
      {
        "head": "FLOT",
        "relation": "evaluated_on",
        "tail": "EMNIST"
      },
      {
        "head": "FLOT",
        "relation": "uses_metric",
        "tail": "accuracy"
      },
      {
        "head": "FLOT",
        "relation": "uses_metric",
        "tail": "scalability"
      },
      {
        "head": "Attention is All you Need",
        "relation": "proposed_model",
        "tail": "Transformer"
      },
      {
        "head": "Transformer",
        "relation": "evaluated_on",
        "tail": "WMT 2014 English-to-German translation task"
      },
      {
        "head": "Transformer",
        "relation": "evaluated_on",
        "tail": "WMT 2014 English-to-French translation task"
      },
      {
        "head": "Transformer",
        "relation": "uses_metric",
        "tail": "BLEU"
      },
      {
        "head": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
        "relation": "proposed_model",
        "tail": "Unified Text-to-Text Transformer"
      },
      {
        "head": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
        "relation": "evaluated_on",
        "tail": "Colossal Clean Crawled Corpus"
      },
      {
        "head": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
        "relation": "uses_metric",
        "tail": "state-of-the-art results"
      },
      {
        "head": "Sora as a World Model? A Complete Survey on Text-to-Video Generation",
        "relation": "proposed_model",
        "tail": "Sora"
      },
      {
        "head": "Sora as a World Model? A Complete Survey on Text-to-Video Generation",
        "relation": "baseline_model",
        "tail": "text-to-video generation"
      },
      {
        "head": "Sora",
        "relation": "evaluated_on",
        "tail": "MNIST"
      },
      {
        "head": "Sora",
        "relation": "uses_metric",
        "tail": "world modeling"
      },
      {
        "head": "text-to-video generation",
        "relation": "uses_metric",
        "tail": "world modeling"
      },
      {
        "head": "OmniNWM: Omniscient Driving Navigation World Models",
        "relation": "proposed_model",
        "tail": "OmniNWM"
      },
      {
        "head": "OmniNWM: Omniscient Driving Navigation World Models",
        "relation": "baseline_model",
        "tail": "existing models"
      },
      {
        "head": "OmniNWM",
        "relation": "evaluated_on",
        "tail": "panoramic videos"
      },
      {
        "head": "OmniNWM",
        "relation": "uses_metric",
        "tail": "video generation"
      },
      {
        "head": "OmniNWM",
        "relation": "uses_metric",
        "tail": "control accuracy"
      },
      {
        "head": "OmniNWM",
        "relation": "uses_metric",
        "tail": "long-horizon stability"
      },
      {
        "head": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "relation": "proposed_model",
        "tail": "BERT"
      },
      {
        "head": "BERT",
        "relation": "evaluated_on",
        "tail": "GLUE"
      },
      {
        "head": "BERT",
        "relation": "evaluated_on",
        "tail": "MultiNLI"
      },
      {
        "head": "BERT",
        "relation": "evaluated_on",
        "tail": "SQuAD v1.1"
      },
      {
        "head": "BERT",
        "relation": "evaluated_on",
        "tail": "SQuAD v2.0"
      },
      {
        "head": "BERT",
        "relation": "uses_metric",
        "tail": "GLUE score"
      },
      {
        "head": "BERT",
        "relation": "uses_metric",
        "tail": "MultiNLI accuracy"
      },
      {
        "head": "BERT",
        "relation": "uses_metric",
        "tail": "SQuAD v1.1 question answering Test F1"
      },
      {
        "head": "BERT",
        "relation": "uses_metric",
        "tail": "SQuAD v2.0 Test F1"
      },
      {
        "head": "Long Short-Term Memory",
        "relation": "proposed_model",
        "tail": "Long Short-Term Memory"
      },
      {
        "head": "Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond",
        "relation": "proposed_model",
        "tail": "Sora model"
      },
      {
        "head": "Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond",
        "relation": "evaluated_on",
        "tail": "video generation"
      },
      {
        "head": "Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond",
        "relation": "proposed_model",
        "tail": "autonomous-driving world models"
      },
      {
        "head": "Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond",
        "relation": "proposed_model",
        "tail": "autonomous agents"
      },
      {
        "head": "Understanding World or Predicting Future? A Comprehensive Survey of World Models",
        "relation": "proposed_model",
        "tail": "world models"
      },
      {
        "head": "Understanding World or Predicting Future? A Comprehensive Survey of World Models",
        "relation": "baseline_model",
        "tail": "GPT-4"
      },
      {
        "head": "Understanding World or Predicting Future? A Comprehensive Survey of World Models",
        "relation": "baseline_model",
        "tail": "Sora"
      },
      {
        "head": "Understanding World or Predicting Future? A Comprehensive Survey of World Models",
        "relation": "evaluated_on",
        "tail": "generative games"
      },
      {
        "head": "Understanding World or Predicting Future? A Comprehensive Survey of World Models",
        "relation": "evaluated_on",
        "tail": "autonomous driving"
      },
      {
        "head": "Understanding World or Predicting Future? A Comprehensive Survey of World Models",
        "relation": "evaluated_on",
        "tail": "robotics"
      },
      {
        "head": "Understanding World or Predicting Future? A Comprehensive Survey of World Models",
        "relation": "evaluated_on",
        "tail": "social simulacra"
      }
    ]
  }
}