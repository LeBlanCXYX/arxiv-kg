<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Top Citations KG - Attention Is All You Need</title>
    <script src="echarts.min.js"></script>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        html, body { height: 100%; }
        body { background: #f5f5f5; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; }
        #main { width: 100%; height: 100%; min-height: 400px; }
        .panel {
            position: absolute; background: white; border-radius: 8px;
            box-shadow: 0 2px 12px rgba(0,0,0,0.1); padding: 20px; font-size: 14px; z-index: 999; max-width: 420px;
        }
        .header { top: 20px; left: 20px; }
        .stats { top: 20px; right: 20px; }
        .header h2 { margin-bottom: 10px; color: #333; }
        .header p { color: #666; margin: 5px 0; line-height: 1.5; }
        .stat-item { margin: 8px 0; }
        .stat-label { font-weight: bold; color: #333; }
        .stat-value { color: #0066cc; }
    </style>
</head>
<body>
    <div id="main"></div>
    <div class="panel header">
        <h2>üìÑ Attention Is All You Need</h2>
        <p><strong>‰ΩúËÄÖ:</strong> Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit</p>
        <p><strong>ÂèëË°®Êó•Êúü:</strong> 2017-06-12</p>
        <p><strong>ArXiv ID:</strong> <code>1706.03762</code></p>
    </div>
    <div class="panel stats">
        <div class="stat-item"><span class="stat-label">ËÆ∫ÊñáËäÇÁÇπ:</span> <span class="stat-value">0</span></div>
        <div class="stat-item"><span class="stat-label">Á†îÁ©∂ËÄÖËäÇÁÇπ:</span> <span class="stat-value">0</span></div>
        <div class="stat-item"><span class="stat-label">ÂÖ≥Á≥ªÊï∞:</span> <span class="stat-value">6324</span></div>
        <div class="stat-item"><span class="stat-label">ÂºïÁî®ÁöÑËÆ∫Êñá (top N):</span> <span class="stat-value">5</span></div>
        <div class="stat-item"><span class="stat-label">Ë¢´ÂºïÁî®ÁöÑËÆ∫Êñá (top N):</span> <span class="stat-value">5</span></div>
    </div>
    <script type="text/javascript">
        function initChart() {
            if (typeof echarts === 'undefined') {
                document.getElementById('main').innerHTML = '<p style="padding:20px">Êó†Ê≥ïÂä†ËΩΩ EChartsÔºåËØ∑Ê£ÄÊü•ÁΩëÁªúÊàñ CDN„ÄÇ</p>';
                return;
            }
            var chartDom = document.getElementById('main');
            var myChart = echarts.init(chartDom);
            var option = {
                tooltip: { formatter: function(params) {
                    if (params.dataType === 'node') return params.name + ' (' + (params.value || '') + ')';
                    return (params.source && params.source.name) + ' ' + (params.value || '') + ' ' + (params.target && params.target.name);
                }},
                legend: { data: ["Thesis", "Person", "TechArticle", "Dataset", "SoftwareApplication", "CreativeWork", "Article", "Report"] },
                series: [{
                    type: 'graph', layout: 'force',
                    data: [{"name": "Attention Is All You Need", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Deep Residual Learning for Image Recognition", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Adam: A Method for Stochastic Optimization", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Long Short-Term Memory", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Dropout: a simple way to prevent neural networks from overfitting", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Rethinking the Inception Architecture for Computer Vision", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "A comprehensive review of recommender systems: Transitioning from theory to practice", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "CNC-VLM: An RLHF-optimized industrial large vision-language model with multimodal learning for imbalanced CNC fault detection", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Enhanced Transformer-BiLSTM Deep Learning Framework for Day-Ahead Energy Price Forecasting", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "UAV-based quantitative crack measurement for bridges integrating four-point laser metric calibration and mamba segmentation", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "ImageNet classification with deep convolutional neural networks", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Et al", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "DiffusionEngine: Diffusion model is scalable data engine for object detection", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Enhancing hyperspectral image prediction with contrastive learning in low-label regimes", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "WarmGait: Thermal Array-Based Gait Recognition for Privacy-Preserving Person Re-ID", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Auto-Encoding Variational Bayes", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Supporting Online Material for Reducing the Dimensionality of Data with Neural Networks", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Speech recognition with deep recurrent neural networks", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Weakly Supervised Image Dehazing via Physics-Based Decomposition", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "A Machine Learning Approach for Face Mask Detection System with AdamW Optimizer", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Probabilistic hierarchical interpolation and interpretable neural network configurations for flood prediction", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Generating an annual 30\u00a0m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Going deeper with convolutions", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "ImageNet Large Scale Visual Recognition Challenge", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Diffusion Transformers with Representation Autoencoders", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "HybridVisionNet: An advanced hybrid deep learning framework for automated multi-class ocular disease diagnosis using fundus imaging", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Revisiting Transferable Adversarial Images: Systemization, Evaluation, and New Insights", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Dataset Purification-Driven Lightweight Deep Learning Model Construction for Empty-Dish Recycling Robot", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Attention is All you Need", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "nuScenes: A Multimodal Dataset for Autonomous Driving", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "CARLA: An Open Urban Driving Simulator", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "OmniNWM: Omniscient Driving Navigation World Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "ConsisDrive: Identity-Preserving Driving World Models for Video Generation by Instance Mask", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "I and J", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "ImageNet: A large-scale hierarchical image database", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "A and V", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "What matters for Representation Alignment: Global Information or Spatial Structure?", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "SCB-DETR: Multiscale Deformable Transformers for Occlusion-Resilient Student Learning Behavior Detection in Smart Classroom", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Robust Deep Feature Ultrasound Image-Based Visual Servoing: Focus on Cardiac Examination", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Bio-Inspired Fine-Tuning for Selective Transfer Learning in Image Classification", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Hand Sign Language Detection Using Deep Learning", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Representation Learning: A Review and New Perspectives", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "In Advances in Neural Information Processing Systems", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Stochastic Backpropagation and Approximate Inference in Deep Generative Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "SDXL-Lightning: Progressive Adversarial Diffusion Distillation", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditions", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "GenAD: Generative End-to-End Autonomous Driving", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Ovis: Structural Embedding Alignment for Multimodal Large Language Model", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Improving Video Generation with Human Feedback", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Speech Recognition with Deep Recurrent Neural Networks", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Learning representations by back-propagating errors", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Bidirectional recurrent neural networks", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Connectionist Temporal Classi\ufb01cation: Labelling Unsegmented Sequence Data with Recurrent Neural Networks", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "2005 Special Issue: Framewise phoneme classification with bidirectional LSTM and other neural network architectures", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "A high-performance neuroprosthesis for speech decoding and avatar control", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Artificial Intelligence Meets Flexible Sensors: Emerging Smart Flexible Sensing Systems Driven by Machine Learning and Artificial Synapses", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "A high-performance speech neuroprosthesis", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Loss of plasticity in deep continual learning", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "An analog-AI chip for energy-efficient speech recognition and transcription", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "A Mathematical Theory of Communication", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "LiteToken: Removing Intermediate Merge Residues From BPE Tokenizers", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "MeKi: Memory-based Expert Knowledge Injection for Efficient LLM Scaling", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Beyond Conditional Computation: Retrieval-Augmented Genomic Foundation Models with Gengram", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "L$^3$: Large Lookup Layers", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Going Deeper with Convolutions", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Gradient-based learning applied to document recognition", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Regression Shrinkage and Selection via the Lasso", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Microsoft COCO: Common Objects in Context", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "LifeCLEF Plant Identification Task 2015", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "FedMicro-IDA: A Federated Learning and Microservices-based Framework for IoT Data Analytics", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Enhancing pine wilt disease detection with synthetic data and external attention-based transformers", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "A comprehensive review on YOLO versions for object detection", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Harnessing large vision and language models in agriculture: a review", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Multi-axis vision transformer for medical image segmentation", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "A comprehensive review of facial beauty prediction using deep learning techniques", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes.", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Distinctive Image Features from Scale-Invariant Keypoints", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Aligning machine and human visual representations across abstraction levels", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Learning Transferable Visual Models From Natural Language Supervision", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "GENERATIVE ADVERSARIAL NETS", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Improved Mean Flows: On the Challenges of Fastforward Generative Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "There is No VAE: End-to-End Pixel-Space Generative Modeling via Self-Supervised Pre-training", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "PixelDiT: Pixel Diffusion Transformers for Image Generation", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "A comprehensive review of object detection with traditional and deep learning methods", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Diffusion Language Models are Super Data Learners", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "DreamOn: Diffusion Language Models For Code Infilling Beyond Fixed-size Canvas", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "FLEX: Continuous Agent Evolution via Forward Learning from Experience", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "nuScenes: A multimodal dataset for autonomous driving", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Squeeze-and-Excitation Networks", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Decoupled Weight Decay Regularization", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Light-X: Generative 4D Video Rendering with Camera and Illumination Control", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "DriveLaW:Unifying Planning and Video Generation in a Latent Driving World", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "DVGT: Driving Visual Geometry Transformer", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Adding Conditional Control to Text-to-Image Diffusion Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Scaling Instruction-Finetuned Language Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "High-Resolution Image Synthesis with Latent Diffusion Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "AUTO-ENCODING VARIATIONAL BAYES", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Histograms of oriented gradients for human detection", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Generative Adversarial Networks", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Generalization of Diffusion Models Arises with a Balanced Representation Space", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Stable Velocity: A Variance Perspective on Flow Matching", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Laminating Representation Autoencoders for Efficient Diffusion", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Adaptive 1D Video Diffusion Autoencoder", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Test-Time Conditioning with Representation-Aligned Visual Features", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Bio-inspired fine-tuning for selective transfer learning in image classification", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "VGG Induced Deep Hand Sign Language Detection", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "MediaPipe: A Framework for Building Perception Pipelines", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Hand Pose Estimation and Hand Shape Classification Using Multi-layered Randomized Decision Forests", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "A robust static hand gesture recognition system using geometry based normalizations and Krawtchouk moments", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Hand signal classification system for sign language communication in Virtual Reality", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Real-Time Static Hand Sign Recognition System using MediaPipe and Fully Connected Neural Network", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Real-Time Gesture Recognition to Aid Communication in Children with Motor Impairments", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Visualizing Data using t-SNE", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Learning Multiple Layers of Features from Tiny Images", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "LLM Social Simulations Are a Promising Research Method", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Federated Contrastive Learning With Feature-Based Distillation for Human Activity Recognition", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Diffuse and Disperse: Image Generation with Representation Regularization", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Deep Autoencoder Neural Networks: A Comprehensive Review and New Perspectives", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "KABB: Knowledge-Aware Bayesian Bandits for Dynamic Expert Coordination in Multi-Agent Systems", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "U-Net: Convolutional Networks for Biomedical Image Segmentation", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Improved Distribution Matching Distillation for Fast Image Synthesis", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Fast High-Resolution Image Synthesis with Latent Adversarial Diffusion Distillation", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Evolutionary optimization of model merging recipes", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "From Slow Bidirectional to Fast Autoregressive Video Diffusion Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "PuLID: Pure and Lightning ID Customization via Contrastive Alignment", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Denoising Diffusion Probabilistic Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Loopy: Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "OmniHuman-1: Rethinking the Scaling-Up of One-Stage Conditioned Human Animation Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Hallo2: Long-Duration and High-Resolution Audio-Driven Portrait Image Animation", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "EchoMimicV2: Towards Striking, Simplified, and Semi-Body Human Animation", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Feature Pyramid Networks for Object Detection", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "DriveMLM: aligning multi-modal large language models with behavioral planning states for autonomous driving", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "How Far is Video Generation from World Model: A Physical Law Perspective", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "EMMA: End-to-End Multimodal Model for Autonomous Driving", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Language Models are Few-Shot Learners", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "LLaVA-CoT: Let Vision Language Models Reason Step-by-Step", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Proximal Policy Optimization Algorithms", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Flow-GRPO: Training Flow Matching Models via Online RL", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "DanceGRPO: Unleashing GRPO on Visual Generation", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "SkyReels-V2: Infinite-length Film Generative Model", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Unified Reward Model for Multimodal Understanding and Generation", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "SQuAD: 100,000+ Questions for Machine Comprehension of Text", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Neural Machine Translation of Rare Words with Subword Units", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "GPT-4 Technical Report", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "LLaMA: Open and Efficient Foundation Language Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Chain of Thought Prompting Elicits Reasoning in Large Language Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Training Verifiers to Solve Math Word Problems", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Crystal structure of the nucleosome core particle at 2.8\u2009\u00c5 resolution", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "A catalogue of splice junction sequences.", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Origin of the Genetic Code", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "SGDR: Stochastic Gradient Descent with Warm Restarts", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Compression of individual sequences via variable-rate coding", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Pointer Sentinel Mixture Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Measuring Massive Multitask Language Understanding", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Let's Verify Step by Step", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "GPQA: A Graduate-Level Google-Proof Q&A Benchmark", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "MuMu-LLaMA: Multi-modal music understanding and generation via large language models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Mass Concept Erasure in Diffusion Models with Concept Hierarchy", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Intelligent Recognition of GPR Road Hidden Defect Images Based on Feature Fusion and Attention Mechanism", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Flexible Partial Screen-Shooting Watermarking With Provable Robustness", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Pattern Recognition and Machine Learning", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Bagging Predictors", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Automatic Image-Based Plant Disease Severity Estimation Using Deep Learning", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Plant identification using deep neural networks via optimization of transfer learning parameters", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "New perspectives on plant disease characterization based on deep learning", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Deep Learning for Plant Identification in Natural Environment", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Going deeper in the automated identification of Herbarium specimens", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Densely Connected Convolutional Networks", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "MobileNetV2: Inverted Residuals and Linear Bottlenecks", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Communication-Efficient Learning of Deep Networks from Decentralized Data", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "A Comprehensive Survey on Transfer Learning", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Privacy Preserved and Decentralized Smartphone Recommendation System", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "A Survey on Heterogeneity Taxonomy, Security and Privacy Preservation in the Integration of IoT, Wireless Sensor Networks and Federated Learning", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "A privacy-preserving federated learning with a secure collaborative for malware detection models using Internet of Things resources", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Graph-based deep learning techniques for remote sensing applications: Techniques, taxonomy, and applications - A comprehensive review", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Federated Learning Architectures: A Performance Evaluation With Crop Yield Prediction Application", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Segment Anything", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Visual Instruction Tuning", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Improved Baselines with Visual Instruction Tuning", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Enhancing Descriptive Image Quality Assessment With a Large-Scale Multi-Modal Dataset", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Adaptive Chain-of-Focus Reasoning via Dynamic Visual Search and Zooming for Efficient VLMs", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Think with 3D: Geometric Imagination Grounded Spatial Reasoning from Limited Views", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Vision-Language-Action (VLA) Models: Concepts, Progress, Applications and Challenges", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Leave No Observation Behind: Real-time Correction for VLA Action Chunks", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Latent Chain-of-Thought World Modeling for End-to-End Driving", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "HyperVLA: Efficient Inference in Vision-Language-Action Models via Hypernetworks", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Token Expand-Merge: Training-Free Token Compression for Vision-Language-Action Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "TransSIL: A Silhouette Cue-Aware Image Classification Framework for Bird Ecological Monitoring Systems", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "CBRFormer: rendering technology-based transformer for refinement segmentation of bridge crack images", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "A Fast and Compact Threshold Switch-Based Cellular Nonlinear Network Cell", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Deep contrastive learning enables genome-wide virtual screening.", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "LLaVA-based semantic feature modulation diffusion model for underwater image enhancement", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "3DGS-Drag: Dragging Gaussians for Intuitive Point-Based 3D Editing", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "LILaC: Late Interacting in Layered Component Graph for Open-domain Multimodal Multihop Retrieval", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Bidirectional Normalizing Flow: From Data to Noise and Back", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "One-step Latent-free Image Generation with Pixel Mean Flows", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Meta Flow Maps enable scalable reward alignment", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Accelerated Sequential Flow Matching: A Bayesian Filtering Perspective", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Generative Modeling via Drifting", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "A Simple Framework for Contrastive Learning of Visual Representations", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "ImagerySearch: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Simulating the Visual World with Artificial Intelligence: A Roadmap", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "RecTok: Reconstruction Distillation along Rectified Flow", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "RePack then Refine: Efficient Diffusion Transformer with Vision Foundation Model", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Diffusion Models Beat GANs on Image Synthesis", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "DINOv2: Learning Robust Visual Features without Supervision", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "MentisOculi: Revealing the Limits of Reasoning with Mental Imagery", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "OpenVision 3: A Family of Unified Visual Encoder for Both Understanding and Generation", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Distributed Representations of Words and Phrases and their Compositionality", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "GloVe: Global Vectors for Word Representation", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Deep Contextualized Word Representations", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Protein Language Models: Is Scaling Necessary?", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Relating Word Embedding Gender Biases to Gender Gaps: A Cross-Cultural Analysis", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "SegMamba-V2: Long-Range Sequential Modeling Mamba for General 3-D Medical Image Segmentation", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Generative Classifiers Avoid Shortcut Solutions", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Edge Large AI Model Agent-Empowered Cognitive Multimodal Semantic Communication", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Language Models are Unsupervised Multitask Learners", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "The Llama 3 Herd of Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "A Survey on Diffusion Language Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Training Optimal Large Diffusion Language Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Inpainting-Guided Policy Optimization for Diffusion Large Language Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Encoder-Decoder Diffusion Language Models for Efficient Training and Inference", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Stable-DiffCoder: Pushing the Frontier of Code Diffusion Large Language Model", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Empirical-MCTS: Continuous Agent Evolution via Dual-Experience Monte Carlo Tree Search", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "TAME: A Trustworthy Test-Time Evolution of Agent Memory with Systematic Benchmarking", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "ProcMEM: Learning Reusable Procedural Memory from Experience via Non-Parametric PPO for LLM Agents", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Position: Beyond Model-Centric Prediction -- Agentic Time Series Forecasting", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Training language models to follow instructions with human feedback", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "PaLM: Scaling Language Modeling with Pathways", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "ReAct: Synergizing Reasoning and Acting in Language Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Deep Research Agents: A Systematic Examination And Roadmap", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Table-R1: Inference-Time Scaling for Table Reasoning", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Mind2Report: A Cognitive Deep Research Agent for Expert-Level Commercial Report Synthesis", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "PaperScout: An Autonomous Agent for Academic Paper Search with Process-Aware Sequence-Level Policy Optimization", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Gradient-Guided Learning Network for Infrared Small Target Detection", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "A Retrieval-Augmented Generation Approach to Extracting Algorithmic Logic from Neural Networks", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "CenterMamba-SAM: Center-Prioritized Scanning and Temporal Prototypes for Brain Lesion Segmentation", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "IMobileTransformer: A fusion-based lightweight model for rice disease identification", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "RF-DETR: Neural Architecture Search for Real-Time Detection Transformers", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Non-invasive diagnosis of nutrient deficiencies in winter wheat and winter rye using UAV-based RGB images", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Deep learning models for efficient geotechnical predictions: reducing training effort and data requirements with transfer learning", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Image quality assessment: from error visibility to structural similarity", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "FreeOrbit4D: Training-Free Arbitrary Camera Redirection for Monocular Videos via Geometry-Complete 4D Reconstruction", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Scalable Diffusion Models with Transformers", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "RoFormer: Enhanced Transformer with Rotary Position Embedding", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "The Role of World Models in Shaping Autonomous Driving: A Comprehensive Survey", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Vision meets robotics: The KITTI dataset", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Least-Squares Estimation of Transformation Parameters Between Two Point Patterns", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "FlexMap: Generalized HD Map Construction from Flexible Camera Configurations", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Deep Learning", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "MapAnything: Universal Feed-Forward Metric 3D Reconstruction", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "RoBERTa: A Robustly Optimized BERT Pretraining Approach", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Toward expert-level medical question answering with large language models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Equivariant Diffusion for Crystal Structure Prediction", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Native and Compact Structured Latents for 3D Generation", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "and as an in", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Progressive Learned Image Transmission for Semantic Communication Using Hierarchical VAE", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "STORM: Search-Guided Generative World Models for Robotic Manipulation", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Evolutionary Optimization of Model Merging Recipes", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Rich feature hierarchies for accurate object detection and semantic segmentation", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Intelligent recognition of GPR road hidden defect images based on feature fusion and attention mechanism", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Federated Learning Architectures: A Performance Evaluation with Crop Yield Prediction Application", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Enhancing Descriptive Image Quality Assessment with A Large-scale Multi-modal Dataset", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Deep contextualized word representations", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Ashish Vaswani", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Noam Shazeer", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Niki Parmar", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jakob Uszkoreit", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Llion Jones", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Aidan N. Gomez", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lukasz Kaiser", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Illia Polosukhin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kaiming He", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiangyu Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shaoqing Ren", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jian Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Diederik P. Kingma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jimmy Ba", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sepp Hochreiter", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "J. Schmidhuber", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nitish Srivastava", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Geoffrey E. Hinton", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "A. Krizhevsky", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "I. Sutskever", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "R. Salakhutdinov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Christian Szegedy", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vincent Vanhoucke", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sergey Ioffe", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jonathon Shlens", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zbigniew Wojna", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shaina Raza", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mizanur Rahman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Safiullah Kamawal", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Armin Toroghi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ananya Raval", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "F. Navah", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Amirmohammad Kazemeini", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhuoran Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xi Guo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chenjing Ding", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chiyu Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wei Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yanyong Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zisheng Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Junjie Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chisen Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Cong Peng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jianping Xuan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tielin Shi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ming J. Zuo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Abdullah Al Ahad Khan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Md Habib Ullah", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ruchira Tabassum", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Md Faisal Kabir", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jinghuan Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wang Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jian Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Karen Simonyan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Andrew Zisserman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "P. Cochat", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "L. Vaucoret", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "J. Sarles", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ross Girshick", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuqi Cheng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yunkang Cao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haiming Yao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wei Luo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Cheng Jiang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hui Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Weiming Shen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Naveen Kumar Srinivasa", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ajeet Rao Chalamala", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kumar Singh", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ieee Krishna Mohan Senior Member", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "K. Naveen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Srinivasa Rao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ajeet Kumar Singh", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Manlin Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jie Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuxi Ren", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiahong Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ming Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Andy J. Ma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Salma Haidar", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jos\u00e9 Oramas", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hongbo Jiang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lei Ye", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jingyang Hu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaotian Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Siyu Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wei Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kehua Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Diederik P Kingma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Max Welling", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "John C. Duchi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Elad Hazan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Y. Singer", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alex Graves", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Abdel-rahman Mohamed", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Geoffrey Hinton", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nian Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhigao Cui", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yanzhao Su", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yunwei Lan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuanliang Xue", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Cong Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Aihua Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Leong Kah Meng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ho Hooi Yi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ng Bo Wei", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lim Jia Xin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zailan Arabee Abdul Salam", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xin Cheng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wangding Zeng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Damai Dai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qinyu Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bingxuan Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhenda Xie", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kezhao Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xingkai Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhewen Hao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yukun Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Han Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Huishuai Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dongyan Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenfeng Liang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mostafa Saberian", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vidya Samadi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ioana Popescu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Husheng Fang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shunlin Liang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenyuan Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yongzhe Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Han Ma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jianglei Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yichuan Ma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tao He", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Feng Tian", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fengjiao Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hui Liang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wei Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yangqing Jia", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pierre Sermanet", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Scott Reed", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dragomir Anguelov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dumitru Erhan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Andrew Rabinovich", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Olga Russakovsky", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jia Deng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hao Su", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jonathan Krause", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sanjeev Satheesh", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sean Ma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhiheng Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Andrej Karpathy", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Aditya Khosla", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Michael Bernstein", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alexander C. Berg", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Li Fei-Fei", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Boyang Zheng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nanye Ma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shengbang Tong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Saining Xie", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "S. Rizvi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Daniel Levine", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Aakash Patel", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shiyang Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Eric Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Curtis Jamison Perry", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ivan Vrkic", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nicole Mayerli Constante", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zirui Fu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sizhuang He", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "David Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Cerise Tang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhuoyang Lyu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rayyan Y Darji", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chang Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Emily Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "David Jeong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lawrence Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "J. Kwan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "David Braun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Brian Hafler", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hattie Chung", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "R. M. Dhodapkar", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Paul F. Jaeger", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bryan Perozzi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jeffrey Ishizuka", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shekoofeh Azizi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "D. van Dijk", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "\u015eafak K\u0131l\u0131\u00e7", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhengyu Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hanwei Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Renjue Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "R. Sicre", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "L. Amsaleg", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Michael Backes", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qi Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chao Shen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yifei Ge", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhuo Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xuebin Yue", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hengyi Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lin Meng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Colin Raffel", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Adam Roberts", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Katherine Lee", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sharan Narang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Michael Matena", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yanqi Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wei Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Peter J. Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "M. Heusel", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hubert Ramsauer", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Thomas Unterthiner", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bernhard Nessler", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Holger Caesar", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Varun Bankiti", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alex H. Lang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sourabh Vora", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Venice Erin Liong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qiang Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Anush Krishnan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yu Pan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Giancarlo Baldan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Oscar Beijbom", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alexey Dosovitskiy", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "German Ros", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Felipe Codevilla", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Antonio Lopez", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vladlen Koltun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fachrina Dewi Puspitasari", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chaoning Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Joseph Cho", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Adnan Haider", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Noor Ul Eman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Omer Amin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alexis Mankowski", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Muhammad Umair", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jingyao Zheng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sheng Zheng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lik-Hang Lee", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Caiyan Qin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tae-Ho Kim", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Choong Seon Hong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yang Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Heng Tao Shen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bohan Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhuang Ma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dalong Du", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Baorui Peng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhujin Liang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhenqiang Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chao Ma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yueming Jin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hao Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenjun Zeng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xin Jin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guosheng Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yaozeng Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaofeng Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zheng Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tingdong Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guan Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yongchen Zai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ji Jiao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Changliang Xue", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaole Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhen Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Futang Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xingang Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ahmad Rahimi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Valentin Gerard", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Eloi Zablocki", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Matthieu Cord", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alexandre Alahi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "W. Marsden", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wei Dong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "R. Socher", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Li-Jia Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "K. Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "R. Stephenson", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jaskirat Singh", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xingjian Leng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zongze Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Liang Zheng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Richard Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Eli Shechtman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhifeng Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Minghui Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chunyan Zeng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Longlong Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ehsan Zakeri", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Amanda Spilkin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hanae Elmekki", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Antonela Zanuttini", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "L. Kadem", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jamal Bentahar", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wen-Fang Xie", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Philippe Pibarot", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ana Davila", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jacinto Colan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yasuhisa Hasegawa", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Subham Sharma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sharmila Subudhi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yoshua Bengio", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Aaron Courville", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pascal Vincent", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "D. Touretzky", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "M. C. Mozer", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "M. E. Hasselmo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "RegressionChristopher", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "I. K.", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "WilliamsNeural", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "GroupAston", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "UniversityBirmingham", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Danilo Jimenez Rezende", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "S. Mohamed", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Daan Wierstra", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shanchuan Lin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Anran Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiao Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhiyuan Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiajiong Cao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhiquan Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuming Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chenguang Ma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenzhao Zheng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ruiqi Song", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xianda Guo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chenming Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Long Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shiyin Lu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yang Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qing-Guo Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhao Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Weihua Luo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kaifu Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Han-Jia Ye", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jie Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Gongye Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiajun Liang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ziyang Yuan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaokun Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mingwu Zheng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiele Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qiulin Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Menghan Xia", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xintao Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaohong Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fei Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pengfei Wan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Di Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kun Gai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yujiu Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wanli Ouyang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "D. Rumelhart", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ronald J. Williams", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "M. Schuster", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "K. Paliwal", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Santiago Fern\u00b4andez", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Faustino J. Gomez", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "J\u00a8urgen Schmidhuber", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tianming Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bin Feng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jinpeng Huo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yu Xiao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wengan Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jin Peng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zehua Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chengjie Du", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenxian Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "G. Zou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lei Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Francis R. Willett", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Erin M. Kunz", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chaofei Fan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Donald T. Avansino", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "G. Wilson", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Eun Young Choi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Foram B. Kamdar", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "M. Glasser", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "L. Hochberg", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "S. Druckmann", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "K. Shenoy", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "J. Henderson", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shibhansh Dohare", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "J. F. Hernandez-Garcia", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qingfeng Lan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Parash Rahman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "A. Mahmood", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "R. Sutton", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "S. Ambrogio", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "P. Narayanan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "A. Okazaki", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "A. Fasoli", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "C. Mackin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "K. Hosokawa", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "A. Nomura", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Takeo Yasuda", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "An Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "A. Friz", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "M. Ishii", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "J. Luquin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Y. Kohda", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "N. Saulnier", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "K. Brew", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Samuel Choi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "I. Ok", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Timothy Philip", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Victor Chan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "M. Silvestre", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ishtiaq Ahsan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vijay Narayanan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "H. Tsai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Geoffrey W. Burr", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "J. Shin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sang Joon Kim", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yike Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haotong Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhouchen Lin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Muhan Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ning Ding", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fangcheng Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kyungrae Kim", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Linji Hao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kyeng-Hun Lee", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hyeonmok Ko", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yehui Tang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Huinan Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xuyang Feng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Junhong Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Junchen Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kaiwen Deng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kai Ding", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shengning Long", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiaxue Shuai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhaorong Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shiping Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guirong Xue", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhan Xiao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Albert Tseng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Christopher De Sa", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hong Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiaqi Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chao Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xing Hu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Linkun Lyu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiaqi Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xurui Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bo Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fengcun Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yulei Qian", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lingtong Si", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yerui Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rumei Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Peng Pei", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuchen Xie", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xunliang Cai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yann LeCun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "L. Bottou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "P. Haffner", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "R. Tibshirani", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tsung-Yi Lin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Michael Maire", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Serge Belongie", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lubomir Bourdev", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "James Hays", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pietro Perona", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Deva Ramanan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "C. Lawrence Zitnick", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Piotr Doll\u00e1r", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Herve Goeau", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pierre Bonnet", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alexis Joly", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Safa Ben Atitallah", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Maha Driss", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Henda Ben Ghezela", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sareer Ul Amin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yonghoon Jung", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Muhammad Fayaz", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bumsoo Kim", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sanghyun Seo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ay\u015fe Aybilge Murat", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "M. S. K\u0131ran", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hongyan Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shuai Qin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Min Su", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chengzhi Lin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Anjie Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Junfeng Gao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Abdul Rehman Khan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Asifullah Khan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "D. E. Boukhari", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "F. Dornaika", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "A. Chemsa", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Abdelmalik Taleb-Ahmed", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Benjamin DeMeo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Charlotte Nesbitt", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "S. A. Miller", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Daniel B. Burkhardt", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Inna Lipchina", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Doris Fu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Peter Holderreith", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "David Kim", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sergey Kolchenko", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Artur Sza\u0142ata", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ishan Gupta", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Christine Kerr", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Thomas Pfefer", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Raziel Rojas-Rodriguez", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sunil Kuppassani", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Laurens Kruidenier", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Parul B Doshi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mahdi Zamanighomi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "James J. Collins", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "A. Shalek", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "F. Theis", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mauricio Cortes", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "D. Lowe", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiang An", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yin Xie", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kaicheng Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenkang Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiuwei Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zheng Cheng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yirui Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Songcen Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Changrui Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Didi Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chunsheng Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Huajie Tan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chunyuan Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jing Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jie Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiyao Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bin Qin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yumeng Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zizhen Yan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ziyong Feng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ziwei Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bo Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiankang Deng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kento Kawaharazuka", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jihoon Oh", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jun Yamada", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ingmar Posner", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuke Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lukas Muttenthaler", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Klaus Greff", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Frieda Born", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bernhard Spitzer", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Simon Kornblith", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Klaus-Robert Muller", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Andrew Kyle Lampinen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lucas Beyer", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alexander Kolesnikov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dirk Weissenborn", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaohua Zhai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mostafa Dehghani", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Matthias Minderer", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Georg Heigold", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sylvain Gelly", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Neil Houlsby", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alec Radford", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jong Wook Kim", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chris Hallacy", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Aditya Ramesh", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Gabriel Goh", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sandhini Agarwal", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Girish Sastry", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Amanda Askell", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pamela Mishkin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jack Clark", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Gretchen Krueger", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ilya Sutskever", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Individualized Treat", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jinsung Yoon", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhengyang Geng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yiyang Lu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "J. Zico Kolter", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiachen Lei", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Keli Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Julius Berner", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haiming Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hongkai Zheng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiahong Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiangxiang Chu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Minglei Shi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haolin Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Borui Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bohan Zeng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaoshi Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuanxing Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Huan Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jie Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiwen Lu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yongsheng Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wei Xiong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Weili Nie", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yichen Sheng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shiqiu Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiebo Luo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhiheng Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Weiming Ren", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haozhe Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zijian Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shoufa Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haonan Qiu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaoke Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhaochong An", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fanny Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Aditya Patel", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Viktar Atliha", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tony Ng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiao Han", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chuyan Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chenyang Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ding Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Juan-Manuel Perez-Rua", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sen He", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "J\u00fcrgen Schmidhuber", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenhu Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ping Luo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tao Xiang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jonas Schult", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuren Cong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jacob Devlin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ming-Wei Chang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kenton Lee", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kristina Toutanova", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vrushali Pagire", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "M. Chavali", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ashish Kale", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jinjie Ni", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qian Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Longxu Dou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chao Du", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zili Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hang Yan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tianyu Pang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Michael Qizhe Shieh", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zirui Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lin Zheng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhihui Xie", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiacheng Ye", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiahui Gao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shansan Gong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yansong Feng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhenguo Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wei Bi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guorui Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lingpeng Kong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhicheng Cai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xinyuan Guo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yu Pei", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiangtao Feng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jinsong Su", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiangjie Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ya-Qin Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wei-Ying Ma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mingxuan Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hao Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mingyue Cheng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jie Ouyang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shuo Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ruiran Yan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yucong Luo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zirui Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Daoyu Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qi Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Enhong Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jie Hu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Li Shen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Samuel Albanie", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Gang Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Enhua Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "I. Loshchilov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "F. Hutter", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mingxing Tan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Quoc V. Le", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tianqi Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhaoxi Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zihao Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shaocong Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Saining Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chongjie Ye", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhiguo Cao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tianze Xia", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yongkang Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lijun Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jingfeng Yao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kaixin Xiong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haiyang Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bing Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kun Ma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guang Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hangjun Ye", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenyu Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xinggang Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sicheng Zuo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zixun Xie", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shaoqing Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fang Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shengyin Jiang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhi-Xin Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lvmin Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Anyi Rao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Maneesh Agrawala", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hyung Won Chung", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Le Hou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shayne Longpre", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Barret Zoph", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yi Tay", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "William Fedus", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yunxuan Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xuezhi Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Siddhartha Brahma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Albert Webson", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shixiang Shane Gu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhuyun Dai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mirac Suzgun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xinyun Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Aakanksha Chowdhery", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alex Castro-Ros", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Marie Pellat", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kevin Robinson", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dasha Valter", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Gaurav Mishra", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Adams Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vincent Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yanping Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Andrew Dai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hongkun Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Slav Petrov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ed H. Chi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jeff Dean", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Denny Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jason Wei", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Robin Rombach", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Andreas Blattmann", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dominik Lorenz", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Patrick Esser", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bj\u00f6rn Ommer", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Romain Lopez", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pierre Boyeau", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "N. Yosef", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Michael I. Jordan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "J. Regier", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Phillip Isola", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alexei A. Efros", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Oliver Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pei Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Henrik Kretzschmar", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xerxes Dotiwalla", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Aurelien Chouard", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vijaysai Patnaik", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Paul Tsui", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "James Guo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yin Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuning Chai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Benjamin Caine", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vijay Vasudevan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wei Han", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiquan Ngiam", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hang Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Aleksei Timofeev", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Scott Ettinger", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Maxim Krivokon", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Amy Gao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Aditya Joshi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sheng Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shuyang Cheng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yu Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhifeng Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Navneet Dalal", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "B. Triggs", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Gilad Cohen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Raja Giryes", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zekai Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiao Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiang Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lianghe Shi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Meng Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Molei Tao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qing Qu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Donglin Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yongxing Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xin Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Liang Hou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xin Tao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaojuan Qi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Renjie Liao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ram\u00f3n Calvo-Gonz\u00e1lez", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fran\u00e7ois Fleuret", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yao Teng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Minxuan Lin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xian Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shuai Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xihui Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nicolas Sereyjol-Garros", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ellington Kirby", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Victor Letzelter", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Victor Besnier", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nermin Samet", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Camillo Lugaresi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiuqiang Tang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hadon Nash", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chris McClanahan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Esha Uboweja", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Michael Hays", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fan Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chuo-Ling Chang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ming Guang Yong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Juhyun Lee", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wan-Teh Chang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wei Hua", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Manfred Georg", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Matthias Grundmann", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Cem Keskin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mustafa Furkan K\u0131ra\u00e7", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yunus Emre Kara", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "L. Akarun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "S. P. Priyal", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "P. Bora", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Octavian Dudas", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "C. Nandra", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "C. Mocan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "D. Gorgan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Avinash Dhiran", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Anurag Kumbhare", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Achal Patil", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mrugank Vichare", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dhananjay Patel", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Saransh Mishra", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pavan Nair", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pushpalatha M", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Poornima S", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "A. Dempster", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "N. Laird", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "D. Rubin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "L. Maaten", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jacy Reese Anthis", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ryan Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sean M. Richardson", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Austin C. Kozlowski", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bernard Koch", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "James Evans", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Erik Brynjolfsson", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhiwen Xiao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Huagang Tong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Runqian Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ibomoiye Domor Mienye", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Theo G. Swart", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jusheng Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zimeng Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yijia Fan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ningyuan Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mingyan Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhuojie Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiawei Yao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jian Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Keze Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Olaf Ronneberger", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Philipp Fischer", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Thomas Brox", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tianwei Yin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Micha\u00ebl Gharbi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Taesung Park", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fredo Durand", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "William T. Freeman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Axel Sauer", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Frederic Boesel", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tim Dockhorn", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Takuya Akiba", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Makoto Shing", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yujin Tang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qi Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "David Ha", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qiang Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xun Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zinan Guo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yanze Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhuowei Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lang Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Peng Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qian He", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jonathan Ho", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ajay Jain", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pieter Abbeel", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Weijie Kong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qi Tian", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zijian Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rox Min", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zuozhuo Dai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jin Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiangfeng Xiong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xin Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bo Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jianwei Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kathrina Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qin Lin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Junkun Yuan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yanxin Long", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Aladdin Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Andong Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Changlin Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Duojun Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fang Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hao Tan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hongmei Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jacob Song", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiawang Bai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jianbing Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jinbao Xue", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Joey Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kai Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mengyang Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pengyu Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shuai Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Weiyan Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenqing Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xinchi Deng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yi Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yutao Cui", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuanbo Peng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhentao Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhiyu He", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhiyong Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zixiang Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zunnan Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yangyu Tao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qinglin Lu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Songtao Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dax Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hongfa Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yong Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Di Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuhong Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jie Jiang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Caesar Zhong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jianwen Jiang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chao Liang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiaqi Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Gaojie Lin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tianyun Zhong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yanbo Zheng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zerong Zheng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiahao Cui", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hui Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yao Yao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hao Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hanlin Shang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kaihui Cheng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hang Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Siyu Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jingdong Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rang Meng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xingyu Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bharath Hariharan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kyunghyun Cho", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bart van Merrienboer", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Caglar Gulcehre", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dzmitry Bahdanau", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fethi Bougares", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Holger Schwenk", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Erfei Cui", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenhai Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhiqi Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiangwei Xie", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haoming Zou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hanming Deng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Gen Luo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lewei Lu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xizhou Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jifeng Dai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shenyuan Gao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiazhi Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Li Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kashyap Chitta", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yihang Qiu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Andreas Geiger", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jun Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hongyang Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bencheng Liao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shaoyu Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haoran Yin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bo Jiang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Cheng Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sixu Yan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xinbang Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiangyu Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ying Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qian Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bingyi Kang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yang Yue", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rui Lu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhijie Lin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yang Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kaixin Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Gao Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiashi Feng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jyh-Jing Hwang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Runsheng Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hubert Lin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wei-Chih Hung", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jingwei Ji", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kristy Choi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Di Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tong He", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Paul Covington", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Benjamin Sapp", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tom B. Brown", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Benjamin Mann", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nick Ryder", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Melanie Subbiah", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jared Kaplan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Prafulla Dhariwal", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Arvind Neelakantan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pranav Shyam", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ariel Herbert-Voss", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tom Henighan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rewon Child", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Daniel M. Ziegler", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jeffrey Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Clemens Winter", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Christopher Hesse", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mark Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Eric Sigler", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mateusz Litwin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Scott Gray", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Benjamin Chess", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Christopher Berner", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sam McCandlish", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dario Amodei", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhe Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Weiyun Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yue Cao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yangzhou Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhangwei Gao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jinguo Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shenglong Ye", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hao Tian", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhaoyang Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lixin Gu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xuehui Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qingyun Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yiming Ren", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zixuan Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiapeng Luo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiahao Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tan Jiang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Conghui He", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Botian Shi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xingcheng Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Han Lv", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yi Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenqi Shao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pei Chu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhongying Tu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhiyong Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Huipeng Deng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiaye Ge", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kai Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kaipeng Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Limin Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Min Dou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tong Lu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dahua Lin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yu Qiao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuchen Duan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Weijie Su", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jie Shao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xingguang Wei", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hongjie Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haomin Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Weiye Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hao Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nianchen Deng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Songze Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yinan He", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Junjun He", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yingtong Xiong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenwen Qu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Peng Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Penglong Jiao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lijun Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haodong Duan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xinyu Fang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Junming Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiangyu Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuxuan Qiao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mo Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Amit Agarwal", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lin Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuan Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yubo Ma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hailong Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yifan Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tack Hwa Wong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Peiheng Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaozhe Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chaoyou Fu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Junbo Cui", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jixuan Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Enxin Song", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Song Mao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shengyuan Ding", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tianhao Liang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zicheng Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaoyi Dong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuhang Zang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pan Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiaqi Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guowei Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Peng Jin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ziang Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yibing Song", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lichao Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Li Yuan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hengjun Pu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Long Cui", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Linglin Jing", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhaokai Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ganlin Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qi Wei", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jinhui Yin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenhao Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guanzhou Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zichen Ding", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Changyao Tian", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhenyu Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jingjing Xie", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zehao Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bowen Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhi Hou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haoran Hao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tianyi Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bin Fu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Biqing Qi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qipeng Guo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenwei Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Songyang Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Maosong Cao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Junyao Lin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kexian Tang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jianfei Gao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haian Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuzhe Gu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chengqi Lyu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Huanze Tang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rui Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haijun Lv", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bowen Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "John Schulman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Filip Wolski", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Oleg Klimov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yangguang Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiaheng Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zeyue Xue", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yu Gao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fangyuan Kong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lingting Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mengzhao Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qiushan Guo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Weilin Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haoyuan Guo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tuyen Hoang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lu Jiang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Huixia Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiashi Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Liang Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaojie Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xunsong Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yifu Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiawei Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shu Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaonan Nie", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhiwu Qing", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Li Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhi Tian", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sen Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guoqiang Wei", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guohong Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ruiqi Xia", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fei Xiao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xuefeng Xiao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiangqiao Yan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ceyuan Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jianchao Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Runkai Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tao Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yihang Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zilyu Ye", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xuejiao Zeng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yan Zeng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Heng Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaozheng Zheng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Peihao Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiaxin Zou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Feilong Zuo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guibin Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dixuan Lin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiangping Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chunze Lin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Junchen Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mingyuan Fan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hao Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sheng Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zheng Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chengcheng Ma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Weiming Xiong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wei Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nuo Pang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kang Kang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhiheng Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuzhe Jin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yupeng Liang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yubing Song", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Peng Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Boyuan Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Di Qiu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Debang Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhengcong Fei", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yahui Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yibin Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Cheng Jin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "\u77e5\u79c0 \u67f4\u7530", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pranav Rajpurkar", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Konstantin Lopyrev", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Percy Liang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rico Sennrich", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Barry Haddow", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alexandra Birch", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Taku Kudo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "John Richardson", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "OpenAI", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Josh Achiam", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Steven Adler", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lama Ahmad", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ilge Akkaya", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Florencia Leoni Aleman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Diogo Almeida", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Janko Altenschmidt", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sam Altman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shyamal Anadkat", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Red Avila", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Igor Babuschkin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Suchir Balaji", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Valerie Balcom", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Paul Baltescu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haiming Bao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mohammad Bavarian", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jeff Belgum", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Irwan Bello", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jake Berdine", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Gabriel Bernadett-Shapiro", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lenny Bogdonoff", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Oleg Boiko", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Madelaine Boyd", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Anna-Luisa Brakman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Greg Brockman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tim Brooks", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Miles Brundage", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kevin Button", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Trevor Cai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rosie Campbell", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Andrew Cann", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Brittany Carey", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chelsea Carlson", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rory Carmichael", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Brooke Chan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Che Chang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fotis Chantzis", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Derek Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sully Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ruby Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jason Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ben Chess", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chester Cho", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Casey Chu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dave Cummings", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jeremiah Currier", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yunxing Dai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Cory Decareaux", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Thomas Degry", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Noah Deutsch", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Damien Deville", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Arka Dhar", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "David Dohan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Steve Dowling", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sheila Dunning", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Adrien Ecoffet", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Atty Eleti", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tyna Eloundou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "David Farhi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Liam Fedus", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Niko Felix", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sim\u00f3n Posada Fishman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Juston Forte", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Isabella Fulford", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Leo Gao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Elie Georges", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Christian Gibson", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vik Goel", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tarun Gogineni", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rapha Gontijo-Lopes", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jonathan Gordon", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Morgan Grafstein", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ryan Greene", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Joshua Gross", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yufei Guo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jesse Han", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jeff Harris", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuchen He", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mike Heaton", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Johannes Heidecke", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chris Hesse", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alan Hickey", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wade Hickey", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Peter Hoeschele", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Brandon Houghton", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kenny Hsu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shengli Hu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xin Hu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Joost Huizinga", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shantanu Jain", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shawn Jain", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Joanne Jang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Angela Jiang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Roger Jiang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haozhun Jin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Denny Jin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shino Jomoto", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Billie Jonn", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Heewoo Jun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tomer Kaftan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "\u0141ukasz Kaiser", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ali Kamali", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ingmar Kanitscheider", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nitish Shirish Keskar", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tabarak Khan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Logan Kilpatrick", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Christina Kim", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yongjik Kim", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jan Hendrik Kirchner", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jamie Kiros", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Matt Knight", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Daniel Kokotajlo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "\u0141ukasz Kondraciuk", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Andrew Kondrich", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Aris Konstantinidis", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kyle Kosic", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vishal Kuo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Michael Lampe", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ikai Lan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Teddy Lee", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jan Leike", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jade Leung", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Daniel Levy", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chak Ming Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rachel Lim", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Molly Lin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Stephanie Lin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Theresa Lopez", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ryan Lowe", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Patricia Lue", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Anna Makanju", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kim Malfacini", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sam Manning", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Todor Markov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yaniv Markovski", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bianca Martin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Katie Mayer", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Andrew Mayne", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bob McGrew", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Scott Mayer McKinney", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Christine McLeavey", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Paul McMillan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jake McNeil", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "David Medina", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Aalok Mehta", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jacob Menick", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Luke Metz", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Andrey Mishchenko", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vinnie Monaco", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Evan Morikawa", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Daniel Mossing", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tong Mu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mira Murati", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Oleg Murk", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "David M\u00e9ly", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ashvin Nair", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Reiichiro Nakano", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rajeev Nayak", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Richard Ngo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hyeonwoo Noh", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Long Ouyang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Cullen O'Keefe", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jakub Pachocki", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alex Paino", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Joe Palermo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ashley Pantuliano", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Giambattista Parascandolo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Joel Parish", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Emy Parparita", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alex Passos", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mikhail Pavlov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Andrew Peng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Adam Perelman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Filipe de Avila Belbute Peres", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Michael Petrov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Henrique Ponde de Oliveira Pinto", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Michael", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pokorny", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Michelle Pokrass", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vitchyr H. Pong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tolly Powell", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alethea Power", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Boris Power", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Elizabeth Proehl", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Raul Puri", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jack Rae", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Cameron Raymond", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Francis Real", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kendra Rimbach", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Carl Ross", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bob Rotsted", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Henri Roussez", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mario Saltarelli", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ted Sanders", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shibani Santurkar", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Heather Schmidt", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "David Schnurr", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Daniel Selsam", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kyla Sheppard", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Toki Sherbakov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jessica Shieh", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sarah Shoker", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Szymon Sidor", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Maddie Simens", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jordan Sitkin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Katarina Slama", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ian Sohl", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Benjamin Sokolowsky", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yang Song", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Natalie Staudacher", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Felipe Petroski Such", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Natalie Summers", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jie Tang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nikolas Tezak", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Madeleine B. Thompson", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Phil Tillet", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Amin Tootoonchian", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Elizabeth Tseng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Preston Tuggle", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nick Turley", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jerry Tworek", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Juan Felipe Cer\u00f3n Uribe", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Andrea Vallone", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Arun Vijayvergiya", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chelsea Voss", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Carroll Wainwright", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Justin Jay Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alvin Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ben Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jonathan Ward", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "CJ Weinmann", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Akila Welihinda", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Peter Welinder", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiayi Weng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lilian Weng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Matt Wiethoff", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dave Willner", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Samuel Wolrich", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hannah Wong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lauren Workman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sherwin Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jeff Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Michael Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kai Xiao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tao Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sarah Yoo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kevin Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qiming Yuan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wojciech Zaremba", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rowan Zellers", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chong Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Marvin Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shengjia Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tianhao Zheng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Juntang Zhuang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "William Zhuk", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hugo Touvron", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Thibaut Lavril", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Gautier Izacard", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xavier Martinet", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Marie-Anne Lachaux", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Timoth\u00e9e Lacroix", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Baptiste Rozi\u00e8re", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Naman Goyal", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Eric Hambro", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Faisal Azhar", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Aurelien Rodriguez", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Armand Joulin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Edouard Grave", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guillaume Lample", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dale Schuurmans", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Maarten Bosma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Brian Ichter", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fei Xia", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ed Chi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Quoc Le", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Karl Cobbe", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vineet Kosaraju", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Matthias Plappert", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jacob Hilton", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Albert Gu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tri Dao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Stephen M. Mount", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "F. Crick", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ilya Loshchilov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Frank Hutter", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Azalia Mirhoseini", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Krzysztof Maziarz", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Andy Davis", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "J. Ziv", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "A. Lempel", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Stephen Merity", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Caiming Xiong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "James Bradbury", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Richard Socher", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dan Hendrycks", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Collin Burns", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Steven Basart", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Andy Zou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mantas Mazeika", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dawn Song", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jacob Steinhardt", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hunter Lightman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yura Burda", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Harri Edwards", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bowen Baker", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "David Rein", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Betty Li Hou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Asa Cooper Stickland", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jackson Petty", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Richard Yuanzhe Pang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Julien Dirani", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Julian Michael", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Samuel R. Bowman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dmitry Lepikhin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "HyoukJoong Lee", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuanzhong Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dehao Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Orhan Firat", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Maxim Krikun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jeff Donahue", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Trevor Darrell", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jitendra Malik", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shansong Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Atin Sakkeer Hussain", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qilong Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chenshuo Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ying Shan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiahang Tu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ye Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yiming Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hanbin Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chao Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hui Qian", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haotian Lv", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuhui Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiangbo Dai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hanli Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiaji Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dawei Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mingxin Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yanzhao Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dingkun Long", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Keqin Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sibo Song", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shuai Bai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhibo Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pengjun Xie", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "An Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dayiheng Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jingren Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Junyang Lin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mingyue Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xin Liao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Han Fang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jinlin Guo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yanxiang Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaoshuai Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Radford M. Neal", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "L. Breiman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guan Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yu Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jianxin Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mostafa Mehdipour-Ghazi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "B. Yanikoglu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "E. Aptoula", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sue Han Lee", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "H. Go\u00ebau", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "P. Bonnet", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "A. Joly", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haiyan Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jose Carranza-Rojas", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Herv\u00e9 Goeau", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Erick Mata-Montero", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhuang Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Laurens van der Maaten", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kilian Q. Weinberger", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mark Sandler", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Andrew Howard", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Menglong Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Andrey Zhmoginov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Liang-Chieh Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "H. Brendan McMahan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Eider Moore", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Daniel Ramage", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Seth Hampson", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Blaise Ag\u00fcera y Arcas", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fuzhen Zhuang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhiyuan Qi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Keyu Duan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dongbo Xi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yongchun Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hengshu Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hui Xiong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qing He", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "A. Khan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wadii Boulila", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "G. A. Sampedro", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sidra Abbas", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chitapong Wechtaisong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tesfahunegn Minwuyelet Mengistu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Taewoon Kim", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jenn-Wei Lin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "A. Alamer", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Manel Khazri Khlifi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "I. Farah", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Anwesha Mukherjee", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rajkumar Buyya", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alexander Kirillov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Eric Mintun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nikhila Ravi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hanzi Mao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chloe Rolland", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Laura Gustafson", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tete Xiao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Spencer Whitehead", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wan-Yen Lo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haotian Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qingyang Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yong Jae Lee", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuheng Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhiyuan You", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jinjin Gu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xin Cai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zheyuan Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kaiwen Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chao Dong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tianfan Xue", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xintong Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhi Gao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bofei Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pengxiang Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaowen Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yang Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tao Yuan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuwei Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yunde Jia", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Song-Chun Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qing Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhangquan Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Manyuan Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xinlei Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xufang Luo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mingze Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zihao Pan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yan Feng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ruqi Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tiancheng Gu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kaichen Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yueyi Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Weidong Cai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lidong Bing", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Keming Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zuhao Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kairui Hu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bin Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xingxuan Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ranjan Sapkota", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yang Cao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Konstantinos I. Roumeliotis", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Manoj Karkee", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kohei Sendai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Maxime Alvarez", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tatsuya Matsushima", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yutaka Matsuo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yusuke Iwasawa", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shuhan Tan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuxiao Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ran Tian", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yurong You", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yan Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenjie Luo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yulong Cao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Philipp Krahenbuhl", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Marco Pavone", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Boris Ivanovic", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zheng Xiong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kang Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zilin Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Matthew Jackson", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jakob Foerster", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shimon Whiteson", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yifan Ye", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiaqi Ma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jun Cen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhihe Lu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hai Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yu Song", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tingting Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhaoli Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaolan Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Neal N. Xiong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Honghu Chu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiahao Gai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Weiwei Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jun Ma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "A. S. Demirkol", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "A. Ascoli", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "I. Messaris", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "V. Ntinas", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "D. Prousalis", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "R. Tetzlaff", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yinjun Jia", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bowen Gao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiaxin Tan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiqing Zheng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xin Hong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenyu Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haichuan Tan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuan Xiao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Liping Tan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hongyi Cai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yanwen Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhiheng Deng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiangwei Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yue Jin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yafei Yuan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiekang Tian", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wei He", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Weiying Ma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chuangye Yan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yanyan Lan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guodong Fan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shengning Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhen Hua", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jinjiang Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jingchun Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiahua Dong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yu-Xiong Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Joohyung Yun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Doyup Lee", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wook-Shin Han", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qiao Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xianbang Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhicheng Jiang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hanhong Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Susie Lu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tianhong Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Peter Potaptchik", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Adhi Saravanan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Abbas Mammadov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alvaro Prat", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Michael S. Albergo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yee Whye Teh", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yinan Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hans Hao-Hsun Hsu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Junran Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bo Dai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pan Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mingyang Deng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "He Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yilun Du", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ting Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mohammad Norouzi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chubin Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sujie Hu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiashu Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Meiqi Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jintao Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yanxun Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nisha Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chengyu Fang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiu Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaokun Feng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chen Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bingze Song", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fangyuan Mao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kaiqi Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ziteng Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bingda Tang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ellis Brown", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jihan Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rob Fergus", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jingtong Yue", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ziqi Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kaixin Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Daili Hua", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bozhou Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chengzhuo Tong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuran Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xinyi Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yifan Dai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zixiang Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yifan Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhou Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hao Liang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaochen Ma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ruichuan An", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tianyi Bai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hongcheng Gao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Junbo Niu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yang Shi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xinlong Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yue Ding", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kai Zeng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yiwen Tang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wentao Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qingyu Shi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Size Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jinbin Bai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kaidong Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yujing Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yunhai Tong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiangtai Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xuelong Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guanfang Dong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Luke Schultz", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Negar Hassanpour", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chao Gao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alex Nichol", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Maxime Oquab", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Timoth\u00e9e Darcet", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Th\u00e9o Moutakanni", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Huy Vo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Marc Szafraniec", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vasil Khalidov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pierre Fernandez", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Daniel Haziza", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Francisco Massa", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alaaeldin El-Nouby", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mahmoud Assran", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nicolas Ballas", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wojciech Galuba", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Russell Howes", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Po-Yao Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shang-Wen Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ishan Misra", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Michael Rabbat", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vasu Sharma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Gabriel Synnaeve", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hu Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Herv\u00e9 Jegou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Julien Mairal", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Patrick Labatut", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Piotr Bojanowski", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zehong Ma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ruihan Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shiliang Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shanshan Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xinjie Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jintao Guo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiakui Hu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lunhao Duan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Minghao Fu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yong Xien Chng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guo-Hua Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jana Zeller", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Thadd\u00e4us Wiedemer", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fanfei Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Thomas Klein", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Prasanna Mayilvahanan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Matthias Bethge", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Felix Wichmann", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ryan Cotterell", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wieland Brendel", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Letian Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sucheng Ren", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yanqing Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xianhang Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zeyu Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuyin Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Huaxiu Yao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zeyu Zheng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guilin Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhiding Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Cihang Xie", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tomas Mikolov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Greg Corrado", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jeffrey Dean", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jeffrey Pennington", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Christopher D. Manning", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Matthew E. Peters", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mark Neumann", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mohit Iyyer", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Matt Gardner", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Christopher Clark", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Luke Zettlemoyer", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Quentin Fournier", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Robert M. Vernon", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Almer M. van der Sloot", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Benjamin Schulz", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sarath Chandar", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "C. Langmead", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Scott Friedman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sonja Schmer-Galunder", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Anthony Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jeffrey Rye", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhaohu Xing", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tian Ye", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yijun Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "D. Cai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Baowen Gai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiao-Jian Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Feng Gao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lei Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alexander C. Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ananya Kumar", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Deepak Pathak", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Y. Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yinqiu Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shaoyong Guo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xuesong Qiu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiewei Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiakai Hao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dusist Niyato", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "R. Child", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "D. Luan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Aaron Grattafiori", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Abhimanyu Dubey", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Abhinav Jauhri", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Abhinav Pandey", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Abhishek Kadian", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ahmad Al-Dahle", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Aiesha Letman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Akhil Mathur", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alan Schelten", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alex Vaughan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Amy Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Angela Fan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Anirudh Goyal", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Anthony Hartshorn", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Aobo Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Archi Mitra", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Archie Sravankumar", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Artem Korenev", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Arthur Hinsvark", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Arun Rao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Aston Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Austen Gregerson", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ava Spataru", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Baptiste Roziere", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bethany Biron", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Binh Tang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bobbie Chern", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Charlotte Caucheteux", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chaya Nayak", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chloe Bi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chris Marra", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chris McConnell", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Christian Keller", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Christophe Touret", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chunyang Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Corinne Wong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Cristian Canton Ferrer", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Cyrus Nikolaidis", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Damien Allonsius", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Daniel Song", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Danielle Pintz", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Danny Livshits", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Danny Wyatt", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "David Esiobu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dhruv Choudhary", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dhruv Mahajan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Diego Garcia-Olano", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Diego Perino", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dieuwke Hupkes", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Egor Lakomkin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ehab AlBadawy", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Elina Lobanova", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Emily Dinan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Eric Michael Smith", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Filip Radenovic", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Francisco Guzm\u00e1n", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Frank Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Gabrielle Lee", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Georgia Lewis Anderson", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Govind Thattai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Graeme Nail", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Gregoire Mialon", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guan Pang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guillem Cucurell", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hailey Nguyen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hannah Korevaar", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Iliyan Zarov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Imanol Arrieta Ibarra", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Isabel Kloumann", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ivan Evtimov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jack Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jade Copet", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jaewon Lee", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jan Geffert", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jana Vranes", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jason Park", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jay Mahadeokar", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jeet Shah", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jelmer van der Linde", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jennifer Billock", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jenny Hong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jenya Lee", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jeremy Fu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jianfeng Chi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jianyu Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiawen Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jie Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiecao Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Joanna Bitton", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Joe Spisak", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jongsoo Park", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Joseph Rocca", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Joshua Johnstun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Joshua Saxe", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Junteng Jia", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kalyan Vasuden Alwala", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Karthik Prasad", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kartikeya Upasani", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kate Plawiak", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ke Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kenneth Heafield", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kevin Stone", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Khalid El-Arini", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Krithika Iyer", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kshitiz Malik", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kuenley Chiu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kunal Bhalla", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kushal Lakhotia", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lauren Rantala-Yeary", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lawrence Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Liang Tan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Liz Jenkins", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Louis Martin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lovish Madaan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lubo Malo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lukas Blecher", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lukas Landzaat", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Luke de Oliveira", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Madeline Muzzi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mahesh Pasupuleti", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mannat Singh", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Manohar Paluri", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Marcin Kardas", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Maria Tsimpoukelli", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mathew Oldham", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mathieu Rita", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Maya Pavlova", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Melanie Kambadur", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mike Lewis", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Min Si", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mitesh Kumar Singh", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mona Hassan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Narjes Torabi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nikolay Bashlykov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nikolay Bogoychev", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Niladri Chatterji", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ning Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Olivier Duchenne", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Onur \u00c7elebi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Patrick Alrassy", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pengchuan Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pengwei Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Petar Vasic", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Peter Weng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Prajjwal Bhargava", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pratik Dubal", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Praveen Krishnan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Punit Singh Koura", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Puxin Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qingxiao Dong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ragavan Srinivasan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Raj Ganapathy", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ramon Calderer", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ricardo Silveira Cabral", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Robert Stojnic", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Roberta Raileanu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rohan Maheswari", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rohit Girdhar", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rohit Patel", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Romain Sauvestre", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ronnie Polidoro", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Roshan Sumbaly", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ross Taylor", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ruan Silva", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rui Hou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Saghar Hosseini", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sahana Chennabasappa", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sanjay Singh", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sean Bell", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Seohyun Sonia Kim", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sergey Edunov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shaoliang Nie", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sharath Raparthy", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sheng Shen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shengye Wan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shruti Bhosale", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shun Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Simon Vandenhende", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Soumya Batra", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Spencer Whitman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sten Sootla", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Stephane Collot", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Suchin Gururangan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sydney Borodinsky", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tamar Herman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tara Fowler", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tarek Sheasha", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Thomas Georgiou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Thomas Scialom", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tobias Speckbacher", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Todor Mihaylov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tong Xiao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ujjwal Karn", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vedanuj Goswami", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vibhor Gupta", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vignesh Ramanathan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Viktor Kerkez", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vincent Gonguet", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Virginie Do", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vish Vogeti", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "V\u00edtor Albiero", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vladan Petrovic", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Weiwei Chu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenhan Xiong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenyin Fu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Whitney Meers", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaodong Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaofang Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaoqing Ellen Tan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xide Xia", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xinfeng Xie", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xuchao Jia", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xuewei Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yaelle Goldschlag", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yashesh Gaur", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yasmine Babaei", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yi Wen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yiwen Song", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuchen Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yue Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuning Mao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zacharie Delpierre Coudert", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zheng Yan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhengxing Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zoe Papakipos", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Aaditya Singh", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Aayushi Srivastava", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Abha Jain", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Adam Kelsey", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Adam Shajnfeld", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Adithya Gangidi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Adolfo Victoria", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ahuva Goldstand", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ajay Menon", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ajay Sharma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alex Boesenberg", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alexei Baevski", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Allie Feinstein", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Amanda Kallet", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Amit Sangani", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Amos Teo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Anam Yunus", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Andrei Lupu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Andres Alvarado", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Andrew Caples", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Andrew Gu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Andrew Ho", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Andrew Poulton", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Andrew Ryan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ankit Ramchandani", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Annie Dong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Annie Franco", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Anuj Goyal", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Aparajita Saraf", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Arkabandhu Chowdhury", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ashley Gabriel", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ashwin Bharambe", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Assaf Eisenman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Azadeh Yazdan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Beau James", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ben Maurer", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Benjamin Leonhardi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bernie Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Beth Loyd", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Beto De Paola", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bhargavi Paranjape", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bing Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Boyu Ni", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Braden Hancock", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bram Wasti", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Brandon Spence", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Brani Stojkovic", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Brian Gamido", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Britt Montalvo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Carl Parker", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Carly Burton", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Catalina Mejia", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ce Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Changhan Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Changkyu Kim", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chao Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chester Hu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ching-Hsiang Chu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chris Cai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chris Tindal", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Christoph Feichtenhofer", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Cynthia Gao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Damon Civin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dana Beaty", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Daniel Kreymer", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Daniel Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "David Adkins", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "David Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Davide Testuggine", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Delia David", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Devi Parikh", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Diana Liskovich", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Didem Foss", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dingkang Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Duc Le", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dustin Holland", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Edward Dowling", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Eissa Jamil", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Elaine Montgomery", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Eleonora Presani", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Emily Hahn", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Emily Wood", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Eric-Tuan Le", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Erik Brinkman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Esteban Arcaute", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Evan Dunbar", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Evan Smothers", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fei Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Felix Kreuk", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Filippos Kokkinos", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Firat Ozgenel", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Francesco Caggioni", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Frank Kanayet", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Frank Seide", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Gabriela Medina Florez", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Gabriella Schwarz", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Gada Badeer", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Georgia Swee", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Gil Halpern", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Grant Herman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Grigory Sizov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guangyi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guna Lakshminarayanan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hakan Inan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hamid Shojanazeri", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Han Zou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hannah Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hanwen Zha", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haroun Habeeb", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Harrison Rudolph", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Helen Suk", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Henry Aspegren", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hunter Goldman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hongyuan Zhan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ibrahim Damlaj", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Igor Molybog", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Igor Tufanov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ilias Leontiadis", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Irina-Elena Veliche", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Itai Gat", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jake Weissman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "James Geboski", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "James Kohli", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Janice Lam", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Japhet Asher", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jean-Baptiste Gaya", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jeff Marcus", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jeff Tang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jennifer Chan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jenny Zhen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jeremy Reizenstein", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jeremy Teboul", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jessica Zhong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jian Jin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jingyi Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Joe Cummings", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jon Carvill", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jon Shepard", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jonathan McPhie", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jonathan Torres", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Josh Ginsburg", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Junjie Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kai Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kam Hou U", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Karan Saxena", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kartikay Khandelwal", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Katayoun Zand", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kathy Matosich", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kaushik Veeraraghavan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kelly Michelena", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Keqian Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kiran Jagadeesh", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kun Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kunal Chawla", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kyle Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lailin Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lakshya Garg", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lavender A", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Leandro Silva", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lee Bell", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lei Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Liangpeng Guo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Licheng Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Liron Moshkovich", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Luca Wehrstedt", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Madian Khabsa", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Manav Avalani", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Manish Bhatt", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Martynas Mankus", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Matan Hasson", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Matthew Lennie", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Matthias Reso", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Maxim Groshev", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Maxim Naumov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Maya Lathi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Meghan Keneally", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Miao Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Michael L. Seltzer", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Michal Valko", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Michelle Restrepo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mihir Patel", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mik Vyatskov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mikayel Samvelyan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mike Clark", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mike Macey", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mike Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Miquel Jubert Hermoso", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mo Metanat", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mohammad Rastegari", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Munish Bansal", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nandhini Santhanam", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Natascha Parks", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Natasha White", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Navyata Bawa", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nayan Singhal", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nick Egebo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nicolas Usunier", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nikhil Mehta", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nikolay Pavlovich Laptev", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ning Dong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Norman Cheng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Oleg Chernoguz", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Olivia Hart", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Omkar Salpekar", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ozlem Kalinli", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Parkin Kent", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Parth Parekh", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Paul Saab", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pavan Balaji", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pedro Rittner", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Philip Bontrager", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pierre Roux", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Piotr Dollar", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Polina Zvyagina", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Prashant Ratanchandani", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pritish Yuvraj", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qian Liang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rachad Alao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rachel Rodriguez", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rafi Ayub", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Raghotham Murthy", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Raghu Nayani", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rahul Mitra", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rangaprabhu Parthasarathy", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Raymond Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rebekkah Hogan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Robin Battey", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rocky Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Russ Howes", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ruty Rinott", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sachin Mehta", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sachin Siby", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sai Jayesh Bondu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Samyak Datta", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sara Chugh", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sara Hunt", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sargun Dhillon", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sasha Sidorov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Satadru Pan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Saurabh Mahajan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Saurabh Verma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Seiji Yamamoto", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sharadh Ramaswamy", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shaun Lindsay", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sheng Feng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shenghao Lin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shengxin Cindy Zha", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shishir Patil", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shiva Shankar", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shuqiang Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sinong Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sneha Agarwal", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Soji Sajuyigbe", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Soumith Chintala", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Stephanie Max", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Stephen Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Steve Kehoe", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Steve Satterfield", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sudarshan Govindaprasad", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sumit Gupta", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Summer Deng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sungmin Cho", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sunny Virk", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Suraj Subramanian", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sy Choudhury", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sydney Goldman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tal Remez", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tamar Glaser", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tamara Best", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Thilo Koehler", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Thomas Robinson", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tianhe Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tianjun Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tim Matthews", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Timothy Chou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tzook Shaked", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Varun Vontimitta", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Victoria Ajayi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Victoria Montanez", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vijai Mohan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vinay Satish Kumar", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vishal Mangla", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vlad Ionescu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vlad Poenaru", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vlad Tiberiu Mihailescu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vladimir Ivanov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenchen Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenwen Jiang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wes Bouaziz", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Will Constable", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaocheng Tang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaojian Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaolan Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xilun Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xinbo Gao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yaniv Kleinman", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yanjun Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ye Hu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ye Jia", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ye Qi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yenda Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yilin Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yossi Adi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Youngjin Nam", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yu Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuchen Hao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yundi Qian", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yunlu Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuzi He", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zach Rait", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zachary DeVito", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zef Rosnbrick", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhaoduo Wen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhenyu Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhiwei Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhiyu Ma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tianyi Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mingda Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bowei Guo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhiqiang Shen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Siyan Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mengchen Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jing Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chenyu Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bo Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuandong Tian", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Aditya Grover", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Feiyu Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Marianne Arriola", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yair Schiff", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hao Phung", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Aaron Gokaslan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Volodymyr Kuleshov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chenghao Fan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wen Heng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sichen Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuxuan Song", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jing Su", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaoye Qu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kai Shen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wei Wei", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chang Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chuang Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yilin Xiao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Su Dong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Luyao Zhuang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yujing Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhu Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zijin Hong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zheng Yuan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhishang Xiang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shengyuan Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Huachi Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qinggang Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ninghao Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xinrun Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yi Chang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiao Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hao Lu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haoyuan Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yulin Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chen Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ningxin Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yu Cheng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiuan Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yongkang Hu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yihang Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Huichi Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mingang Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhizhong Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kun Shao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuan Xie", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhaoxia Yin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qirui Mi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhijian Ma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mengyue Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haoxuan Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yisen Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haifeng Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jun Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaoyu Tao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ze Guo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xu Jiang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Carroll L. Wainwright", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alex Ray", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fraser Kelton", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Luke Miller", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Paul Christiano", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Paul Barham", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Charles Sutton", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sebastian Gehrmann", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Parker Schuh", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kensen Shi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sasha Tsvyashchenko", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Joshua Maynez", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Abhishek Rao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Parker Barnes", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vinodkumar Prabhakaran", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Emily Reif", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nan Du", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ben Hutchinson", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Reiner Pope", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jacob Austin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Michael Isard", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guy Gur-Ari", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pengcheng Yin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Toju Duke", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Anselm Levskaya", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sanjay Ghemawat", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sunipa Dev", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Henryk Michalewski", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xavier Garcia", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vedant Misra", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Daphne Ippolito", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "David Luan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hyeontaek Lim", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Alexander Spiridonov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ryan Sepassi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shivani Agrawal", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mark Omernick", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Andrew M. Dai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Thanumalayan Sankaranarayana Pillai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Aitor Lewkowycz", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Erica Moreira", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Oleksandr Polozov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zongwei Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Brennan Saeta", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mark Diaz", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Michele Catasta", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kathy Meier-Hellstern", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Douglas Eck", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Noah Fiedel", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shunyu Yao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jeffrey Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dian Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Izhak Shafran", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Karthik Narasimhan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuan Cao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhong-Zhi Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Duzhen Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ming-Liang Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiaxin Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zengyan Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuxuan Yao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haotian Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Junhao Zheng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pei-Jie Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiuyi Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yingying Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fei Yin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhiwei Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bao-Long Bi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ling-Rui Mei", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Junfeng Fang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiao Liang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhijiang Guo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Le Song", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Cheng-Lin Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuxuan Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haozheng Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Meng Fang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Linyi Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaoguang Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lifeng Shang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jianye Hao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zheyuan Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lyuhao Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Arman Cohan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yilun Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuqian Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chengzhong Chu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yu Duan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mingkang Long", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tingyue Pan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qingchuan Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mingfan Pan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jinmiao Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chuang Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zelin Shi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yunpeng Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yingdi Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Waleed Khalid", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dmitry Ignatov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Radu Timofte", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yu Tian", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhongheng Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chenshi Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yiyun Su", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ziwei Hong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zexi Gong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jingyuan Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yang Lu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haoyang Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Peng Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Erzhi Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Gongfa Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tongjian Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Isaac Robinson", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Peter Robicheaux", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Matvei Popov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Neehar Peri", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jinhui Yi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Gina Lopez", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "S. Hadir", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jan Weyler", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lasse Klingbeil", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Marion Deichmann", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Juergen Gall", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "S. J. Seidel", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haoding Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xuzhen He", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shaoheng Dai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Caihui Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "F. Shan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qin Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Faning Dang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Daichao Sheng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhou Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "A. Bovik", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "H. Sheikh", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Eero P. Simoncelli", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wei Cao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fengrui Tian", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yulun Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yingying Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shenlong Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ning Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yaoyao Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuxue Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lue Fan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ziqi Shi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Junran Peng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Feng Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhaoxiang Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "William Peebles", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jianlin Su", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yu Lu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shengfeng Pan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ahmed Murtadha", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bo Wen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yunfeng Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sifan Tu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xin Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dingkang Liang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xingyu Jiang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yumeng Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaofan Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiang Bai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Philip Lenz", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "C. Stiller", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "R. Urtasun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "S. Umeyama", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Run Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chaoyi Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Amir Salarpour", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xi Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhi-Qi Cheng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Feng Luo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mert D. Pes\u00e9", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Siyu Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xingbang Hao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guigang Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shang Ma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nikhil Keetha", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Norman M\u00fcller", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Johannes Sch\u00f6nberger", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lorenzo Porzi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tobias Fischer", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Arno Knapitsch", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Duncan Zauss", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ethan Weber", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nelson Antunes", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jonathon Luiten", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Manuel Lopez-Antequera", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Samuel Rota Bul\u00f2", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Christian Richardt", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sebastian Scherer", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Peter Kontschieder", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Team Seedream", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": ":", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yunpeng Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lixue Gong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Meng Guo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhiyao Guo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaoxia Hou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yixuan Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaowen Jian", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Huafeng Kuang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhichao Lai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fanshi Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaochen Lian", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chao Liao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Liyang Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yanzuo Lu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhengxiong Luo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tongtong Ou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guang Shi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yichun Shi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shiqi Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xun Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ye Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guofeng Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenxu Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yonghui Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xin Xia", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shuang Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xin Yan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhonghua Zhai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chenlin Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qi Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xinyu Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuwei Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shijia Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenliang Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenjia Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Junyan Ye", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dongzhi Jiang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zihao Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Leqi Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhenghao Hu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zilong Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jun He", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhiyuan Yan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jinghua Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hongsheng Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Weijia Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yi Xin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qi Qin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Siqi Luo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Juncheng Yan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yan Tai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiayi Lei", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuewen Cao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Keqi Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qian Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dengyang Jiang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuandong Pu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haoxing Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Le Zhuo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tianbin Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ming Hu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jin Ye", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bo Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chang Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guangtao Zhai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yihao Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "NextStep Team", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chunrui Han", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guopeng Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jingwei Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Quan Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yan Cai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuang Peng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zheng Ge", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Deyu Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haomiao Tang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hongyu Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kenkun Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ailin Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Changxin Miao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Deshan Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "En Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fukun Yin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Gang Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hao Nie", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haoran Lv", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hanpeng Hu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jia Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jian Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jianjian Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kaijun Tan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kang An", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kangheng Lin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Liang Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mei Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Peng Xing", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shiyu Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shutao Xia", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tianhao You", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wei Ji", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xianfang Zeng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xin Han", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xuelin Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yana Wei", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yanming Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yimin Jiang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yingming Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yu Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yucheng Han", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ziyang Meng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Binxing Jiao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Daxin Jiang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yibo Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yinhan Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Myle Ott", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jingfei Du", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mandar Joshi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Danqi Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Omer Levy", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Veselin Stoyanov", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "DeepSeek-AI", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Daya Guo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dejian Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haowei Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Junxiao Song", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Peiyi Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qihao Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Runxin Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ruoyu Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shirong Ma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiao Bi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaokang Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yu Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Z. F. Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhibin Gou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhihong Shao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhuoshu Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ziyi Gao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Aixin Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bing Xue", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bochao Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bei Feng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chengda Lu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chenggang Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chengqi Deng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chenyu Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chong Ruan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Deli Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dongjie Ji", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Erhang Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fangyun Lin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fucong Dai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Fuli Luo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guangbo Hao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guanting Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guowei Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "H. Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Han Bao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hanwei Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haocheng Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Honghui Ding", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Huajian Xin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Huazuo Gao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hui Qu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jianzhong Guo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiawei Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jingchang Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jingyang Yuan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Junjie Qiu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Junlong Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "J. L. Cai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiaqi Ni", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jian Liang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jin Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kai Dong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kai Hu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kaige Gao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kang Guan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kexin Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kuai Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lean Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lecong Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Litong Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Liyue Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Lei Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Leyi Xia", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mingchuan Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Minghua Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Minghui Tang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Meng Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Miaojun Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mingming Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ning Tian", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Panpan Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qiancheng Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qiushi Du", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ruiqi Ge", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ruisong Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ruizhe Pan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Runji Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "R. J. Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "R. L. Jin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ruyi Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shanghao Lu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shangyan Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shanhuang Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shengfeng Ye", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shiyu Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shuiping Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shunfeng Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shuting Pan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "S. S. Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shuang Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Shaoqing Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tao Yun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tian Pei", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tianyu Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "T. Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wanjia Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wen Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenjun Gao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenqin Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "W. L. Xiao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wei An", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaodong Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaohan Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaokang Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaotao Nie", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xin Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xin Xie", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xingchao Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xinyu Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xinyuan Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xuecheng Su", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xuheng Lin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "X. Q. Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiangyue Jin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaojin Shen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaosha Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaowen Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaoxiang Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xinnan Song", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xinyi Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xianzu Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xinxia Shan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Y. K. Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Y. Q. Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Y. X. Wei", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yang Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yanhong Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yao Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yao Zhao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yaofeng Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yaohui Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yi Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yichao Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yifan Shi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yiliang Xiong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ying He", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yishi Piao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yisong Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yixuan Tan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yiyang Ma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yiyuan Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yongqiang Guo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuan Ou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuduan Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yue Gong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuheng Zou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yujia He", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yunfan Xiong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuxiang Luo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuxiang You", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuxuan Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuyang Zhou", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Y. X. Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yaohui Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yi Zheng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuchen Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yunxian Ma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ying Tang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yukun Zha", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuting Yan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Z. Z. Ren", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zehui Ren", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhangli Sha", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhe Fu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhean Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhengyan Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhicheng Ma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhigang Yan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhiyu Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zihui Gu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zijia Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zijun Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zilin Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ziwei Xie", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ziyang Song", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zizheng Pan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhen Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhipeng Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhongyu Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhen Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bowen Jin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hansi Zeng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhenrui Yue", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sercan Arik", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dong Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hamed Zamani", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiawei Han", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Karan Singhal", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tao Tu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Juraj Gottweis", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "R. Sayres", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ellery Wulczyn", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mohamed Amin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kevin Clark", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Stephen R. Pfohl", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Heather Cole-Lewis", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Darlene Neal", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Q. Rashid", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Mike Schaekermann", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Amy Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dev Dash", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jonathan H. Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nigam H. Shah", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sami Lachgar", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "P. Mansfield", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sushant Prakash", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Bradley Green", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ewa Dominowska", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nenad Toma\u0161ev", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yun Liu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Renee Wong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Christopher Semturs", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "S. Mahdavi", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Joelle K. Barral", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dale R. Webster", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "G. Corrado", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yossi Matias", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "A. Karthikesalingam", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Vivek Natarajan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tianzhe Chu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yuexiang Zhai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sergey Levine", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yi Ma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Peijia Lin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Pin Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Rui Jiao", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qing Mo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jianhuan Cen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenbing Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Dan Huang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yutong Lu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenqiang Sun", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haiyu Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Haoyuan Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Junta Wu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zehan Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhenwei Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yunhong Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tengfei Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Chunchao Guo", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jianfeng Xiang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Xiaoxue Chen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sicheng Xu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ruicheng Wang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zelong Lv", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yu Deng", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hongyuan Zhu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yue Dong", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Nicholas Jing Yuan", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jiaolong Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Basile Terver", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Tsung-Yen Yang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jean Ponce", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Adrien Bardes", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guangyi Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Hanlei Li", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Yunlong Cai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Qiyu Hu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Guanding Yu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Zhijing Qin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Wenjun Lin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Jensen Zhang", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Kaitong Cai", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Transformer", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "WMT 2014 English-to-German translation task", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "WMT 2014 English-to-French translation task", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "BLEU", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "English constituency parsing", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "residual learning framework", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "residual networks", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "VGG nets", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "ImageNet dataset", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "ILSVRC 2015 classification task", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "CIFAR-10", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "COCO object detection dataset", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "ILSVRC & COCO 2015 competitions", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "ImageNet detection", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "ImageNet localization", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "COCO detection", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "COCO segmentation", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Adam", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "AdaMax", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "other stochastic optimization methods", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Dropout", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "neural networks", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "ILSVRC 2012 classification challenge validation set", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "top-1 error", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "top-5 error", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "convolutional networks", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "Inception Architecture", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "InstaDrive", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Instance Flow Guider", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Spatial Geometric Aligner", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "nuScenes dataset", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "CARLA", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "CNC-VLM", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "RLHF", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "multimodal learning", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "CNC fault detection", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Bidirectional Long Short-Term Memory (BiLSTM)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "New York Independent System Operator", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "MAE", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "RMSE", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "sMAPE", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "MAPE", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "R\u00b2", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "four-point laser metric calibration", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "mamba segmentation", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Alex Krizhevsky", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "ImageNet", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "deep convolutional neural network", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "ImageNet Challenge 2014", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "ConvNet models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Faster R-CNN", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Region Proposal Network (RPN)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "SPPnet", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Fast R-CNN", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "VGG-16", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "PASCAL VOC 2007", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "PASCAL VOC 2012", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "MS COCO", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "ILSVRC", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "COCO 2015", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Federated Learning Optimal Transport (FLOT)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "GTSRB", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "KBTS", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "CIFAR10", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "EMNIST", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "DiffusionEngine", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "object detection", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "contrastive learning", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "hyperspectral image prediction", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "WarmGait", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Person re-identification (Re-ID)", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "thermal array sensors", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "Taylor Finite Difference (TFD)", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "gait recognition", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "edge module", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "gait profiles", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "average recognition accuracy of 87.3%", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "stochastic variational inference and learning algorithm", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "variational lower bound", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "lower bound estimator", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "standard stochastic gradient methods", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "i.i.d. datasets", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "approximate inference model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "recognition model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Reducing the Dimensionality of Data with Neural Networks", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "Online Learning", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Stochastic Optimization", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Recurrent neural networks", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "Connectionist Temporal Classification", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "Long Short-term Memory", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "deep recurrent neural networks", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "deep Long Short-term Memory RNNs", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "TIMIT phoneme recognition benchmark", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "GAN", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "PBD", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "DWD", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "seven benchmarks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "NianWang-HJJGCDX", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "AdamW optimizer", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Adam optimizer", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "face mask detection model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Adam with L2-regularization", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Mixture-of-Experts (MoE)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Transformers", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Engram", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "MMLU", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "CMMLU", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "BBH", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "ARC-Challenge", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "HumanEval", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "MATH", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Multi-Query NIAH", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Neural Hierarchical Interpolation for Time Series Forecasting (N-HiTS)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Network-Based Expansion Analysis for Interpretable Time Series Forecasting (N-BEATS)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "long short-term memory (LSTM)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Multi-Quantile Loss", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "flood prediction", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "headwater streams in Georgia and North Carolina, USA", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "95th percentile prediction uncertainty (95 PPU)", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Generating an annual 30 m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "category": 7, "symbolSize": 25, "draggable": true, "value": "Report"}, {"name": "harmonized Landsat and Sentinel-2 data", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "NASA-IBM geospatial foundation model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Inception", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "GoogLeNet", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "ImageNet Large-Scale Visual Recognition Challenge 2014", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "ILSVRC 2014", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Batch Normalization", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "state-of-the-art image classification model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "This paper", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "Diffusion Transformers (DiT)", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "VAE encoder", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "Representation Autoencoders (RAEs)", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "DINO", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "SigLIP", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "DDT head", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "FID", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Cell2Sentence (C2S) framework", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Large Language Models (LLMs)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "C2S-Scale", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "silmitasertib (CX-4945)", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "single-cell RNA sequencing", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "transcriptomic data", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "biological text", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "metadata", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "human cell models", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "HybridVisionNet", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "fundus imaging", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "DI", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "DiffPure", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Google Cloud Vision", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "transfer attacks", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "defenses", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "computer vision systems", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "adversarial images", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "imperceptibility metrics", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "user study", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Lp constraint", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "authors", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "OGNet", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "YOLO-OG", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Empty-dish Recycling Robot", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "Dish-10", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Dish-20", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "mean Average Precision (mAP)", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "Colossal Clean Crawled Corpus", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "pre-trained models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "code", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "summarization", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "question answering", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "text classification", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Two Time-Scale Update Rule", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "Local Nash Equilibrium", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "nuScenes", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "KITTI dataset", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "nuTonomy scenes", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Robust detection and tracking of objects", "category": 7, "symbolSize": 25, "draggable": true, "value": "Report"}, {"name": "3D detection and tracking metrics", "category": 7, "symbolSize": 25, "draggable": true, "value": "Report"}, {"name": "baselines for lidar and image based detection and tracking", "category": 7, "symbolSize": 25, "draggable": true, "value": "Report"}, {"name": "Image based benchmark datasets", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "autonomous vehicle technology", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "computer vision tasks", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "machine learning based methods for detection and tracking", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "autonomous driving research", "category": 7, "symbolSize": 25, "draggable": true, "value": "Report"}, {"name": "classic modular pipeline", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "end-to-end model trained via imitation learning", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "end-to-end model trained via reinforcement learning", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "autonomous urban driving systems", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Sora", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "MNIST", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "text-to-video generation", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "world modeling", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "OmniNWM", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "autonomous driving world models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "panoramic videos", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "3D occupancy", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "normalized panoramic Plucker ray-map representation", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "occupancy-grounded rewards", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "ConsisDrive", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Instance-Masked Attention", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Instance-Masked Loss", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "UniDriveDreamer", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "LiDAR-specific variational autoencoder (VAE)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "video VAE", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Unified Latent Anchoring (ULA)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "diffusion transformer", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "multi-camera video", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "LiDAR sequence", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "autonomous driving", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "SVD", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "LTX", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "MAD-LTX", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "video diffusion models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "driving world models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "REPA", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "iREPA", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "ImageNet-1K", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "REPA-E", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Meanflow", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "JiT", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "SCB-DETR", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "SCBehavior dataset", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "baseline model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "AP50", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "We", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "ultrasound-cardiac-feature-net (UCF-Net)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "filtered integral quasi-super-twisting algorithm (FIQSTA)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "proportional (P) controller", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "sliding mode controller", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "super-twisting algorithm (STA)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "integral quasi-STA", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "deep ultrasound image features", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "cardiac phantom", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "BioTune", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "AutoRGN", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "LoRA", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "nine image classification datasets", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "medical imaging", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "four different CNN architectures", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "VGG-16 net", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "NUS dataset", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Google's open source Application Programming Interface (API)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "convolutional neural network", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Python", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Keras", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "machine learning algorithms", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "unsupervised feature learning", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "deep learning", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "probabilistic models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "auto-encoders", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "manifold learning", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "deep networks", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "representation learning", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "density estimation", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Stacked Denoising Autoencoders", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Stochastic Backpropagation", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Deep Generative Models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "SDXL", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "SDXL-Lightning models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "UNet", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "EchoMimic", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "portrait image animation", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "audios", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "facial landmarks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "public datasets", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "collected dataset", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "GenAD", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "variational autoencoder", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "temporal model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "instance-centric scene tokenizer", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "end-to-end autonomous driving methods", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Ovis", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Multimodal Large Language Models (MLLMs)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "LLM", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "vision transformer", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "MLP", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Qwen-VL-Plus", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "various multimodal benchmarks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "VideoReward", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Flow-DPO", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Flow-RWR", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Flow-NRG", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "rectified flow techniques", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "large-scale human preference dataset", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "modern video generation models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "supervised fine-tuning methods", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Long Short-term Memory RNN", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "Recurrent Neural Networks", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Framewise phoneme classification with bidirectional LSTM and other neural network architectures", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "bidirectional LSTM", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "neural network architectures", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "machine learning", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "artificial synapses", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "flexible sensors", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "flexible sensory systems", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "soft/humanoid robotics", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "human activity monitoring", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "speech-to-text BCI", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "speech brain\u2013computer interfaces (BCIs)", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "intracortical microelectrode arrays", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "study participant", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "word error rate", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "50-word vocabulary", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "125,000-word vocabulary", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "neural code for speech", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "deep-learning methods", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "backpropagation algorithm", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "continual backpropagation algorithm", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "artificial neural networks", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "gradient descent", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "analog-AI chip", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "speech-recognition tasks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "keyword-spotting network", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "MLPerf", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "recurrent neural-network transducer (RNNT)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "analog in-memory computing (analog-AI)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "graphics processing units", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "central processing units", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "BPE tokenizers", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "LiteToken", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "intermediate merge residues", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "token fragmentation", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "noisy or misspelled inputs", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "MeKi", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Large Language Models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "dense LLM baselines", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Gengram", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "genomic foundation models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "functional genomics tasks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Large Lookup Layer (L$^3$)", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "tokenizer embedding table", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "transformers", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "language modeling", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "downstream tasks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "dense models", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "iso-sparse MoEs", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "Mixture-of-Experts (MoE) architectures", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "embedding scaling", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "expert scaling", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "LongCat-Flash-Lite", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "parameter-equivalent MoE baselines", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "existing models of comparable scale", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "LeNet", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Lasso", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "PASCAL", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "SUN", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Deformable Parts Model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "LifeCLEF plant identification challenge", "category": 7, "symbolSize": 25, "draggable": true, "value": "Report"}, {"name": "dataset", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "participatory sensing plateform", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "FedMicro-IDA", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "MaleVis", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "IoT-malware detection and classification use case", "category": 7, "symbolSize": 25, "draggable": true, "value": "Report"}, {"name": "federated learning", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "microservices-based architecture", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "existing state-of-the-art methods", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "YOLO", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "large language models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "large vision models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "multimodal large language models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Web of Science", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "arXiv", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "agricultural question-answering", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "robotic automation", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "advanced image analysis", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "remote sensing", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "spectral data", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "pragmatic framework", "category": 7, "symbolSize": 25, "draggable": true, "value": "Report"}, {"name": "Multi-axis vision transformer", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "medical image segmentation", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "active deep-learning framework", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "generalizable algorithm", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "state-of-the-art models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "omics", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "classical recall", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "hematological discovery campaigns", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "lab-in-the-loop signature refinement step", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "LLaVA-OneVision-1.5", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "LLaVA-OneVision-1.5-Mid-Traning", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "LLaVA-OneVision-1.5-Instruct", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Qwen2.5-VL-7B", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Qwen2.5-VL-3B", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Vision-Language-Action (VLA) models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "large language models (LLMs)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "vision-language models (VLMs)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "robotics community", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "publicly available datasets", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "evaluation benchmarks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "teacher model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "human-aligned models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "pretrained state-of-the-art vision foundation models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "dataset of human judgements spanning multiple levels of semantic abstractions", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "human judgements", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Vision Transformer (ViT)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Transformer architecture", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "CIFAR-100", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "VTAB", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "ResNet-50", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "CLIP", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "MeanFlow", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "improved MeanFlow", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "iMF", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "ImageNet 256\u00d7256", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "ImageNet-256", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "ImageNet-512", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "DiT", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "diffusion model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "consistency model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "VAE", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "pixel-space diffusion", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "pixel-space consistency models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "two-stage training framework", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "SVG (Self-supervised representations for Visual Generation)", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "Visual Foundation Model (VFM)", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "GenEval", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "DPG-Bench", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "autoencoder", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "generation model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "PixelDiT", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Diffusion Transformers (DiTs)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "ImageNet 256x256", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "DPG-bench", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "latent diffusion models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "TUNA", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Unified multimodal models (UMMs)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "representation encoder", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "multimodal understanding and generation benchmarks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "image and video understanding", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "image and video generation", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "image editing", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "BERT", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "GLUE", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "MultiNLI", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "SQuAD v1.1", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "SQuAD v2.0", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "traditional methods", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "deep learning methods", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "diffusion language models (DLMs)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "autoregressive (AR) models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "AR coder", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "HellaSwag", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Python tokens", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "DreamOn", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Diffusion Language Models (DLMs)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Dream-Coder-7B", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "DiffuCoder-7B", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "HumanEval-Infilling", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "SantaCoder-FIM", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Forward Learning with EXperience (FLEX)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "AIME25", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "USPTO50k", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "ProteinGym", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Agent-R1", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Reinforcement Learning (RL)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Markov Decision Process (MDP)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Multihop QA benchmark tasks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Squeeze-and-Excitation block", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "SENet", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "ILSVRC 2017 classification submission", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "convolutional neural networks", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "prior research", "category": 7, "symbolSize": 25, "draggable": true, "value": "Report"}, {"name": "MobileNets", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "ResNet", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "EfficientNets", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "EfficientNet-B7", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Flowers", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Light-X", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Light-Syn", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "DriveLaW", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "DriveLaW-Video", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "DriveLaW-Act", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "NAVSIM", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "FVD", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "OpenScene", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Waymo", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "KITTI", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "DDAD", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "ControlNet", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Stable Diffusion", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "PaLM", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "T5", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "U-PaLM", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Flan-PaLM 540B", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "PALM 540B", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Flan-T5", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "PaLM 62B", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "TyDiQA", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "MGSM", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "diffusion models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "image inpainting", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "unconditional image generation", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "semantic scene synthesis", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "super-resolution", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "CompVis/latent-diffusion", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Variational Auto-Encoder", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "PSNR", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "SSIM", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "VGG network", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "new dataset of human perceptual similarity judgments", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Waymo Open Dataset", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "research community", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "we", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "2D detection and tracking tasks", "category": 7, "symbolSize": 25, "draggable": true, "value": "Report"}, {"name": "3D detection and tracking tasks", "category": 7, "symbolSize": 25, "draggable": true, "value": "Report"}, {"name": "3D detection methods", "category": 7, "symbolSize": 25, "draggable": true, "value": "Report"}, {"name": "diversity metric", "category": 7, "symbolSize": 25, "draggable": true, "value": "Report"}, {"name": "human detection", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Generative Adversarial Networks (GANs)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "GANs", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Data augmentation", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "face images generation", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "two-layer ReLU denoising autoencoder (DAE)", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "real-world unconditional and text-to-image diffusion models", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "representation-based method for detecting memorization", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "training-free editing technique", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "memorization", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "generalization", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "balanced representations", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "localized spiky representations", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "local data statistics", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "deep generative models", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "generative modeling", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "Stable Velocity", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "flow matching", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Stable Velocity Matching (StableVM)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Variance-Aware Representation Alignment (VA-REPA)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Stable Velocity Sampling (StableVS)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "SD3.5", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Flux", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Qwen-Image", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Wan2.2", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "FlatDINO", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "DINOv2", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "DiT-XL", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "gFID", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "One-Dimensional Diffusion Video Autoencoder (One-DVA)", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "3D-CNN VAEs", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "video autoencoders", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "video generation models", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "transformer-based framework", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "query-based vision transformers", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "pixel-space diffusion transformer", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "two-stage training strategy", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "variable-length dropout mechanism", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "reconstruction metrics", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "latent distribution", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "decoder", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "encoder", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "REPA-G", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "COCO", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "evolutionary optimization", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "MediaPipe", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Multi-layered Randomized Decision Forests", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "geometry based normalizations", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "Krawtchouk moments", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "machine learning model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "virtual reality headset", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "system meant to facilitate communication with hearing impaired individuals", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "fully connected neural network (FCNN)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "American Sign Language (ASL)", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "World Health Organization", "category": 7, "symbolSize": 25, "draggable": true, "value": "Report"}, {"name": "Sign Language Recognition (SLR)", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "EM algorithm", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "t-SNE", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "LLM social simulations", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "human research subjects", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "LLMs", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "social science datasets", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "conceptual models", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "iterative evaluations", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "FCLFD", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "CST", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "AWS", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "WISDM", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "PAMAP2", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Dispersive Loss", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "representation alignment (REPA)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "diffusion-based generative models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Knowledge-Aware Bayesian Bandits (KABB)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "multi-agent systems", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "three-dimensional knowledge distance model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "dual-adaptation mechanism", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "knowledge-aware Thompson Sampling strategy", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "sliding-window convolutional network", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "ISBI challenge for segmentation of neuronal structures in electron microscopic stacks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "ISBI cell tracking challenge 2015", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Caffe", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Distribution Matching Distillation (DMD)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "DMD2", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "ImageNet-64x64", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "COCO 2014", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Latent Adversarial Diffusion Distillation (LADD)", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "adversarial diffusion distillation (ADD)", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Stable Diffusion 3 (8B)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "SD3-Turbo", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Large language models (LLMs)", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "Japanese LLM with Math reasoning capabilities", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "Japanese Math LLM", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "culturally-aware Japanese VLM", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "Japanese LLM benchmarks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Japanese culture-specific content", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "evolutionary approach", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "model merging", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "open-source models", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "previous Japanese VLMs", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "bidirectional diffusion transformer", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "autoregressive transformer", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "distribution matching distillation (DMD)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "generator", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "student initialization scheme", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "asymmetric distillation strategy", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "causal student model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "bidirectional teacher", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "VBench-Long benchmark", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "KV caching", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "streaming video-to-video translation", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "image-to-video", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "dynamic prompting", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "PuLID", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "text-to-image generation", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "Lightning T2I branch", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "standard diffusion", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "contrastive alignment loss", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "accurate ID loss", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "ID fidelity", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "editability", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "image elements", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "background", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "lighting", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "composition", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "style", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "ToTheBeginning", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "diffusion probabilistic models", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "LSUN", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "ProgressiveGAN", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "Inception score", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "FID score", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "HunyuanVideo", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Runway Gen-3", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Luma 1.6", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Tencent", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Loopy", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "audio-conditioned human video generation", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "diffusion-based video generation techniques", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "audio-driven portrait diffusion models", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "audio-only conditioned video diffusion model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "inter- and intra-clip temporal module", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "audio-to-latents module", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "long-term motion information", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "audio-portrait movement correlation", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "spatial motion templates", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "various scenarios", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "OmniHuman", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Diffusion Transformer-based framework", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "existing end-to-end audio-driven methods", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "large general video generation models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Hallo", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "HDTF", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "CelebV", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Wild", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "EchoMimicV2", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Audio-Pose Dynamic Harmonization strategy", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Pose Sampling", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Audio Diffusion", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Head Partial Attention", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Phase-specific Denoising Loss", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "novel benchmark for evaluating the effectiveness of half-body human animation", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Recent work on human animation", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "Towards Striking, Simplified, and Semi-Body Human Animation", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "Feature Pyramid Network (FPN)", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "COCO detection benchmark", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "COCO 2016 challenge winners", "category": 7, "symbolSize": 25, "draggable": true, "value": "Report"}, {"name": "RNN Encoder-Decoder", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "statistical machine translation system", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "log-linear model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "DriveMLM", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Autonomous driving (AD)", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "Autopilot", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Apollo", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "CARLA Town05 Long", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "multimodal LLM (MLLM)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Vista", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "general-purpose video generator", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "driving world model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "multiple datasets", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "DiffusionDrive", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "vanilla diffusion policy", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "NAVSIM dataset", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "ResNet-34", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "2D simulation testbed for object movement and collisions", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "diffusion-based video generation models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Gemini", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Waymo Open Motion Dataset (WOMD)", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Waymo Open Dataset (WOD)", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "GPT-3", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "NLP tasks and benchmarks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "translation, question-answering, and cloze tasks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "news articles", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "InternVL 2.5", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "InternVL 2.0", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "GPT-4o", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Claude-3.5-Sonnet", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "MMMU benchmark", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "InternVL3", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "InternVL3-78B", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "ChatGPT-4o", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Claude 3.5 Sonnet", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Gemini 2.5 Pro", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "PyTorch", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "OpenVLM Leaderboard", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "large multi-modality models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "multi-modal benchmarks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "LLaVA-CoT", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "LLaVA-CoT-100k", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Gemini-1.5-pro", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "GPT-4o-mini", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Llama-3.2-90B-Vision-Instruct", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "InternVL 3.5", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Cascade Reinforcement Learning (Cascade RL) framework", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Visual Resolution Router (ViR)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Decoupled Vision-Language Deployment (DvD) strategy", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "InternVL3.5-241B-A28B", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "GPT-5", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "MMMU", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "MathVista", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "InternVL series", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "proximal policy optimization (PPO)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "trust region policy optimization (TRPO)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "simulated robotic locomotion", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Atari game playing", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Flow-GRPO", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "ODE-to-SDE conversion", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Denoising Reduction strategy", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "SD3.5-M", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "online policy gradient reinforcement learning (RL)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "flow matching models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Ordinary Differential Equation (ODE)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Stochastic Differential Equation (SDE)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "text-to-image tasks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "compositional generation", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "visual text rendering", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "human preference alignment", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "DanceGRPO", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Group Relative Policy Optimization (GRPO)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "DDPO", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "DPOK", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "HPS-v2.1", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "CLIP Score", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "VideoAlign", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Reinforcement Learning from Human Feedback (RLHF)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Seedance 1.0", "category": 7, "symbolSize": 25, "draggable": true, "value": "Report"}, {"name": "diffusion modeling", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "multi-source data curation", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "precision and meaningful video captioning", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "efficient architecture design", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "proposed training paradigm", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "multi-shot generation", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "text-to-video", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "fine-grained supervised fine-tuning", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "video-specific RLHF", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "multi-dimensional reward mechanisms", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "multi-stage distillation strategies", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "system-level optimizations", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "NVIDIA-L20", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "SkyReels-V2", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "SkyCaptioner-V1", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Multi-modal Large Language Model (MLLM)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Multi-stage Pretraining", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Reinforcement Learning", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Diffusion Forcing Framework", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Supervised Fine-Tuning (SFT)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Motion-specific Reinforcement Learning (RL) training", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "diffusion forcing framework with non-decreasing noise schedules", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "UnifiedReward", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Direct Preference Optimization (DPO)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "Stanford Question Answering Dataset (SQuAD)", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "logistic regression model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "simple baseline", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Neural machine translation (NMT) models", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "subword models", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "back-off dictionary baseline", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "WMT 15 translation tasks English-German and English-Russian", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "SentencePiece", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Neural Machine Translation", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "English-Japanese machine translation", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "GPT-4", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Transformer-based model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "bar exam", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "professional and academic benchmarks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "LLaMA", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Chinchilla-70B", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "PaLM-540B", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "chain of thought", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "GSM8K benchmark", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "GSM8K", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "verifiers", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "transformer models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "finetuning baseline", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Crystal structure of the nucleosome core particle at 2.8 \u00c5 resolution", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "Mamba", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Mamba-3B", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "structured state space models (SSMs)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "linear attention", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "gated convolution", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "recurrent models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "language", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "audio", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "genomics", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "A catalogue of splice junction sequences", "category": 7, "symbolSize": 25, "draggable": true, "value": "Report"}, {"name": "stochastic gradient descent", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "EEG recordings", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "loshchil", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Sparsely-Gated Mixture-of-Experts layer (MoE)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "machine translation", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "LSTM layers", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "large language modeling benchmarks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "machine translation benchmarks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "pointer sentinel mixture architecture", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "pointer sentinel-LSTM model", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "Penn Treebank", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "WikiText corpus", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "MATH dataset", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "PRM800K", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "process-supervised model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "reward model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "GPQA", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "GShard", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "XLA compiler", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "multilingual neural machine translation Transformer model with Sparsely-Gated Mixture-of-Experts", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "TPU v3 accelerators", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "prior art", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "PASCAL VOC dataset", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "R-CNN", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "OverFeat", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "ILSVRC2013 detection dataset", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "mean average precision (mAP)", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Supertype-Preserving Low-Rank Adaptation (SuPLoRA)", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "supertype-subtype concept hierarchy", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "group-wise suppression method", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "standard diffusion regularization", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "concept erasure approaches", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "benchmark", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Multi-modal Chain and Global Attention Network (MCGA-Net)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "DCGAN-based data augmentation strategy", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Multi-modal Chain Feature Fusion (MCFF)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Global Attention Mechanism (GAM)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "GPR images", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Precision", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Recall", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "mAP@50", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Qwen3-VL-Embedding", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Qwen3-VL-Reranker", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Qwen3-VL", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "MMEB-V2", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "FPSMark", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "intrinsic signal localization network", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "hybrid loss", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "existing methods", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Probability Distributions", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "Linear Models for Regression", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "Linear Models for Classification", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "Neural Networks", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "Kernel Methods", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "Sparse Kernel Machines", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "Graphical Models", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "Mixture Models and EM", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "Approximate Inference", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "Sampling Methods", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "Continuous Latent Variables", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "Sequential Data", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "Combining Models", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "PlantVillage dataset", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "deep VGG16 model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "deep convolutional neural networks", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "botanists", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "deep neural networks", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "transfer learning parameters", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "A 26-layer deep learning model consisting of 8 residual building blocks", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "BJFU100 dataset", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Plant image identification", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "herbarium images", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "photos of plants in the field", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "big dataset with thousands of species from herbaria", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "different datasets from different herbaria", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "automated system", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Dense Convolutional Network (DenseNet)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "SVHN", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "MobileNetV2", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "SSDLite", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "DeepLabv3", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Mobile DeepLabv3", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Imagenet", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "VOC", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "multiply-adds (MAdd)", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Federated Learning", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "synchronized stochastic gradient descent", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "five different model architectures", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "four datasets", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Amazon Reviews", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Reuters-21578", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Office-31", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "federated deep neural network (FDNN)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Flipkart dataset", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Term Frequency-Inverse Document Frequency (TF-IDF)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Federated learning", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Internet of Things", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Wireless Sensor Networks", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "privacy-preserving federated learning", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "malware detection models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Internet of Things resources", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Long Short-Term Memory Network", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "centralized federated learning framework", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "decentralized federated learning framework", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "crop yield prediction", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "prediction accuracy", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "precision", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "recall", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "F1-Score", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "training time", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "cloud-only framework", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Segment Anything (SA) project", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "Segment Anything Model (SAM)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "SA-1B", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "LLaVA: Large Language and Vision Assistant", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Science QA", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "GPT-4 generated visual instruction tuning data", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "code base", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "LLaVA", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "CLIP-ViT-L-336px", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "MLP projection", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "academic-task-oriented VQA data", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Large multimodal models (LMM)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "visual instruction tuning", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "DepictQA-Wild", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "DQ-495K", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Vision Language Models (VLMs)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "VLM-based Image Quality Assessment (IQA)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "GPT-4V", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "traditional score-based methods", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "prior VLM-based IQA models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Chain-of-Focus (CoF) method", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "MM-CoF dataset", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Qwen2.5-VL model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "V* benchmark", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Vision language models (VLMs)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "3DThinker", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "topological cognitive maps", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "VGGT", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "zhangquanchen", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "UniME-V2", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "UniME-V2-Reranker", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "MMEB benchmark", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Universal Multimodal Embedding (UniME-V2) model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "MLLM-as-a-Judge mechanism", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "OpenMMReasoner", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Qwen2.5-VL-7B-Instruct", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "874K-sample cold-start dataset", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "74K-sample dataset", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "nine multimodal reasoning benchmarks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "agentic AI", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "cross-modal learning architectures", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "generalist agents", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "action planners", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "hierarchical controllers", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "over 80 VLA models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "architectural innovations", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "efficient training strategies", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "real-time inference accelerations", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "autonomous vehicles", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "medical and industrial robotics", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "precision agriculture", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "humanoid robotics", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "augmented reality", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "agentic adaptation", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "cross-embodiment planning", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "socially aligned, adaptive, and general-purpose embodied agents", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "intelligent, real-world robotics", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "artificial general intelligence", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Applied-AI-Research-Lab", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Asynchronous Action Chunk Correction (A2C2)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Real Time Chunking (RTC)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "dynamic Kinetix task suite", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "LIBERO Spatial", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Latent-CoT-Drive (LCDrive)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "chain-of-thought (CoT) reasoning", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "large-scale end-to-end driving benchmark", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "non-reasoning baselines", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "text-reasoning baselines", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "HyperVLA", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "OpenVLA", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Token Expand-and-Merge-VLA (TEAM-VLA)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "LIBERO benchmark", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "TransSIL", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "CUB200-2011", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "NABirds", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "bird ecological intelligent detection system", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "fine-grained bird image classification (FBIC)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "bridge crack images", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "threshold switch (TS) model", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "standard isolated CNN cell", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "image processing tasks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Deep contrastive learning enables genome-wide virtual screening", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "DrugCLIP", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "GenomeScreenDB", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "AlphaFold2", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "norepinephrine transporter", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "thyroid hormone receptor interactor 12", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "underwater image enhancement", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "3DGS-Drag", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Dragging Gaussians for Intuitive Point-Based 3D Editing", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "3D Gaussian Splatting", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "RTX 4090 GPU", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "LILaC", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "layered component graph", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "late-interaction-based subgraph retrieval method", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "five benchmarks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Bidirectional Normalizing Flow (BiFlow)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Normalizing Flows (NFs)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "TARFlow", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "pixel MeanFlow", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Meta Flow Maps", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "consistency models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "flow maps", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Best-of-1000", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Sequential Flow Matching", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Bayesian filtering", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "diffusion and flow-matching models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "full-step diffusion", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "forecasting, decision-making and state estimation tasks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Drifting Models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "flow-based models", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "SimCLR", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "AlexNet", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "DivGenBench", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Directional Decoupling Alignment (D\u00b2-Align)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Preference Mode Collapse (PMC)", "category": 7, "symbolSize": 25, "draggable": true, "value": "Report"}, {"name": "Reinforcement Learning from Human Feedback", "category": 7, "symbolSize": 25, "draggable": true, "value": "Report"}, {"name": "ImagerySearch", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "LDT-Bench", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "VBench", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "SigLIP-2", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "FLUX VAE", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "VAEs", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "video foundation models", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "implicit world model", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "video renderer", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "world model", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "video generation model", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "robotics", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "interactive gaming", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "World models", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "visual prediction", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "3D estimation", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "symbol grounding", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "unified design specification for world models", "category": 7, "symbolSize": 25, "draggable": true, "value": "Report"}, {"name": "interaction", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "perception", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "symbolic reasoning", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "spatial representation", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "RecTok", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "visual tokenizers", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "vision foundation models", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "diffusion transformers", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "VFMs", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "gFID-50K", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Shi Qingyu", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "RePack then Refine", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "Vision Foundation Models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Latent Diffusion Models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Diffusion Transformers", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "RePack-DiT-XL/1", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "RePack module", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Latent-Guided Refiner", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Refiner module", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "BigGAN-deep", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "ImageNet 128\u00d7128", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "ImageNet 512\u00d7512", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "classifier guidance", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "upsampling diffusion models", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "ViT model (Dosovitskiy et al., 2020)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "OpenCLIP (Ilharco et al., 2021)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Dosovitskiy et al.", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Ilharco et al.", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "PixelGen", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "latent diffusion", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "LPIPS", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Zehong-Ma", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "multimodal understanding models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "image generation models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "autoregressive-based architectures", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "diffusion-based models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "unified frameworks", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "diffusion-based", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "autoregressive-based", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "hybrid approaches", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "datasets and benchmarks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "GitHub", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "MentisOculi", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Frontier models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "multimodal large language models (MLLMs)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "unified multimodal models (UMMs)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "OpenVision 3", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "ViT", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "ViT-VAE", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "LLaVA-1.5", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "RAE", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "SeedBench", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "POPE", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "continuous Skip-gram model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "subsampling of the frequent words", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "negative sampling", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "hierarchical softmax", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "simple method for finding phrases in text", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "global logbilinear regression model", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "global matrix factorization", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "local context window methods", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "word-word cooccurrence matrix", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "word analogy task", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "similarity tasks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "named entity recognition", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "deep bidirectional language model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "textual entailment", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "sentiment analysis", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Modern models for common NLP tasks", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "2018 Twitter data spanning 51 U.S. regions and 99 countries", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "18 international and 5 U.S.-based statistical gender gaps", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "SegMamba-V2", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "State Space Model (SSM)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "CRC-2000", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "ge-xing", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "diffusion-based generative classifiers", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "autoregressive generative classifiers", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "five standard image and text distribution shift benchmarks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "medical datasets", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "satellite datasets", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Gaussian toy setting", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Edge Large AI Model Agent", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Cognitive Multimodal Semantic Communication", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "GPT-2", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Llama 3", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Llama Guard 3", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Diffusion Language Models", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "autoregressive paradigm", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "masked language models", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "VILA-Lab", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Awesome-DLMs", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Quokka", "category": 7, "symbolSize": 25, "draggable": true, "value": "Report"}, {"name": "Chinchilla", "category": 7, "symbolSize": 25, "draggable": true, "value": "Report"}, {"name": "IGPO (Inpainting Guided Policy Optimization)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "masked diffusion large language models (dLLMs)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "autoregressive LLMs", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "reinforcement learning", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "GRPO", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Math500", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "AMC", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "supervised fine-tuning", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "entropy-based filtering", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Efficient Encoder-Decoder Diffusion (E2D2)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "discrete diffusion models", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "autoregressive approaches", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "encoder-decoder architecture", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "block diffusion models", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "translation", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "mathematical reasoning", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Stable-DiffCoder", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Seed-Coder", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "block diffusion continual pretraining (CPT)", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "code benchmarks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "low-resource coding languages", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Large Language Model (LLM)-based agents", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "graph-based agent memory", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "self-evolving agent memory", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "open-sourced libraries and benchmarks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "research papers", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "open-source data", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "projects", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "https://github.com/DEEP-PolyU/Awesome-GraphMemory", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Empirical-MCTS", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Monte Carlo Tree Search (MCTS)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Pairwise-Experience-Evolutionary Meta-Prompting (PE-EMP)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Memory Optimization Agent", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "ARC-AGI-2", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "MathArena Apex", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Trust-Memevo benchmark", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "TAME", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Agent Memory Misevolution", "category": 7, "symbolSize": 25, "draggable": true, "value": "Report"}, {"name": "ProcMEM", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Non-Parametric PPO", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Skill-MDP", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "PPO Gate", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "agentic time series forecasting (ATSF)", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "workflow-based design", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "agentic reinforcement learning", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "hybrid agentic workflow paradigm", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "InstructGPT", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "OpenAI API", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "labeler-written prompts", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "prompts submitted through the OpenAI API", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "dataset of labeler demonstrations", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "dataset of rankings of model outputs", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "public NLP datasets", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Pathways Language Model PaLM", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Pathways", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "BIG-bench", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Transformer language model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "TPU v4 chips", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "TPU Pods", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "ReAct", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "chain-of-thought prompting", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "HotpotQA", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Fever", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Wikipedia API", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "ALFWorld", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "WebShop", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "imitation and reinforcement learning methods", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "OpenAI's o1/o3", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "DeepSeek's R1", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "zzli2022", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Awesome-Slow-Reason-System", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Deep Research (DR) agents", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "Model Context Protocols (MCPs)", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "taxonomy", "category": 7, "symbolSize": 25, "draggable": true, "value": "Report"}, {"name": "benchmarks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "repository of DR agent research", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "DeepSeek-R1", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Table-R1-SFT", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Table-R1-Zero", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "GPT-4.1", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "GRPO algorithm", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "large-scale dataset of reasoning traces", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Mind2Report", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "QRC-Eval", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "OpenAI deep research agents", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Gemini deep research agents", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "general large language models (LLMs)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "PaperScout", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Proximal Sequence Policy Optimization (PSPO)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "synthetic and real-world benchmarks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "workflow-driven baselines", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "RL baselines", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "GGL-Net", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "gradient supplementary module (GSM)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "two-way guidance fusion module (TGFM)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "NUAA-SIRST dataset", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "NUDT-SIRST dataset", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "YuChuang1205", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "NN-RAG", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "LEMUR dataset", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "CenterMamba-SAM", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "CenterMamba encoder", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "memory-driven structural prompt generator", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "memory-augmented multi-scale decoder", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "brain lesion segmentation", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "public benchmarks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "IMobileTransformer", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "rice disease identification", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "RF-DETR", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Roboflow100-VL", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "D-FINE", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "GroundingDINO", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "vision-language model (VLM)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "DETRs", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "UAV-based RGB images", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "winter wheat", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "winter rye", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "transfer learning", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "error visibility", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "structural similarity", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "FreeOrbit4D", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "monocular video", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "geometry-complete 4D proxy", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "object-centric multi-view diffusion model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "conditional video diffusion model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "diffusion-based methods", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "edit propagation", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "4D data generation", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "NeoVerse", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "4D world modeling methods", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "in-the-wild monocular videos", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "standard reconstruction and generation benchmarks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "U-Net", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "DiT-XL/2", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "ImageNet 512x512", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Gflops", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "RoPE", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "transformer", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "RoFormer", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Huggingface", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "long text classification benchmark datasets", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Driving World Model (DWM)", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "autonomous driving (AD)", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "mainstream simulators", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "high-impact datasets", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "various metrics", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "video", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "point cloud", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "occupancy", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "latent feature", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "traffic map", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "AD research", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "representative approaches", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "generating tasks", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "driving tasks", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "current research", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "future directions", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "LMD0311", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "FlexMap", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "HD maps", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "autonomous driving systems", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "geometry-aware foundation model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "spatial-temporal enhancement module", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "camera-aware decoder", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "MapAnything", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Universal Feed-Forward Metric 3D Reconstruction", "category": 6, "symbolSize": 50, "draggable": true, "value": "Article"}, {"name": "Seedream 4.0", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Seedream 4.5", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Volcano Engine", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "VLM model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "adversarial distillation", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "distribution matching", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "quantization", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "speculative decoding", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "text-to-image synthesis", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "multi-image composition", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "text-image pairs", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Echo-4o", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Echo-4o-Image", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Bagel", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "GenEval++", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Imagine-Bench", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "OmniGen2", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "BLIP3-o", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Lumina-DiMOO", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "autoregressive (AR) or hybrid AR-Diffusion paradigms", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "image-to-image generation", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "image understanding", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "multiple benchmarks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "code and checkpoints", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "NextStep-1", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "autoregressive models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "vector quantization (VQ)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "flow matching head", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "text-to-image generation tasks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Devlin et al., 2019", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "RACE", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "SQuAD", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "reinforcement learning (RL)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "supervised learning", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "mathematics", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "coding competitions", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "STEM fields", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "human-labeled reasoning trajectories", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "human-annotated demonstrations", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "reasoning patterns", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "self-reflection", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "verification", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "dynamic strategy adaptation", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "smaller models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Search-R1", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Qwen2.5-7B", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Qwen2.5-3B", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "seven question-answering datasets", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "PeterGriffinJin", "category": 1, "symbolSize": 25, "draggable": true, "value": "Person"}, {"name": "Med-PaLM", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Med-PaLM 2", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "MedQA", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "MedMCQA", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "PubMedQA", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "MMLU clinical topics", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Supervised fine-tuning (SFT)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "GeneralPoints", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "V-IRL", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "outcome-based reward", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "EquiCSP", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Crystal Structure Prediction", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "symmetry-aware deep learning models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "existing models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "WorldPlay", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Dual Action Representation", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "Reconstituted Context Memory", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "Context Forcing", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "streaming video diffusion model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "memory-aware model", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "teacher", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "student", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "existing techniques", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "O-Voxel", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "Sparse Compression VAE", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "flow-matching models", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "public 3D asset datasets", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "JEPA-WMs", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "DINO-WM", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "V-JEPA-2-AC", "category": 5, "symbolSize": 50, "draggable": true, "value": "CreativeWork"}, {"name": "simulated environments", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "real-world robotic data", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "https://github.com/facebookresearch/jepa-wms", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "PLIT", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "hierarchical variational autoencoder", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "rate attention mechanism", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "spatial grouping strategy", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "STORM", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Search-Guided Generative World Models", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "CogACT", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "SimplerEnv", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Frechet Video Distance", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "Japanese VLMs", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "chain of thought prompting", "category": 0, "symbolSize": 50, "draggable": true, "value": "Thesis"}, {"name": "R-CNN: Regions with CNN features", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}, {"name": "Ground Penetrating Radar (GPR)", "category": 2, "symbolSize": 25, "draggable": true, "value": "TechArticle"}, {"name": "GPR road hidden defect images", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "distortion identification", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "instant rating", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "reasoning tasks", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "web-downloaded images", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "model-processed images", "category": 3, "symbolSize": 25, "draggable": true, "value": "Dataset"}, {"name": "deep bidirectional language model (biLM)", "category": 4, "symbolSize": 25, "draggable": true, "value": "SoftwareApplication"}],
                    links: [{"source": "Ashish Vaswani", "target": "Attention Is All You Need", "value": "author_of"}, {"source": "Noam Shazeer", "target": "Attention Is All You Need", "value": "author_of"}, {"source": "Niki Parmar", "target": "Attention Is All You Need", "value": "author_of"}, {"source": "Jakob Uszkoreit", "target": "Attention Is All You Need", "value": "author_of"}, {"source": "Llion Jones", "target": "Attention Is All You Need", "value": "author_of"}, {"source": "Aidan N. Gomez", "target": "Attention Is All You Need", "value": "author_of"}, {"source": "Lukasz Kaiser", "target": "Attention Is All You Need", "value": "author_of"}, {"source": "Illia Polosukhin", "target": "Attention Is All You Need", "value": "author_of"}, {"source": "Kaiming He", "target": "Deep Residual Learning for Image Recognition", "value": "author_of"}, {"source": "Xiangyu Zhang", "target": "Deep Residual Learning for Image Recognition", "value": "author_of"}, {"source": "Shaoqing Ren", "target": "Deep Residual Learning for Image Recognition", "value": "author_of"}, {"source": "Jian Sun", "target": "Deep Residual Learning for Image Recognition", "value": "author_of"}, {"source": "Diederik P. Kingma", "target": "Adam: A Method for Stochastic Optimization", "value": "author_of"}, {"source": "Jimmy Ba", "target": "Adam: A Method for Stochastic Optimization", "value": "author_of"}, {"source": "Sepp Hochreiter", "target": "Long Short-Term Memory", "value": "author_of"}, {"source": "J. Schmidhuber", "target": "Long Short-Term Memory", "value": "author_of"}, {"source": "Nitish Srivastava", "target": "Dropout: a simple way to prevent neural networks from overfitting", "value": "author_of"}, {"source": "Geoffrey E. Hinton", "target": "Dropout: a simple way to prevent neural networks from overfitting", "value": "author_of"}, {"source": "A. Krizhevsky", "target": "Dropout: a simple way to prevent neural networks from overfitting", "value": "author_of"}, {"source": "I. Sutskever", "target": "Dropout: a simple way to prevent neural networks from overfitting", "value": "author_of"}, {"source": "R. Salakhutdinov", "target": "Dropout: a simple way to prevent neural networks from overfitting", "value": "author_of"}, {"source": "Christian Szegedy", "target": "Rethinking the Inception Architecture for Computer Vision", "value": "author_of"}, {"source": "Vincent Vanhoucke", "target": "Rethinking the Inception Architecture for Computer Vision", "value": "author_of"}, {"source": "Sergey Ioffe", "target": "Rethinking the Inception Architecture for Computer Vision", "value": "author_of"}, {"source": "Jonathon Shlens", "target": "Rethinking the Inception Architecture for Computer Vision", "value": "author_of"}, {"source": "Zbigniew Wojna", "target": "Rethinking the Inception Architecture for Computer Vision", "value": "author_of"}, {"source": "Shaina Raza", "target": "A comprehensive review of recommender systems: Transitioning from theory to practice", "value": "author_of"}, {"source": "Mizanur Rahman", "target": "A comprehensive review of recommender systems: Transitioning from theory to practice", "value": "author_of"}, {"source": "Safiullah Kamawal", "target": "A comprehensive review of recommender systems: Transitioning from theory to practice", "value": "author_of"}, {"source": "Armin Toroghi", "target": "A comprehensive review of recommender systems: Transitioning from theory to practice", "value": "author_of"}, {"source": "Ananya Raval", "target": "A comprehensive review of recommender systems: Transitioning from theory to practice", "value": "author_of"}, {"source": "F. Navah", "target": "A comprehensive review of recommender systems: Transitioning from theory to practice", "value": "author_of"}, {"source": "Amirmohammad Kazemeini", "target": "A comprehensive review of recommender systems: Transitioning from theory to practice", "value": "author_of"}, {"source": "Zhuoran Yang", "target": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "value": "author_of"}, {"source": "Xi Guo", "target": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "value": "author_of"}, {"source": "Chenjing Ding", "target": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "value": "author_of"}, {"source": "Chiyu Wang", "target": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "value": "author_of"}, {"source": "Wei Wu", "target": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "value": "author_of"}, {"source": "Yanyong Zhang", "target": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "value": "author_of"}, {"source": "Zisheng Wang", "target": "CNC-VLM: An RLHF-optimized industrial large vision-language model with multimodal learning for imbalanced CNC fault detection", "value": "author_of"}, {"source": "Junjie Chen", "target": "CNC-VLM: An RLHF-optimized industrial large vision-language model with multimodal learning for imbalanced CNC fault detection", "value": "author_of"}, {"source": "Chisen Wang", "target": "CNC-VLM: An RLHF-optimized industrial large vision-language model with multimodal learning for imbalanced CNC fault detection", "value": "author_of"}, {"source": "Cong Peng", "target": "CNC-VLM: An RLHF-optimized industrial large vision-language model with multimodal learning for imbalanced CNC fault detection", "value": "author_of"}, {"source": "Jianping Xuan", "target": "CNC-VLM: An RLHF-optimized industrial large vision-language model with multimodal learning for imbalanced CNC fault detection", "value": "author_of"}, {"source": "Tielin Shi", "target": "CNC-VLM: An RLHF-optimized industrial large vision-language model with multimodal learning for imbalanced CNC fault detection", "value": "author_of"}, {"source": "Ming J. Zuo", "target": "CNC-VLM: An RLHF-optimized industrial large vision-language model with multimodal learning for imbalanced CNC fault detection", "value": "author_of"}, {"source": "Abdullah Al Ahad Khan", "target": "Enhanced Transformer-BiLSTM Deep Learning Framework for Day-Ahead Energy Price Forecasting", "value": "author_of"}, {"source": "Md Habib Ullah", "target": "Enhanced Transformer-BiLSTM Deep Learning Framework for Day-Ahead Energy Price Forecasting", "value": "author_of"}, {"source": "Ruchira Tabassum", "target": "Enhanced Transformer-BiLSTM Deep Learning Framework for Day-Ahead Energy Price Forecasting", "value": "author_of"}, {"source": "Md Faisal Kabir", "target": "Enhanced Transformer-BiLSTM Deep Learning Framework for Day-Ahead Energy Price Forecasting", "value": "author_of"}, {"source": "Jinghuan Zhang", "target": "UAV-based quantitative crack measurement for bridges integrating four-point laser metric calibration and mamba segmentation", "value": "author_of"}, {"source": "Wang Chen", "target": "UAV-based quantitative crack measurement for bridges integrating four-point laser metric calibration and mamba segmentation", "value": "author_of"}, {"source": "Jian Zhang", "target": "UAV-based quantitative crack measurement for bridges integrating four-point laser metric calibration and mamba segmentation", "value": "author_of"}, {"source": "A. Krizhevsky", "target": "ImageNet classification with deep convolutional neural networks", "value": "author_of"}, {"source": "I. Sutskever", "target": "ImageNet classification with deep convolutional neural networks", "value": "author_of"}, {"source": "Geoffrey E. Hinton", "target": "ImageNet classification with deep convolutional neural networks", "value": "author_of"}, {"source": "Karen Simonyan", "target": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "value": "author_of"}, {"source": "Andrew Zisserman", "target": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "value": "author_of"}, {"source": "P. Cochat", "target": "Et al", "value": "author_of"}, {"source": "L. Vaucoret", "target": "Et al", "value": "author_of"}, {"source": "J. Sarles", "target": "Et al", "value": "author_of"}, {"source": "Shaoqing Ren", "target": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "value": "author_of"}, {"source": "Kaiming He", "target": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "value": "author_of"}, {"source": "Ross Girshick", "target": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "value": "author_of"}, {"source": "Jian Sun", "target": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "value": "author_of"}, {"source": "Yuqi Cheng", "target": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects", "value": "author_of"}, {"source": "Yunkang Cao", "target": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects", "value": "author_of"}, {"source": "Haiming Yao", "target": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects", "value": "author_of"}, {"source": "Wei Luo", "target": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects", "value": "author_of"}, {"source": "Cheng Jiang", "target": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects", "value": "author_of"}, {"source": "Hui Zhang", "target": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects", "value": "author_of"}, {"source": "Weiming Shen", "target": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects", "value": "author_of"}, {"source": "Naveen Kumar Srinivasa", "target": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning", "value": "author_of"}, {"source": "Ajeet Rao Chalamala", "target": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning", "value": "author_of"}, {"source": "Kumar Singh", "target": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning", "value": "author_of"}, {"source": "Ieee Krishna Mohan Senior Member", "target": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning", "value": "author_of"}, {"source": "K. Naveen", "target": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning", "value": "author_of"}, {"source": "Srinivasa Rao", "target": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning", "value": "author_of"}, {"source": "Ajeet Kumar Singh", "target": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning", "value": "author_of"}, {"source": "Manlin Zhang", "target": "DiffusionEngine: Diffusion model is scalable data engine for object detection", "value": "author_of"}, {"source": "Jie Wu", "target": "DiffusionEngine: Diffusion model is scalable data engine for object detection", "value": "author_of"}, {"source": "Yuxi Ren", "target": "DiffusionEngine: Diffusion model is scalable data engine for object detection", "value": "author_of"}, {"source": "Jiahong Yang", "target": "DiffusionEngine: Diffusion model is scalable data engine for object detection", "value": "author_of"}, {"source": "Ming Li", "target": "DiffusionEngine: Diffusion model is scalable data engine for object detection", "value": "author_of"}, {"source": "Andy J. Ma", "target": "DiffusionEngine: Diffusion model is scalable data engine for object detection", "value": "author_of"}, {"source": "Salma Haidar", "target": "Enhancing hyperspectral image prediction with contrastive learning in low-label regimes", "value": "author_of"}, {"source": "Jos\u00e9 Oramas", "target": "Enhancing hyperspectral image prediction with contrastive learning in low-label regimes", "value": "author_of"}, {"source": "Hongbo Jiang", "target": "WarmGait: Thermal Array-Based Gait Recognition for Privacy-Preserving Person Re-ID", "value": "author_of"}, {"source": "Lei Ye", "target": "WarmGait: Thermal Array-Based Gait Recognition for Privacy-Preserving Person Re-ID", "value": "author_of"}, {"source": "Jingyang Hu", "target": "WarmGait: Thermal Array-Based Gait Recognition for Privacy-Preserving Person Re-ID", "value": "author_of"}, {"source": "Xiaotian Chen", "target": "WarmGait: Thermal Array-Based Gait Recognition for Privacy-Preserving Person Re-ID", "value": "author_of"}, {"source": "Siyu Chen", "target": "WarmGait: Thermal Array-Based Gait Recognition for Privacy-Preserving Person Re-ID", "value": "author_of"}, {"source": "Wei Zhang", "target": "WarmGait: Thermal Array-Based Gait Recognition for Privacy-Preserving Person Re-ID", "value": "author_of"}, {"source": "Kehua Yang", "target": "WarmGait: Thermal Array-Based Gait Recognition for Privacy-Preserving Person Re-ID", "value": "author_of"}, {"source": "Diederik P Kingma", "target": "Auto-Encoding Variational Bayes", "value": "author_of"}, {"source": "Max Welling", "target": "Auto-Encoding Variational Bayes", "value": "author_of"}, {"source": "Geoffrey E. Hinton", "target": "Supporting Online Material for Reducing the Dimensionality of Data with Neural Networks", "value": "author_of"}, {"source": "R. Salakhutdinov", "target": "Supporting Online Material for Reducing the Dimensionality of Data with Neural Networks", "value": "author_of"}, {"source": "John C. Duchi", "target": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization", "value": "author_of"}, {"source": "Elad Hazan", "target": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization", "value": "author_of"}, {"source": "Y. Singer", "target": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization", "value": "author_of"}, {"source": "Alex Graves", "target": "Speech recognition with deep recurrent neural networks", "value": "author_of"}, {"source": "Abdel-rahman Mohamed", "target": "Speech recognition with deep recurrent neural networks", "value": "author_of"}, {"source": "Geoffrey Hinton", "target": "Speech recognition with deep recurrent neural networks", "value": "author_of"}, {"source": "Nian Wang", "target": "Weakly Supervised Image Dehazing via Physics-Based Decomposition", "value": "author_of"}, {"source": "Zhigao Cui", "target": "Weakly Supervised Image Dehazing via Physics-Based Decomposition", "value": "author_of"}, {"source": "Yanzhao Su", "target": "Weakly Supervised Image Dehazing via Physics-Based Decomposition", "value": "author_of"}, {"source": "Yunwei Lan", "target": "Weakly Supervised Image Dehazing via Physics-Based Decomposition", "value": "author_of"}, {"source": "Yuanliang Xue", "target": "Weakly Supervised Image Dehazing via Physics-Based Decomposition", "value": "author_of"}, {"source": "Cong Zhang", "target": "Weakly Supervised Image Dehazing via Physics-Based Decomposition", "value": "author_of"}, {"source": "Aihua Li", "target": "Weakly Supervised Image Dehazing via Physics-Based Decomposition", "value": "author_of"}, {"source": "Leong Kah Meng", "target": "A Machine Learning Approach for Face Mask Detection System with AdamW Optimizer", "value": "author_of"}, {"source": "Ho Hooi Yi", "target": "A Machine Learning Approach for Face Mask Detection System with AdamW Optimizer", "value": "author_of"}, {"source": "Ng Bo Wei", "target": "A Machine Learning Approach for Face Mask Detection System with AdamW Optimizer", "value": "author_of"}, {"source": "Lim Jia Xin", "target": "A Machine Learning Approach for Face Mask Detection System with AdamW Optimizer", "value": "author_of"}, {"source": "Zailan Arabee Abdul Salam", "target": "A Machine Learning Approach for Face Mask Detection System with AdamW Optimizer", "value": "author_of"}, {"source": "Xin Cheng", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Wangding Zeng", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Damai Dai", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Qinyu Chen", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Bingxuan Wang", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Zhenda Xie", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Kezhao Huang", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Xingkai Yu", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Zhewen Hao", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Yukun Li", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Han Zhang", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Huishuai Zhang", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Dongyan Zhao", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Wenfeng Liang", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "author_of"}, {"source": "Mostafa Saberian", "target": "Probabilistic hierarchical interpolation and interpretable neural network configurations for flood prediction", "value": "author_of"}, {"source": "Vidya Samadi", "target": "Probabilistic hierarchical interpolation and interpretable neural network configurations for flood prediction", "value": "author_of"}, {"source": "Ioana Popescu", "target": "Probabilistic hierarchical interpolation and interpretable neural network configurations for flood prediction", "value": "author_of"}, {"source": "Husheng Fang", "target": "Generating an annual 30\u00a0m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "value": "author_of"}, {"source": "Shunlin Liang", "target": "Generating an annual 30\u00a0m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "value": "author_of"}, {"source": "Wenyuan Li", "target": "Generating an annual 30\u00a0m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "value": "author_of"}, {"source": "Yongzhe Chen", "target": "Generating an annual 30\u00a0m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "value": "author_of"}, {"source": "Han Ma", "target": "Generating an annual 30\u00a0m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "value": "author_of"}, {"source": "Jianglei Xu", "target": "Generating an annual 30\u00a0m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "value": "author_of"}, {"source": "Yichuan Ma", "target": "Generating an annual 30\u00a0m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "value": "author_of"}, {"source": "Tao He", "target": "Generating an annual 30\u00a0m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "value": "author_of"}, {"source": "Feng Tian", "target": "Generating an annual 30\u00a0m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "value": "author_of"}, {"source": "Fengjiao Zhang", "target": "Generating an annual 30\u00a0m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "value": "author_of"}, {"source": "Hui Liang", "target": "Generating an annual 30\u00a0m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "value": "author_of"}, {"source": "Christian Szegedy", "target": "Going deeper with convolutions", "value": "author_of"}, {"source": "Wei Liu", "target": "Going deeper with convolutions", "value": "author_of"}, {"source": "Yangqing Jia", "target": "Going deeper with convolutions", "value": "author_of"}, {"source": "Pierre Sermanet", "target": "Going deeper with convolutions", "value": "author_of"}, {"source": "Scott Reed", "target": "Going deeper with convolutions", "value": "author_of"}, {"source": "Dragomir Anguelov", "target": "Going deeper with convolutions", "value": "author_of"}, {"source": "Dumitru Erhan", "target": "Going deeper with convolutions", "value": "author_of"}, {"source": "Vincent Vanhoucke", "target": "Going deeper with convolutions", "value": "author_of"}, {"source": "Andrew Rabinovich", "target": "Going deeper with convolutions", "value": "author_of"}, {"source": "Sergey Ioffe", "target": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "value": "author_of"}, {"source": "Christian Szegedy", "target": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "value": "author_of"}, {"source": "Olga Russakovsky", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "author_of"}, {"source": "Jia Deng", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "author_of"}, {"source": "Hao Su", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "author_of"}, {"source": "Jonathan Krause", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "author_of"}, {"source": "Sanjeev Satheesh", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "author_of"}, {"source": "Sean Ma", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "author_of"}, {"source": "Zhiheng Huang", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "author_of"}, {"source": "Andrej Karpathy", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "author_of"}, {"source": "Aditya Khosla", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "author_of"}, {"source": "Michael Bernstein", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "author_of"}, {"source": "Alexander C. Berg", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "author_of"}, {"source": "Li Fei-Fei", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "author_of"}, {"source": "Boyang Zheng", "target": "Diffusion Transformers with Representation Autoencoders", "value": "author_of"}, {"source": "Nanye Ma", "target": "Diffusion Transformers with Representation Autoencoders", "value": "author_of"}, {"source": "Shengbang Tong", "target": "Diffusion Transformers with Representation Autoencoders", "value": "author_of"}, {"source": "Saining Xie", "target": "Diffusion Transformers with Representation Autoencoders", "value": "author_of"}, {"source": "S. Rizvi", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "Daniel Levine", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "Aakash Patel", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "Shiyang Zhang", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "Eric Wang", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "Curtis Jamison Perry", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "Ivan Vrkic", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "Nicole Mayerli Constante", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "Zirui Fu", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "Sizhuang He", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "David Zhang", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "Cerise Tang", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "Zhuoyang Lyu", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "Rayyan Y Darji", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "Chang Li", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "Emily Sun", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "David Jeong", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "Lawrence Zhao", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "J. Kwan", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "David Braun", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "Brian Hafler", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "Hattie Chung", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "R. M. Dhodapkar", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "Paul F. Jaeger", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "Bryan Perozzi", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "Jeffrey Ishizuka", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "Shekoofeh Azizi", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "D. van Dijk", "target": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "value": "author_of"}, {"source": "\u015eafak K\u0131l\u0131\u00e7", "target": "HybridVisionNet: An advanced hybrid deep learning framework for automated multi-class ocular disease diagnosis using fundus imaging", "value": "author_of"}, {"source": "Zhengyu Zhao", "target": "Revisiting Transferable Adversarial Images: Systemization, Evaluation, and New Insights", "value": "author_of"}, {"source": "Hanwei Zhang", "target": "Revisiting Transferable Adversarial Images: Systemization, Evaluation, and New Insights", "value": "author_of"}, {"source": "Renjue Li", "target": "Revisiting Transferable Adversarial Images: Systemization, Evaluation, and New Insights", "value": "author_of"}, {"source": "R. Sicre", "target": "Revisiting Transferable Adversarial Images: Systemization, Evaluation, and New Insights", "value": "author_of"}, {"source": "L. Amsaleg", "target": "Revisiting Transferable Adversarial Images: Systemization, Evaluation, and New Insights", "value": "author_of"}, {"source": "Michael Backes", "target": "Revisiting Transferable Adversarial Images: Systemization, Evaluation, and New Insights", "value": "author_of"}, {"source": "Qi Li", "target": "Revisiting Transferable Adversarial Images: Systemization, Evaluation, and New Insights", "value": "author_of"}, {"source": "Chao Shen", "target": "Revisiting Transferable Adversarial Images: Systemization, Evaluation, and New Insights", "value": "author_of"}, {"source": "Yifei Ge", "target": "Dataset Purification-Driven Lightweight Deep Learning Model Construction for Empty-Dish Recycling Robot", "value": "author_of"}, {"source": "Zhuo Li", "target": "Dataset Purification-Driven Lightweight Deep Learning Model Construction for Empty-Dish Recycling Robot", "value": "author_of"}, {"source": "Xuebin Yue", "target": "Dataset Purification-Driven Lightweight Deep Learning Model Construction for Empty-Dish Recycling Robot", "value": "author_of"}, {"source": "Hengyi Li", "target": "Dataset Purification-Driven Lightweight Deep Learning Model Construction for Empty-Dish Recycling Robot", "value": "author_of"}, {"source": "Lin Meng", "target": "Dataset Purification-Driven Lightweight Deep Learning Model Construction for Empty-Dish Recycling Robot", "value": "author_of"}, {"source": "Ashish Vaswani", "target": "Attention is All you Need", "value": "author_of"}, {"source": "Noam Shazeer", "target": "Attention is All you Need", "value": "author_of"}, {"source": "Niki Parmar", "target": "Attention is All you Need", "value": "author_of"}, {"source": "Jakob Uszkoreit", "target": "Attention is All you Need", "value": "author_of"}, {"source": "Llion Jones", "target": "Attention is All you Need", "value": "author_of"}, {"source": "Aidan N. Gomez", "target": "Attention is All you Need", "value": "author_of"}, {"source": "Lukasz Kaiser", "target": "Attention is All you Need", "value": "author_of"}, {"source": "Illia Polosukhin", "target": "Attention is All you Need", "value": "author_of"}, {"source": "Colin Raffel", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "author_of"}, {"source": "Noam Shazeer", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "author_of"}, {"source": "Adam Roberts", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "author_of"}, {"source": "Katherine Lee", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "author_of"}, {"source": "Sharan Narang", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "author_of"}, {"source": "Michael Matena", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "author_of"}, {"source": "Yanqi Zhou", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "author_of"}, {"source": "Wei Li", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "author_of"}, {"source": "Peter J. Liu", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "author_of"}, {"source": "M. Heusel", "target": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium", "value": "author_of"}, {"source": "Hubert Ramsauer", "target": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium", "value": "author_of"}, {"source": "Thomas Unterthiner", "target": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium", "value": "author_of"}, {"source": "Bernhard Nessler", "target": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium", "value": "author_of"}, {"source": "Sepp Hochreiter", "target": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium", "value": "author_of"}, {"source": "Holger Caesar", "target": "nuScenes: A Multimodal Dataset for Autonomous Driving", "value": "author_of"}, {"source": "Varun Bankiti", "target": "nuScenes: A Multimodal Dataset for Autonomous Driving", "value": "author_of"}, {"source": "Alex H. Lang", "target": "nuScenes: A Multimodal Dataset for Autonomous Driving", "value": "author_of"}, {"source": "Sourabh Vora", "target": "nuScenes: A Multimodal Dataset for Autonomous Driving", "value": "author_of"}, {"source": "Venice Erin Liong", "target": "nuScenes: A Multimodal Dataset for Autonomous Driving", "value": "author_of"}, {"source": "Qiang Xu", "target": "nuScenes: A Multimodal Dataset for Autonomous Driving", "value": "author_of"}, {"source": "Anush Krishnan", "target": "nuScenes: A Multimodal Dataset for Autonomous Driving", "value": "author_of"}, {"source": "Yu Pan", "target": "nuScenes: A Multimodal Dataset for Autonomous Driving", "value": "author_of"}, {"source": "Giancarlo Baldan", "target": "nuScenes: A Multimodal Dataset for Autonomous Driving", "value": "author_of"}, {"source": "Oscar Beijbom", "target": "nuScenes: A Multimodal Dataset for Autonomous Driving", "value": "author_of"}, {"source": "Alexey Dosovitskiy", "target": "CARLA: An Open Urban Driving Simulator", "value": "author_of"}, {"source": "German Ros", "target": "CARLA: An Open Urban Driving Simulator", "value": "author_of"}, {"source": "Felipe Codevilla", "target": "CARLA: An Open Urban Driving Simulator", "value": "author_of"}, {"source": "Antonio Lopez", "target": "CARLA: An Open Urban Driving Simulator", "value": "author_of"}, {"source": "Vladlen Koltun", "target": "CARLA: An Open Urban Driving Simulator", "value": "author_of"}, {"source": "Fachrina Dewi Puspitasari", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Chaoning Zhang", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Joseph Cho", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Adnan Haider", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Noor Ul Eman", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Omer Amin", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Alexis Mankowski", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Muhammad Umair", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Jingyao Zheng", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Sheng Zheng", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Lik-Hang Lee", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Caiyan Qin", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Tae-Ho Kim", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Choong Seon Hong", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Yang Yang", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Heng Tao Shen", "target": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "value": "author_of"}, {"source": "Bohan Li", "target": "OmniNWM: Omniscient Driving Navigation World Models", "value": "author_of"}, {"source": "Zhuang Ma", "target": "OmniNWM: Omniscient Driving Navigation World Models", "value": "author_of"}, {"source": "Dalong Du", "target": "OmniNWM: Omniscient Driving Navigation World Models", "value": "author_of"}, {"source": "Baorui Peng", "target": "OmniNWM: Omniscient Driving Navigation World Models", "value": "author_of"}, {"source": "Zhujin Liang", "target": "OmniNWM: Omniscient Driving Navigation World Models", "value": "author_of"}, {"source": "Zhenqiang Liu", "target": "OmniNWM: Omniscient Driving Navigation World Models", "value": "author_of"}, {"source": "Chao Ma", "target": "OmniNWM: Omniscient Driving Navigation World Models", "value": "author_of"}, {"source": "Yueming Jin", "target": "OmniNWM: Omniscient Driving Navigation World Models", "value": "author_of"}, {"source": "Hao Zhao", "target": "OmniNWM: Omniscient Driving Navigation World Models", "value": "author_of"}, {"source": "Wenjun Zeng", "target": "OmniNWM: Omniscient Driving Navigation World Models", "value": "author_of"}, {"source": "Xin Jin", "target": "OmniNWM: Omniscient Driving Navigation World Models", "value": "author_of"}, {"source": "Zhuoran Yang", "target": "ConsisDrive: Identity-Preserving Driving World Models for Video Generation by Instance Mask", "value": "author_of"}, {"source": "Yanyong Zhang", "target": "ConsisDrive: Identity-Preserving Driving World Models for Video Generation by Instance Mask", "value": "author_of"}, {"source": "Guosheng Zhao", "target": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "value": "author_of"}, {"source": "Yaozeng Wang", "target": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "value": "author_of"}, {"source": "Xiaofeng Wang", "target": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "value": "author_of"}, {"source": "Zheng Zhu", "target": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "value": "author_of"}, {"source": "Tingdong Yu", "target": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "value": "author_of"}, {"source": "Guan Huang", "target": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "value": "author_of"}, {"source": "Yongchen Zai", "target": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "value": "author_of"}, {"source": "Ji Jiao", "target": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "value": "author_of"}, {"source": "Changliang Xue", "target": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "value": "author_of"}, {"source": "Xiaole Wang", "target": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "value": "author_of"}, {"source": "Zhen Yang", "target": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "value": "author_of"}, {"source": "Futang Zhu", "target": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "value": "author_of"}, {"source": "Xingang Wang", "target": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "value": "author_of"}, {"source": "Ahmad Rahimi", "target": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "value": "author_of"}, {"source": "Valentin Gerard", "target": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "value": "author_of"}, {"source": "Eloi Zablocki", "target": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "value": "author_of"}, {"source": "Matthieu Cord", "target": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "value": "author_of"}, {"source": "Alexandre Alahi", "target": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "value": "author_of"}, {"source": "W. Marsden", "target": "I and J", "value": "author_of"}, {"source": "Jia Deng", "target": "ImageNet: A large-scale hierarchical image database", "value": "author_of"}, {"source": "Wei Dong", "target": "ImageNet: A large-scale hierarchical image database", "value": "author_of"}, {"source": "R. Socher", "target": "ImageNet: A large-scale hierarchical image database", "value": "author_of"}, {"source": "Li-Jia Li", "target": "ImageNet: A large-scale hierarchical image database", "value": "author_of"}, {"source": "K. Li", "target": "ImageNet: A large-scale hierarchical image database", "value": "author_of"}, {"source": "Li Fei-Fei", "target": "ImageNet: A large-scale hierarchical image database", "value": "author_of"}, {"source": "R. Stephenson", "target": "A and V", "value": "author_of"}, {"source": "Jaskirat Singh", "target": "What matters for Representation Alignment: Global Information or Spatial Structure?", "value": "author_of"}, {"source": "Xingjian Leng", "target": "What matters for Representation Alignment: Global Information or Spatial Structure?", "value": "author_of"}, {"source": "Zongze Wu", "target": "What matters for Representation Alignment: Global Information or Spatial Structure?", "value": "author_of"}, {"source": "Liang Zheng", "target": "What matters for Representation Alignment: Global Information or Spatial Structure?", "value": "author_of"}, {"source": "Richard Zhang", "target": "What matters for Representation Alignment: Global Information or Spatial Structure?", "value": "author_of"}, {"source": "Eli Shechtman", "target": "What matters for Representation Alignment: Global Information or Spatial Structure?", "value": "author_of"}, {"source": "Saining Xie", "target": "What matters for Representation Alignment: Global Information or Spatial Structure?", "value": "author_of"}, {"source": "Zhifeng Wang", "target": "SCB-DETR: Multiscale Deformable Transformers for Occlusion-Resilient Student Learning Behavior Detection in Smart Classroom", "value": "author_of"}, {"source": "Minghui Wang", "target": "SCB-DETR: Multiscale Deformable Transformers for Occlusion-Resilient Student Learning Behavior Detection in Smart Classroom", "value": "author_of"}, {"source": "Chunyan Zeng", "target": "SCB-DETR: Multiscale Deformable Transformers for Occlusion-Resilient Student Learning Behavior Detection in Smart Classroom", "value": "author_of"}, {"source": "Longlong Li", "target": "SCB-DETR: Multiscale Deformable Transformers for Occlusion-Resilient Student Learning Behavior Detection in Smart Classroom", "value": "author_of"}, {"source": "Ehsan Zakeri", "target": "Robust Deep Feature Ultrasound Image-Based Visual Servoing: Focus on Cardiac Examination", "value": "author_of"}, {"source": "Amanda Spilkin", "target": "Robust Deep Feature Ultrasound Image-Based Visual Servoing: Focus on Cardiac Examination", "value": "author_of"}, {"source": "Hanae Elmekki", "target": "Robust Deep Feature Ultrasound Image-Based Visual Servoing: Focus on Cardiac Examination", "value": "author_of"}, {"source": "Antonela Zanuttini", "target": "Robust Deep Feature Ultrasound Image-Based Visual Servoing: Focus on Cardiac Examination", "value": "author_of"}, {"source": "L. Kadem", "target": "Robust Deep Feature Ultrasound Image-Based Visual Servoing: Focus on Cardiac Examination", "value": "author_of"}, {"source": "Jamal Bentahar", "target": "Robust Deep Feature Ultrasound Image-Based Visual Servoing: Focus on Cardiac Examination", "value": "author_of"}, {"source": "Wen-Fang Xie", "target": "Robust Deep Feature Ultrasound Image-Based Visual Servoing: Focus on Cardiac Examination", "value": "author_of"}, {"source": "Philippe Pibarot", "target": "Robust Deep Feature Ultrasound Image-Based Visual Servoing: Focus on Cardiac Examination", "value": "author_of"}, {"source": "Ana Davila", "target": "Bio-Inspired Fine-Tuning for Selective Transfer Learning in Image Classification", "value": "author_of"}, {"source": "Jacinto Colan", "target": "Bio-Inspired Fine-Tuning for Selective Transfer Learning in Image Classification", "value": "author_of"}, {"source": "Yasuhisa Hasegawa", "target": "Bio-Inspired Fine-Tuning for Selective Transfer Learning in Image Classification", "value": "author_of"}, {"source": "Subham Sharma", "target": "Hand Sign Language Detection Using Deep Learning", "value": "author_of"}, {"source": "Sharmila Subudhi", "target": "Hand Sign Language Detection Using Deep Learning", "value": "author_of"}, {"source": "Yoshua Bengio", "target": "Representation Learning: A Review and New Perspectives", "value": "author_of"}, {"source": "Aaron Courville", "target": "Representation Learning: A Review and New Perspectives", "value": "author_of"}, {"source": "Pascal Vincent", "target": "Representation Learning: A Review and New Perspectives", "value": "author_of"}, {"source": "D. Touretzky", "target": "In Advances in Neural Information Processing Systems", "value": "author_of"}, {"source": "M. C. Mozer", "target": "In Advances in Neural Information Processing Systems", "value": "author_of"}, {"source": "M. E. Hasselmo", "target": "In Advances in Neural Information Processing Systems", "value": "author_of"}, {"source": "RegressionChristopher", "target": "In Advances in Neural Information Processing Systems", "value": "author_of"}, {"source": "I. K.", "target": "In Advances in Neural Information Processing Systems", "value": "author_of"}, {"source": "WilliamsNeural", "target": "In Advances in Neural Information Processing Systems", "value": "author_of"}, {"source": "GroupAston", "target": "In Advances in Neural Information Processing Systems", "value": "author_of"}, {"source": "UniversityBirmingham", "target": "In Advances in Neural Information Processing Systems", "value": "author_of"}, {"source": "Danilo Jimenez Rezende", "target": "Stochastic Backpropagation and Approximate Inference in Deep Generative Models", "value": "author_of"}, {"source": "S. Mohamed", "target": "Stochastic Backpropagation and Approximate Inference in Deep Generative Models", "value": "author_of"}, {"source": "Daan Wierstra", "target": "Stochastic Backpropagation and Approximate Inference in Deep Generative Models", "value": "author_of"}, {"source": "Shanchuan Lin", "target": "SDXL-Lightning: Progressive Adversarial Diffusion Distillation", "value": "author_of"}, {"source": "Anran Wang", "target": "SDXL-Lightning: Progressive Adversarial Diffusion Distillation", "value": "author_of"}, {"source": "Xiao Yang", "target": "SDXL-Lightning: Progressive Adversarial Diffusion Distillation", "value": "author_of"}, {"source": "Zhiyuan Chen", "target": "EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditions", "value": "author_of"}, {"source": "Jiajiong Cao", "target": "EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditions", "value": "author_of"}, {"source": "Zhiquan Chen", "target": "EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditions", "value": "author_of"}, {"source": "Yuming Li", "target": "EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditions", "value": "author_of"}, {"source": "Chenguang Ma", "target": "EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditions", "value": "author_of"}, {"source": "Wenzhao Zheng", "target": "GenAD: Generative End-to-End Autonomous Driving", "value": "author_of"}, {"source": "Ruiqi Song", "target": "GenAD: Generative End-to-End Autonomous Driving", "value": "author_of"}, {"source": "Xianda Guo", "target": "GenAD: Generative End-to-End Autonomous Driving", "value": "author_of"}, {"source": "Chenming Zhang", "target": "GenAD: Generative End-to-End Autonomous Driving", "value": "author_of"}, {"source": "Long Chen", "target": "GenAD: Generative End-to-End Autonomous Driving", "value": "author_of"}, {"source": "Shiyin Lu", "target": "Ovis: Structural Embedding Alignment for Multimodal Large Language Model", "value": "author_of"}, {"source": "Yang Li", "target": "Ovis: Structural Embedding Alignment for Multimodal Large Language Model", "value": "author_of"}, {"source": "Qing-Guo Chen", "target": "Ovis: Structural Embedding Alignment for Multimodal Large Language Model", "value": "author_of"}, {"source": "Zhao Xu", "target": "Ovis: Structural Embedding Alignment for Multimodal Large Language Model", "value": "author_of"}, {"source": "Weihua Luo", "target": "Ovis: Structural Embedding Alignment for Multimodal Large Language Model", "value": "author_of"}, {"source": "Kaifu Zhang", "target": "Ovis: Structural Embedding Alignment for Multimodal Large Language Model", "value": "author_of"}, {"source": "Han-Jia Ye", "target": "Ovis: Structural Embedding Alignment for Multimodal Large Language Model", "value": "author_of"}, {"source": "Jie Liu", "target": "Improving Video Generation with Human Feedback", "value": "author_of"}, {"source": "Gongye Liu", "target": "Improving Video Generation with Human Feedback", "value": "author_of"}, {"source": "Jiajun Liang", "target": "Improving Video Generation with Human Feedback", "value": "author_of"}, {"source": "Ziyang Yuan", "target": "Improving Video Generation with Human Feedback", "value": "author_of"}, {"source": "Xiaokun Liu", "target": "Improving Video Generation with Human Feedback", "value": "author_of"}, {"source": "Mingwu Zheng", "target": "Improving Video Generation with Human Feedback", "value": "author_of"}, {"source": "Xiele Wu", "target": "Improving Video Generation with Human Feedback", "value": "author_of"}, {"source": "Qiulin Wang", "target": "Improving Video Generation with Human Feedback", "value": "author_of"}, {"source": "Menghan Xia", "target": "Improving Video Generation with Human Feedback", "value": "author_of"}, {"source": "Xintao Wang", "target": "Improving Video Generation with Human Feedback", "value": "author_of"}, {"source": "Xiaohong Liu", "target": "Improving Video Generation with Human Feedback", "value": "author_of"}, {"source": "Fei Yang", "target": "Improving Video Generation with Human Feedback", "value": "author_of"}, {"source": "Pengfei Wan", "target": "Improving Video Generation with Human Feedback", "value": "author_of"}, {"source": "Di Zhang", "target": "Improving Video Generation with Human Feedback", "value": "author_of"}, {"source": "Kun Gai", "target": "Improving Video Generation with Human Feedback", "value": "author_of"}, {"source": "Yujiu Yang", "target": "Improving Video Generation with Human Feedback", "value": "author_of"}, {"source": "Wanli Ouyang", "target": "Improving Video Generation with Human Feedback", "value": "author_of"}, {"source": "Alex Graves", "target": "Speech Recognition with Deep Recurrent Neural Networks", "value": "author_of"}, {"source": "Abdel-rahman Mohamed", "target": "Speech Recognition with Deep Recurrent Neural Networks", "value": "author_of"}, {"source": "Geoffrey Hinton", "target": "Speech Recognition with Deep Recurrent Neural Networks", "value": "author_of"}, {"source": "D. Rumelhart", "target": "Learning representations by back-propagating errors", "value": "author_of"}, {"source": "Geoffrey E. Hinton", "target": "Learning representations by back-propagating errors", "value": "author_of"}, {"source": "Ronald J. Williams", "target": "Learning representations by back-propagating errors", "value": "author_of"}, {"source": "M. Schuster", "target": "Bidirectional recurrent neural networks", "value": "author_of"}, {"source": "K. Paliwal", "target": "Bidirectional recurrent neural networks", "value": "author_of"}, {"source": "Alex Graves", "target": "Connectionist Temporal Classi\ufb01cation: Labelling Unsegmented Sequence Data with Recurrent Neural Networks", "value": "author_of"}, {"source": "Santiago Fern\u00b4andez", "target": "Connectionist Temporal Classi\ufb01cation: Labelling Unsegmented Sequence Data with Recurrent Neural Networks", "value": "author_of"}, {"source": "Faustino J. Gomez", "target": "Connectionist Temporal Classi\ufb01cation: Labelling Unsegmented Sequence Data with Recurrent Neural Networks", "value": "author_of"}, {"source": "J\u00a8urgen Schmidhuber", "target": "Connectionist Temporal Classi\ufb01cation: Labelling Unsegmented Sequence Data with Recurrent Neural Networks", "value": "author_of"}, {"source": "Alex Graves", "target": "2005 Special Issue: Framewise phoneme classification with bidirectional LSTM and other neural network architectures", "value": "author_of"}, {"source": "J. Schmidhuber", "target": "2005 Special Issue: Framewise phoneme classification with bidirectional LSTM and other neural network architectures", "value": "author_of"}, {"source": "Tianming Sun", "target": "Artificial Intelligence Meets Flexible Sensors: Emerging Smart Flexible Sensing Systems Driven by Machine Learning and Artificial Synapses", "value": "author_of"}, {"source": "Bin Feng", "target": "Artificial Intelligence Meets Flexible Sensors: Emerging Smart Flexible Sensing Systems Driven by Machine Learning and Artificial Synapses", "value": "author_of"}, {"source": "Jinpeng Huo", "target": "Artificial Intelligence Meets Flexible Sensors: Emerging Smart Flexible Sensing Systems Driven by Machine Learning and Artificial Synapses", "value": "author_of"}, {"source": "Yu Xiao", "target": "Artificial Intelligence Meets Flexible Sensors: Emerging Smart Flexible Sensing Systems Driven by Machine Learning and Artificial Synapses", "value": "author_of"}, {"source": "Wengan Wang", "target": "Artificial Intelligence Meets Flexible Sensors: Emerging Smart Flexible Sensing Systems Driven by Machine Learning and Artificial Synapses", "value": "author_of"}, {"source": "Jin Peng", "target": "Artificial Intelligence Meets Flexible Sensors: Emerging Smart Flexible Sensing Systems Driven by Machine Learning and Artificial Synapses", "value": "author_of"}, {"source": "Zehua Li", "target": "Artificial Intelligence Meets Flexible Sensors: Emerging Smart Flexible Sensing Systems Driven by Machine Learning and Artificial Synapses", "value": "author_of"}, {"source": "Chengjie Du", "target": "Artificial Intelligence Meets Flexible Sensors: Emerging Smart Flexible Sensing Systems Driven by Machine Learning and Artificial Synapses", "value": "author_of"}, {"source": "Wenxian Wang", "target": "Artificial Intelligence Meets Flexible Sensors: Emerging Smart Flexible Sensing Systems Driven by Machine Learning and Artificial Synapses", "value": "author_of"}, {"source": "G. Zou", "target": "Artificial Intelligence Meets Flexible Sensors: Emerging Smart Flexible Sensing Systems Driven by Machine Learning and Artificial Synapses", "value": "author_of"}, {"source": "Lei Liu", "target": "Artificial Intelligence Meets Flexible Sensors: Emerging Smart Flexible Sensing Systems Driven by Machine Learning and Artificial Synapses", "value": "author_of"}, {"source": "Francis R. Willett", "target": "A high-performance speech neuroprosthesis", "value": "author_of"}, {"source": "Erin M. Kunz", "target": "A high-performance speech neuroprosthesis", "value": "author_of"}, {"source": "Chaofei Fan", "target": "A high-performance speech neuroprosthesis", "value": "author_of"}, {"source": "Donald T. Avansino", "target": "A high-performance speech neuroprosthesis", "value": "author_of"}, {"source": "G. Wilson", "target": "A high-performance speech neuroprosthesis", "value": "author_of"}, {"source": "Eun Young Choi", "target": "A high-performance speech neuroprosthesis", "value": "author_of"}, {"source": "Foram B. Kamdar", "target": "A high-performance speech neuroprosthesis", "value": "author_of"}, {"source": "M. Glasser", "target": "A high-performance speech neuroprosthesis", "value": "author_of"}, {"source": "L. Hochberg", "target": "A high-performance speech neuroprosthesis", "value": "author_of"}, {"source": "S. Druckmann", "target": "A high-performance speech neuroprosthesis", "value": "author_of"}, {"source": "K. Shenoy", "target": "A high-performance speech neuroprosthesis", "value": "author_of"}, {"source": "J. Henderson", "target": "A high-performance speech neuroprosthesis", "value": "author_of"}, {"source": "Shibhansh Dohare", "target": "Loss of plasticity in deep continual learning", "value": "author_of"}, {"source": "J. F. Hernandez-Garcia", "target": "Loss of plasticity in deep continual learning", "value": "author_of"}, {"source": "Qingfeng Lan", "target": "Loss of plasticity in deep continual learning", "value": "author_of"}, {"source": "Parash Rahman", "target": "Loss of plasticity in deep continual learning", "value": "author_of"}, {"source": "A. Mahmood", "target": "Loss of plasticity in deep continual learning", "value": "author_of"}, {"source": "R. Sutton", "target": "Loss of plasticity in deep continual learning", "value": "author_of"}, {"source": "S. Ambrogio", "target": "An analog-AI chip for energy-efficient speech recognition and transcription", "value": "author_of"}, {"source": "P. Narayanan", "target": "An analog-AI chip for energy-efficient speech recognition and transcription", "value": "author_of"}, {"source": "A. Okazaki", "target": "An analog-AI chip for energy-efficient speech recognition and transcription", "value": "author_of"}, {"source": "A. Fasoli", "target": "An analog-AI chip for energy-efficient speech recognition and transcription", "value": "author_of"}, {"source": "C. Mackin", "target": "An analog-AI chip for energy-efficient speech recognition and transcription", "value": "author_of"}, {"source": "K. Hosokawa", "target": "An analog-AI chip for energy-efficient speech recognition and transcription", "value": "author_of"}, {"source": "A. Nomura", "target": "An analog-AI chip for energy-efficient speech recognition and transcription", "value": "author_of"}, {"source": "Takeo Yasuda", "target": "An analog-AI chip for energy-efficient speech recognition and transcription", "value": "author_of"}, {"source": "An Chen", "target": "An analog-AI chip for energy-efficient speech recognition and transcription", "value": "author_of"}, {"source": "A. Friz", "target": "An analog-AI chip for energy-efficient speech recognition and transcription", "value": "author_of"}, {"source": "M. Ishii", "target": "An analog-AI chip for energy-efficient speech recognition and transcription", "value": "author_of"}, {"source": "J. Luquin", "target": "An analog-AI chip for energy-efficient speech recognition and transcription", "value": "author_of"}, {"source": "Y. Kohda", "target": "An analog-AI chip for energy-efficient speech recognition and transcription", "value": "author_of"}, {"source": "N. Saulnier", "target": "An analog-AI chip for energy-efficient speech recognition and transcription", "value": "author_of"}, {"source": "K. Brew", "target": "An analog-AI chip for energy-efficient speech recognition and transcription", "value": "author_of"}, {"source": "Samuel Choi", "target": "An analog-AI chip for energy-efficient speech recognition and transcription", "value": "author_of"}, {"source": "I. Ok", "target": "An analog-AI chip for energy-efficient speech recognition and transcription", "value": "author_of"}, {"source": "Timothy Philip", "target": "An analog-AI chip for energy-efficient speech recognition and transcription", "value": "author_of"}, {"source": "Victor Chan", "target": "An analog-AI chip for energy-efficient speech recognition and transcription", "value": "author_of"}, {"source": "M. Silvestre", "target": "An analog-AI chip for energy-efficient speech recognition and transcription", "value": "author_of"}, {"source": "Ishtiaq Ahsan", "target": "An analog-AI chip for energy-efficient speech recognition and transcription", "value": "author_of"}, {"source": "Vijay Narayanan", "target": "An analog-AI chip for energy-efficient speech recognition and transcription", "value": "author_of"}, {"source": "H. Tsai", "target": "An analog-AI chip for energy-efficient speech recognition and transcription", "value": "author_of"}, {"source": "Geoffrey W. Burr", "target": "An analog-AI chip for energy-efficient speech recognition and transcription", "value": "author_of"}, {"source": "J. Shin", "target": "A Mathematical Theory of Communication", "value": "author_of"}, {"source": "Sang Joon Kim", "target": "A Mathematical Theory of Communication", "value": "author_of"}, {"source": "Yike Sun", "target": "LiteToken: Removing Intermediate Merge Residues From BPE Tokenizers", "value": "author_of"}, {"source": "Haotong Yang", "target": "LiteToken: Removing Intermediate Merge Residues From BPE Tokenizers", "value": "author_of"}, {"source": "Zhouchen Lin", "target": "LiteToken: Removing Intermediate Merge Residues From BPE Tokenizers", "value": "author_of"}, {"source": "Muhan Zhang", "target": "LiteToken: Removing Intermediate Merge Residues From BPE Tokenizers", "value": "author_of"}, {"source": "Ning Ding", "target": "MeKi: Memory-based Expert Knowledge Injection for Efficient LLM Scaling", "value": "author_of"}, {"source": "Fangcheng Liu", "target": "MeKi: Memory-based Expert Knowledge Injection for Efficient LLM Scaling", "value": "author_of"}, {"source": "Kyungrae Kim", "target": "MeKi: Memory-based Expert Knowledge Injection for Efficient LLM Scaling", "value": "author_of"}, {"source": "Linji Hao", "target": "MeKi: Memory-based Expert Knowledge Injection for Efficient LLM Scaling", "value": "author_of"}, {"source": "Kyeng-Hun Lee", "target": "MeKi: Memory-based Expert Knowledge Injection for Efficient LLM Scaling", "value": "author_of"}, {"source": "Hyeonmok Ko", "target": "MeKi: Memory-based Expert Knowledge Injection for Efficient LLM Scaling", "value": "author_of"}, {"source": "Yehui Tang", "target": "MeKi: Memory-based Expert Knowledge Injection for Efficient LLM Scaling", "value": "author_of"}, {"source": "Huinan Xu", "target": "Beyond Conditional Computation: Retrieval-Augmented Genomic Foundation Models with Gengram", "value": "author_of"}, {"source": "Xuyang Feng", "target": "Beyond Conditional Computation: Retrieval-Augmented Genomic Foundation Models with Gengram", "value": "author_of"}, {"source": "Junhong Chen", "target": "Beyond Conditional Computation: Retrieval-Augmented Genomic Foundation Models with Gengram", "value": "author_of"}, {"source": "Junchen Liu", "target": "Beyond Conditional Computation: Retrieval-Augmented Genomic Foundation Models with Gengram", "value": "author_of"}, {"source": "Kaiwen Deng", "target": "Beyond Conditional Computation: Retrieval-Augmented Genomic Foundation Models with Gengram", "value": "author_of"}, {"source": "Kai Ding", "target": "Beyond Conditional Computation: Retrieval-Augmented Genomic Foundation Models with Gengram", "value": "author_of"}, {"source": "Shengning Long", "target": "Beyond Conditional Computation: Retrieval-Augmented Genomic Foundation Models with Gengram", "value": "author_of"}, {"source": "Jiaxue Shuai", "target": "Beyond Conditional Computation: Retrieval-Augmented Genomic Foundation Models with Gengram", "value": "author_of"}, {"source": "Zhaorong Li", "target": "Beyond Conditional Computation: Retrieval-Augmented Genomic Foundation Models with Gengram", "value": "author_of"}, {"source": "Shiping Liu", "target": "Beyond Conditional Computation: Retrieval-Augmented Genomic Foundation Models with Gengram", "value": "author_of"}, {"source": "Guirong Xue", "target": "Beyond Conditional Computation: Retrieval-Augmented Genomic Foundation Models with Gengram", "value": "author_of"}, {"source": "Zhan Xiao", "target": "Beyond Conditional Computation: Retrieval-Augmented Genomic Foundation Models with Gengram", "value": "author_of"}, {"source": "Albert Tseng", "target": "L$^3$: Large Lookup Layers", "value": "author_of"}, {"source": "Christopher De Sa", "target": "L$^3$: Large Lookup Layers", "value": "author_of"}, {"source": "Hong Liu", "target": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "value": "author_of"}, {"source": "Jiaqi Zhang", "target": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "value": "author_of"}, {"source": "Chao Wang", "target": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "value": "author_of"}, {"source": "Xing Hu", "target": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "value": "author_of"}, {"source": "Linkun Lyu", "target": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "value": "author_of"}, {"source": "Jiaqi Sun", "target": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "value": "author_of"}, {"source": "Xurui Yang", "target": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "value": "author_of"}, {"source": "Bo Wang", "target": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "value": "author_of"}, {"source": "Fengcun Li", "target": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "value": "author_of"}, {"source": "Yulei Qian", "target": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "value": "author_of"}, {"source": "Lingtong Si", "target": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "value": "author_of"}, {"source": "Yerui Sun", "target": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "value": "author_of"}, {"source": "Rumei Li", "target": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "value": "author_of"}, {"source": "Peng Pei", "target": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "value": "author_of"}, {"source": "Yuchen Xie", "target": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "value": "author_of"}, {"source": "Xunliang Cai", "target": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "value": "author_of"}, {"source": "Christian Szegedy", "target": "Going Deeper with Convolutions", "value": "author_of"}, {"source": "Wei Liu", "target": "Going Deeper with Convolutions", "value": "author_of"}, {"source": "Yangqing Jia", "target": "Going Deeper with Convolutions", "value": "author_of"}, {"source": "Pierre Sermanet", "target": "Going Deeper with Convolutions", "value": "author_of"}, {"source": "Scott Reed", "target": "Going Deeper with Convolutions", "value": "author_of"}, {"source": "Dragomir Anguelov", "target": "Going Deeper with Convolutions", "value": "author_of"}, {"source": "Dumitru Erhan", "target": "Going Deeper with Convolutions", "value": "author_of"}, {"source": "Vincent Vanhoucke", "target": "Going Deeper with Convolutions", "value": "author_of"}, {"source": "Andrew Rabinovich", "target": "Going Deeper with Convolutions", "value": "author_of"}, {"source": "Yann LeCun", "target": "Gradient-based learning applied to document recognition", "value": "author_of"}, {"source": "L. Bottou", "target": "Gradient-based learning applied to document recognition", "value": "author_of"}, {"source": "Yoshua Bengio", "target": "Gradient-based learning applied to document recognition", "value": "author_of"}, {"source": "P. Haffner", "target": "Gradient-based learning applied to document recognition", "value": "author_of"}, {"source": "R. Tibshirani", "target": "Regression Shrinkage and Selection via the Lasso", "value": "author_of"}, {"source": "Tsung-Yi Lin", "target": "Microsoft COCO: Common Objects in Context", "value": "author_of"}, {"source": "Michael Maire", "target": "Microsoft COCO: Common Objects in Context", "value": "author_of"}, {"source": "Serge Belongie", "target": "Microsoft COCO: Common Objects in Context", "value": "author_of"}, {"source": "Lubomir Bourdev", "target": "Microsoft COCO: Common Objects in Context", "value": "author_of"}, {"source": "Ross Girshick", "target": "Microsoft COCO: Common Objects in Context", "value": "author_of"}, {"source": "James Hays", "target": "Microsoft COCO: Common Objects in Context", "value": "author_of"}, {"source": "Pietro Perona", "target": "Microsoft COCO: Common Objects in Context", "value": "author_of"}, {"source": "Deva Ramanan", "target": "Microsoft COCO: Common Objects in Context", "value": "author_of"}, {"source": "C. Lawrence Zitnick", "target": "Microsoft COCO: Common Objects in Context", "value": "author_of"}, {"source": "Piotr Doll\u00e1r", "target": "Microsoft COCO: Common Objects in Context", "value": "author_of"}, {"source": "Herve Goeau", "target": "LifeCLEF Plant Identification Task 2015", "value": "author_of"}, {"source": "Pierre Bonnet", "target": "LifeCLEF Plant Identification Task 2015", "value": "author_of"}, {"source": "Alexis Joly", "target": "LifeCLEF Plant Identification Task 2015", "value": "author_of"}, {"source": "Safa Ben Atitallah", "target": "FedMicro-IDA: A Federated Learning and Microservices-based Framework for IoT Data Analytics", "value": "author_of"}, {"source": "Maha Driss", "target": "FedMicro-IDA: A Federated Learning and Microservices-based Framework for IoT Data Analytics", "value": "author_of"}, {"source": "Henda Ben Ghezela", "target": "FedMicro-IDA: A Federated Learning and Microservices-based Framework for IoT Data Analytics", "value": "author_of"}, {"source": "Sareer Ul Amin", "target": "Enhancing pine wilt disease detection with synthetic data and external attention-based transformers", "value": "author_of"}, {"source": "Yonghoon Jung", "target": "Enhancing pine wilt disease detection with synthetic data and external attention-based transformers", "value": "author_of"}, {"source": "Muhammad Fayaz", "target": "Enhancing pine wilt disease detection with synthetic data and external attention-based transformers", "value": "author_of"}, {"source": "Bumsoo Kim", "target": "Enhancing pine wilt disease detection with synthetic data and external attention-based transformers", "value": "author_of"}, {"source": "Sanghyun Seo", "target": "Enhancing pine wilt disease detection with synthetic data and external attention-based transformers", "value": "author_of"}, {"source": "Ay\u015fe Aybilge Murat", "target": "A comprehensive review on YOLO versions for object detection", "value": "author_of"}, {"source": "M. S. K\u0131ran", "target": "A comprehensive review on YOLO versions for object detection", "value": "author_of"}, {"source": "Hongyan Zhu", "target": "Harnessing large vision and language models in agriculture: a review", "value": "author_of"}, {"source": "Shuai Qin", "target": "Harnessing large vision and language models in agriculture: a review", "value": "author_of"}, {"source": "Min Su", "target": "Harnessing large vision and language models in agriculture: a review", "value": "author_of"}, {"source": "Chengzhi Lin", "target": "Harnessing large vision and language models in agriculture: a review", "value": "author_of"}, {"source": "Anjie Li", "target": "Harnessing large vision and language models in agriculture: a review", "value": "author_of"}, {"source": "Junfeng Gao", "target": "Harnessing large vision and language models in agriculture: a review", "value": "author_of"}, {"source": "Abdul Rehman Khan", "target": "Multi-axis vision transformer for medical image segmentation", "value": "author_of"}, {"source": "Asifullah Khan", "target": "Multi-axis vision transformer for medical image segmentation", "value": "author_of"}, {"source": "D. E. Boukhari", "target": "A comprehensive review of facial beauty prediction using deep learning techniques", "value": "author_of"}, {"source": "F. Dornaika", "target": "A comprehensive review of facial beauty prediction using deep learning techniques", "value": "author_of"}, {"source": "A. Chemsa", "target": "A comprehensive review of facial beauty prediction using deep learning techniques", "value": "author_of"}, {"source": "Abdelmalik Taleb-Ahmed", "target": "A comprehensive review of facial beauty prediction using deep learning techniques", "value": "author_of"}, {"source": "Benjamin DeMeo", "target": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes.", "value": "author_of"}, {"source": "Charlotte Nesbitt", "target": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes.", "value": "author_of"}, {"source": "S. A. Miller", "target": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes.", "value": "author_of"}, {"source": "Daniel B. Burkhardt", "target": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes.", "value": "author_of"}, {"source": "Inna Lipchina", "target": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes.", "value": "author_of"}, {"source": "Doris Fu", "target": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes.", "value": "author_of"}, {"source": "Peter Holderreith", "target": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes.", "value": "author_of"}, {"source": "David Kim", "target": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes.", "value": "author_of"}, {"source": "Sergey Kolchenko", "target": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes.", "value": "author_of"}, {"source": "Artur Sza\u0142ata", "target": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes.", "value": "author_of"}, {"source": "Ishan Gupta", "target": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes.", "value": "author_of"}, {"source": "Christine Kerr", "target": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes.", "value": "author_of"}, {"source": "Thomas Pfefer", "target": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes.", "value": "author_of"}, {"source": "Raziel Rojas-Rodriguez", "target": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes.", "value": "author_of"}, {"source": "Sunil Kuppassani", "target": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes.", "value": "author_of"}, {"source": "Laurens Kruidenier", "target": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes.", "value": "author_of"}, {"source": "Parul B Doshi", "target": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes.", "value": "author_of"}, {"source": "Mahdi Zamanighomi", "target": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes.", "value": "author_of"}, {"source": "James J. Collins", "target": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes.", "value": "author_of"}, {"source": "A. Shalek", "target": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes.", "value": "author_of"}, {"source": "F. Theis", "target": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes.", "value": "author_of"}, {"source": "Mauricio Cortes", "target": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes.", "value": "author_of"}, {"source": "D. Lowe", "target": "Distinctive Image Features from Scale-Invariant Keypoints", "value": "author_of"}, {"source": "Xiang An", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "author_of"}, {"source": "Yin Xie", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "author_of"}, {"source": "Kaicheng Yang", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "author_of"}, {"source": "Wenkang Zhang", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "author_of"}, {"source": "Xiuwei Zhao", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "author_of"}, {"source": "Zheng Cheng", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "author_of"}, {"source": "Yirui Wang", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "author_of"}, {"source": "Songcen Xu", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "author_of"}, {"source": "Changrui Chen", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "author_of"}, {"source": "Didi Zhu", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "author_of"}, {"source": "Chunsheng Wu", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "author_of"}, {"source": "Huajie Tan", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "author_of"}, {"source": "Chunyuan Li", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "author_of"}, {"source": "Jing Yang", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "author_of"}, {"source": "Jie Yu", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "author_of"}, {"source": "Xiyao Wang", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "author_of"}, {"source": "Bin Qin", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "author_of"}, {"source": "Yumeng Wang", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "author_of"}, {"source": "Zizhen Yan", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "author_of"}, {"source": "Ziyong Feng", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "author_of"}, {"source": "Ziwei Liu", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "author_of"}, {"source": "Bo Li", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "author_of"}, {"source": "Jiankang Deng", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "author_of"}, {"source": "Kento Kawaharazuka", "target": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "value": "author_of"}, {"source": "Jihoon Oh", "target": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "value": "author_of"}, {"source": "Jun Yamada", "target": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "value": "author_of"}, {"source": "Ingmar Posner", "target": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "value": "author_of"}, {"source": "Yuke Zhu", "target": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "value": "author_of"}, {"source": "Lukas Muttenthaler", "target": "Aligning machine and human visual representations across abstraction levels", "value": "author_of"}, {"source": "Klaus Greff", "target": "Aligning machine and human visual representations across abstraction levels", "value": "author_of"}, {"source": "Frieda Born", "target": "Aligning machine and human visual representations across abstraction levels", "value": "author_of"}, {"source": "Bernhard Spitzer", "target": "Aligning machine and human visual representations across abstraction levels", "value": "author_of"}, {"source": "Simon Kornblith", "target": "Aligning machine and human visual representations across abstraction levels", "value": "author_of"}, {"source": "M. C. Mozer", "target": "Aligning machine and human visual representations across abstraction levels", "value": "author_of"}, {"source": "Klaus-Robert Muller", "target": "Aligning machine and human visual representations across abstraction levels", "value": "author_of"}, {"source": "Thomas Unterthiner", "target": "Aligning machine and human visual representations across abstraction levels", "value": "author_of"}, {"source": "Andrew Kyle Lampinen", "target": "Aligning machine and human visual representations across abstraction levels", "value": "author_of"}, {"source": "Alexey Dosovitskiy", "target": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "value": "author_of"}, {"source": "Lucas Beyer", "target": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "value": "author_of"}, {"source": "Alexander Kolesnikov", "target": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "value": "author_of"}, {"source": "Dirk Weissenborn", "target": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "value": "author_of"}, {"source": "Xiaohua Zhai", "target": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "value": "author_of"}, {"source": "Thomas Unterthiner", "target": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "value": "author_of"}, {"source": "Mostafa Dehghani", "target": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "value": "author_of"}, {"source": "Matthias Minderer", "target": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "value": "author_of"}, {"source": "Georg Heigold", "target": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "value": "author_of"}, {"source": "Sylvain Gelly", "target": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "value": "author_of"}, {"source": "Jakob Uszkoreit", "target": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "value": "author_of"}, {"source": "Neil Houlsby", "target": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "value": "author_of"}, {"source": "Alec Radford", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "author_of"}, {"source": "Jong Wook Kim", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "author_of"}, {"source": "Chris Hallacy", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "author_of"}, {"source": "Aditya Ramesh", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "author_of"}, {"source": "Gabriel Goh", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "author_of"}, {"source": "Sandhini Agarwal", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "author_of"}, {"source": "Girish Sastry", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "author_of"}, {"source": "Amanda Askell", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "author_of"}, {"source": "Pamela Mishkin", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "author_of"}, {"source": "Jack Clark", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "author_of"}, {"source": "Gretchen Krueger", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "author_of"}, {"source": "Ilya Sutskever", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "author_of"}, {"source": "Individualized Treat", "target": "GENERATIVE ADVERSARIAL NETS", "value": "author_of"}, {"source": "Jinsung Yoon", "target": "GENERATIVE ADVERSARIAL NETS", "value": "author_of"}, {"source": "Zhengyang Geng", "target": "Improved Mean Flows: On the Challenges of Fastforward Generative Models", "value": "author_of"}, {"source": "Yiyang Lu", "target": "Improved Mean Flows: On the Challenges of Fastforward Generative Models", "value": "author_of"}, {"source": "Zongze Wu", "target": "Improved Mean Flows: On the Challenges of Fastforward Generative Models", "value": "author_of"}, {"source": "Eli Shechtman", "target": "Improved Mean Flows: On the Challenges of Fastforward Generative Models", "value": "author_of"}, {"source": "J. Zico Kolter", "target": "Improved Mean Flows: On the Challenges of Fastforward Generative Models", "value": "author_of"}, {"source": "Kaiming He", "target": "Improved Mean Flows: On the Challenges of Fastforward Generative Models", "value": "author_of"}, {"source": "Jiachen Lei", "target": "There is No VAE: End-to-End Pixel-Space Generative Modeling via Self-Supervised Pre-training", "value": "author_of"}, {"source": "Keli Liu", "target": "There is No VAE: End-to-End Pixel-Space Generative Modeling via Self-Supervised Pre-training", "value": "author_of"}, {"source": "Julius Berner", "target": "There is No VAE: End-to-End Pixel-Space Generative Modeling via Self-Supervised Pre-training", "value": "author_of"}, {"source": "Haiming Yu", "target": "There is No VAE: End-to-End Pixel-Space Generative Modeling via Self-Supervised Pre-training", "value": "author_of"}, {"source": "Hongkai Zheng", "target": "There is No VAE: End-to-End Pixel-Space Generative Modeling via Self-Supervised Pre-training", "value": "author_of"}, {"source": "Jiahong Wu", "target": "There is No VAE: End-to-End Pixel-Space Generative Modeling via Self-Supervised Pre-training", "value": "author_of"}, {"source": "Xiangxiang Chu", "target": "There is No VAE: End-to-End Pixel-Space Generative Modeling via Self-Supervised Pre-training", "value": "author_of"}, {"source": "Minglei Shi", "target": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "value": "author_of"}, {"source": "Haolin Wang", "target": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "value": "author_of"}, {"source": "Borui Zhang", "target": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "value": "author_of"}, {"source": "Wenzhao Zheng", "target": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "value": "author_of"}, {"source": "Bohan Zeng", "target": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "value": "author_of"}, {"source": "Ziyang Yuan", "target": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "value": "author_of"}, {"source": "Xiaoshi Wu", "target": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "value": "author_of"}, {"source": "Yuanxing Zhang", "target": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "value": "author_of"}, {"source": "Huan Yang", "target": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "value": "author_of"}, {"source": "Xintao Wang", "target": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "value": "author_of"}, {"source": "Pengfei Wan", "target": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "value": "author_of"}, {"source": "Kun Gai", "target": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "value": "author_of"}, {"source": "Jie Zhou", "target": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "value": "author_of"}, {"source": "Jiwen Lu", "target": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "value": "author_of"}, {"source": "Yongsheng Yu", "target": "PixelDiT: Pixel Diffusion Transformers for Image Generation", "value": "author_of"}, {"source": "Wei Xiong", "target": "PixelDiT: Pixel Diffusion Transformers for Image Generation", "value": "author_of"}, {"source": "Weili Nie", "target": "PixelDiT: Pixel Diffusion Transformers for Image Generation", "value": "author_of"}, {"source": "Yichen Sheng", "target": "PixelDiT: Pixel Diffusion Transformers for Image Generation", "value": "author_of"}, {"source": "Shiqiu Liu", "target": "PixelDiT: Pixel Diffusion Transformers for Image Generation", "value": "author_of"}, {"source": "Jiebo Luo", "target": "PixelDiT: Pixel Diffusion Transformers for Image Generation", "value": "author_of"}, {"source": "Zhiheng Liu", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "author_of"}, {"source": "Weiming Ren", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "author_of"}, {"source": "Haozhe Liu", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "author_of"}, {"source": "Zijian Zhou", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "author_of"}, {"source": "Shoufa Chen", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "author_of"}, {"source": "Haonan Qiu", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "author_of"}, {"source": "Xiaoke Huang", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "author_of"}, {"source": "Zhaochong An", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "author_of"}, {"source": "Fanny Yang", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "author_of"}, {"source": "Aditya Patel", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "author_of"}, {"source": "Viktar Atliha", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "author_of"}, {"source": "Tony Ng", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "author_of"}, {"source": "Xiao Han", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "author_of"}, {"source": "Chuyan Zhu", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "author_of"}, {"source": "Chenyang Zhang", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "author_of"}, {"source": "Ding Liu", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "author_of"}, {"source": "Juan-Manuel Perez-Rua", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "author_of"}, {"source": "Sen He", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "author_of"}, {"source": "J\u00fcrgen Schmidhuber", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "author_of"}, {"source": "Wenhu Chen", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "author_of"}, {"source": "Ping Luo", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "author_of"}, {"source": "Wei Liu", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "author_of"}, {"source": "Tao Xiang", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "author_of"}, {"source": "Jonas Schult", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "author_of"}, {"source": "Yuren Cong", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "author_of"}, {"source": "Jacob Devlin", "target": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "value": "author_of"}, {"source": "Ming-Wei Chang", "target": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "value": "author_of"}, {"source": "Kenton Lee", "target": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "value": "author_of"}, {"source": "Kristina Toutanova", "target": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "value": "author_of"}, {"source": "Vrushali Pagire", "target": "A comprehensive review of object detection with traditional and deep learning methods", "value": "author_of"}, {"source": "M. Chavali", "target": "A comprehensive review of object detection with traditional and deep learning methods", "value": "author_of"}, {"source": "Ashish Kale", "target": "A comprehensive review of object detection with traditional and deep learning methods", "value": "author_of"}, {"source": "Jinjie Ni", "target": "Diffusion Language Models are Super Data Learners", "value": "author_of"}, {"source": "Qian Liu", "target": "Diffusion Language Models are Super Data Learners", "value": "author_of"}, {"source": "Longxu Dou", "target": "Diffusion Language Models are Super Data Learners", "value": "author_of"}, {"source": "Chao Du", "target": "Diffusion Language Models are Super Data Learners", "value": "author_of"}, {"source": "Zili Wang", "target": "Diffusion Language Models are Super Data Learners", "value": "author_of"}, {"source": "Hang Yan", "target": "Diffusion Language Models are Super Data Learners", "value": "author_of"}, {"source": "Tianyu Pang", "target": "Diffusion Language Models are Super Data Learners", "value": "author_of"}, {"source": "Michael Qizhe Shieh", "target": "Diffusion Language Models are Super Data Learners", "value": "author_of"}, {"source": "Zirui Wu", "target": "DreamOn: Diffusion Language Models For Code Infilling Beyond Fixed-size Canvas", "value": "author_of"}, {"source": "Lin Zheng", "target": "DreamOn: Diffusion Language Models For Code Infilling Beyond Fixed-size Canvas", "value": "author_of"}, {"source": "Zhihui Xie", "target": "DreamOn: Diffusion Language Models For Code Infilling Beyond Fixed-size Canvas", "value": "author_of"}, {"source": "Jiacheng Ye", "target": "DreamOn: Diffusion Language Models For Code Infilling Beyond Fixed-size Canvas", "value": "author_of"}, {"source": "Jiahui Gao", "target": "DreamOn: Diffusion Language Models For Code Infilling Beyond Fixed-size Canvas", "value": "author_of"}, {"source": "Shansan Gong", "target": "DreamOn: Diffusion Language Models For Code Infilling Beyond Fixed-size Canvas", "value": "author_of"}, {"source": "Yansong Feng", "target": "DreamOn: Diffusion Language Models For Code Infilling Beyond Fixed-size Canvas", "value": "author_of"}, {"source": "Zhenguo Li", "target": "DreamOn: Diffusion Language Models For Code Infilling Beyond Fixed-size Canvas", "value": "author_of"}, {"source": "Wei Bi", "target": "DreamOn: Diffusion Language Models For Code Infilling Beyond Fixed-size Canvas", "value": "author_of"}, {"source": "Guorui Zhou", "target": "DreamOn: Diffusion Language Models For Code Infilling Beyond Fixed-size Canvas", "value": "author_of"}, {"source": "Lingpeng Kong", "target": "DreamOn: Diffusion Language Models For Code Infilling Beyond Fixed-size Canvas", "value": "author_of"}, {"source": "Zhicheng Cai", "target": "FLEX: Continuous Agent Evolution via Forward Learning from Experience", "value": "author_of"}, {"source": "Xinyuan Guo", "target": "FLEX: Continuous Agent Evolution via Forward Learning from Experience", "value": "author_of"}, {"source": "Yu Pei", "target": "FLEX: Continuous Agent Evolution via Forward Learning from Experience", "value": "author_of"}, {"source": "Jiangtao Feng", "target": "FLEX: Continuous Agent Evolution via Forward Learning from Experience", "value": "author_of"}, {"source": "Jinsong Su", "target": "FLEX: Continuous Agent Evolution via Forward Learning from Experience", "value": "author_of"}, {"source": "Jiangjie Chen", "target": "FLEX: Continuous Agent Evolution via Forward Learning from Experience", "value": "author_of"}, {"source": "Ya-Qin Zhang", "target": "FLEX: Continuous Agent Evolution via Forward Learning from Experience", "value": "author_of"}, {"source": "Wei-Ying Ma", "target": "FLEX: Continuous Agent Evolution via Forward Learning from Experience", "value": "author_of"}, {"source": "Mingxuan Wang", "target": "FLEX: Continuous Agent Evolution via Forward Learning from Experience", "value": "author_of"}, {"source": "Hao Zhou", "target": "FLEX: Continuous Agent Evolution via Forward Learning from Experience", "value": "author_of"}, {"source": "Mingyue Cheng", "target": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "value": "author_of"}, {"source": "Jie Ouyang", "target": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "value": "author_of"}, {"source": "Shuo Yu", "target": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "value": "author_of"}, {"source": "Ruiran Yan", "target": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "value": "author_of"}, {"source": "Yucong Luo", "target": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "value": "author_of"}, {"source": "Zirui Liu", "target": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "value": "author_of"}, {"source": "Daoyu Wang", "target": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "value": "author_of"}, {"source": "Qi Liu", "target": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "value": "author_of"}, {"source": "Enhong Chen", "target": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "value": "author_of"}, {"source": "Holger Caesar", "target": "nuScenes: A multimodal dataset for autonomous driving", "value": "author_of"}, {"source": "Varun Bankiti", "target": "nuScenes: A multimodal dataset for autonomous driving", "value": "author_of"}, {"source": "Alex H. Lang", "target": "nuScenes: A multimodal dataset for autonomous driving", "value": "author_of"}, {"source": "Sourabh Vora", "target": "nuScenes: A multimodal dataset for autonomous driving", "value": "author_of"}, {"source": "Venice Erin Liong", "target": "nuScenes: A multimodal dataset for autonomous driving", "value": "author_of"}, {"source": "Qiang Xu", "target": "nuScenes: A multimodal dataset for autonomous driving", "value": "author_of"}, {"source": "Anush Krishnan", "target": "nuScenes: A multimodal dataset for autonomous driving", "value": "author_of"}, {"source": "Yu Pan", "target": "nuScenes: A multimodal dataset for autonomous driving", "value": "author_of"}, {"source": "Giancarlo Baldan", "target": "nuScenes: A multimodal dataset for autonomous driving", "value": "author_of"}, {"source": "Oscar Beijbom", "target": "nuScenes: A multimodal dataset for autonomous driving", "value": "author_of"}, {"source": "Jie Hu", "target": "Squeeze-and-Excitation Networks", "value": "author_of"}, {"source": "Li Shen", "target": "Squeeze-and-Excitation Networks", "value": "author_of"}, {"source": "Samuel Albanie", "target": "Squeeze-and-Excitation Networks", "value": "author_of"}, {"source": "Gang Sun", "target": "Squeeze-and-Excitation Networks", "value": "author_of"}, {"source": "Enhua Wu", "target": "Squeeze-and-Excitation Networks", "value": "author_of"}, {"source": "I. Loshchilov", "target": "Decoupled Weight Decay Regularization", "value": "author_of"}, {"source": "F. Hutter", "target": "Decoupled Weight Decay Regularization", "value": "author_of"}, {"source": "Mingxing Tan", "target": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks", "value": "author_of"}, {"source": "Quoc V. Le", "target": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks", "value": "author_of"}, {"source": "Tianqi Liu", "target": "Light-X: Generative 4D Video Rendering with Camera and Illumination Control", "value": "author_of"}, {"source": "Zhaoxi Chen", "target": "Light-X: Generative 4D Video Rendering with Camera and Illumination Control", "value": "author_of"}, {"source": "Zihao Huang", "target": "Light-X: Generative 4D Video Rendering with Camera and Illumination Control", "value": "author_of"}, {"source": "Shaocong Xu", "target": "Light-X: Generative 4D Video Rendering with Camera and Illumination Control", "value": "author_of"}, {"source": "Saining Zhang", "target": "Light-X: Generative 4D Video Rendering with Camera and Illumination Control", "value": "author_of"}, {"source": "Chongjie Ye", "target": "Light-X: Generative 4D Video Rendering with Camera and Illumination Control", "value": "author_of"}, {"source": "Bohan Li", "target": "Light-X: Generative 4D Video Rendering with Camera and Illumination Control", "value": "author_of"}, {"source": "Zhiguo Cao", "target": "Light-X: Generative 4D Video Rendering with Camera and Illumination Control", "value": "author_of"}, {"source": "Wei Li", "target": "Light-X: Generative 4D Video Rendering with Camera and Illumination Control", "value": "author_of"}, {"source": "Hao Zhao", "target": "Light-X: Generative 4D Video Rendering with Camera and Illumination Control", "value": "author_of"}, {"source": "Ziwei Liu", "target": "Light-X: Generative 4D Video Rendering with Camera and Illumination Control", "value": "author_of"}, {"source": "Tianze Xia", "target": "DriveLaW:Unifying Planning and Video Generation in a Latent Driving World", "value": "author_of"}, {"source": "Yongkang Li", "target": "DriveLaW:Unifying Planning and Video Generation in a Latent Driving World", "value": "author_of"}, {"source": "Lijun Zhou", "target": "DriveLaW:Unifying Planning and Video Generation in a Latent Driving World", "value": "author_of"}, {"source": "Jingfeng Yao", "target": "DriveLaW:Unifying Planning and Video Generation in a Latent Driving World", "value": "author_of"}, {"source": "Kaixin Xiong", "target": "DriveLaW:Unifying Planning and Video Generation in a Latent Driving World", "value": "author_of"}, {"source": "Haiyang Sun", "target": "DriveLaW:Unifying Planning and Video Generation in a Latent Driving World", "value": "author_of"}, {"source": "Bing Wang", "target": "DriveLaW:Unifying Planning and Video Generation in a Latent Driving World", "value": "author_of"}, {"source": "Kun Ma", "target": "DriveLaW:Unifying Planning and Video Generation in a Latent Driving World", "value": "author_of"}, {"source": "Guang Chen", "target": "DriveLaW:Unifying Planning and Video Generation in a Latent Driving World", "value": "author_of"}, {"source": "Hangjun Ye", "target": "DriveLaW:Unifying Planning and Video Generation in a Latent Driving World", "value": "author_of"}, {"source": "Wenyu Liu", "target": "DriveLaW:Unifying Planning and Video Generation in a Latent Driving World", "value": "author_of"}, {"source": "Xinggang Wang", "target": "DriveLaW:Unifying Planning and Video Generation in a Latent Driving World", "value": "author_of"}, {"source": "Sicheng Zuo", "target": "DVGT: Driving Visual Geometry Transformer", "value": "author_of"}, {"source": "Zixun Xie", "target": "DVGT: Driving Visual Geometry Transformer", "value": "author_of"}, {"source": "Wenzhao Zheng", "target": "DVGT: Driving Visual Geometry Transformer", "value": "author_of"}, {"source": "Shaoqing Xu", "target": "DVGT: Driving Visual Geometry Transformer", "value": "author_of"}, {"source": "Fang Li", "target": "DVGT: Driving Visual Geometry Transformer", "value": "author_of"}, {"source": "Shengyin Jiang", "target": "DVGT: Driving Visual Geometry Transformer", "value": "author_of"}, {"source": "Long Chen", "target": "DVGT: Driving Visual Geometry Transformer", "value": "author_of"}, {"source": "Zhi-Xin Yang", "target": "DVGT: Driving Visual Geometry Transformer", "value": "author_of"}, {"source": "Jiwen Lu", "target": "DVGT: Driving Visual Geometry Transformer", "value": "author_of"}, {"source": "Lvmin Zhang", "target": "Adding Conditional Control to Text-to-Image Diffusion Models", "value": "author_of"}, {"source": "Anyi Rao", "target": "Adding Conditional Control to Text-to-Image Diffusion Models", "value": "author_of"}, {"source": "Maneesh Agrawala", "target": "Adding Conditional Control to Text-to-Image Diffusion Models", "value": "author_of"}, {"source": "Hyung Won Chung", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Le Hou", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Shayne Longpre", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Barret Zoph", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Yi Tay", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "William Fedus", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Yunxuan Li", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Xuezhi Wang", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Mostafa Dehghani", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Siddhartha Brahma", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Albert Webson", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Shixiang Shane Gu", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Zhuyun Dai", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Mirac Suzgun", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Xinyun Chen", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Aakanksha Chowdhery", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Alex Castro-Ros", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Marie Pellat", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Kevin Robinson", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Dasha Valter", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Sharan Narang", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Gaurav Mishra", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Adams Yu", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Vincent Zhao", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Yanping Huang", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Andrew Dai", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Hongkun Yu", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Slav Petrov", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Ed H. Chi", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Jeff Dean", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Jacob Devlin", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Adam Roberts", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Denny Zhou", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Quoc V. Le", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Jason Wei", "target": "Scaling Instruction-Finetuned Language Models", "value": "author_of"}, {"source": "Robin Rombach", "target": "High-Resolution Image Synthesis with Latent Diffusion Models", "value": "author_of"}, {"source": "Andreas Blattmann", "target": "High-Resolution Image Synthesis with Latent Diffusion Models", "value": "author_of"}, {"source": "Dominik Lorenz", "target": "High-Resolution Image Synthesis with Latent Diffusion Models", "value": "author_of"}, {"source": "Patrick Esser", "target": "High-Resolution Image Synthesis with Latent Diffusion Models", "value": "author_of"}, {"source": "Bj\u00f6rn Ommer", "target": "High-Resolution Image Synthesis with Latent Diffusion Models", "value": "author_of"}, {"source": "Romain Lopez", "target": "AUTO-ENCODING VARIATIONAL BAYES", "value": "author_of"}, {"source": "Pierre Boyeau", "target": "AUTO-ENCODING VARIATIONAL BAYES", "value": "author_of"}, {"source": "N. Yosef", "target": "AUTO-ENCODING VARIATIONAL BAYES", "value": "author_of"}, {"source": "Michael I. Jordan", "target": "AUTO-ENCODING VARIATIONAL BAYES", "value": "author_of"}, {"source": "J. Regier", "target": "AUTO-ENCODING VARIATIONAL BAYES", "value": "author_of"}, {"source": "Richard Zhang", "target": "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric", "value": "author_of"}, {"source": "Phillip Isola", "target": "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric", "value": "author_of"}, {"source": "Alexei A. Efros", "target": "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric", "value": "author_of"}, {"source": "Eli Shechtman", "target": "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric", "value": "author_of"}, {"source": "Oliver Wang", "target": "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric", "value": "author_of"}, {"source": "Pei Sun", "target": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "value": "author_of"}, {"source": "Henrik Kretzschmar", "target": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "value": "author_of"}, {"source": "Xerxes Dotiwalla", "target": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "value": "author_of"}, {"source": "Aurelien Chouard", "target": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "value": "author_of"}, {"source": "Vijaysai Patnaik", "target": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "value": "author_of"}, {"source": "Paul Tsui", "target": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "value": "author_of"}, {"source": "James Guo", "target": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "value": "author_of"}, {"source": "Yin Zhou", "target": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "value": "author_of"}, {"source": "Yuning Chai", "target": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "value": "author_of"}, {"source": "Benjamin Caine", "target": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "value": "author_of"}, {"source": "Vijay Vasudevan", "target": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "value": "author_of"}, {"source": "Wei Han", "target": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "value": "author_of"}, {"source": "Jiquan Ngiam", "target": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "value": "author_of"}, {"source": "Hang Zhao", "target": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "value": "author_of"}, {"source": "Aleksei Timofeev", "target": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "value": "author_of"}, {"source": "Scott Ettinger", "target": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "value": "author_of"}, {"source": "Maxim Krivokon", "target": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "value": "author_of"}, {"source": "Amy Gao", "target": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "value": "author_of"}, {"source": "Aditya Joshi", "target": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "value": "author_of"}, {"source": "Sheng Zhao", "target": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "value": "author_of"}, {"source": "Shuyang Cheng", "target": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "value": "author_of"}, {"source": "Yu Zhang", "target": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "value": "author_of"}, {"source": "Jonathon Shlens", "target": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "value": "author_of"}, {"source": "Zhifeng Chen", "target": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "value": "author_of"}, {"source": "Dragomir Anguelov", "target": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "value": "author_of"}, {"source": "Navneet Dalal", "target": "Histograms of oriented gradients for human detection", "value": "author_of"}, {"source": "B. Triggs", "target": "Histograms of oriented gradients for human detection", "value": "author_of"}, {"source": "Gilad Cohen", "target": "Generative Adversarial Networks", "value": "author_of"}, {"source": "Raja Giryes", "target": "Generative Adversarial Networks", "value": "author_of"}, {"source": "Zekai Zhang", "target": "Generalization of Diffusion Models Arises with a Balanced Representation Space", "value": "author_of"}, {"source": "Xiao Li", "target": "Generalization of Diffusion Models Arises with a Balanced Representation Space", "value": "author_of"}, {"source": "Xiang Li", "target": "Generalization of Diffusion Models Arises with a Balanced Representation Space", "value": "author_of"}, {"source": "Lianghe Shi", "target": "Generalization of Diffusion Models Arises with a Balanced Representation Space", "value": "author_of"}, {"source": "Meng Wu", "target": "Generalization of Diffusion Models Arises with a Balanced Representation Space", "value": "author_of"}, {"source": "Molei Tao", "target": "Generalization of Diffusion Models Arises with a Balanced Representation Space", "value": "author_of"}, {"source": "Qing Qu", "target": "Generalization of Diffusion Models Arises with a Balanced Representation Space", "value": "author_of"}, {"source": "Donglin Yang", "target": "Stable Velocity: A Variance Perspective on Flow Matching", "value": "author_of"}, {"source": "Yongxing Zhang", "target": "Stable Velocity: A Variance Perspective on Flow Matching", "value": "author_of"}, {"source": "Xin Yu", "target": "Stable Velocity: A Variance Perspective on Flow Matching", "value": "author_of"}, {"source": "Liang Hou", "target": "Stable Velocity: A Variance Perspective on Flow Matching", "value": "author_of"}, {"source": "Xin Tao", "target": "Stable Velocity: A Variance Perspective on Flow Matching", "value": "author_of"}, {"source": "Pengfei Wan", "target": "Stable Velocity: A Variance Perspective on Flow Matching", "value": "author_of"}, {"source": "Xiaojuan Qi", "target": "Stable Velocity: A Variance Perspective on Flow Matching", "value": "author_of"}, {"source": "Renjie Liao", "target": "Stable Velocity: A Variance Perspective on Flow Matching", "value": "author_of"}, {"source": "Ram\u00f3n Calvo-Gonz\u00e1lez", "target": "Laminating Representation Autoencoders for Efficient Diffusion", "value": "author_of"}, {"source": "Fran\u00e7ois Fleuret", "target": "Laminating Representation Autoencoders for Efficient Diffusion", "value": "author_of"}, {"source": "Yao Teng", "target": "Adaptive 1D Video Diffusion Autoencoder", "value": "author_of"}, {"source": "Minxuan Lin", "target": "Adaptive 1D Video Diffusion Autoencoder", "value": "author_of"}, {"source": "Xian Liu", "target": "Adaptive 1D Video Diffusion Autoencoder", "value": "author_of"}, {"source": "Shuai Wang", "target": "Adaptive 1D Video Diffusion Autoencoder", "value": "author_of"}, {"source": "Xiao Yang", "target": "Adaptive 1D Video Diffusion Autoencoder", "value": "author_of"}, {"source": "Xihui Liu", "target": "Adaptive 1D Video Diffusion Autoencoder", "value": "author_of"}, {"source": "Nicolas Sereyjol-Garros", "target": "Test-Time Conditioning with Representation-Aligned Visual Features", "value": "author_of"}, {"source": "Ellington Kirby", "target": "Test-Time Conditioning with Representation-Aligned Visual Features", "value": "author_of"}, {"source": "Victor Letzelter", "target": "Test-Time Conditioning with Representation-Aligned Visual Features", "value": "author_of"}, {"source": "Victor Besnier", "target": "Test-Time Conditioning with Representation-Aligned Visual Features", "value": "author_of"}, {"source": "Nermin Samet", "target": "Test-Time Conditioning with Representation-Aligned Visual Features", "value": "author_of"}, {"source": "Ana Davila", "target": "Bio-inspired fine-tuning for selective transfer learning in image classification", "value": "author_of"}, {"source": "Jacinto Colan", "target": "Bio-inspired fine-tuning for selective transfer learning in image classification", "value": "author_of"}, {"source": "Yasuhisa Hasegawa", "target": "Bio-inspired fine-tuning for selective transfer learning in image classification", "value": "author_of"}, {"source": "Subham Sharma", "target": "VGG Induced Deep Hand Sign Language Detection", "value": "author_of"}, {"source": "Sharmila Subudhi", "target": "VGG Induced Deep Hand Sign Language Detection", "value": "author_of"}, {"source": "Camillo Lugaresi", "target": "MediaPipe: A Framework for Building Perception Pipelines", "value": "author_of"}, {"source": "Jiuqiang Tang", "target": "MediaPipe: A Framework for Building Perception Pipelines", "value": "author_of"}, {"source": "Hadon Nash", "target": "MediaPipe: A Framework for Building Perception Pipelines", "value": "author_of"}, {"source": "Chris McClanahan", "target": "MediaPipe: A Framework for Building Perception Pipelines", "value": "author_of"}, {"source": "Esha Uboweja", "target": "MediaPipe: A Framework for Building Perception Pipelines", "value": "author_of"}, {"source": "Michael Hays", "target": "MediaPipe: A Framework for Building Perception Pipelines", "value": "author_of"}, {"source": "Fan Zhang", "target": "MediaPipe: A Framework for Building Perception Pipelines", "value": "author_of"}, {"source": "Chuo-Ling Chang", "target": "MediaPipe: A Framework for Building Perception Pipelines", "value": "author_of"}, {"source": "Ming Guang Yong", "target": "MediaPipe: A Framework for Building Perception Pipelines", "value": "author_of"}, {"source": "Juhyun Lee", "target": "MediaPipe: A Framework for Building Perception Pipelines", "value": "author_of"}, {"source": "Wan-Teh Chang", "target": "MediaPipe: A Framework for Building Perception Pipelines", "value": "author_of"}, {"source": "Wei Hua", "target": "MediaPipe: A Framework for Building Perception Pipelines", "value": "author_of"}, {"source": "Manfred Georg", "target": "MediaPipe: A Framework for Building Perception Pipelines", "value": "author_of"}, {"source": "Matthias Grundmann", "target": "MediaPipe: A Framework for Building Perception Pipelines", "value": "author_of"}, {"source": "Cem Keskin", "target": "Hand Pose Estimation and Hand Shape Classification Using Multi-layered Randomized Decision Forests", "value": "author_of"}, {"source": "Mustafa Furkan K\u0131ra\u00e7", "target": "Hand Pose Estimation and Hand Shape Classification Using Multi-layered Randomized Decision Forests", "value": "author_of"}, {"source": "Yunus Emre Kara", "target": "Hand Pose Estimation and Hand Shape Classification Using Multi-layered Randomized Decision Forests", "value": "author_of"}, {"source": "L. Akarun", "target": "Hand Pose Estimation and Hand Shape Classification Using Multi-layered Randomized Decision Forests", "value": "author_of"}, {"source": "S. P. Priyal", "target": "A robust static hand gesture recognition system using geometry based normalizations and Krawtchouk moments", "value": "author_of"}, {"source": "P. Bora", "target": "A robust static hand gesture recognition system using geometry based normalizations and Krawtchouk moments", "value": "author_of"}, {"source": "Octavian Dudas", "target": "Hand signal classification system for sign language communication in Virtual Reality", "value": "author_of"}, {"source": "C. Nandra", "target": "Hand signal classification system for sign language communication in Virtual Reality", "value": "author_of"}, {"source": "C. Mocan", "target": "Hand signal classification system for sign language communication in Virtual Reality", "value": "author_of"}, {"source": "D. Gorgan", "target": "Hand signal classification system for sign language communication in Virtual Reality", "value": "author_of"}, {"source": "Avinash Dhiran", "target": "Real-Time Static Hand Sign Recognition System using MediaPipe and Fully Connected Neural Network", "value": "author_of"}, {"source": "Anurag Kumbhare", "target": "Real-Time Static Hand Sign Recognition System using MediaPipe and Fully Connected Neural Network", "value": "author_of"}, {"source": "Achal Patil", "target": "Real-Time Static Hand Sign Recognition System using MediaPipe and Fully Connected Neural Network", "value": "author_of"}, {"source": "Mrugank Vichare", "target": "Real-Time Static Hand Sign Recognition System using MediaPipe and Fully Connected Neural Network", "value": "author_of"}, {"source": "Dhananjay Patel", "target": "Real-Time Static Hand Sign Recognition System using MediaPipe and Fully Connected Neural Network", "value": "author_of"}, {"source": "Saransh Mishra", "target": "Real-Time Gesture Recognition to Aid Communication in Children with Motor Impairments", "value": "author_of"}, {"source": "Pavan Nair", "target": "Real-Time Gesture Recognition to Aid Communication in Children with Motor Impairments", "value": "author_of"}, {"source": "Pushpalatha M", "target": "Real-Time Gesture Recognition to Aid Communication in Children with Motor Impairments", "value": "author_of"}, {"source": "Poornima S", "target": "Real-Time Gesture Recognition to Aid Communication in Children with Motor Impairments", "value": "author_of"}, {"source": "A. Dempster", "target": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper", "value": "author_of"}, {"source": "N. Laird", "target": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper", "value": "author_of"}, {"source": "D. Rubin", "target": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper", "value": "author_of"}, {"source": "L. Maaten", "target": "Visualizing Data using t-SNE", "value": "author_of"}, {"source": "Geoffrey E. Hinton", "target": "Visualizing Data using t-SNE", "value": "author_of"}, {"source": "A. Krizhevsky", "target": "Learning Multiple Layers of Features from Tiny Images", "value": "author_of"}, {"source": "Jacy Reese Anthis", "target": "LLM Social Simulations Are a Promising Research Method", "value": "author_of"}, {"source": "Ryan Liu", "target": "LLM Social Simulations Are a Promising Research Method", "value": "author_of"}, {"source": "Sean M. Richardson", "target": "LLM Social Simulations Are a Promising Research Method", "value": "author_of"}, {"source": "Austin C. Kozlowski", "target": "LLM Social Simulations Are a Promising Research Method", "value": "author_of"}, {"source": "Bernard Koch", "target": "LLM Social Simulations Are a Promising Research Method", "value": "author_of"}, {"source": "James Evans", "target": "LLM Social Simulations Are a Promising Research Method", "value": "author_of"}, {"source": "Erik Brynjolfsson", "target": "LLM Social Simulations Are a Promising Research Method", "value": "author_of"}, {"source": "Michael Bernstein", "target": "LLM Social Simulations Are a Promising Research Method", "value": "author_of"}, {"source": "Zhiwen Xiao", "target": "Federated Contrastive Learning With Feature-Based Distillation for Human Activity Recognition", "value": "author_of"}, {"source": "Huagang Tong", "target": "Federated Contrastive Learning With Feature-Based Distillation for Human Activity Recognition", "value": "author_of"}, {"source": "Runqian Wang", "target": "Diffuse and Disperse: Image Generation with Representation Regularization", "value": "author_of"}, {"source": "Kaiming He", "target": "Diffuse and Disperse: Image Generation with Representation Regularization", "value": "author_of"}, {"source": "Ibomoiye Domor Mienye", "target": "Deep Autoencoder Neural Networks: A Comprehensive Review and New Perspectives", "value": "author_of"}, {"source": "Theo G. Swart", "target": "Deep Autoencoder Neural Networks: A Comprehensive Review and New Perspectives", "value": "author_of"}, {"source": "Jusheng Zhang", "target": "KABB: Knowledge-Aware Bayesian Bandits for Dynamic Expert Coordination in Multi-Agent Systems", "value": "author_of"}, {"source": "Zimeng Huang", "target": "KABB: Knowledge-Aware Bayesian Bandits for Dynamic Expert Coordination in Multi-Agent Systems", "value": "author_of"}, {"source": "Yijia Fan", "target": "KABB: Knowledge-Aware Bayesian Bandits for Dynamic Expert Coordination in Multi-Agent Systems", "value": "author_of"}, {"source": "Ningyuan Liu", "target": "KABB: Knowledge-Aware Bayesian Bandits for Dynamic Expert Coordination in Multi-Agent Systems", "value": "author_of"}, {"source": "Mingyan Li", "target": "KABB: Knowledge-Aware Bayesian Bandits for Dynamic Expert Coordination in Multi-Agent Systems", "value": "author_of"}, {"source": "Zhuojie Yang", "target": "KABB: Knowledge-Aware Bayesian Bandits for Dynamic Expert Coordination in Multi-Agent Systems", "value": "author_of"}, {"source": "Jiawei Yao", "target": "KABB: Knowledge-Aware Bayesian Bandits for Dynamic Expert Coordination in Multi-Agent Systems", "value": "author_of"}, {"source": "Jian Wang", "target": "KABB: Knowledge-Aware Bayesian Bandits for Dynamic Expert Coordination in Multi-Agent Systems", "value": "author_of"}, {"source": "Keze Wang", "target": "KABB: Knowledge-Aware Bayesian Bandits for Dynamic Expert Coordination in Multi-Agent Systems", "value": "author_of"}, {"source": "Olaf Ronneberger", "target": "U-Net: Convolutional Networks for Biomedical Image Segmentation", "value": "author_of"}, {"source": "Philipp Fischer", "target": "U-Net: Convolutional Networks for Biomedical Image Segmentation", "value": "author_of"}, {"source": "Thomas Brox", "target": "U-Net: Convolutional Networks for Biomedical Image Segmentation", "value": "author_of"}, {"source": "Tianwei Yin", "target": "Improved Distribution Matching Distillation for Fast Image Synthesis", "value": "author_of"}, {"source": "Micha\u00ebl Gharbi", "target": "Improved Distribution Matching Distillation for Fast Image Synthesis", "value": "author_of"}, {"source": "Taesung Park", "target": "Improved Distribution Matching Distillation for Fast Image Synthesis", "value": "author_of"}, {"source": "Richard Zhang", "target": "Improved Distribution Matching Distillation for Fast Image Synthesis", "value": "author_of"}, {"source": "Eli Shechtman", "target": "Improved Distribution Matching Distillation for Fast Image Synthesis", "value": "author_of"}, {"source": "Fredo Durand", "target": "Improved Distribution Matching Distillation for Fast Image Synthesis", "value": "author_of"}, {"source": "William T. Freeman", "target": "Improved Distribution Matching Distillation for Fast Image Synthesis", "value": "author_of"}, {"source": "Axel Sauer", "target": "Fast High-Resolution Image Synthesis with Latent Adversarial Diffusion Distillation", "value": "author_of"}, {"source": "Frederic Boesel", "target": "Fast High-Resolution Image Synthesis with Latent Adversarial Diffusion Distillation", "value": "author_of"}, {"source": "Tim Dockhorn", "target": "Fast High-Resolution Image Synthesis with Latent Adversarial Diffusion Distillation", "value": "author_of"}, {"source": "Andreas Blattmann", "target": "Fast High-Resolution Image Synthesis with Latent Adversarial Diffusion Distillation", "value": "author_of"}, {"source": "Patrick Esser", "target": "Fast High-Resolution Image Synthesis with Latent Adversarial Diffusion Distillation", "value": "author_of"}, {"source": "Robin Rombach", "target": "Fast High-Resolution Image Synthesis with Latent Adversarial Diffusion Distillation", "value": "author_of"}, {"source": "Takuya Akiba", "target": "Evolutionary optimization of model merging recipes", "value": "author_of"}, {"source": "Makoto Shing", "target": "Evolutionary optimization of model merging recipes", "value": "author_of"}, {"source": "Yujin Tang", "target": "Evolutionary optimization of model merging recipes", "value": "author_of"}, {"source": "Qi Sun", "target": "Evolutionary optimization of model merging recipes", "value": "author_of"}, {"source": "David Ha", "target": "Evolutionary optimization of model merging recipes", "value": "author_of"}, {"source": "Tianwei Yin", "target": "From Slow Bidirectional to Fast Autoregressive Video Diffusion Models", "value": "author_of"}, {"source": "Qiang Zhang", "target": "From Slow Bidirectional to Fast Autoregressive Video Diffusion Models", "value": "author_of"}, {"source": "Richard Zhang", "target": "From Slow Bidirectional to Fast Autoregressive Video Diffusion Models", "value": "author_of"}, {"source": "William T. Freeman", "target": "From Slow Bidirectional to Fast Autoregressive Video Diffusion Models", "value": "author_of"}, {"source": "Fredo Durand", "target": "From Slow Bidirectional to Fast Autoregressive Video Diffusion Models", "value": "author_of"}, {"source": "Eli Shechtman", "target": "From Slow Bidirectional to Fast Autoregressive Video Diffusion Models", "value": "author_of"}, {"source": "Xun Huang", "target": "From Slow Bidirectional to Fast Autoregressive Video Diffusion Models", "value": "author_of"}, {"source": "Zinan Guo", "target": "PuLID: Pure and Lightning ID Customization via Contrastive Alignment", "value": "author_of"}, {"source": "Yanze Wu", "target": "PuLID: Pure and Lightning ID Customization via Contrastive Alignment", "value": "author_of"}, {"source": "Zhuowei Chen", "target": "PuLID: Pure and Lightning ID Customization via Contrastive Alignment", "value": "author_of"}, {"source": "Lang Chen", "target": "PuLID: Pure and Lightning ID Customization via Contrastive Alignment", "value": "author_of"}, {"source": "Peng Zhang", "target": "PuLID: Pure and Lightning ID Customization via Contrastive Alignment", "value": "author_of"}, {"source": "Qian He", "target": "PuLID: Pure and Lightning ID Customization via Contrastive Alignment", "value": "author_of"}, {"source": "Jonathan Ho", "target": "Denoising Diffusion Probabilistic Models", "value": "author_of"}, {"source": "Ajay Jain", "target": "Denoising Diffusion Probabilistic Models", "value": "author_of"}, {"source": "Pieter Abbeel", "target": "Denoising Diffusion Probabilistic Models", "value": "author_of"}, {"source": "Weijie Kong", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Qi Tian", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Zijian Zhang", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Rox Min", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Zuozhuo Dai", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Jin Zhou", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Jiangfeng Xiong", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Xin Li", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Bo Wu", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Jianwei Zhang", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Kathrina Wu", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Qin Lin", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Junkun Yuan", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Yanxin Long", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Aladdin Wang", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Andong Wang", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Changlin Li", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Duojun Huang", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Fang Yang", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Hao Tan", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Hongmei Wang", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Jacob Song", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Jiawang Bai", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Jianbing Wu", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Jinbao Xue", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Joey Wang", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Kai Wang", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Mengyang Liu", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Pengyu Li", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Shuai Li", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Weiyan Wang", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Wenqing Yu", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Xinchi Deng", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Yang Li", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Yi Chen", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Yutao Cui", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Yuanbo Peng", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Zhentao Yu", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Zhiyu He", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Zhiyong Xu", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Zixiang Zhou", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Zunnan Xu", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Yangyu Tao", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Qinglin Lu", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Songtao Liu", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Dax Zhou", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Hongfa Wang", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Yong Yang", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Di Wang", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Yuhong Liu", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Jie Jiang", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Caesar Zhong", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Jianwen Jiang", "target": "Loopy: Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency", "value": "author_of"}, {"source": "Chao Liang", "target": "Loopy: Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency", "value": "author_of"}, {"source": "Jiaqi Yang", "target": "Loopy: Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency", "value": "author_of"}, {"source": "Gaojie Lin", "target": "Loopy: Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency", "value": "author_of"}, {"source": "Tianyun Zhong", "target": "Loopy: Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency", "value": "author_of"}, {"source": "Yanbo Zheng", "target": "Loopy: Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency", "value": "author_of"}, {"source": "Gaojie Lin", "target": "OmniHuman-1: Rethinking the Scaling-Up of One-Stage Conditioned Human Animation Models", "value": "author_of"}, {"source": "Jianwen Jiang", "target": "OmniHuman-1: Rethinking the Scaling-Up of One-Stage Conditioned Human Animation Models", "value": "author_of"}, {"source": "Jiaqi Yang", "target": "OmniHuman-1: Rethinking the Scaling-Up of One-Stage Conditioned Human Animation Models", "value": "author_of"}, {"source": "Zerong Zheng", "target": "OmniHuman-1: Rethinking the Scaling-Up of One-Stage Conditioned Human Animation Models", "value": "author_of"}, {"source": "Chao Liang", "target": "OmniHuman-1: Rethinking the Scaling-Up of One-Stage Conditioned Human Animation Models", "value": "author_of"}, {"source": "Jiahao Cui", "target": "Hallo2: Long-Duration and High-Resolution Audio-Driven Portrait Image Animation", "value": "author_of"}, {"source": "Hui Li", "target": "Hallo2: Long-Duration and High-Resolution Audio-Driven Portrait Image Animation", "value": "author_of"}, {"source": "Yao Yao", "target": "Hallo2: Long-Duration and High-Resolution Audio-Driven Portrait Image Animation", "value": "author_of"}, {"source": "Hao Zhu", "target": "Hallo2: Long-Duration and High-Resolution Audio-Driven Portrait Image Animation", "value": "author_of"}, {"source": "Hanlin Shang", "target": "Hallo2: Long-Duration and High-Resolution Audio-Driven Portrait Image Animation", "value": "author_of"}, {"source": "Kaihui Cheng", "target": "Hallo2: Long-Duration and High-Resolution Audio-Driven Portrait Image Animation", "value": "author_of"}, {"source": "Hang Zhou", "target": "Hallo2: Long-Duration and High-Resolution Audio-Driven Portrait Image Animation", "value": "author_of"}, {"source": "Siyu Zhu", "target": "Hallo2: Long-Duration and High-Resolution Audio-Driven Portrait Image Animation", "value": "author_of"}, {"source": "Jingdong Wang", "target": "Hallo2: Long-Duration and High-Resolution Audio-Driven Portrait Image Animation", "value": "author_of"}, {"source": "Rang Meng", "target": "EchoMimicV2: Towards Striking, Simplified, and Semi-Body Human Animation", "value": "author_of"}, {"source": "Xingyu Zhang", "target": "EchoMimicV2: Towards Striking, Simplified, and Semi-Body Human Animation", "value": "author_of"}, {"source": "Yuming Li", "target": "EchoMimicV2: Towards Striking, Simplified, and Semi-Body Human Animation", "value": "author_of"}, {"source": "Chenguang Ma", "target": "EchoMimicV2: Towards Striking, Simplified, and Semi-Body Human Animation", "value": "author_of"}, {"source": "Tsung-Yi Lin", "target": "Feature Pyramid Networks for Object Detection", "value": "author_of"}, {"source": "Piotr Doll\u00e1r", "target": "Feature Pyramid Networks for Object Detection", "value": "author_of"}, {"source": "Ross Girshick", "target": "Feature Pyramid Networks for Object Detection", "value": "author_of"}, {"source": "Kaiming He", "target": "Feature Pyramid Networks for Object Detection", "value": "author_of"}, {"source": "Bharath Hariharan", "target": "Feature Pyramid Networks for Object Detection", "value": "author_of"}, {"source": "Serge Belongie", "target": "Feature Pyramid Networks for Object Detection", "value": "author_of"}, {"source": "Kyunghyun Cho", "target": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation", "value": "author_of"}, {"source": "Bart van Merrienboer", "target": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation", "value": "author_of"}, {"source": "Caglar Gulcehre", "target": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation", "value": "author_of"}, {"source": "Dzmitry Bahdanau", "target": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation", "value": "author_of"}, {"source": "Fethi Bougares", "target": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation", "value": "author_of"}, {"source": "Holger Schwenk", "target": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation", "value": "author_of"}, {"source": "Yoshua Bengio", "target": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation", "value": "author_of"}, {"source": "Erfei Cui", "target": "DriveMLM: aligning multi-modal large language models with behavioral planning states for autonomous driving", "value": "author_of"}, {"source": "Wenhai Wang", "target": "DriveMLM: aligning multi-modal large language models with behavioral planning states for autonomous driving", "value": "author_of"}, {"source": "Zhiqi Li", "target": "DriveMLM: aligning multi-modal large language models with behavioral planning states for autonomous driving", "value": "author_of"}, {"source": "Jiangwei Xie", "target": "DriveMLM: aligning multi-modal large language models with behavioral planning states for autonomous driving", "value": "author_of"}, {"source": "Haoming Zou", "target": "DriveMLM: aligning multi-modal large language models with behavioral planning states for autonomous driving", "value": "author_of"}, {"source": "Hanming Deng", "target": "DriveMLM: aligning multi-modal large language models with behavioral planning states for autonomous driving", "value": "author_of"}, {"source": "Gen Luo", "target": "DriveMLM: aligning multi-modal large language models with behavioral planning states for autonomous driving", "value": "author_of"}, {"source": "Lewei Lu", "target": "DriveMLM: aligning multi-modal large language models with behavioral planning states for autonomous driving", "value": "author_of"}, {"source": "Xizhou Zhu", "target": "DriveMLM: aligning multi-modal large language models with behavioral planning states for autonomous driving", "value": "author_of"}, {"source": "Jifeng Dai", "target": "DriveMLM: aligning multi-modal large language models with behavioral planning states for autonomous driving", "value": "author_of"}, {"source": "Shenyuan Gao", "target": "Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability", "value": "author_of"}, {"source": "Jiazhi Yang", "target": "Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability", "value": "author_of"}, {"source": "Li Chen", "target": "Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability", "value": "author_of"}, {"source": "Kashyap Chitta", "target": "Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability", "value": "author_of"}, {"source": "Yihang Qiu", "target": "Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability", "value": "author_of"}, {"source": "Andreas Geiger", "target": "Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability", "value": "author_of"}, {"source": "Jun Zhang", "target": "Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability", "value": "author_of"}, {"source": "Hongyang Li", "target": "Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability", "value": "author_of"}, {"source": "Bencheng Liao", "target": "DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving", "value": "author_of"}, {"source": "Shaoyu Chen", "target": "DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving", "value": "author_of"}, {"source": "Haoran Yin", "target": "DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving", "value": "author_of"}, {"source": "Bo Jiang", "target": "DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving", "value": "author_of"}, {"source": "Cheng Wang", "target": "DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving", "value": "author_of"}, {"source": "Sixu Yan", "target": "DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving", "value": "author_of"}, {"source": "Xinbang Zhang", "target": "DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving", "value": "author_of"}, {"source": "Xiangyu Li", "target": "DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving", "value": "author_of"}, {"source": "Ying Zhang", "target": "DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving", "value": "author_of"}, {"source": "Qian Zhang", "target": "DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving", "value": "author_of"}, {"source": "Xinggang Wang", "target": "DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving", "value": "author_of"}, {"source": "Bingyi Kang", "target": "How Far is Video Generation from World Model: A Physical Law Perspective", "value": "author_of"}, {"source": "Yang Yue", "target": "How Far is Video Generation from World Model: A Physical Law Perspective", "value": "author_of"}, {"source": "Rui Lu", "target": "How Far is Video Generation from World Model: A Physical Law Perspective", "value": "author_of"}, {"source": "Zhijie Lin", "target": "How Far is Video Generation from World Model: A Physical Law Perspective", "value": "author_of"}, {"source": "Yang Zhao", "target": "How Far is Video Generation from World Model: A Physical Law Perspective", "value": "author_of"}, {"source": "Kaixin Wang", "target": "How Far is Video Generation from World Model: A Physical Law Perspective", "value": "author_of"}, {"source": "Gao Huang", "target": "How Far is Video Generation from World Model: A Physical Law Perspective", "value": "author_of"}, {"source": "Jiashi Feng", "target": "How Far is Video Generation from World Model: A Physical Law Perspective", "value": "author_of"}, {"source": "Jyh-Jing Hwang", "target": "EMMA: End-to-End Multimodal Model for Autonomous Driving", "value": "author_of"}, {"source": "Runsheng Xu", "target": "EMMA: End-to-End Multimodal Model for Autonomous Driving", "value": "author_of"}, {"source": "Hubert Lin", "target": "EMMA: End-to-End Multimodal Model for Autonomous Driving", "value": "author_of"}, {"source": "Wei-Chih Hung", "target": "EMMA: End-to-End Multimodal Model for Autonomous Driving", "value": "author_of"}, {"source": "Jingwei Ji", "target": "EMMA: End-to-End Multimodal Model for Autonomous Driving", "value": "author_of"}, {"source": "Kristy Choi", "target": "EMMA: End-to-End Multimodal Model for Autonomous Driving", "value": "author_of"}, {"source": "Di Huang", "target": "EMMA: End-to-End Multimodal Model for Autonomous Driving", "value": "author_of"}, {"source": "Tong He", "target": "EMMA: End-to-End Multimodal Model for Autonomous Driving", "value": "author_of"}, {"source": "Paul Covington", "target": "EMMA: End-to-End Multimodal Model for Autonomous Driving", "value": "author_of"}, {"source": "Benjamin Sapp", "target": "EMMA: End-to-End Multimodal Model for Autonomous Driving", "value": "author_of"}, {"source": "Yin Zhou", "target": "EMMA: End-to-End Multimodal Model for Autonomous Driving", "value": "author_of"}, {"source": "James Guo", "target": "EMMA: End-to-End Multimodal Model for Autonomous Driving", "value": "author_of"}, {"source": "Dragomir Anguelov", "target": "EMMA: End-to-End Multimodal Model for Autonomous Driving", "value": "author_of"}, {"source": "Mingxing Tan", "target": "EMMA: End-to-End Multimodal Model for Autonomous Driving", "value": "author_of"}, {"source": "Tom B. Brown", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Benjamin Mann", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Nick Ryder", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Melanie Subbiah", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Jared Kaplan", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Prafulla Dhariwal", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Arvind Neelakantan", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Pranav Shyam", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Girish Sastry", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Amanda Askell", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Sandhini Agarwal", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Ariel Herbert-Voss", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Gretchen Krueger", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Tom Henighan", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Rewon Child", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Aditya Ramesh", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Daniel M. Ziegler", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Jeffrey Wu", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Clemens Winter", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Christopher Hesse", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Mark Chen", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Eric Sigler", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Mateusz Litwin", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Scott Gray", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Benjamin Chess", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Jack Clark", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Christopher Berner", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Sam McCandlish", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Alec Radford", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Ilya Sutskever", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Dario Amodei", "target": "Language Models are Few-Shot Learners", "value": "author_of"}, {"source": "Zhe Chen", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Weiyun Wang", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Yue Cao", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Yangzhou Liu", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Zhangwei Gao", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Erfei Cui", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Jinguo Zhu", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Shenglong Ye", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Hao Tian", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Zhaoyang Liu", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Lixin Gu", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Xuehui Wang", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Qingyun Li", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Yiming Ren", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Zixuan Chen", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Jiapeng Luo", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Jiahao Wang", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Tan Jiang", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Bo Wang", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Conghui He", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Botian Shi", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Xingcheng Zhang", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Han Lv", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Yi Wang", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Wenqi Shao", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Pei Chu", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Zhongying Tu", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Tong He", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Zhiyong Wu", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Huipeng Deng", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Jiaye Ge", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Kai Chen", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Kaipeng Zhang", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Limin Wang", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Min Dou", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Lewei Lu", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Xizhou Zhu", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Tong Lu", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Dahua Lin", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Yu Qiao", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Jifeng Dai", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Wenhai Wang", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "author_of"}, {"source": "Jinguo Zhu", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Weiyun Wang", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Zhe Chen", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Zhaoyang Liu", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Shenglong Ye", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Lixin Gu", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Hao Tian", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Yuchen Duan", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Weijie Su", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Jie Shao", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Zhangwei Gao", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Erfei Cui", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Xuehui Wang", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Yue Cao", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Yangzhou Liu", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Xingguang Wei", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Hongjie Zhang", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Haomin Wang", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Weiye Xu", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Hao Li", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Jiahao Wang", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Nianchen Deng", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Songze Li", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Yinan He", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Tan Jiang", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Jiapeng Luo", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Yi Wang", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Conghui He", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Botian Shi", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Xingcheng Zhang", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Wenqi Shao", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Junjun He", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Yingtong Xiong", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Wenwen Qu", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Peng Sun", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Penglong Jiao", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Han Lv", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Lijun Wu", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Kaipeng Zhang", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Huipeng Deng", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Jiaye Ge", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Kai Chen", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Limin Wang", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Min Dou", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Lewei Lu", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Xizhou Zhu", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Tong Lu", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Dahua Lin", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Yu Qiao", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Jifeng Dai", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Wenhai Wang", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "author_of"}, {"source": "Haodong Duan", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Xinyu Fang", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Junming Yang", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Xiangyu Zhao", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Yuxuan Qiao", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Mo Li", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Amit Agarwal", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Zhe Chen", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Lin Chen", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Yuan Liu", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Yubo Ma", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Hailong Sun", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Yifan Zhang", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Shiyin Lu", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Tack Hwa Wong", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Weiyun Wang", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Peiheng Zhou", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Xiaozhe Li", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Chaoyou Fu", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Junbo Cui", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Jixuan Chen", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Enxin Song", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Song Mao", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Shengyuan Ding", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Tianhao Liang", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Zicheng Zhang", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Xiaoyi Dong", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Yuhang Zang", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Pan Zhang", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Jiaqi Wang", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Dahua Lin", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Kai Chen", "target": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Guowei Xu", "target": "LLaVA-CoT: Let Vision Language Models Reason Step-by-Step", "value": "author_of"}, {"source": "Peng Jin", "target": "LLaVA-CoT: Let Vision Language Models Reason Step-by-Step", "value": "author_of"}, {"source": "Ziang Wu", "target": "LLaVA-CoT: Let Vision Language Models Reason Step-by-Step", "value": "author_of"}, {"source": "Hao Li", "target": "LLaVA-CoT: Let Vision Language Models Reason Step-by-Step", "value": "author_of"}, {"source": "Yibing Song", "target": "LLaVA-CoT: Let Vision Language Models Reason Step-by-Step", "value": "author_of"}, {"source": "Lichao Sun", "target": "LLaVA-CoT: Let Vision Language Models Reason Step-by-Step", "value": "author_of"}, {"source": "Li Yuan", "target": "LLaVA-CoT: Let Vision Language Models Reason Step-by-Step", "value": "author_of"}, {"source": "Weiyun Wang", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Zhangwei Gao", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Lixin Gu", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Hengjun Pu", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Long Cui", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Xingguang Wei", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Zhaoyang Liu", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Linglin Jing", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Shenglong Ye", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Jie Shao", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Zhaokai Wang", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Zhe Chen", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Hongjie Zhang", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Ganlin Yang", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Haomin Wang", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Qi Wei", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Jinhui Yin", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Wenhao Li", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Erfei Cui", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Guanzhou Chen", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Zichen Ding", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Changyao Tian", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Zhenyu Wu", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Jingjing Xie", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Zehao Li", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Bowen Yang", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Yuchen Duan", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Xuehui Wang", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Zhi Hou", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Haoran Hao", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Tianyi Zhang", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Songze Li", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Xiangyu Zhao", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Haodong Duan", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Nianchen Deng", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Bin Fu", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Yinan He", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Yi Wang", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Conghui He", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Botian Shi", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Junjun He", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Yingtong Xiong", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Han Lv", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Lijun Wu", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Wenqi Shao", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Kaipeng Zhang", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Huipeng Deng", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Biqing Qi", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Jiaye Ge", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Qipeng Guo", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Wenwei Zhang", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Songyang Zhang", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Maosong Cao", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Junyao Lin", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Kexian Tang", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Jianfei Gao", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Haian Huang", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Yuzhe Gu", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Chengqi Lyu", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Huanze Tang", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Rui Wang", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Haijun Lv", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Wanli Ouyang", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Limin Wang", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Min Dou", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Xizhou Zhu", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Tong Lu", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Dahua Lin", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Jifeng Dai", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Weijie Su", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Bowen Zhou", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Kai Chen", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Yu Qiao", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Wenhai Wang", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "Gen Luo", "target": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "value": "author_of"}, {"source": "John Schulman", "target": "Proximal Policy Optimization Algorithms", "value": "author_of"}, {"source": "Filip Wolski", "target": "Proximal Policy Optimization Algorithms", "value": "author_of"}, {"source": "Prafulla Dhariwal", "target": "Proximal Policy Optimization Algorithms", "value": "author_of"}, {"source": "Alec Radford", "target": "Proximal Policy Optimization Algorithms", "value": "author_of"}, {"source": "Oleg Klimov", "target": "Proximal Policy Optimization Algorithms", "value": "author_of"}, {"source": "Jie Liu", "target": "Flow-GRPO: Training Flow Matching Models via Online RL", "value": "author_of"}, {"source": "Gongye Liu", "target": "Flow-GRPO: Training Flow Matching Models via Online RL", "value": "author_of"}, {"source": "Jiajun Liang", "target": "Flow-GRPO: Training Flow Matching Models via Online RL", "value": "author_of"}, {"source": "Yangguang Li", "target": "Flow-GRPO: Training Flow Matching Models via Online RL", "value": "author_of"}, {"source": "Jiaheng Liu", "target": "Flow-GRPO: Training Flow Matching Models via Online RL", "value": "author_of"}, {"source": "Xintao Wang", "target": "Flow-GRPO: Training Flow Matching Models via Online RL", "value": "author_of"}, {"source": "Pengfei Wan", "target": "Flow-GRPO: Training Flow Matching Models via Online RL", "value": "author_of"}, {"source": "Di Zhang", "target": "Flow-GRPO: Training Flow Matching Models via Online RL", "value": "author_of"}, {"source": "Wanli Ouyang", "target": "Flow-GRPO: Training Flow Matching Models via Online RL", "value": "author_of"}, {"source": "Zeyue Xue", "target": "DanceGRPO: Unleashing GRPO on Visual Generation", "value": "author_of"}, {"source": "Jie Wu", "target": "DanceGRPO: Unleashing GRPO on Visual Generation", "value": "author_of"}, {"source": "Yu Gao", "target": "DanceGRPO: Unleashing GRPO on Visual Generation", "value": "author_of"}, {"source": "Fangyuan Kong", "target": "DanceGRPO: Unleashing GRPO on Visual Generation", "value": "author_of"}, {"source": "Lingting Zhu", "target": "DanceGRPO: Unleashing GRPO on Visual Generation", "value": "author_of"}, {"source": "Mengzhao Chen", "target": "DanceGRPO: Unleashing GRPO on Visual Generation", "value": "author_of"}, {"source": "Zhiheng Liu", "target": "DanceGRPO: Unleashing GRPO on Visual Generation", "value": "author_of"}, {"source": "Wei Liu", "target": "DanceGRPO: Unleashing GRPO on Visual Generation", "value": "author_of"}, {"source": "Qiushan Guo", "target": "DanceGRPO: Unleashing GRPO on Visual Generation", "value": "author_of"}, {"source": "Weilin Huang", "target": "DanceGRPO: Unleashing GRPO on Visual Generation", "value": "author_of"}, {"source": "Ping Luo", "target": "DanceGRPO: Unleashing GRPO on Visual Generation", "value": "author_of"}, {"source": "Yu Gao", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Haoyuan Guo", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Tuyen Hoang", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Weilin Huang", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Lu Jiang", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Fangyuan Kong", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Huixia Li", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Jiashi Li", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Liang Li", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Xiaojie Li", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Xunsong Li", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Yifu Li", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Shanchuan Lin", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Zhijie Lin", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Jiawei Liu", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Shu Liu", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Xiaonan Nie", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Zhiwu Qing", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Yuxi Ren", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Li Sun", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Zhi Tian", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Rui Wang", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Sen Wang", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Guoqiang Wei", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Guohong Wu", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Jie Wu", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Ruiqi Xia", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Fei Xiao", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Xuefeng Xiao", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Jiangqiao Yan", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Ceyuan Yang", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Jianchao Yang", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Runkai Yang", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Tao Yang", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Yihang Yang", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Zilyu Ye", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Xuejiao Zeng", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Yan Zeng", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Heng Zhang", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Yang Zhao", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Xiaozheng Zheng", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Peihao Zhu", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Jiaxin Zou", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Feilong Zuo", "target": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "value": "author_of"}, {"source": "Guibin Chen", "target": "SkyReels-V2: Infinite-length Film Generative Model", "value": "author_of"}, {"source": "Dixuan Lin", "target": "SkyReels-V2: Infinite-length Film Generative Model", "value": "author_of"}, {"source": "Jiangping Yang", "target": "SkyReels-V2: Infinite-length Film Generative Model", "value": "author_of"}, {"source": "Chunze Lin", "target": "SkyReels-V2: Infinite-length Film Generative Model", "value": "author_of"}, {"source": "Junchen Zhu", "target": "SkyReels-V2: Infinite-length Film Generative Model", "value": "author_of"}, {"source": "Mingyuan Fan", "target": "SkyReels-V2: Infinite-length Film Generative Model", "value": "author_of"}, {"source": "Hao Zhang", "target": "SkyReels-V2: Infinite-length Film Generative Model", "value": "author_of"}, {"source": "Sheng Chen", "target": "SkyReels-V2: Infinite-length Film Generative Model", "value": "author_of"}, {"source": "Zheng Chen", "target": "SkyReels-V2: Infinite-length Film Generative Model", "value": "author_of"}, {"source": "Chengcheng Ma", "target": "SkyReels-V2: Infinite-length Film Generative Model", "value": "author_of"}, {"source": "Weiming Xiong", "target": "SkyReels-V2: Infinite-length Film Generative Model", "value": "author_of"}, {"source": "Wei Wang", "target": "SkyReels-V2: Infinite-length Film Generative Model", "value": "author_of"}, {"source": "Nuo Pang", "target": "SkyReels-V2: Infinite-length Film Generative Model", "value": "author_of"}, {"source": "Kang Kang", "target": "SkyReels-V2: Infinite-length Film Generative Model", "value": "author_of"}, {"source": "Zhiheng Xu", "target": "SkyReels-V2: Infinite-length Film Generative Model", "value": "author_of"}, {"source": "Yuzhe Jin", "target": "SkyReels-V2: Infinite-length Film Generative Model", "value": "author_of"}, {"source": "Yupeng Liang", "target": "SkyReels-V2: Infinite-length Film Generative Model", "value": "author_of"}, {"source": "Yubing Song", "target": "SkyReels-V2: Infinite-length Film Generative Model", "value": "author_of"}, {"source": "Peng Zhao", "target": "SkyReels-V2: Infinite-length Film Generative Model", "value": "author_of"}, {"source": "Boyuan Xu", "target": "SkyReels-V2: Infinite-length Film Generative Model", "value": "author_of"}, {"source": "Di Qiu", "target": "SkyReels-V2: Infinite-length Film Generative Model", "value": "author_of"}, {"source": "Debang Li", "target": "SkyReels-V2: Infinite-length Film Generative Model", "value": "author_of"}, {"source": "Zhengcong Fei", "target": "SkyReels-V2: Infinite-length Film Generative Model", "value": "author_of"}, {"source": "Yang Li", "target": "SkyReels-V2: Infinite-length Film Generative Model", "value": "author_of"}, {"source": "Yahui Zhou", "target": "SkyReels-V2: Infinite-length Film Generative Model", "value": "author_of"}, {"source": "Yibin Wang", "target": "Unified Reward Model for Multimodal Understanding and Generation", "value": "author_of"}, {"source": "Yuhang Zang", "target": "Unified Reward Model for Multimodal Understanding and Generation", "value": "author_of"}, {"source": "Hao Li", "target": "Unified Reward Model for Multimodal Understanding and Generation", "value": "author_of"}, {"source": "Cheng Jin", "target": "Unified Reward Model for Multimodal Understanding and Generation", "value": "author_of"}, {"source": "Jiaqi Wang", "target": "Unified Reward Model for Multimodal Understanding and Generation", "value": "author_of"}, {"source": "\u77e5\u79c0 \u67f4\u7530", "target": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding", "value": "author_of"}, {"source": "Pranav Rajpurkar", "target": "SQuAD: 100,000+ Questions for Machine Comprehension of Text", "value": "author_of"}, {"source": "Jian Zhang", "target": "SQuAD: 100,000+ Questions for Machine Comprehension of Text", "value": "author_of"}, {"source": "Konstantin Lopyrev", "target": "SQuAD: 100,000+ Questions for Machine Comprehension of Text", "value": "author_of"}, {"source": "Percy Liang", "target": "SQuAD: 100,000+ Questions for Machine Comprehension of Text", "value": "author_of"}, {"source": "Rico Sennrich", "target": "Neural Machine Translation of Rare Words with Subword Units", "value": "author_of"}, {"source": "Barry Haddow", "target": "Neural Machine Translation of Rare Words with Subword Units", "value": "author_of"}, {"source": "Alexandra Birch", "target": "Neural Machine Translation of Rare Words with Subword Units", "value": "author_of"}, {"source": "Taku Kudo", "target": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing", "value": "author_of"}, {"source": "John Richardson", "target": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing", "value": "author_of"}, {"source": "OpenAI", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Josh Achiam", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Steven Adler", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Sandhini Agarwal", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Lama Ahmad", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Ilge Akkaya", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Florencia Leoni Aleman", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Diogo Almeida", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Janko Altenschmidt", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Sam Altman", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Shyamal Anadkat", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Red Avila", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Igor Babuschkin", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Suchir Balaji", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Valerie Balcom", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Paul Baltescu", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Haiming Bao", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Mohammad Bavarian", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Jeff Belgum", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Irwan Bello", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Jake Berdine", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Gabriel Bernadett-Shapiro", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Christopher Berner", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Lenny Bogdonoff", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Oleg Boiko", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Madelaine Boyd", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Anna-Luisa Brakman", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Greg Brockman", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Tim Brooks", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Miles Brundage", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Kevin Button", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Trevor Cai", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Rosie Campbell", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Andrew Cann", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Brittany Carey", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Chelsea Carlson", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Rory Carmichael", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Brooke Chan", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Che Chang", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Fotis Chantzis", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Derek Chen", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Sully Chen", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Ruby Chen", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Jason Chen", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Mark Chen", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Ben Chess", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Chester Cho", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Casey Chu", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Hyung Won Chung", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Dave Cummings", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Jeremiah Currier", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Yunxing Dai", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Cory Decareaux", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Thomas Degry", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Noah Deutsch", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Damien Deville", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Arka Dhar", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "David Dohan", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Steve Dowling", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Sheila Dunning", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Adrien Ecoffet", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Atty Eleti", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Tyna Eloundou", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "David Farhi", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Liam Fedus", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Niko Felix", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Sim\u00f3n Posada Fishman", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Juston Forte", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Isabella Fulford", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Leo Gao", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Elie Georges", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Christian Gibson", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Vik Goel", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Tarun Gogineni", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Gabriel Goh", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Rapha Gontijo-Lopes", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Jonathan Gordon", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Morgan Grafstein", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Scott Gray", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Ryan Greene", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Joshua Gross", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Shixiang Shane Gu", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Yufei Guo", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Chris Hallacy", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Jesse Han", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Jeff Harris", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Yuchen He", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Mike Heaton", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Johannes Heidecke", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Chris Hesse", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Alan Hickey", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Wade Hickey", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Peter Hoeschele", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Brandon Houghton", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Kenny Hsu", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Shengli Hu", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Xin Hu", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Joost Huizinga", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Shantanu Jain", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Shawn Jain", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Joanne Jang", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Angela Jiang", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Roger Jiang", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Haozhun Jin", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Denny Jin", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Shino Jomoto", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Billie Jonn", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Heewoo Jun", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Tomer Kaftan", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "\u0141ukasz Kaiser", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Ali Kamali", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Ingmar Kanitscheider", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Nitish Shirish Keskar", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Tabarak Khan", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Logan Kilpatrick", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Jong Wook Kim", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Christina Kim", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Yongjik Kim", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Jan Hendrik Kirchner", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Jamie Kiros", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Matt Knight", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Daniel Kokotajlo", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "\u0141ukasz Kondraciuk", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Andrew Kondrich", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Aris Konstantinidis", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Kyle Kosic", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Gretchen Krueger", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Vishal Kuo", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Michael Lampe", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Ikai Lan", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Teddy Lee", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Jan Leike", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Jade Leung", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Daniel Levy", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Chak Ming Li", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Rachel Lim", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Molly Lin", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Stephanie Lin", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Mateusz Litwin", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Theresa Lopez", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Ryan Lowe", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Patricia Lue", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Anna Makanju", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Kim Malfacini", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Sam Manning", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Todor Markov", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Yaniv Markovski", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Bianca Martin", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Katie Mayer", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Andrew Mayne", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Bob McGrew", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Scott Mayer McKinney", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Christine McLeavey", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Paul McMillan", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Jake McNeil", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "David Medina", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Aalok Mehta", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Jacob Menick", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Luke Metz", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Andrey Mishchenko", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Pamela Mishkin", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Vinnie Monaco", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Evan Morikawa", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Daniel Mossing", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Tong Mu", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Mira Murati", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Oleg Murk", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "David M\u00e9ly", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Ashvin Nair", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Reiichiro Nakano", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Rajeev Nayak", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Arvind Neelakantan", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Richard Ngo", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Hyeonwoo Noh", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Long Ouyang", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Cullen O'Keefe", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Jakub Pachocki", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Alex Paino", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Joe Palermo", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Ashley Pantuliano", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Giambattista Parascandolo", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Joel Parish", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Emy Parparita", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Alex Passos", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Mikhail Pavlov", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Andrew Peng", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Adam Perelman", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Filipe de Avila Belbute Peres", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Michael Petrov", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Henrique Ponde de Oliveira Pinto", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Michael", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Pokorny", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Michelle Pokrass", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Vitchyr H. Pong", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Tolly Powell", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Alethea Power", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Boris Power", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Elizabeth Proehl", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Raul Puri", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Alec Radford", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Jack Rae", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Aditya Ramesh", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Cameron Raymond", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Francis Real", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Kendra Rimbach", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Carl Ross", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Bob Rotsted", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Henri Roussez", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Nick Ryder", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Mario Saltarelli", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Ted Sanders", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Shibani Santurkar", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Girish Sastry", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Heather Schmidt", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "David Schnurr", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "John Schulman", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Daniel Selsam", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Kyla Sheppard", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Toki Sherbakov", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Jessica Shieh", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Sarah Shoker", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Pranav Shyam", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Szymon Sidor", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Eric Sigler", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Maddie Simens", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Jordan Sitkin", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Katarina Slama", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Ian Sohl", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Benjamin Sokolowsky", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Yang Song", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Natalie Staudacher", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Felipe Petroski Such", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Natalie Summers", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Ilya Sutskever", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Jie Tang", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Nikolas Tezak", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Madeleine B. Thompson", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Phil Tillet", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Amin Tootoonchian", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Elizabeth Tseng", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Preston Tuggle", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Nick Turley", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Jerry Tworek", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Juan Felipe Cer\u00f3n Uribe", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Andrea Vallone", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Arun Vijayvergiya", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Chelsea Voss", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Carroll Wainwright", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Justin Jay Wang", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Alvin Wang", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Ben Wang", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Jonathan Ward", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Jason Wei", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "CJ Weinmann", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Akila Welihinda", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Peter Welinder", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Jiayi Weng", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Lilian Weng", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Matt Wiethoff", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Dave Willner", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Clemens Winter", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Samuel Wolrich", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Hannah Wong", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Lauren Workman", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Sherwin Wu", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Jeff Wu", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Michael Wu", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Kai Xiao", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Tao Xu", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Sarah Yoo", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Kevin Yu", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Qiming Yuan", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Wojciech Zaremba", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Rowan Zellers", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Chong Zhang", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Marvin Zhang", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Shengjia Zhao", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Tianhao Zheng", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Juntang Zhuang", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "William Zhuk", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Barret Zoph", "target": "GPT-4 Technical Report", "value": "author_of"}, {"source": "Hugo Touvron", "target": "LLaMA: Open and Efficient Foundation Language Models", "value": "author_of"}, {"source": "Thibaut Lavril", "target": "LLaMA: Open and Efficient Foundation Language Models", "value": "author_of"}, {"source": "Gautier Izacard", "target": "LLaMA: Open and Efficient Foundation Language Models", "value": "author_of"}, {"source": "Xavier Martinet", "target": "LLaMA: Open and Efficient Foundation Language Models", "value": "author_of"}, {"source": "Marie-Anne Lachaux", "target": "LLaMA: Open and Efficient Foundation Language Models", "value": "author_of"}, {"source": "Timoth\u00e9e Lacroix", "target": "LLaMA: Open and Efficient Foundation Language Models", "value": "author_of"}, {"source": "Baptiste Rozi\u00e8re", "target": "LLaMA: Open and Efficient Foundation Language Models", "value": "author_of"}, {"source": "Naman Goyal", "target": "LLaMA: Open and Efficient Foundation Language Models", "value": "author_of"}, {"source": "Eric Hambro", "target": "LLaMA: Open and Efficient Foundation Language Models", "value": "author_of"}, {"source": "Faisal Azhar", "target": "LLaMA: Open and Efficient Foundation Language Models", "value": "author_of"}, {"source": "Aurelien Rodriguez", "target": "LLaMA: Open and Efficient Foundation Language Models", "value": "author_of"}, {"source": "Armand Joulin", "target": "LLaMA: Open and Efficient Foundation Language Models", "value": "author_of"}, {"source": "Edouard Grave", "target": "LLaMA: Open and Efficient Foundation Language Models", "value": "author_of"}, {"source": "Guillaume Lample", "target": "LLaMA: Open and Efficient Foundation Language Models", "value": "author_of"}, {"source": "Jason Wei", "target": "Chain of Thought Prompting Elicits Reasoning in Large Language Models", "value": "author_of"}, {"source": "Xuezhi Wang", "target": "Chain of Thought Prompting Elicits Reasoning in Large Language Models", "value": "author_of"}, {"source": "Dale Schuurmans", "target": "Chain of Thought Prompting Elicits Reasoning in Large Language Models", "value": "author_of"}, {"source": "Maarten Bosma", "target": "Chain of Thought Prompting Elicits Reasoning in Large Language Models", "value": "author_of"}, {"source": "Brian Ichter", "target": "Chain of Thought Prompting Elicits Reasoning in Large Language Models", "value": "author_of"}, {"source": "Fei Xia", "target": "Chain of Thought Prompting Elicits Reasoning in Large Language Models", "value": "author_of"}, {"source": "Ed Chi", "target": "Chain of Thought Prompting Elicits Reasoning in Large Language Models", "value": "author_of"}, {"source": "Quoc Le", "target": "Chain of Thought Prompting Elicits Reasoning in Large Language Models", "value": "author_of"}, {"source": "Denny Zhou", "target": "Chain of Thought Prompting Elicits Reasoning in Large Language Models", "value": "author_of"}, {"source": "Karl Cobbe", "target": "Training Verifiers to Solve Math Word Problems", "value": "author_of"}, {"source": "Vineet Kosaraju", "target": "Training Verifiers to Solve Math Word Problems", "value": "author_of"}, {"source": "Mohammad Bavarian", "target": "Training Verifiers to Solve Math Word Problems", "value": "author_of"}, {"source": "Mark Chen", "target": "Training Verifiers to Solve Math Word Problems", "value": "author_of"}, {"source": "Heewoo Jun", "target": "Training Verifiers to Solve Math Word Problems", "value": "author_of"}, {"source": "Lukasz Kaiser", "target": "Training Verifiers to Solve Math Word Problems", "value": "author_of"}, {"source": "Matthias Plappert", "target": "Training Verifiers to Solve Math Word Problems", "value": "author_of"}, {"source": "Jerry Tworek", "target": "Training Verifiers to Solve Math Word Problems", "value": "author_of"}, {"source": "Jacob Hilton", "target": "Training Verifiers to Solve Math Word Problems", "value": "author_of"}, {"source": "Reiichiro Nakano", "target": "Training Verifiers to Solve Math Word Problems", "value": "author_of"}, {"source": "Christopher Hesse", "target": "Training Verifiers to Solve Math Word Problems", "value": "author_of"}, {"source": "John Schulman", "target": "Training Verifiers to Solve Math Word Problems", "value": "author_of"}, {"source": "Albert Gu", "target": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces", "value": "author_of"}, {"source": "Tri Dao", "target": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces", "value": "author_of"}, {"source": "Stephen M. Mount", "target": "A catalogue of splice junction sequences.", "value": "author_of"}, {"source": "F. Crick", "target": "Origin of the Genetic Code", "value": "author_of"}, {"source": "Ilya Loshchilov", "target": "SGDR: Stochastic Gradient Descent with Warm Restarts", "value": "author_of"}, {"source": "Frank Hutter", "target": "SGDR: Stochastic Gradient Descent with Warm Restarts", "value": "author_of"}, {"source": "Noam Shazeer", "target": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer", "value": "author_of"}, {"source": "Azalia Mirhoseini", "target": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer", "value": "author_of"}, {"source": "Krzysztof Maziarz", "target": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer", "value": "author_of"}, {"source": "Andy Davis", "target": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer", "value": "author_of"}, {"source": "Quoc Le", "target": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer", "value": "author_of"}, {"source": "Geoffrey Hinton", "target": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer", "value": "author_of"}, {"source": "Jeff Dean", "target": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer", "value": "author_of"}, {"source": "J. Ziv", "target": "Compression of individual sequences via variable-rate coding", "value": "author_of"}, {"source": "A. Lempel", "target": "Compression of individual sequences via variable-rate coding", "value": "author_of"}, {"source": "Stephen Merity", "target": "Pointer Sentinel Mixture Models", "value": "author_of"}, {"source": "Caiming Xiong", "target": "Pointer Sentinel Mixture Models", "value": "author_of"}, {"source": "James Bradbury", "target": "Pointer Sentinel Mixture Models", "value": "author_of"}, {"source": "Richard Socher", "target": "Pointer Sentinel Mixture Models", "value": "author_of"}, {"source": "Dan Hendrycks", "target": "Measuring Massive Multitask Language Understanding", "value": "author_of"}, {"source": "Collin Burns", "target": "Measuring Massive Multitask Language Understanding", "value": "author_of"}, {"source": "Steven Basart", "target": "Measuring Massive Multitask Language Understanding", "value": "author_of"}, {"source": "Andy Zou", "target": "Measuring Massive Multitask Language Understanding", "value": "author_of"}, {"source": "Mantas Mazeika", "target": "Measuring Massive Multitask Language Understanding", "value": "author_of"}, {"source": "Dawn Song", "target": "Measuring Massive Multitask Language Understanding", "value": "author_of"}, {"source": "Jacob Steinhardt", "target": "Measuring Massive Multitask Language Understanding", "value": "author_of"}, {"source": "Hunter Lightman", "target": "Let's Verify Step by Step", "value": "author_of"}, {"source": "Vineet Kosaraju", "target": "Let's Verify Step by Step", "value": "author_of"}, {"source": "Yura Burda", "target": "Let's Verify Step by Step", "value": "author_of"}, {"source": "Harri Edwards", "target": "Let's Verify Step by Step", "value": "author_of"}, {"source": "Bowen Baker", "target": "Let's Verify Step by Step", "value": "author_of"}, {"source": "Teddy Lee", "target": "Let's Verify Step by Step", "value": "author_of"}, {"source": "Jan Leike", "target": "Let's Verify Step by Step", "value": "author_of"}, {"source": "John Schulman", "target": "Let's Verify Step by Step", "value": "author_of"}, {"source": "Ilya Sutskever", "target": "Let's Verify Step by Step", "value": "author_of"}, {"source": "Karl Cobbe", "target": "Let's Verify Step by Step", "value": "author_of"}, {"source": "David Rein", "target": "GPQA: A Graduate-Level Google-Proof Q&A Benchmark", "value": "author_of"}, {"source": "Betty Li Hou", "target": "GPQA: A Graduate-Level Google-Proof Q&A Benchmark", "value": "author_of"}, {"source": "Asa Cooper Stickland", "target": "GPQA: A Graduate-Level Google-Proof Q&A Benchmark", "value": "author_of"}, {"source": "Jackson Petty", "target": "GPQA: A Graduate-Level Google-Proof Q&A Benchmark", "value": "author_of"}, {"source": "Richard Yuanzhe Pang", "target": "GPQA: A Graduate-Level Google-Proof Q&A Benchmark", "value": "author_of"}, {"source": "Julien Dirani", "target": "GPQA: A Graduate-Level Google-Proof Q&A Benchmark", "value": "author_of"}, {"source": "Julian Michael", "target": "GPQA: A Graduate-Level Google-Proof Q&A Benchmark", "value": "author_of"}, {"source": "Samuel R. Bowman", "target": "GPQA: A Graduate-Level Google-Proof Q&A Benchmark", "value": "author_of"}, {"source": "Dmitry Lepikhin", "target": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding", "value": "author_of"}, {"source": "HyoukJoong Lee", "target": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding", "value": "author_of"}, {"source": "Yuanzhong Xu", "target": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding", "value": "author_of"}, {"source": "Dehao Chen", "target": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding", "value": "author_of"}, {"source": "Orhan Firat", "target": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding", "value": "author_of"}, {"source": "Yanping Huang", "target": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding", "value": "author_of"}, {"source": "Maxim Krikun", "target": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding", "value": "author_of"}, {"source": "Noam Shazeer", "target": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding", "value": "author_of"}, {"source": "Zhifeng Chen", "target": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding", "value": "author_of"}, {"source": "Ross Girshick", "target": "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation", "value": "author_of"}, {"source": "Jeff Donahue", "target": "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation", "value": "author_of"}, {"source": "Trevor Darrell", "target": "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation", "value": "author_of"}, {"source": "Jitendra Malik", "target": "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation", "value": "author_of"}, {"source": "Shansong Liu", "target": "MuMu-LLaMA: Multi-modal music understanding and generation via large language models", "value": "author_of"}, {"source": "Atin Sakkeer Hussain", "target": "MuMu-LLaMA: Multi-modal music understanding and generation via large language models", "value": "author_of"}, {"source": "Qilong Wu", "target": "MuMu-LLaMA: Multi-modal music understanding and generation via large language models", "value": "author_of"}, {"source": "Chenshuo Sun", "target": "MuMu-LLaMA: Multi-modal music understanding and generation via large language models", "value": "author_of"}, {"source": "Ying Shan", "target": "MuMu-LLaMA: Multi-modal music understanding and generation via large language models", "value": "author_of"}, {"source": "Jiahang Tu", "target": "Mass Concept Erasure in Diffusion Models with Concept Hierarchy", "value": "author_of"}, {"source": "Ye Li", "target": "Mass Concept Erasure in Diffusion Models with Concept Hierarchy", "value": "author_of"}, {"source": "Yiming Wu", "target": "Mass Concept Erasure in Diffusion Models with Concept Hierarchy", "value": "author_of"}, {"source": "Hanbin Zhao", "target": "Mass Concept Erasure in Diffusion Models with Concept Hierarchy", "value": "author_of"}, {"source": "Chao Zhang", "target": "Mass Concept Erasure in Diffusion Models with Concept Hierarchy", "value": "author_of"}, {"source": "Hui Qian", "target": "Mass Concept Erasure in Diffusion Models with Concept Hierarchy", "value": "author_of"}, {"source": "Haotian Lv", "target": "Intelligent Recognition of GPR Road Hidden Defect Images Based on Feature Fusion and Attention Mechanism", "value": "author_of"}, {"source": "Yuhui Zhang", "target": "Intelligent Recognition of GPR Road Hidden Defect Images Based on Feature Fusion and Attention Mechanism", "value": "author_of"}, {"source": "Jiangbo Dai", "target": "Intelligent Recognition of GPR Road Hidden Defect Images Based on Feature Fusion and Attention Mechanism", "value": "author_of"}, {"source": "Hanli Wu", "target": "Intelligent Recognition of GPR Road Hidden Defect Images Based on Feature Fusion and Attention Mechanism", "value": "author_of"}, {"source": "Jiaji Wang", "target": "Intelligent Recognition of GPR Road Hidden Defect Images Based on Feature Fusion and Attention Mechanism", "value": "author_of"}, {"source": "Dawei Wang", "target": "Intelligent Recognition of GPR Road Hidden Defect Images Based on Feature Fusion and Attention Mechanism", "value": "author_of"}, {"source": "Mingxin Li", "target": "Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking", "value": "author_of"}, {"source": "Yanzhao Zhang", "target": "Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking", "value": "author_of"}, {"source": "Dingkun Long", "target": "Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking", "value": "author_of"}, {"source": "Keqin Chen", "target": "Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking", "value": "author_of"}, {"source": "Sibo Song", "target": "Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking", "value": "author_of"}, {"source": "Shuai Bai", "target": "Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking", "value": "author_of"}, {"source": "Zhibo Yang", "target": "Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking", "value": "author_of"}, {"source": "Pengjun Xie", "target": "Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking", "value": "author_of"}, {"source": "An Yang", "target": "Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking", "value": "author_of"}, {"source": "Dayiheng Liu", "target": "Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking", "value": "author_of"}, {"source": "Jingren Zhou", "target": "Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking", "value": "author_of"}, {"source": "Junyang Lin", "target": "Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking", "value": "author_of"}, {"source": "Mingyue Chen", "target": "Flexible Partial Screen-Shooting Watermarking With Provable Robustness", "value": "author_of"}, {"source": "Xin Liao", "target": "Flexible Partial Screen-Shooting Watermarking With Provable Robustness", "value": "author_of"}, {"source": "Han Fang", "target": "Flexible Partial Screen-Shooting Watermarking With Provable Robustness", "value": "author_of"}, {"source": "Jinlin Guo", "target": "Flexible Partial Screen-Shooting Watermarking With Provable Robustness", "value": "author_of"}, {"source": "Yanxiang Chen", "target": "Flexible Partial Screen-Shooting Watermarking With Provable Robustness", "value": "author_of"}, {"source": "Xiaoshuai Wu", "target": "Flexible Partial Screen-Shooting Watermarking With Provable Robustness", "value": "author_of"}, {"source": "Radford M. Neal", "target": "Pattern Recognition and Machine Learning", "value": "author_of"}, {"source": "L. Breiman", "target": "Bagging Predictors", "value": "author_of"}, {"source": "Guan Wang", "target": "Automatic Image-Based Plant Disease Severity Estimation Using Deep Learning", "value": "author_of"}, {"source": "Yu Sun", "target": "Automatic Image-Based Plant Disease Severity Estimation Using Deep Learning", "value": "author_of"}, {"source": "Jianxin Wang", "target": "Automatic Image-Based Plant Disease Severity Estimation Using Deep Learning", "value": "author_of"}, {"source": "Mostafa Mehdipour-Ghazi", "target": "Plant identification using deep neural networks via optimization of transfer learning parameters", "value": "author_of"}, {"source": "B. Yanikoglu", "target": "Plant identification using deep neural networks via optimization of transfer learning parameters", "value": "author_of"}, {"source": "E. Aptoula", "target": "Plant identification using deep neural networks via optimization of transfer learning parameters", "value": "author_of"}, {"source": "Sue Han Lee", "target": "New perspectives on plant disease characterization based on deep learning", "value": "author_of"}, {"source": "H. Go\u00ebau", "target": "New perspectives on plant disease characterization based on deep learning", "value": "author_of"}, {"source": "P. Bonnet", "target": "New perspectives on plant disease characterization based on deep learning", "value": "author_of"}, {"source": "A. Joly", "target": "New perspectives on plant disease characterization based on deep learning", "value": "author_of"}, {"source": "Yu Sun", "target": "Deep Learning for Plant Identification in Natural Environment", "value": "author_of"}, {"source": "Yuan Liu", "target": "Deep Learning for Plant Identification in Natural Environment", "value": "author_of"}, {"source": "Guan Wang", "target": "Deep Learning for Plant Identification in Natural Environment", "value": "author_of"}, {"source": "Haiyan Zhang", "target": "Deep Learning for Plant Identification in Natural Environment", "value": "author_of"}, {"source": "Jose Carranza-Rojas", "target": "Going deeper in the automated identification of Herbarium specimens", "value": "author_of"}, {"source": "Herv\u00e9 Goeau", "target": "Going deeper in the automated identification of Herbarium specimens", "value": "author_of"}, {"source": "P. Bonnet", "target": "Going deeper in the automated identification of Herbarium specimens", "value": "author_of"}, {"source": "Erick Mata-Montero", "target": "Going deeper in the automated identification of Herbarium specimens", "value": "author_of"}, {"source": "A. Joly", "target": "Going deeper in the automated identification of Herbarium specimens", "value": "author_of"}, {"source": "Gao Huang", "target": "Densely Connected Convolutional Networks", "value": "author_of"}, {"source": "Zhuang Liu", "target": "Densely Connected Convolutional Networks", "value": "author_of"}, {"source": "Laurens van der Maaten", "target": "Densely Connected Convolutional Networks", "value": "author_of"}, {"source": "Kilian Q. Weinberger", "target": "Densely Connected Convolutional Networks", "value": "author_of"}, {"source": "Mark Sandler", "target": "MobileNetV2: Inverted Residuals and Linear Bottlenecks", "value": "author_of"}, {"source": "Andrew Howard", "target": "MobileNetV2: Inverted Residuals and Linear Bottlenecks", "value": "author_of"}, {"source": "Menglong Zhu", "target": "MobileNetV2: Inverted Residuals and Linear Bottlenecks", "value": "author_of"}, {"source": "Andrey Zhmoginov", "target": "MobileNetV2: Inverted Residuals and Linear Bottlenecks", "value": "author_of"}, {"source": "Liang-Chieh Chen", "target": "MobileNetV2: Inverted Residuals and Linear Bottlenecks", "value": "author_of"}, {"source": "H. Brendan McMahan", "target": "Communication-Efficient Learning of Deep Networks from Decentralized Data", "value": "author_of"}, {"source": "Eider Moore", "target": "Communication-Efficient Learning of Deep Networks from Decentralized Data", "value": "author_of"}, {"source": "Daniel Ramage", "target": "Communication-Efficient Learning of Deep Networks from Decentralized Data", "value": "author_of"}, {"source": "Seth Hampson", "target": "Communication-Efficient Learning of Deep Networks from Decentralized Data", "value": "author_of"}, {"source": "Blaise Ag\u00fcera y Arcas", "target": "Communication-Efficient Learning of Deep Networks from Decentralized Data", "value": "author_of"}, {"source": "Fuzhen Zhuang", "target": "A Comprehensive Survey on Transfer Learning", "value": "author_of"}, {"source": "Zhiyuan Qi", "target": "A Comprehensive Survey on Transfer Learning", "value": "author_of"}, {"source": "Keyu Duan", "target": "A Comprehensive Survey on Transfer Learning", "value": "author_of"}, {"source": "Dongbo Xi", "target": "A Comprehensive Survey on Transfer Learning", "value": "author_of"}, {"source": "Yongchun Zhu", "target": "A Comprehensive Survey on Transfer Learning", "value": "author_of"}, {"source": "Hengshu Zhu", "target": "A Comprehensive Survey on Transfer Learning", "value": "author_of"}, {"source": "Hui Xiong", "target": "A Comprehensive Survey on Transfer Learning", "value": "author_of"}, {"source": "Qing He", "target": "A Comprehensive Survey on Transfer Learning", "value": "author_of"}, {"source": "A. Khan", "target": "Privacy Preserved and Decentralized Smartphone Recommendation System", "value": "author_of"}, {"source": "Maha Driss", "target": "Privacy Preserved and Decentralized Smartphone Recommendation System", "value": "author_of"}, {"source": "Wadii Boulila", "target": "Privacy Preserved and Decentralized Smartphone Recommendation System", "value": "author_of"}, {"source": "G. A. Sampedro", "target": "Privacy Preserved and Decentralized Smartphone Recommendation System", "value": "author_of"}, {"source": "Sidra Abbas", "target": "Privacy Preserved and Decentralized Smartphone Recommendation System", "value": "author_of"}, {"source": "Chitapong Wechtaisong", "target": "Privacy Preserved and Decentralized Smartphone Recommendation System", "value": "author_of"}, {"source": "Tesfahunegn Minwuyelet Mengistu", "target": "A Survey on Heterogeneity Taxonomy, Security and Privacy Preservation in the Integration of IoT, Wireless Sensor Networks and Federated Learning", "value": "author_of"}, {"source": "Taewoon Kim", "target": "A Survey on Heterogeneity Taxonomy, Security and Privacy Preservation in the Integration of IoT, Wireless Sensor Networks and Federated Learning", "value": "author_of"}, {"source": "Jenn-Wei Lin", "target": "A Survey on Heterogeneity Taxonomy, Security and Privacy Preservation in the Integration of IoT, Wireless Sensor Networks and Federated Learning", "value": "author_of"}, {"source": "A. Alamer", "target": "A privacy-preserving federated learning with a secure collaborative for malware detection models using Internet of Things resources", "value": "author_of"}, {"source": "Manel Khazri Khlifi", "target": "Graph-based deep learning techniques for remote sensing applications: Techniques, taxonomy, and applications - A comprehensive review", "value": "author_of"}, {"source": "Wadii Boulila", "target": "Graph-based deep learning techniques for remote sensing applications: Techniques, taxonomy, and applications - A comprehensive review", "value": "author_of"}, {"source": "I. Farah", "target": "Graph-based deep learning techniques for remote sensing applications: Techniques, taxonomy, and applications - A comprehensive review", "value": "author_of"}, {"source": "Anwesha Mukherjee", "target": "Federated Learning Architectures: A Performance Evaluation With Crop Yield Prediction Application", "value": "author_of"}, {"source": "Rajkumar Buyya", "target": "Federated Learning Architectures: A Performance Evaluation With Crop Yield Prediction Application", "value": "author_of"}, {"source": "Alexander Kirillov", "target": "Segment Anything", "value": "author_of"}, {"source": "Eric Mintun", "target": "Segment Anything", "value": "author_of"}, {"source": "Nikhila Ravi", "target": "Segment Anything", "value": "author_of"}, {"source": "Hanzi Mao", "target": "Segment Anything", "value": "author_of"}, {"source": "Chloe Rolland", "target": "Segment Anything", "value": "author_of"}, {"source": "Laura Gustafson", "target": "Segment Anything", "value": "author_of"}, {"source": "Tete Xiao", "target": "Segment Anything", "value": "author_of"}, {"source": "Spencer Whitehead", "target": "Segment Anything", "value": "author_of"}, {"source": "Alexander C. Berg", "target": "Segment Anything", "value": "author_of"}, {"source": "Wan-Yen Lo", "target": "Segment Anything", "value": "author_of"}, {"source": "Piotr Doll\u00e1r", "target": "Segment Anything", "value": "author_of"}, {"source": "Ross Girshick", "target": "Segment Anything", "value": "author_of"}, {"source": "Haotian Liu", "target": "Visual Instruction Tuning", "value": "author_of"}, {"source": "Chunyuan Li", "target": "Visual Instruction Tuning", "value": "author_of"}, {"source": "Qingyang Wu", "target": "Visual Instruction Tuning", "value": "author_of"}, {"source": "Yong Jae Lee", "target": "Visual Instruction Tuning", "value": "author_of"}, {"source": "Haotian Liu", "target": "Improved Baselines with Visual Instruction Tuning", "value": "author_of"}, {"source": "Chunyuan Li", "target": "Improved Baselines with Visual Instruction Tuning", "value": "author_of"}, {"source": "Yuheng Li", "target": "Improved Baselines with Visual Instruction Tuning", "value": "author_of"}, {"source": "Yong Jae Lee", "target": "Improved Baselines with Visual Instruction Tuning", "value": "author_of"}, {"source": "Zhiyuan You", "target": "Enhancing Descriptive Image Quality Assessment With a Large-Scale Multi-Modal Dataset", "value": "author_of"}, {"source": "Jinjin Gu", "target": "Enhancing Descriptive Image Quality Assessment With a Large-Scale Multi-Modal Dataset", "value": "author_of"}, {"source": "Xin Cai", "target": "Enhancing Descriptive Image Quality Assessment With a Large-Scale Multi-Modal Dataset", "value": "author_of"}, {"source": "Zheyuan Li", "target": "Enhancing Descriptive Image Quality Assessment With a Large-Scale Multi-Modal Dataset", "value": "author_of"}, {"source": "Kaiwen Zhu", "target": "Enhancing Descriptive Image Quality Assessment With a Large-Scale Multi-Modal Dataset", "value": "author_of"}, {"source": "Chao Dong", "target": "Enhancing Descriptive Image Quality Assessment With a Large-Scale Multi-Modal Dataset", "value": "author_of"}, {"source": "Tianfan Xue", "target": "Enhancing Descriptive Image Quality Assessment With a Large-Scale Multi-Modal Dataset", "value": "author_of"}, {"source": "Xintong Zhang", "target": "Adaptive Chain-of-Focus Reasoning via Dynamic Visual Search and Zooming for Efficient VLMs", "value": "author_of"}, {"source": "Zhi Gao", "target": "Adaptive Chain-of-Focus Reasoning via Dynamic Visual Search and Zooming for Efficient VLMs", "value": "author_of"}, {"source": "Bofei Zhang", "target": "Adaptive Chain-of-Focus Reasoning via Dynamic Visual Search and Zooming for Efficient VLMs", "value": "author_of"}, {"source": "Pengxiang Li", "target": "Adaptive Chain-of-Focus Reasoning via Dynamic Visual Search and Zooming for Efficient VLMs", "value": "author_of"}, {"source": "Xiaowen Zhang", "target": "Adaptive Chain-of-Focus Reasoning via Dynamic Visual Search and Zooming for Efficient VLMs", "value": "author_of"}, {"source": "Yang Liu", "target": "Adaptive Chain-of-Focus Reasoning via Dynamic Visual Search and Zooming for Efficient VLMs", "value": "author_of"}, {"source": "Tao Yuan", "target": "Adaptive Chain-of-Focus Reasoning via Dynamic Visual Search and Zooming for Efficient VLMs", "value": "author_of"}, {"source": "Yuwei Wu", "target": "Adaptive Chain-of-Focus Reasoning via Dynamic Visual Search and Zooming for Efficient VLMs", "value": "author_of"}, {"source": "Yunde Jia", "target": "Adaptive Chain-of-Focus Reasoning via Dynamic Visual Search and Zooming for Efficient VLMs", "value": "author_of"}, {"source": "Song-Chun Zhu", "target": "Adaptive Chain-of-Focus Reasoning via Dynamic Visual Search and Zooming for Efficient VLMs", "value": "author_of"}, {"source": "Qing Li", "target": "Adaptive Chain-of-Focus Reasoning via Dynamic Visual Search and Zooming for Efficient VLMs", "value": "author_of"}, {"source": "Zhangquan Chen", "target": "Think with 3D: Geometric Imagination Grounded Spatial Reasoning from Limited Views", "value": "author_of"}, {"source": "Manyuan Zhang", "target": "Think with 3D: Geometric Imagination Grounded Spatial Reasoning from Limited Views", "value": "author_of"}, {"source": "Xinlei Yu", "target": "Think with 3D: Geometric Imagination Grounded Spatial Reasoning from Limited Views", "value": "author_of"}, {"source": "Xufang Luo", "target": "Think with 3D: Geometric Imagination Grounded Spatial Reasoning from Limited Views", "value": "author_of"}, {"source": "Mingze Sun", "target": "Think with 3D: Geometric Imagination Grounded Spatial Reasoning from Limited Views", "value": "author_of"}, {"source": "Zihao Pan", "target": "Think with 3D: Geometric Imagination Grounded Spatial Reasoning from Limited Views", "value": "author_of"}, {"source": "Yan Feng", "target": "Think with 3D: Geometric Imagination Grounded Spatial Reasoning from Limited Views", "value": "author_of"}, {"source": "Peng Pei", "target": "Think with 3D: Geometric Imagination Grounded Spatial Reasoning from Limited Views", "value": "author_of"}, {"source": "Xunliang Cai", "target": "Think with 3D: Geometric Imagination Grounded Spatial Reasoning from Limited Views", "value": "author_of"}, {"source": "Ruqi Huang", "target": "Think with 3D: Geometric Imagination Grounded Spatial Reasoning from Limited Views", "value": "author_of"}, {"source": "Tiancheng Gu", "target": "UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning", "value": "author_of"}, {"source": "Kaicheng Yang", "target": "UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning", "value": "author_of"}, {"source": "Kaichen Zhang", "target": "UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning", "value": "author_of"}, {"source": "Xiang An", "target": "UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning", "value": "author_of"}, {"source": "Ziyong Feng", "target": "UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning", "value": "author_of"}, {"source": "Yueyi Zhang", "target": "UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning", "value": "author_of"}, {"source": "Weidong Cai", "target": "UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning", "value": "author_of"}, {"source": "Jiankang Deng", "target": "UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning", "value": "author_of"}, {"source": "Lidong Bing", "target": "UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning", "value": "author_of"}, {"source": "Kaichen Zhang", "target": "OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe", "value": "author_of"}, {"source": "Keming Wu", "target": "OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe", "value": "author_of"}, {"source": "Zuhao Yang", "target": "OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe", "value": "author_of"}, {"source": "Bo Li", "target": "OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe", "value": "author_of"}, {"source": "Kairui Hu", "target": "OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe", "value": "author_of"}, {"source": "Bin Wang", "target": "OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe", "value": "author_of"}, {"source": "Ziwei Liu", "target": "OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe", "value": "author_of"}, {"source": "Xingxuan Li", "target": "OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe", "value": "author_of"}, {"source": "Lidong Bing", "target": "OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe", "value": "author_of"}, {"source": "Ranjan Sapkota", "target": "Vision-Language-Action (VLA) Models: Concepts, Progress, Applications and Challenges", "value": "author_of"}, {"source": "Yang Cao", "target": "Vision-Language-Action (VLA) Models: Concepts, Progress, Applications and Challenges", "value": "author_of"}, {"source": "Konstantinos I. Roumeliotis", "target": "Vision-Language-Action (VLA) Models: Concepts, Progress, Applications and Challenges", "value": "author_of"}, {"source": "Manoj Karkee", "target": "Vision-Language-Action (VLA) Models: Concepts, Progress, Applications and Challenges", "value": "author_of"}, {"source": "Kohei Sendai", "target": "Leave No Observation Behind: Real-time Correction for VLA Action Chunks", "value": "author_of"}, {"source": "Maxime Alvarez", "target": "Leave No Observation Behind: Real-time Correction for VLA Action Chunks", "value": "author_of"}, {"source": "Tatsuya Matsushima", "target": "Leave No Observation Behind: Real-time Correction for VLA Action Chunks", "value": "author_of"}, {"source": "Yutaka Matsuo", "target": "Leave No Observation Behind: Real-time Correction for VLA Action Chunks", "value": "author_of"}, {"source": "Yusuke Iwasawa", "target": "Leave No Observation Behind: Real-time Correction for VLA Action Chunks", "value": "author_of"}, {"source": "Shuhan Tan", "target": "Latent Chain-of-Thought World Modeling for End-to-End Driving", "value": "author_of"}, {"source": "Kashyap Chitta", "target": "Latent Chain-of-Thought World Modeling for End-to-End Driving", "value": "author_of"}, {"source": "Yuxiao Chen", "target": "Latent Chain-of-Thought World Modeling for End-to-End Driving", "value": "author_of"}, {"source": "Ran Tian", "target": "Latent Chain-of-Thought World Modeling for End-to-End Driving", "value": "author_of"}, {"source": "Yurong You", "target": "Latent Chain-of-Thought World Modeling for End-to-End Driving", "value": "author_of"}, {"source": "Yan Wang", "target": "Latent Chain-of-Thought World Modeling for End-to-End Driving", "value": "author_of"}, {"source": "Wenjie Luo", "target": "Latent Chain-of-Thought World Modeling for End-to-End Driving", "value": "author_of"}, {"source": "Yulong Cao", "target": "Latent Chain-of-Thought World Modeling for End-to-End Driving", "value": "author_of"}, {"source": "Philipp Krahenbuhl", "target": "Latent Chain-of-Thought World Modeling for End-to-End Driving", "value": "author_of"}, {"source": "Marco Pavone", "target": "Latent Chain-of-Thought World Modeling for End-to-End Driving", "value": "author_of"}, {"source": "Boris Ivanovic", "target": "Latent Chain-of-Thought World Modeling for End-to-End Driving", "value": "author_of"}, {"source": "Zheng Xiong", "target": "HyperVLA: Efficient Inference in Vision-Language-Action Models via Hypernetworks", "value": "author_of"}, {"source": "Kang Li", "target": "HyperVLA: Efficient Inference in Vision-Language-Action Models via Hypernetworks", "value": "author_of"}, {"source": "Zilin Wang", "target": "HyperVLA: Efficient Inference in Vision-Language-Action Models via Hypernetworks", "value": "author_of"}, {"source": "Matthew Jackson", "target": "HyperVLA: Efficient Inference in Vision-Language-Action Models via Hypernetworks", "value": "author_of"}, {"source": "Jakob Foerster", "target": "HyperVLA: Efficient Inference in Vision-Language-Action Models via Hypernetworks", "value": "author_of"}, {"source": "Shimon Whiteson", "target": "HyperVLA: Efficient Inference in Vision-Language-Action Models via Hypernetworks", "value": "author_of"}, {"source": "Yifan Ye", "target": "Token Expand-Merge: Training-Free Token Compression for Vision-Language-Action Models", "value": "author_of"}, {"source": "Jiaqi Ma", "target": "Token Expand-Merge: Training-Free Token Compression for Vision-Language-Action Models", "value": "author_of"}, {"source": "Jun Cen", "target": "Token Expand-Merge: Training-Free Token Compression for Vision-Language-Action Models", "value": "author_of"}, {"source": "Zhihe Lu", "target": "Token Expand-Merge: Training-Free Token Compression for Vision-Language-Action Models", "value": "author_of"}, {"source": "Hai Liu", "target": "TransSIL: A Silhouette Cue-Aware Image Classification Framework for Bird Ecological Monitoring Systems", "value": "author_of"}, {"source": "Yu Song", "target": "TransSIL: A Silhouette Cue-Aware Image Classification Framework for Bird Ecological Monitoring Systems", "value": "author_of"}, {"source": "Tingting Liu", "target": "TransSIL: A Silhouette Cue-Aware Image Classification Framework for Bird Ecological Monitoring Systems", "value": "author_of"}, {"source": "Lin Chen", "target": "TransSIL: A Silhouette Cue-Aware Image Classification Framework for Bird Ecological Monitoring Systems", "value": "author_of"}, {"source": "Zhaoli Zhang", "target": "TransSIL: A Silhouette Cue-Aware Image Classification Framework for Bird Ecological Monitoring Systems", "value": "author_of"}, {"source": "Xiaolan Yang", "target": "TransSIL: A Silhouette Cue-Aware Image Classification Framework for Bird Ecological Monitoring Systems", "value": "author_of"}, {"source": "Neal N. Xiong", "target": "TransSIL: A Silhouette Cue-Aware Image Classification Framework for Bird Ecological Monitoring Systems", "value": "author_of"}, {"source": "Honghu Chu", "target": "CBRFormer: rendering technology-based transformer for refinement segmentation of bridge crack images", "value": "author_of"}, {"source": "Jiahao Gai", "target": "CBRFormer: rendering technology-based transformer for refinement segmentation of bridge crack images", "value": "author_of"}, {"source": "Weiwei Chen", "target": "CBRFormer: rendering technology-based transformer for refinement segmentation of bridge crack images", "value": "author_of"}, {"source": "Jun Ma", "target": "CBRFormer: rendering technology-based transformer for refinement segmentation of bridge crack images", "value": "author_of"}, {"source": "A. S. Demirkol", "target": "A Fast and Compact Threshold Switch-Based Cellular Nonlinear Network Cell", "value": "author_of"}, {"source": "A. Ascoli", "target": "A Fast and Compact Threshold Switch-Based Cellular Nonlinear Network Cell", "value": "author_of"}, {"source": "I. Messaris", "target": "A Fast and Compact Threshold Switch-Based Cellular Nonlinear Network Cell", "value": "author_of"}, {"source": "V. Ntinas", "target": "A Fast and Compact Threshold Switch-Based Cellular Nonlinear Network Cell", "value": "author_of"}, {"source": "D. Prousalis", "target": "A Fast and Compact Threshold Switch-Based Cellular Nonlinear Network Cell", "value": "author_of"}, {"source": "R. Tetzlaff", "target": "A Fast and Compact Threshold Switch-Based Cellular Nonlinear Network Cell", "value": "author_of"}, {"source": "Yinjun Jia", "target": "Deep contrastive learning enables genome-wide virtual screening.", "value": "author_of"}, {"source": "Bowen Gao", "target": "Deep contrastive learning enables genome-wide virtual screening.", "value": "author_of"}, {"source": "Jiaxin Tan", "target": "Deep contrastive learning enables genome-wide virtual screening.", "value": "author_of"}, {"source": "Jiqing Zheng", "target": "Deep contrastive learning enables genome-wide virtual screening.", "value": "author_of"}, {"source": "Xin Hong", "target": "Deep contrastive learning enables genome-wide virtual screening.", "value": "author_of"}, {"source": "Wenyu Zhu", "target": "Deep contrastive learning enables genome-wide virtual screening.", "value": "author_of"}, {"source": "Haichuan Tan", "target": "Deep contrastive learning enables genome-wide virtual screening.", "value": "author_of"}, {"source": "Yuan Xiao", "target": "Deep contrastive learning enables genome-wide virtual screening.", "value": "author_of"}, {"source": "Liping Tan", "target": "Deep contrastive learning enables genome-wide virtual screening.", "value": "author_of"}, {"source": "Hongyi Cai", "target": "Deep contrastive learning enables genome-wide virtual screening.", "value": "author_of"}, {"source": "Yanwen Huang", "target": "Deep contrastive learning enables genome-wide virtual screening.", "value": "author_of"}, {"source": "Zhiheng Deng", "target": "Deep contrastive learning enables genome-wide virtual screening.", "value": "author_of"}, {"source": "Xiangwei Wu", "target": "Deep contrastive learning enables genome-wide virtual screening.", "value": "author_of"}, {"source": "Yue Jin", "target": "Deep contrastive learning enables genome-wide virtual screening.", "value": "author_of"}, {"source": "Yafei Yuan", "target": "Deep contrastive learning enables genome-wide virtual screening.", "value": "author_of"}, {"source": "Jiekang Tian", "target": "Deep contrastive learning enables genome-wide virtual screening.", "value": "author_of"}, {"source": "Wei He", "target": "Deep contrastive learning enables genome-wide virtual screening.", "value": "author_of"}, {"source": "Weiying Ma", "target": "Deep contrastive learning enables genome-wide virtual screening.", "value": "author_of"}, {"source": "Ya-Qin Zhang", "target": "Deep contrastive learning enables genome-wide virtual screening.", "value": "author_of"}, {"source": "Lei Liu", "target": "Deep contrastive learning enables genome-wide virtual screening.", "value": "author_of"}, {"source": "Chuangye Yan", "target": "Deep contrastive learning enables genome-wide virtual screening.", "value": "author_of"}, {"source": "Wei Zhang", "target": "Deep contrastive learning enables genome-wide virtual screening.", "value": "author_of"}, {"source": "Yanyan Lan", "target": "Deep contrastive learning enables genome-wide virtual screening.", "value": "author_of"}, {"source": "Guodong Fan", "target": "LLaVA-based semantic feature modulation diffusion model for underwater image enhancement", "value": "author_of"}, {"source": "Shengning Zhou", "target": "LLaVA-based semantic feature modulation diffusion model for underwater image enhancement", "value": "author_of"}, {"source": "Zhen Hua", "target": "LLaVA-based semantic feature modulation diffusion model for underwater image enhancement", "value": "author_of"}, {"source": "Jinjiang Li", "target": "LLaVA-based semantic feature modulation diffusion model for underwater image enhancement", "value": "author_of"}, {"source": "Jingchun Zhou", "target": "LLaVA-based semantic feature modulation diffusion model for underwater image enhancement", "value": "author_of"}, {"source": "Jiahua Dong", "target": "3DGS-Drag: Dragging Gaussians for Intuitive Point-Based 3D Editing", "value": "author_of"}, {"source": "Yu-Xiong Wang", "target": "3DGS-Drag: Dragging Gaussians for Intuitive Point-Based 3D Editing", "value": "author_of"}, {"source": "Joohyung Yun", "target": "LILaC: Late Interacting in Layered Component Graph for Open-domain Multimodal Multihop Retrieval", "value": "author_of"}, {"source": "Doyup Lee", "target": "LILaC: Late Interacting in Layered Component Graph for Open-domain Multimodal Multihop Retrieval", "value": "author_of"}, {"source": "Wook-Shin Han", "target": "LILaC: Late Interacting in Layered Component Graph for Open-domain Multimodal Multihop Retrieval", "value": "author_of"}, {"source": "Yiyang Lu", "target": "Bidirectional Normalizing Flow: From Data to Noise and Back", "value": "author_of"}, {"source": "Qiao Sun", "target": "Bidirectional Normalizing Flow: From Data to Noise and Back", "value": "author_of"}, {"source": "Xianbang Wang", "target": "Bidirectional Normalizing Flow: From Data to Noise and Back", "value": "author_of"}, {"source": "Zhicheng Jiang", "target": "Bidirectional Normalizing Flow: From Data to Noise and Back", "value": "author_of"}, {"source": "Hanhong Zhao", "target": "Bidirectional Normalizing Flow: From Data to Noise and Back", "value": "author_of"}, {"source": "Kaiming He", "target": "Bidirectional Normalizing Flow: From Data to Noise and Back", "value": "author_of"}, {"source": "Yiyang Lu", "target": "One-step Latent-free Image Generation with Pixel Mean Flows", "value": "author_of"}, {"source": "Susie Lu", "target": "One-step Latent-free Image Generation with Pixel Mean Flows", "value": "author_of"}, {"source": "Qiao Sun", "target": "One-step Latent-free Image Generation with Pixel Mean Flows", "value": "author_of"}, {"source": "Hanhong Zhao", "target": "One-step Latent-free Image Generation with Pixel Mean Flows", "value": "author_of"}, {"source": "Zhicheng Jiang", "target": "One-step Latent-free Image Generation with Pixel Mean Flows", "value": "author_of"}, {"source": "Xianbang Wang", "target": "One-step Latent-free Image Generation with Pixel Mean Flows", "value": "author_of"}, {"source": "Tianhong Li", "target": "One-step Latent-free Image Generation with Pixel Mean Flows", "value": "author_of"}, {"source": "Zhengyang Geng", "target": "One-step Latent-free Image Generation with Pixel Mean Flows", "value": "author_of"}, {"source": "Kaiming He", "target": "One-step Latent-free Image Generation with Pixel Mean Flows", "value": "author_of"}, {"source": "Peter Potaptchik", "target": "Meta Flow Maps enable scalable reward alignment", "value": "author_of"}, {"source": "Adhi Saravanan", "target": "Meta Flow Maps enable scalable reward alignment", "value": "author_of"}, {"source": "Abbas Mammadov", "target": "Meta Flow Maps enable scalable reward alignment", "value": "author_of"}, {"source": "Alvaro Prat", "target": "Meta Flow Maps enable scalable reward alignment", "value": "author_of"}, {"source": "Michael S. Albergo", "target": "Meta Flow Maps enable scalable reward alignment", "value": "author_of"}, {"source": "Yee Whye Teh", "target": "Meta Flow Maps enable scalable reward alignment", "value": "author_of"}, {"source": "Yinan Huang", "target": "Accelerated Sequential Flow Matching: A Bayesian Filtering Perspective", "value": "author_of"}, {"source": "Hans Hao-Hsun Hsu", "target": "Accelerated Sequential Flow Matching: A Bayesian Filtering Perspective", "value": "author_of"}, {"source": "Junran Wang", "target": "Accelerated Sequential Flow Matching: A Bayesian Filtering Perspective", "value": "author_of"}, {"source": "Bo Dai", "target": "Accelerated Sequential Flow Matching: A Bayesian Filtering Perspective", "value": "author_of"}, {"source": "Pan Li", "target": "Accelerated Sequential Flow Matching: A Bayesian Filtering Perspective", "value": "author_of"}, {"source": "Mingyang Deng", "target": "Generative Modeling via Drifting", "value": "author_of"}, {"source": "He Li", "target": "Generative Modeling via Drifting", "value": "author_of"}, {"source": "Tianhong Li", "target": "Generative Modeling via Drifting", "value": "author_of"}, {"source": "Yilun Du", "target": "Generative Modeling via Drifting", "value": "author_of"}, {"source": "Kaiming He", "target": "Generative Modeling via Drifting", "value": "author_of"}, {"source": "Ting Chen", "target": "A Simple Framework for Contrastive Learning of Visual Representations", "value": "author_of"}, {"source": "Simon Kornblith", "target": "A Simple Framework for Contrastive Learning of Visual Representations", "value": "author_of"}, {"source": "Mohammad Norouzi", "target": "A Simple Framework for Contrastive Learning of Visual Representations", "value": "author_of"}, {"source": "Geoffrey Hinton", "target": "A Simple Framework for Contrastive Learning of Visual Representations", "value": "author_of"}, {"source": "Chubin Chen", "target": "Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning", "value": "author_of"}, {"source": "Sujie Hu", "target": "Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning", "value": "author_of"}, {"source": "Jiashu Zhu", "target": "Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning", "value": "author_of"}, {"source": "Meiqi Wu", "target": "Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning", "value": "author_of"}, {"source": "Jintao Chen", "target": "Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning", "value": "author_of"}, {"source": "Yanxun Li", "target": "Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning", "value": "author_of"}, {"source": "Nisha Huang", "target": "Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning", "value": "author_of"}, {"source": "Chengyu Fang", "target": "Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning", "value": "author_of"}, {"source": "Jiahong Wu", "target": "Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning", "value": "author_of"}, {"source": "Xiangxiang Chu", "target": "Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning", "value": "author_of"}, {"source": "Xiu Li", "target": "Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning", "value": "author_of"}, {"source": "Meiqi Wu", "target": "ImagerySearch: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints", "value": "author_of"}, {"source": "Jiashu Zhu", "target": "ImagerySearch: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints", "value": "author_of"}, {"source": "Xiaokun Feng", "target": "ImagerySearch: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints", "value": "author_of"}, {"source": "Chubin Chen", "target": "ImagerySearch: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints", "value": "author_of"}, {"source": "Chen Zhu", "target": "ImagerySearch: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints", "value": "author_of"}, {"source": "Bingze Song", "target": "ImagerySearch: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints", "value": "author_of"}, {"source": "Fangyuan Mao", "target": "ImagerySearch: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints", "value": "author_of"}, {"source": "Jiahong Wu", "target": "ImagerySearch: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints", "value": "author_of"}, {"source": "Xiangxiang Chu", "target": "ImagerySearch: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints", "value": "author_of"}, {"source": "Kaiqi Huang", "target": "ImagerySearch: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints", "value": "author_of"}, {"source": "Shengbang Tong", "target": "Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders", "value": "author_of"}, {"source": "Boyang Zheng", "target": "Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders", "value": "author_of"}, {"source": "Ziteng Wang", "target": "Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders", "value": "author_of"}, {"source": "Bingda Tang", "target": "Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders", "value": "author_of"}, {"source": "Nanye Ma", "target": "Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders", "value": "author_of"}, {"source": "Ellis Brown", "target": "Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders", "value": "author_of"}, {"source": "Jihan Yang", "target": "Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders", "value": "author_of"}, {"source": "Rob Fergus", "target": "Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders", "value": "author_of"}, {"source": "Yann LeCun", "target": "Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders", "value": "author_of"}, {"source": "Saining Xie", "target": "Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders", "value": "author_of"}, {"source": "Jingtong Yue", "target": "Simulating the Visual World with Artificial Intelligence: A Roadmap", "value": "author_of"}, {"source": "Ziqi Huang", "target": "Simulating the Visual World with Artificial Intelligence: A Roadmap", "value": "author_of"}, {"source": "Zhaoxi Chen", "target": "Simulating the Visual World with Artificial Intelligence: A Roadmap", "value": "author_of"}, {"source": "Xintao Wang", "target": "Simulating the Visual World with Artificial Intelligence: A Roadmap", "value": "author_of"}, {"source": "Pengfei Wan", "target": "Simulating the Visual World with Artificial Intelligence: A Roadmap", "value": "author_of"}, {"source": "Ziwei Liu", "target": "Simulating the Visual World with Artificial Intelligence: A Roadmap", "value": "author_of"}, {"source": "Bohan Zeng", "target": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "value": "author_of"}, {"source": "Kaixin Zhu", "target": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "value": "author_of"}, {"source": "Daili Hua", "target": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "value": "author_of"}, {"source": "Bozhou Li", "target": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "value": "author_of"}, {"source": "Chengzhuo Tong", "target": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "value": "author_of"}, {"source": "Yuran Wang", "target": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "value": "author_of"}, {"source": "Xinyi Huang", "target": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "value": "author_of"}, {"source": "Yifan Dai", "target": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "value": "author_of"}, {"source": "Zixiang Zhang", "target": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "value": "author_of"}, {"source": "Yifan Yang", "target": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "value": "author_of"}, {"source": "Zhou Liu", "target": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "value": "author_of"}, {"source": "Hao Liang", "target": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "value": "author_of"}, {"source": "Xiaochen Ma", "target": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "value": "author_of"}, {"source": "Ruichuan An", "target": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "value": "author_of"}, {"source": "Tianyi Bai", "target": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "value": "author_of"}, {"source": "Hongcheng Gao", "target": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "value": "author_of"}, {"source": "Junbo Niu", "target": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "value": "author_of"}, {"source": "Yang Shi", "target": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "value": "author_of"}, {"source": "Xinlong Chen", "target": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "value": "author_of"}, {"source": "Yue Ding", "target": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "value": "author_of"}, {"source": "Minglei Shi", "target": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "value": "author_of"}, {"source": "Kai Zeng", "target": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "value": "author_of"}, {"source": "Yiwen Tang", "target": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "value": "author_of"}, {"source": "Yuanxing Zhang", "target": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "value": "author_of"}, {"source": "Pengfei Wan", "target": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "value": "author_of"}, {"source": "Xintao Wang", "target": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "value": "author_of"}, {"source": "Wentao Zhang", "target": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "value": "author_of"}, {"source": "Qingyu Shi", "target": "RecTok: Reconstruction Distillation along Rectified Flow", "value": "author_of"}, {"source": "Size Wu", "target": "RecTok: Reconstruction Distillation along Rectified Flow", "value": "author_of"}, {"source": "Jinbin Bai", "target": "RecTok: Reconstruction Distillation along Rectified Flow", "value": "author_of"}, {"source": "Kaidong Yu", "target": "RecTok: Reconstruction Distillation along Rectified Flow", "value": "author_of"}, {"source": "Yujing Wang", "target": "RecTok: Reconstruction Distillation along Rectified Flow", "value": "author_of"}, {"source": "Yunhai Tong", "target": "RecTok: Reconstruction Distillation along Rectified Flow", "value": "author_of"}, {"source": "Xiangtai Li", "target": "RecTok: Reconstruction Distillation along Rectified Flow", "value": "author_of"}, {"source": "Xuelong Li", "target": "RecTok: Reconstruction Distillation along Rectified Flow", "value": "author_of"}, {"source": "Guanfang Dong", "target": "RePack then Refine: Efficient Diffusion Transformer with Vision Foundation Model", "value": "author_of"}, {"source": "Luke Schultz", "target": "RePack then Refine: Efficient Diffusion Transformer with Vision Foundation Model", "value": "author_of"}, {"source": "Negar Hassanpour", "target": "RePack then Refine: Efficient Diffusion Transformer with Vision Foundation Model", "value": "author_of"}, {"source": "Chao Gao", "target": "RePack then Refine: Efficient Diffusion Transformer with Vision Foundation Model", "value": "author_of"}, {"source": "Prafulla Dhariwal", "target": "Diffusion Models Beat GANs on Image Synthesis", "value": "author_of"}, {"source": "Alex Nichol", "target": "Diffusion Models Beat GANs on Image Synthesis", "value": "author_of"}, {"source": "Maxime Oquab", "target": "DINOv2: Learning Robust Visual Features without Supervision", "value": "author_of"}, {"source": "Timoth\u00e9e Darcet", "target": "DINOv2: Learning Robust Visual Features without Supervision", "value": "author_of"}, {"source": "Th\u00e9o Moutakanni", "target": "DINOv2: Learning Robust Visual Features without Supervision", "value": "author_of"}, {"source": "Huy Vo", "target": "DINOv2: Learning Robust Visual Features without Supervision", "value": "author_of"}, {"source": "Marc Szafraniec", "target": "DINOv2: Learning Robust Visual Features without Supervision", "value": "author_of"}, {"source": "Vasil Khalidov", "target": "DINOv2: Learning Robust Visual Features without Supervision", "value": "author_of"}, {"source": "Pierre Fernandez", "target": "DINOv2: Learning Robust Visual Features without Supervision", "value": "author_of"}, {"source": "Daniel Haziza", "target": "DINOv2: Learning Robust Visual Features without Supervision", "value": "author_of"}, {"source": "Francisco Massa", "target": "DINOv2: Learning Robust Visual Features without Supervision", "value": "author_of"}, {"source": "Alaaeldin El-Nouby", "target": "DINOv2: Learning Robust Visual Features without Supervision", "value": "author_of"}, {"source": "Mahmoud Assran", "target": "DINOv2: Learning Robust Visual Features without Supervision", "value": "author_of"}, {"source": "Nicolas Ballas", "target": "DINOv2: Learning Robust Visual Features without Supervision", "value": "author_of"}, {"source": "Wojciech Galuba", "target": "DINOv2: Learning Robust Visual Features without Supervision", "value": "author_of"}, {"source": "Russell Howes", "target": "DINOv2: Learning Robust Visual Features without Supervision", "value": "author_of"}, {"source": "Po-Yao Huang", "target": "DINOv2: Learning Robust Visual Features without Supervision", "value": "author_of"}, {"source": "Shang-Wen Li", "target": "DINOv2: Learning Robust Visual Features without Supervision", "value": "author_of"}, {"source": "Ishan Misra", "target": "DINOv2: Learning Robust Visual Features without Supervision", "value": "author_of"}, {"source": "Michael Rabbat", "target": "DINOv2: Learning Robust Visual Features without Supervision", "value": "author_of"}, {"source": "Vasu Sharma", "target": "DINOv2: Learning Robust Visual Features without Supervision", "value": "author_of"}, {"source": "Gabriel Synnaeve", "target": "DINOv2: Learning Robust Visual Features without Supervision", "value": "author_of"}, {"source": "Hu Xu", "target": "DINOv2: Learning Robust Visual Features without Supervision", "value": "author_of"}, {"source": "Herv\u00e9 Jegou", "target": "DINOv2: Learning Robust Visual Features without Supervision", "value": "author_of"}, {"source": "Julien Mairal", "target": "DINOv2: Learning Robust Visual Features without Supervision", "value": "author_of"}, {"source": "Patrick Labatut", "target": "DINOv2: Learning Robust Visual Features without Supervision", "value": "author_of"}, {"source": "Armand Joulin", "target": "DINOv2: Learning Robust Visual Features without Supervision", "value": "author_of"}, {"source": "Piotr Bojanowski", "target": "DINOv2: Learning Robust Visual Features without Supervision", "value": "author_of"}, {"source": "Zehong Ma", "target": "PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss", "value": "author_of"}, {"source": "Ruihan Xu", "target": "PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss", "value": "author_of"}, {"source": "Shiliang Zhang", "target": "PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss", "value": "author_of"}, {"source": "Shanshan Zhao", "target": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "value": "author_of"}, {"source": "Xinjie Zhang", "target": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "value": "author_of"}, {"source": "Jintao Guo", "target": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "value": "author_of"}, {"source": "Jiakui Hu", "target": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "value": "author_of"}, {"source": "Lunhao Duan", "target": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "value": "author_of"}, {"source": "Minghao Fu", "target": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "value": "author_of"}, {"source": "Yong Xien Chng", "target": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "value": "author_of"}, {"source": "Guo-Hua Wang", "target": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "value": "author_of"}, {"source": "Qing-Guo Chen", "target": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "value": "author_of"}, {"source": "Zhao Xu", "target": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "value": "author_of"}, {"source": "Weihua Luo", "target": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "value": "author_of"}, {"source": "Kaifu Zhang", "target": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "value": "author_of"}, {"source": "Jana Zeller", "target": "MentisOculi: Revealing the Limits of Reasoning with Mental Imagery", "value": "author_of"}, {"source": "Thadd\u00e4us Wiedemer", "target": "MentisOculi: Revealing the Limits of Reasoning with Mental Imagery", "value": "author_of"}, {"source": "Fanfei Li", "target": "MentisOculi: Revealing the Limits of Reasoning with Mental Imagery", "value": "author_of"}, {"source": "Thomas Klein", "target": "MentisOculi: Revealing the Limits of Reasoning with Mental Imagery", "value": "author_of"}, {"source": "Prasanna Mayilvahanan", "target": "MentisOculi: Revealing the Limits of Reasoning with Mental Imagery", "value": "author_of"}, {"source": "Matthias Bethge", "target": "MentisOculi: Revealing the Limits of Reasoning with Mental Imagery", "value": "author_of"}, {"source": "Felix Wichmann", "target": "MentisOculi: Revealing the Limits of Reasoning with Mental Imagery", "value": "author_of"}, {"source": "Ryan Cotterell", "target": "MentisOculi: Revealing the Limits of Reasoning with Mental Imagery", "value": "author_of"}, {"source": "Wieland Brendel", "target": "MentisOculi: Revealing the Limits of Reasoning with Mental Imagery", "value": "author_of"}, {"source": "Letian Zhang", "target": "OpenVision 3: A Family of Unified Visual Encoder for Both Understanding and Generation", "value": "author_of"}, {"source": "Sucheng Ren", "target": "OpenVision 3: A Family of Unified Visual Encoder for Both Understanding and Generation", "value": "author_of"}, {"source": "Yanqing Liu", "target": "OpenVision 3: A Family of Unified Visual Encoder for Both Understanding and Generation", "value": "author_of"}, {"source": "Xianhang Li", "target": "OpenVision 3: A Family of Unified Visual Encoder for Both Understanding and Generation", "value": "author_of"}, {"source": "Zeyu Wang", "target": "OpenVision 3: A Family of Unified Visual Encoder for Both Understanding and Generation", "value": "author_of"}, {"source": "Yuyin Zhou", "target": "OpenVision 3: A Family of Unified Visual Encoder for Both Understanding and Generation", "value": "author_of"}, {"source": "Huaxiu Yao", "target": "OpenVision 3: A Family of Unified Visual Encoder for Both Understanding and Generation", "value": "author_of"}, {"source": "Zeyu Zheng", "target": "OpenVision 3: A Family of Unified Visual Encoder for Both Understanding and Generation", "value": "author_of"}, {"source": "Weili Nie", "target": "OpenVision 3: A Family of Unified Visual Encoder for Both Understanding and Generation", "value": "author_of"}, {"source": "Guilin Liu", "target": "OpenVision 3: A Family of Unified Visual Encoder for Both Understanding and Generation", "value": "author_of"}, {"source": "Zhiding Yu", "target": "OpenVision 3: A Family of Unified Visual Encoder for Both Understanding and Generation", "value": "author_of"}, {"source": "Cihang Xie", "target": "OpenVision 3: A Family of Unified Visual Encoder for Both Understanding and Generation", "value": "author_of"}, {"source": "Tomas Mikolov", "target": "Distributed Representations of Words and Phrases and their Compositionality", "value": "author_of"}, {"source": "Ilya Sutskever", "target": "Distributed Representations of Words and Phrases and their Compositionality", "value": "author_of"}, {"source": "Kai Chen", "target": "Distributed Representations of Words and Phrases and their Compositionality", "value": "author_of"}, {"source": "Greg Corrado", "target": "Distributed Representations of Words and Phrases and their Compositionality", "value": "author_of"}, {"source": "Jeffrey Dean", "target": "Distributed Representations of Words and Phrases and their Compositionality", "value": "author_of"}, {"source": "Jeffrey Pennington", "target": "GloVe: Global Vectors for Word Representation", "value": "author_of"}, {"source": "R. Socher", "target": "GloVe: Global Vectors for Word Representation", "value": "author_of"}, {"source": "Christopher D. Manning", "target": "GloVe: Global Vectors for Word Representation", "value": "author_of"}, {"source": "Matthew E. Peters", "target": "Deep Contextualized Word Representations", "value": "author_of"}, {"source": "Mark Neumann", "target": "Deep Contextualized Word Representations", "value": "author_of"}, {"source": "Mohit Iyyer", "target": "Deep Contextualized Word Representations", "value": "author_of"}, {"source": "Matt Gardner", "target": "Deep Contextualized Word Representations", "value": "author_of"}, {"source": "Christopher Clark", "target": "Deep Contextualized Word Representations", "value": "author_of"}, {"source": "Kenton Lee", "target": "Deep Contextualized Word Representations", "value": "author_of"}, {"source": "Luke Zettlemoyer", "target": "Deep Contextualized Word Representations", "value": "author_of"}, {"source": "Quentin Fournier", "target": "Protein Language Models: Is Scaling Necessary?", "value": "author_of"}, {"source": "Robert M. Vernon", "target": "Protein Language Models: Is Scaling Necessary?", "value": "author_of"}, {"source": "Almer M. van der Sloot", "target": "Protein Language Models: Is Scaling Necessary?", "value": "author_of"}, {"source": "Benjamin Schulz", "target": "Protein Language Models: Is Scaling Necessary?", "value": "author_of"}, {"source": "Sarath Chandar", "target": "Protein Language Models: Is Scaling Necessary?", "value": "author_of"}, {"source": "C. Langmead", "target": "Protein Language Models: Is Scaling Necessary?", "value": "author_of"}, {"source": "Scott Friedman", "target": "Relating Word Embedding Gender Biases to Gender Gaps: A Cross-Cultural Analysis", "value": "author_of"}, {"source": "Sonja Schmer-Galunder", "target": "Relating Word Embedding Gender Biases to Gender Gaps: A Cross-Cultural Analysis", "value": "author_of"}, {"source": "Anthony Chen", "target": "Relating Word Embedding Gender Biases to Gender Gaps: A Cross-Cultural Analysis", "value": "author_of"}, {"source": "Jeffrey Rye", "target": "Relating Word Embedding Gender Biases to Gender Gaps: A Cross-Cultural Analysis", "value": "author_of"}, {"source": "Zhaohu Xing", "target": "SegMamba-V2: Long-Range Sequential Modeling Mamba for General 3-D Medical Image Segmentation", "value": "author_of"}, {"source": "Tian Ye", "target": "SegMamba-V2: Long-Range Sequential Modeling Mamba for General 3-D Medical Image Segmentation", "value": "author_of"}, {"source": "Yijun Yang", "target": "SegMamba-V2: Long-Range Sequential Modeling Mamba for General 3-D Medical Image Segmentation", "value": "author_of"}, {"source": "D. Cai", "target": "SegMamba-V2: Long-Range Sequential Modeling Mamba for General 3-D Medical Image Segmentation", "value": "author_of"}, {"source": "Baowen Gai", "target": "SegMamba-V2: Long-Range Sequential Modeling Mamba for General 3-D Medical Image Segmentation", "value": "author_of"}, {"source": "Xiao-Jian Wu", "target": "SegMamba-V2: Long-Range Sequential Modeling Mamba for General 3-D Medical Image Segmentation", "value": "author_of"}, {"source": "Feng Gao", "target": "SegMamba-V2: Long-Range Sequential Modeling Mamba for General 3-D Medical Image Segmentation", "value": "author_of"}, {"source": "Lei Zhu", "target": "SegMamba-V2: Long-Range Sequential Modeling Mamba for General 3-D Medical Image Segmentation", "value": "author_of"}, {"source": "Alexander C. Li", "target": "Generative Classifiers Avoid Shortcut Solutions", "value": "author_of"}, {"source": "Ananya Kumar", "target": "Generative Classifiers Avoid Shortcut Solutions", "value": "author_of"}, {"source": "Deepak Pathak", "target": "Generative Classifiers Avoid Shortcut Solutions", "value": "author_of"}, {"source": "Y. Sun", "target": "Edge Large AI Model Agent-Empowered Cognitive Multimodal Semantic Communication", "value": "author_of"}, {"source": "Yinqiu Liu", "target": "Edge Large AI Model Agent-Empowered Cognitive Multimodal Semantic Communication", "value": "author_of"}, {"source": "Shaoyong Guo", "target": "Edge Large AI Model Agent-Empowered Cognitive Multimodal Semantic Communication", "value": "author_of"}, {"source": "Xuesong Qiu", "target": "Edge Large AI Model Agent-Empowered Cognitive Multimodal Semantic Communication", "value": "author_of"}, {"source": "Jiewei Chen", "target": "Edge Large AI Model Agent-Empowered Cognitive Multimodal Semantic Communication", "value": "author_of"}, {"source": "Jiakai Hao", "target": "Edge Large AI Model Agent-Empowered Cognitive Multimodal Semantic Communication", "value": "author_of"}, {"source": "Dusist Niyato", "target": "Edge Large AI Model Agent-Empowered Cognitive Multimodal Semantic Communication", "value": "author_of"}, {"source": "Alec Radford", "target": "Language Models are Unsupervised Multitask Learners", "value": "author_of"}, {"source": "Jeff Wu", "target": "Language Models are Unsupervised Multitask Learners", "value": "author_of"}, {"source": "R. Child", "target": "Language Models are Unsupervised Multitask Learners", "value": "author_of"}, {"source": "D. Luan", "target": "Language Models are Unsupervised Multitask Learners", "value": "author_of"}, {"source": "Dario Amodei", "target": "Language Models are Unsupervised Multitask Learners", "value": "author_of"}, {"source": "I. Sutskever", "target": "Language Models are Unsupervised Multitask Learners", "value": "author_of"}, {"source": "Aaron Grattafiori", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Abhimanyu Dubey", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Abhinav Jauhri", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Abhinav Pandey", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Abhishek Kadian", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ahmad Al-Dahle", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Aiesha Letman", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Akhil Mathur", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Alan Schelten", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Alex Vaughan", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Amy Yang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Angela Fan", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Anirudh Goyal", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Anthony Hartshorn", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Aobo Yang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Archi Mitra", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Archie Sravankumar", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Artem Korenev", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Arthur Hinsvark", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Arun Rao", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Aston Zhang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Aurelien Rodriguez", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Austen Gregerson", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ava Spataru", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Baptiste Roziere", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Bethany Biron", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Binh Tang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Bobbie Chern", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Charlotte Caucheteux", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Chaya Nayak", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Chloe Bi", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Chris Marra", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Chris McConnell", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Christian Keller", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Christophe Touret", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Chunyang Wu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Corinne Wong", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Cristian Canton Ferrer", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Cyrus Nikolaidis", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Damien Allonsius", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Daniel Song", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Danielle Pintz", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Danny Livshits", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Danny Wyatt", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "David Esiobu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Dhruv Choudhary", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Dhruv Mahajan", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Diego Garcia-Olano", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Diego Perino", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Dieuwke Hupkes", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Egor Lakomkin", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ehab AlBadawy", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Elina Lobanova", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Emily Dinan", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Eric Michael Smith", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Filip Radenovic", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Francisco Guzm\u00e1n", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Frank Zhang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Gabriel Synnaeve", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Gabrielle Lee", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Georgia Lewis Anderson", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Govind Thattai", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Graeme Nail", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Gregoire Mialon", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Guan Pang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Guillem Cucurell", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Hailey Nguyen", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Hannah Korevaar", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Hu Xu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Hugo Touvron", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Iliyan Zarov", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Imanol Arrieta Ibarra", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Isabel Kloumann", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ishan Misra", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ivan Evtimov", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jack Zhang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jade Copet", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jaewon Lee", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jan Geffert", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jana Vranes", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jason Park", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jay Mahadeokar", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jeet Shah", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jelmer van der Linde", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jennifer Billock", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jenny Hong", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jenya Lee", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jeremy Fu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jianfeng Chi", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jianyu Huang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jiawen Liu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jie Wang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jiecao Yu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Joanna Bitton", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Joe Spisak", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jongsoo Park", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Joseph Rocca", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Joshua Johnstun", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Joshua Saxe", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Junteng Jia", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Kalyan Vasuden Alwala", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Karthik Prasad", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Kartikeya Upasani", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Kate Plawiak", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ke Li", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Kenneth Heafield", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Kevin Stone", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Khalid El-Arini", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Krithika Iyer", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Kshitiz Malik", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Kuenley Chiu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Kunal Bhalla", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Kushal Lakhotia", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Lauren Rantala-Yeary", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Laurens van der Maaten", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Lawrence Chen", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Liang Tan", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Liz Jenkins", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Louis Martin", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Lovish Madaan", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Lubo Malo", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Lukas Blecher", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Lukas Landzaat", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Luke de Oliveira", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Madeline Muzzi", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Mahesh Pasupuleti", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Mannat Singh", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Manohar Paluri", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Marcin Kardas", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Maria Tsimpoukelli", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Mathew Oldham", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Mathieu Rita", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Maya Pavlova", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Melanie Kambadur", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Mike Lewis", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Min Si", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Mitesh Kumar Singh", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Mona Hassan", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Naman Goyal", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Narjes Torabi", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Nikolay Bashlykov", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Nikolay Bogoychev", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Niladri Chatterji", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ning Zhang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Olivier Duchenne", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Onur \u00c7elebi", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Patrick Alrassy", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Pengchuan Zhang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Pengwei Li", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Petar Vasic", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Peter Weng", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Prajjwal Bhargava", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Pratik Dubal", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Praveen Krishnan", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Punit Singh Koura", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Puxin Xu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Qing He", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Qingxiao Dong", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ragavan Srinivasan", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Raj Ganapathy", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ramon Calderer", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ricardo Silveira Cabral", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Robert Stojnic", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Roberta Raileanu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Rohan Maheswari", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Rohit Girdhar", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Rohit Patel", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Romain Sauvestre", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ronnie Polidoro", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Roshan Sumbaly", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ross Taylor", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ruan Silva", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Rui Hou", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Rui Wang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Saghar Hosseini", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Sahana Chennabasappa", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Sanjay Singh", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Sean Bell", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Seohyun Sonia Kim", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Sergey Edunov", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Shaoliang Nie", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Sharan Narang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Sharath Raparthy", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Sheng Shen", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Shengye Wan", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Shruti Bhosale", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Shun Zhang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Simon Vandenhende", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Soumya Batra", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Spencer Whitman", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Sten Sootla", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Stephane Collot", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Suchin Gururangan", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Sydney Borodinsky", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Tamar Herman", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Tara Fowler", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Tarek Sheasha", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Thomas Georgiou", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Thomas Scialom", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Tobias Speckbacher", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Todor Mihaylov", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Tong Xiao", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ujjwal Karn", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Vedanuj Goswami", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Vibhor Gupta", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Vignesh Ramanathan", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Viktor Kerkez", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Vincent Gonguet", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Virginie Do", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Vish Vogeti", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "V\u00edtor Albiero", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Vladan Petrovic", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Weiwei Chu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Wenhan Xiong", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Wenyin Fu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Whitney Meers", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Xavier Martinet", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Xiaodong Wang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Xiaofang Wang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Xiaoqing Ellen Tan", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Xide Xia", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Xinfeng Xie", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Xuchao Jia", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Xuewei Wang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Yaelle Goldschlag", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Yashesh Gaur", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Yasmine Babaei", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Yi Wen", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Yiwen Song", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Yuchen Zhang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Yue Li", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Yuning Mao", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Zacharie Delpierre Coudert", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Zheng Yan", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Zhengxing Chen", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Zoe Papakipos", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Aaditya Singh", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Aayushi Srivastava", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Abha Jain", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Adam Kelsey", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Adam Shajnfeld", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Adithya Gangidi", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Adolfo Victoria", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ahuva Goldstand", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ajay Menon", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ajay Sharma", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Alex Boesenberg", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Alexei Baevski", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Allie Feinstein", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Amanda Kallet", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Amit Sangani", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Amos Teo", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Anam Yunus", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Andrei Lupu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Andres Alvarado", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Andrew Caples", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Andrew Gu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Andrew Ho", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Andrew Poulton", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Andrew Ryan", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ankit Ramchandani", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Annie Dong", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Annie Franco", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Anuj Goyal", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Aparajita Saraf", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Arkabandhu Chowdhury", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ashley Gabriel", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ashwin Bharambe", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Assaf Eisenman", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Azadeh Yazdan", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Beau James", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ben Maurer", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Benjamin Leonhardi", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Bernie Huang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Beth Loyd", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Beto De Paola", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Bhargavi Paranjape", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Bing Liu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Bo Wu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Boyu Ni", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Braden Hancock", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Bram Wasti", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Brandon Spence", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Brani Stojkovic", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Brian Gamido", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Britt Montalvo", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Carl Parker", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Carly Burton", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Catalina Mejia", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ce Liu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Changhan Wang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Changkyu Kim", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Chao Zhou", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Chester Hu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ching-Hsiang Chu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Chris Cai", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Chris Tindal", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Christoph Feichtenhofer", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Cynthia Gao", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Damon Civin", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Dana Beaty", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Daniel Kreymer", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Daniel Li", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "David Adkins", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "David Xu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Davide Testuggine", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Delia David", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Devi Parikh", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Diana Liskovich", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Didem Foss", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Dingkang Wang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Duc Le", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Dustin Holland", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Edward Dowling", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Eissa Jamil", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Elaine Montgomery", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Eleonora Presani", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Emily Hahn", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Emily Wood", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Eric-Tuan Le", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Erik Brinkman", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Esteban Arcaute", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Evan Dunbar", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Evan Smothers", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Fei Sun", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Felix Kreuk", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Feng Tian", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Filippos Kokkinos", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Firat Ozgenel", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Francesco Caggioni", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Frank Kanayet", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Frank Seide", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Gabriela Medina Florez", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Gabriella Schwarz", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Gada Badeer", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Georgia Swee", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Gil Halpern", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Grant Herman", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Grigory Sizov", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Guangyi", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Zhang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Guna Lakshminarayanan", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Hakan Inan", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Hamid Shojanazeri", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Han Zou", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Hannah Wang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Hanwen Zha", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Haroun Habeeb", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Harrison Rudolph", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Helen Suk", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Henry Aspegren", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Hunter Goldman", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Hongyuan Zhan", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ibrahim Damlaj", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Igor Molybog", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Igor Tufanov", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ilias Leontiadis", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Irina-Elena Veliche", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Itai Gat", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jake Weissman", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "James Geboski", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "James Kohli", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Janice Lam", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Japhet Asher", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jean-Baptiste Gaya", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jeff Marcus", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jeff Tang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jennifer Chan", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jenny Zhen", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jeremy Reizenstein", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jeremy Teboul", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jessica Zhong", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jian Jin", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jingyi Yang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Joe Cummings", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jon Carvill", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jon Shepard", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jonathan McPhie", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Jonathan Torres", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Josh Ginsburg", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Junjie Wang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Kai Wu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Kam Hou U", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Karan Saxena", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Kartikay Khandelwal", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Katayoun Zand", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Kathy Matosich", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Kaushik Veeraraghavan", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Kelly Michelena", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Keqian Li", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Kiran Jagadeesh", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Kun Huang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Kunal Chawla", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Kyle Huang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Lailin Chen", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Lakshya Garg", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Lavender A", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Leandro Silva", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Lee Bell", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Lei Zhang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Liangpeng Guo", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Licheng Yu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Liron Moshkovich", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Luca Wehrstedt", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Madian Khabsa", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Manav Avalani", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Manish Bhatt", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Martynas Mankus", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Matan Hasson", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Matthew Lennie", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Matthias Reso", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Maxim Groshev", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Maxim Naumov", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Maya Lathi", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Meghan Keneally", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Miao Liu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Michael L. Seltzer", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Michal Valko", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Michelle Restrepo", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Mihir Patel", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Mik Vyatskov", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Mikayel Samvelyan", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Mike Clark", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Mike Macey", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Mike Wang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Miquel Jubert Hermoso", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Mo Metanat", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Mohammad Rastegari", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Munish Bansal", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Nandhini Santhanam", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Natascha Parks", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Natasha White", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Navyata Bawa", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Nayan Singhal", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Nick Egebo", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Nicolas Usunier", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Nikhil Mehta", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Nikolay Pavlovich Laptev", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ning Dong", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Norman Cheng", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Oleg Chernoguz", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Olivia Hart", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Omkar Salpekar", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ozlem Kalinli", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Parkin Kent", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Parth Parekh", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Paul Saab", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Pavan Balaji", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Pedro Rittner", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Philip Bontrager", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Pierre Roux", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Piotr Dollar", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Polina Zvyagina", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Prashant Ratanchandani", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Pritish Yuvraj", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Qian Liang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Rachad Alao", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Rachel Rodriguez", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Rafi Ayub", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Raghotham Murthy", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Raghu Nayani", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Rahul Mitra", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Rangaprabhu Parthasarathy", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Raymond Li", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Rebekkah Hogan", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Robin Battey", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Rocky Wang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Russ Howes", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ruty Rinott", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Sachin Mehta", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Sachin Siby", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Sai Jayesh Bondu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Samyak Datta", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Sara Chugh", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Sara Hunt", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Sargun Dhillon", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Sasha Sidorov", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Satadru Pan", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Saurabh Mahajan", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Saurabh Verma", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Seiji Yamamoto", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Sharadh Ramaswamy", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Shaun Lindsay", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Shaun Lindsay", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Sheng Feng", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Shenghao Lin", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Shengxin Cindy Zha", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Shishir Patil", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Shiva Shankar", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Shuqiang Zhang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Shuqiang Zhang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Sinong Wang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Sneha Agarwal", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Soji Sajuyigbe", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Soumith Chintala", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Stephanie Max", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Stephen Chen", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Steve Kehoe", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Steve Satterfield", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Sudarshan Govindaprasad", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Sumit Gupta", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Summer Deng", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Sungmin Cho", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Sunny Virk", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Suraj Subramanian", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Sy Choudhury", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Sydney Goldman", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Tal Remez", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Tamar Glaser", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Tamara Best", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Thilo Koehler", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Thomas Robinson", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Tianhe Li", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Tianjun Zhang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Tim Matthews", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Timothy Chou", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Tzook Shaked", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Varun Vontimitta", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Victoria Ajayi", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Victoria Montanez", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Vijai Mohan", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Vinay Satish Kumar", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Vishal Mangla", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Vlad Ionescu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Vlad Poenaru", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Vlad Tiberiu Mihailescu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Vladimir Ivanov", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Wei Li", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Wenchen Wang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Wenwen Jiang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Wes Bouaziz", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Will Constable", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Xiaocheng Tang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Xiaojian Wu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Xiaolan Wang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Xilun Wu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Xinbo Gao", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Yaniv Kleinman", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Yanjun Chen", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ye Hu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ye Jia", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ye Qi", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Yenda Li", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Yilin Zhang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Ying Zhang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Yossi Adi", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Youngjin Nam", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Yu", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Wang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Yu Zhao", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Yuchen Hao", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Yundi Qian", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Yunlu Li", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Yuzi He", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Zach Rait", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Zachary DeVito", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Zef Rosnbrick", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Zhaoduo Wen", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Zhenyu Yang", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Zhiwei Zhao", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Zhiyu Ma", "target": "The Llama 3 Herd of Models", "value": "author_of"}, {"source": "Tianyi Li", "target": "A Survey on Diffusion Language Models", "value": "author_of"}, {"source": "Mingda Chen", "target": "A Survey on Diffusion Language Models", "value": "author_of"}, {"source": "Bowei Guo", "target": "A Survey on Diffusion Language Models", "value": "author_of"}, {"source": "Zhiqiang Shen", "target": "A Survey on Diffusion Language Models", "value": "author_of"}, {"source": "Jinjie Ni", "target": "Training Optimal Large Diffusion Language Models", "value": "author_of"}, {"source": "Qian Liu", "target": "Training Optimal Large Diffusion Language Models", "value": "author_of"}, {"source": "Chao Du", "target": "Training Optimal Large Diffusion Language Models", "value": "author_of"}, {"source": "Longxu Dou", "target": "Training Optimal Large Diffusion Language Models", "value": "author_of"}, {"source": "Hang Yan", "target": "Training Optimal Large Diffusion Language Models", "value": "author_of"}, {"source": "Zili Wang", "target": "Training Optimal Large Diffusion Language Models", "value": "author_of"}, {"source": "Tianyu Pang", "target": "Training Optimal Large Diffusion Language Models", "value": "author_of"}, {"source": "Michael Qizhe Shieh", "target": "Training Optimal Large Diffusion Language Models", "value": "author_of"}, {"source": "Siyan Zhao", "target": "Inpainting-Guided Policy Optimization for Diffusion Large Language Models", "value": "author_of"}, {"source": "Mengchen Liu", "target": "Inpainting-Guided Policy Optimization for Diffusion Large Language Models", "value": "author_of"}, {"source": "Jing Huang", "target": "Inpainting-Guided Policy Optimization for Diffusion Large Language Models", "value": "author_of"}, {"source": "Miao Liu", "target": "Inpainting-Guided Policy Optimization for Diffusion Large Language Models", "value": "author_of"}, {"source": "Chenyu Wang", "target": "Inpainting-Guided Policy Optimization for Diffusion Large Language Models", "value": "author_of"}, {"source": "Bo Liu", "target": "Inpainting-Guided Policy Optimization for Diffusion Large Language Models", "value": "author_of"}, {"source": "Yuandong Tian", "target": "Inpainting-Guided Policy Optimization for Diffusion Large Language Models", "value": "author_of"}, {"source": "Guan Pang", "target": "Inpainting-Guided Policy Optimization for Diffusion Large Language Models", "value": "author_of"}, {"source": "Sean Bell", "target": "Inpainting-Guided Policy Optimization for Diffusion Large Language Models", "value": "author_of"}, {"source": "Aditya Grover", "target": "Inpainting-Guided Policy Optimization for Diffusion Large Language Models", "value": "author_of"}, {"source": "Feiyu Chen", "target": "Inpainting-Guided Policy Optimization for Diffusion Large Language Models", "value": "author_of"}, {"source": "Marianne Arriola", "target": "Encoder-Decoder Diffusion Language Models for Efficient Training and Inference", "value": "author_of"}, {"source": "Yair Schiff", "target": "Encoder-Decoder Diffusion Language Models for Efficient Training and Inference", "value": "author_of"}, {"source": "Hao Phung", "target": "Encoder-Decoder Diffusion Language Models for Efficient Training and Inference", "value": "author_of"}, {"source": "Aaron Gokaslan", "target": "Encoder-Decoder Diffusion Language Models for Efficient Training and Inference", "value": "author_of"}, {"source": "Volodymyr Kuleshov", "target": "Encoder-Decoder Diffusion Language Models for Efficient Training and Inference", "value": "author_of"}, {"source": "Chenghao Fan", "target": "Stable-DiffCoder: Pushing the Frontier of Code Diffusion Large Language Model", "value": "author_of"}, {"source": "Wen Heng", "target": "Stable-DiffCoder: Pushing the Frontier of Code Diffusion Large Language Model", "value": "author_of"}, {"source": "Bo Li", "target": "Stable-DiffCoder: Pushing the Frontier of Code Diffusion Large Language Model", "value": "author_of"}, {"source": "Sichen Liu", "target": "Stable-DiffCoder: Pushing the Frontier of Code Diffusion Large Language Model", "value": "author_of"}, {"source": "Yuxuan Song", "target": "Stable-DiffCoder: Pushing the Frontier of Code Diffusion Large Language Model", "value": "author_of"}, {"source": "Jing Su", "target": "Stable-DiffCoder: Pushing the Frontier of Code Diffusion Large Language Model", "value": "author_of"}, {"source": "Xiaoye Qu", "target": "Stable-DiffCoder: Pushing the Frontier of Code Diffusion Large Language Model", "value": "author_of"}, {"source": "Kai Shen", "target": "Stable-DiffCoder: Pushing the Frontier of Code Diffusion Large Language Model", "value": "author_of"}, {"source": "Wei Wei", "target": "Stable-DiffCoder: Pushing the Frontier of Code Diffusion Large Language Model", "value": "author_of"}, {"source": "Chang Yang", "target": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "value": "author_of"}, {"source": "Chuang Zhou", "target": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "value": "author_of"}, {"source": "Yilin Xiao", "target": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "value": "author_of"}, {"source": "Su Dong", "target": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "value": "author_of"}, {"source": "Luyao Zhuang", "target": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "value": "author_of"}, {"source": "Yujing Zhang", "target": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "value": "author_of"}, {"source": "Zhu Wang", "target": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "value": "author_of"}, {"source": "Zijin Hong", "target": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "value": "author_of"}, {"source": "Zheng Yuan", "target": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "value": "author_of"}, {"source": "Zhishang Xiang", "target": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "value": "author_of"}, {"source": "Shengyuan Chen", "target": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "value": "author_of"}, {"source": "Huachi Zhou", "target": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "value": "author_of"}, {"source": "Qinggang Zhang", "target": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "value": "author_of"}, {"source": "Ninghao Liu", "target": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "value": "author_of"}, {"source": "Jinsong Su", "target": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "value": "author_of"}, {"source": "Xinrun Wang", "target": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "value": "author_of"}, {"source": "Yi Chang", "target": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "value": "author_of"}, {"source": "Xiao Huang", "target": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "value": "author_of"}, {"source": "Hao Lu", "target": "Empirical-MCTS: Continuous Agent Evolution via Dual-Experience Monte Carlo Tree Search", "value": "author_of"}, {"source": "Haoyuan Huang", "target": "Empirical-MCTS: Continuous Agent Evolution via Dual-Experience Monte Carlo Tree Search", "value": "author_of"}, {"source": "Yulin Zhou", "target": "Empirical-MCTS: Continuous Agent Evolution via Dual-Experience Monte Carlo Tree Search", "value": "author_of"}, {"source": "Chen Li", "target": "Empirical-MCTS: Continuous Agent Evolution via Dual-Experience Monte Carlo Tree Search", "value": "author_of"}, {"source": "Ningxin Zhu", "target": "Empirical-MCTS: Continuous Agent Evolution via Dual-Experience Monte Carlo Tree Search", "value": "author_of"}, {"source": "Yu Cheng", "target": "TAME: A Trustworthy Test-Time Evolution of Agent Memory with Systematic Benchmarking", "value": "author_of"}, {"source": "Jiuan Zhou", "target": "TAME: A Trustworthy Test-Time Evolution of Agent Memory with Systematic Benchmarking", "value": "author_of"}, {"source": "Yongkang Hu", "target": "TAME: A Trustworthy Test-Time Evolution of Agent Memory with Systematic Benchmarking", "value": "author_of"}, {"source": "Yihang Chen", "target": "TAME: A Trustworthy Test-Time Evolution of Agent Memory with Systematic Benchmarking", "value": "author_of"}, {"source": "Huichi Zhou", "target": "TAME: A Trustworthy Test-Time Evolution of Agent Memory with Systematic Benchmarking", "value": "author_of"}, {"source": "Mingang Chen", "target": "TAME: A Trustworthy Test-Time Evolution of Agent Memory with Systematic Benchmarking", "value": "author_of"}, {"source": "Zhizhong Zhang", "target": "TAME: A Trustworthy Test-Time Evolution of Agent Memory with Systematic Benchmarking", "value": "author_of"}, {"source": "Kun Shao", "target": "TAME: A Trustworthy Test-Time Evolution of Agent Memory with Systematic Benchmarking", "value": "author_of"}, {"source": "Yuan Xie", "target": "TAME: A Trustworthy Test-Time Evolution of Agent Memory with Systematic Benchmarking", "value": "author_of"}, {"source": "Zhaoxia Yin", "target": "TAME: A Trustworthy Test-Time Evolution of Agent Memory with Systematic Benchmarking", "value": "author_of"}, {"source": "Qirui Mi", "target": "ProcMEM: Learning Reusable Procedural Memory from Experience via Non-Parametric PPO for LLM Agents", "value": "author_of"}, {"source": "Zhijian Ma", "target": "ProcMEM: Learning Reusable Procedural Memory from Experience via Non-Parametric PPO for LLM Agents", "value": "author_of"}, {"source": "Mengyue Yang", "target": "ProcMEM: Learning Reusable Procedural Memory from Experience via Non-Parametric PPO for LLM Agents", "value": "author_of"}, {"source": "Haoxuan Li", "target": "ProcMEM: Learning Reusable Procedural Memory from Experience via Non-Parametric PPO for LLM Agents", "value": "author_of"}, {"source": "Yisen Wang", "target": "ProcMEM: Learning Reusable Procedural Memory from Experience via Non-Parametric PPO for LLM Agents", "value": "author_of"}, {"source": "Haifeng Zhang", "target": "ProcMEM: Learning Reusable Procedural Memory from Experience via Non-Parametric PPO for LLM Agents", "value": "author_of"}, {"source": "Jun Wang", "target": "ProcMEM: Learning Reusable Procedural Memory from Experience via Non-Parametric PPO for LLM Agents", "value": "author_of"}, {"source": "Mingyue Cheng", "target": "Position: Beyond Model-Centric Prediction -- Agentic Time Series Forecasting", "value": "author_of"}, {"source": "Xiaoyu Tao", "target": "Position: Beyond Model-Centric Prediction -- Agentic Time Series Forecasting", "value": "author_of"}, {"source": "Qi Liu", "target": "Position: Beyond Model-Centric Prediction -- Agentic Time Series Forecasting", "value": "author_of"}, {"source": "Ze Guo", "target": "Position: Beyond Model-Centric Prediction -- Agentic Time Series Forecasting", "value": "author_of"}, {"source": "Enhong Chen", "target": "Position: Beyond Model-Centric Prediction -- Agentic Time Series Forecasting", "value": "author_of"}, {"source": "Long Ouyang", "target": "Training language models to follow instructions with human feedback", "value": "author_of"}, {"source": "Jeff Wu", "target": "Training language models to follow instructions with human feedback", "value": "author_of"}, {"source": "Xu Jiang", "target": "Training language models to follow instructions with human feedback", "value": "author_of"}, {"source": "Diogo Almeida", "target": "Training language models to follow instructions with human feedback", "value": "author_of"}, {"source": "Carroll L. Wainwright", "target": "Training language models to follow instructions with human feedback", "value": "author_of"}, {"source": "Pamela Mishkin", "target": "Training language models to follow instructions with human feedback", "value": "author_of"}, {"source": "Chong Zhang", "target": "Training language models to follow instructions with human feedback", "value": "author_of"}, {"source": "Sandhini Agarwal", "target": "Training language models to follow instructions with human feedback", "value": "author_of"}, {"source": "Katarina Slama", "target": "Training language models to follow instructions with human feedback", "value": "author_of"}, {"source": "Alex Ray", "target": "Training language models to follow instructions with human feedback", "value": "author_of"}, {"source": "John Schulman", "target": "Training language models to follow instructions with human feedback", "value": "author_of"}, {"source": "Jacob Hilton", "target": "Training language models to follow instructions with human feedback", "value": "author_of"}, {"source": "Fraser Kelton", "target": "Training language models to follow instructions with human feedback", "value": "author_of"}, {"source": "Luke Miller", "target": "Training language models to follow instructions with human feedback", "value": "author_of"}, {"source": "Maddie Simens", "target": "Training language models to follow instructions with human feedback", "value": "author_of"}, {"source": "Amanda Askell", "target": "Training language models to follow instructions with human feedback", "value": "author_of"}, {"source": "Peter Welinder", "target": "Training language models to follow instructions with human feedback", "value": "author_of"}, {"source": "Paul Christiano", "target": "Training language models to follow instructions with human feedback", "value": "author_of"}, {"source": "Jan Leike", "target": "Training language models to follow instructions with human feedback", "value": "author_of"}, {"source": "Ryan Lowe", "target": "Training language models to follow instructions with human feedback", "value": "author_of"}, {"source": "Aakanksha Chowdhery", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Sharan Narang", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Jacob Devlin", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Maarten Bosma", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Gaurav Mishra", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Adam Roberts", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Paul Barham", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Hyung Won Chung", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Charles Sutton", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Sebastian Gehrmann", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Parker Schuh", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Kensen Shi", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Sasha Tsvyashchenko", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Joshua Maynez", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Abhishek Rao", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Parker Barnes", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Yi Tay", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Noam Shazeer", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Vinodkumar Prabhakaran", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Emily Reif", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Nan Du", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Ben Hutchinson", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Reiner Pope", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "James Bradbury", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Jacob Austin", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Michael Isard", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Guy Gur-Ari", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Pengcheng Yin", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Toju Duke", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Anselm Levskaya", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Sanjay Ghemawat", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Sunipa Dev", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Henryk Michalewski", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Xavier Garcia", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Vedant Misra", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Kevin Robinson", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Liam Fedus", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Denny Zhou", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Daphne Ippolito", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "David Luan", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Hyeontaek Lim", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Barret Zoph", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Alexander Spiridonov", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Ryan Sepassi", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "David Dohan", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Shivani Agrawal", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Mark Omernick", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Andrew M. Dai", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Thanumalayan Sankaranarayana Pillai", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Marie Pellat", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Aitor Lewkowycz", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Erica Moreira", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Rewon Child", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Oleksandr Polozov", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Katherine Lee", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Zongwei Zhou", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Xuezhi Wang", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Brennan Saeta", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Mark Diaz", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Orhan Firat", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Michele Catasta", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Jason Wei", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Kathy Meier-Hellstern", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Douglas Eck", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Jeff Dean", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Slav Petrov", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Noah Fiedel", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "author_of"}, {"source": "Shunyu Yao", "target": "ReAct: Synergizing Reasoning and Acting in Language Models", "value": "author_of"}, {"source": "Jeffrey Zhao", "target": "ReAct: Synergizing Reasoning and Acting in Language Models", "value": "author_of"}, {"source": "Dian Yu", "target": "ReAct: Synergizing Reasoning and Acting in Language Models", "value": "author_of"}, {"source": "Nan Du", "target": "ReAct: Synergizing Reasoning and Acting in Language Models", "value": "author_of"}, {"source": "Izhak Shafran", "target": "ReAct: Synergizing Reasoning and Acting in Language Models", "value": "author_of"}, {"source": "Karthik Narasimhan", "target": "ReAct: Synergizing Reasoning and Acting in Language Models", "value": "author_of"}, {"source": "Yuan Cao", "target": "ReAct: Synergizing Reasoning and Acting in Language Models", "value": "author_of"}, {"source": "Zhong-Zhi Li", "target": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "value": "author_of"}, {"source": "Duzhen Zhang", "target": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "value": "author_of"}, {"source": "Ming-Liang Zhang", "target": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "value": "author_of"}, {"source": "Jiaxin Zhang", "target": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "value": "author_of"}, {"source": "Zengyan Liu", "target": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "value": "author_of"}, {"source": "Yuxuan Yao", "target": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "value": "author_of"}, {"source": "Haotian Xu", "target": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "value": "author_of"}, {"source": "Junhao Zheng", "target": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "value": "author_of"}, {"source": "Pei-Jie Wang", "target": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "value": "author_of"}, {"source": "Xiuyi Chen", "target": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "value": "author_of"}, {"source": "Yingying Zhang", "target": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "value": "author_of"}, {"source": "Fei Yin", "target": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "value": "author_of"}, {"source": "Jiahua Dong", "target": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "value": "author_of"}, {"source": "Zhiwei Li", "target": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "value": "author_of"}, {"source": "Bao-Long Bi", "target": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "value": "author_of"}, {"source": "Ling-Rui Mei", "target": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "value": "author_of"}, {"source": "Junfeng Fang", "target": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "value": "author_of"}, {"source": "Xiao Liang", "target": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "value": "author_of"}, {"source": "Zhijiang Guo", "target": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "value": "author_of"}, {"source": "Le Song", "target": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "value": "author_of"}, {"source": "Cheng-Lin Liu", "target": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "value": "author_of"}, {"source": "Yuxuan Huang", "target": "Deep Research Agents: A Systematic Examination And Roadmap", "value": "author_of"}, {"source": "Yihang Chen", "target": "Deep Research Agents: A Systematic Examination And Roadmap", "value": "author_of"}, {"source": "Haozheng Zhang", "target": "Deep Research Agents: A Systematic Examination And Roadmap", "value": "author_of"}, {"source": "Kang Li", "target": "Deep Research Agents: A Systematic Examination And Roadmap", "value": "author_of"}, {"source": "Huichi Zhou", "target": "Deep Research Agents: A Systematic Examination And Roadmap", "value": "author_of"}, {"source": "Meng Fang", "target": "Deep Research Agents: A Systematic Examination And Roadmap", "value": "author_of"}, {"source": "Linyi Yang", "target": "Deep Research Agents: A Systematic Examination And Roadmap", "value": "author_of"}, {"source": "Xiaoguang Li", "target": "Deep Research Agents: A Systematic Examination And Roadmap", "value": "author_of"}, {"source": "Lifeng Shang", "target": "Deep Research Agents: A Systematic Examination And Roadmap", "value": "author_of"}, {"source": "Songcen Xu", "target": "Deep Research Agents: A Systematic Examination And Roadmap", "value": "author_of"}, {"source": "Jianye Hao", "target": "Deep Research Agents: A Systematic Examination And Roadmap", "value": "author_of"}, {"source": "Kun Shao", "target": "Deep Research Agents: A Systematic Examination And Roadmap", "value": "author_of"}, {"source": "Jun Wang", "target": "Deep Research Agents: A Systematic Examination And Roadmap", "value": "author_of"}, {"source": "Zheyuan Yang", "target": "Table-R1: Inference-Time Scaling for Table Reasoning", "value": "author_of"}, {"source": "Lyuhao Chen", "target": "Table-R1: Inference-Time Scaling for Table Reasoning", "value": "author_of"}, {"source": "Arman Cohan", "target": "Table-R1: Inference-Time Scaling for Table Reasoning", "value": "author_of"}, {"source": "Yilun Zhao", "target": "Table-R1: Inference-Time Scaling for Table Reasoning", "value": "author_of"}, {"source": "Mingyue Cheng", "target": "Mind2Report: A Cognitive Deep Research Agent for Expert-Level Commercial Report Synthesis", "value": "author_of"}, {"source": "Daoyu Wang", "target": "Mind2Report: A Cognitive Deep Research Agent for Expert-Level Commercial Report Synthesis", "value": "author_of"}, {"source": "Qi Liu", "target": "Mind2Report: A Cognitive Deep Research Agent for Expert-Level Commercial Report Synthesis", "value": "author_of"}, {"source": "Shuo Yu", "target": "Mind2Report: A Cognitive Deep Research Agent for Expert-Level Commercial Report Synthesis", "value": "author_of"}, {"source": "Xiaoyu Tao", "target": "Mind2Report: A Cognitive Deep Research Agent for Expert-Level Commercial Report Synthesis", "value": "author_of"}, {"source": "Yuqian Wang", "target": "Mind2Report: A Cognitive Deep Research Agent for Expert-Level Commercial Report Synthesis", "value": "author_of"}, {"source": "Chengzhong Chu", "target": "Mind2Report: A Cognitive Deep Research Agent for Expert-Level Commercial Report Synthesis", "value": "author_of"}, {"source": "Yu Duan", "target": "Mind2Report: A Cognitive Deep Research Agent for Expert-Level Commercial Report Synthesis", "value": "author_of"}, {"source": "Mingkang Long", "target": "Mind2Report: A Cognitive Deep Research Agent for Expert-Level Commercial Report Synthesis", "value": "author_of"}, {"source": "Enhong Chen", "target": "Mind2Report: A Cognitive Deep Research Agent for Expert-Level Commercial Report Synthesis", "value": "author_of"}, {"source": "Tingyue Pan", "target": "PaperScout: An Autonomous Agent for Academic Paper Search with Process-Aware Sequence-Level Policy Optimization", "value": "author_of"}, {"source": "Jie Ouyang", "target": "PaperScout: An Autonomous Agent for Academic Paper Search with Process-Aware Sequence-Level Policy Optimization", "value": "author_of"}, {"source": "Mingyue Cheng", "target": "PaperScout: An Autonomous Agent for Academic Paper Search with Process-Aware Sequence-Level Policy Optimization", "value": "author_of"}, {"source": "Qingchuan Li", "target": "PaperScout: An Autonomous Agent for Academic Paper Search with Process-Aware Sequence-Level Policy Optimization", "value": "author_of"}, {"source": "Zirui Liu", "target": "PaperScout: An Autonomous Agent for Academic Paper Search with Process-Aware Sequence-Level Policy Optimization", "value": "author_of"}, {"source": "Mingfan Pan", "target": "PaperScout: An Autonomous Agent for Academic Paper Search with Process-Aware Sequence-Level Policy Optimization", "value": "author_of"}, {"source": "Shuo Yu", "target": "PaperScout: An Autonomous Agent for Academic Paper Search with Process-Aware Sequence-Level Policy Optimization", "value": "author_of"}, {"source": "Qi Liu", "target": "PaperScout: An Autonomous Agent for Academic Paper Search with Process-Aware Sequence-Level Policy Optimization", "value": "author_of"}, {"source": "Jinmiao Zhao", "target": "Gradient-Guided Learning Network for Infrared Small Target Detection", "value": "author_of"}, {"source": "Chuang Yu", "target": "Gradient-Guided Learning Network for Infrared Small Target Detection", "value": "author_of"}, {"source": "Zelin Shi", "target": "Gradient-Guided Learning Network for Infrared Small Target Detection", "value": "author_of"}, {"source": "Yunpeng Liu", "target": "Gradient-Guided Learning Network for Infrared Small Target Detection", "value": "author_of"}, {"source": "Yingdi Zhang", "target": "Gradient-Guided Learning Network for Infrared Small Target Detection", "value": "author_of"}, {"source": "Waleed Khalid", "target": "A Retrieval-Augmented Generation Approach to Extracting Algorithmic Logic from Neural Networks", "value": "author_of"}, {"source": "Dmitry Ignatov", "target": "A Retrieval-Augmented Generation Approach to Extracting Algorithmic Logic from Neural Networks", "value": "author_of"}, {"source": "Radu Timofte", "target": "A Retrieval-Augmented Generation Approach to Extracting Algorithmic Logic from Neural Networks", "value": "author_of"}, {"source": "Yu Tian", "target": "CenterMamba-SAM: Center-Prioritized Scanning and Temporal Prototypes for Brain Lesion Segmentation", "value": "author_of"}, {"source": "Zhongheng Yang", "target": "CenterMamba-SAM: Center-Prioritized Scanning and Temporal Prototypes for Brain Lesion Segmentation", "value": "author_of"}, {"source": "Chenshi Liu", "target": "CenterMamba-SAM: Center-Prioritized Scanning and Temporal Prototypes for Brain Lesion Segmentation", "value": "author_of"}, {"source": "Yiyun Su", "target": "CenterMamba-SAM: Center-Prioritized Scanning and Temporal Prototypes for Brain Lesion Segmentation", "value": "author_of"}, {"source": "Ziwei Hong", "target": "CenterMamba-SAM: Center-Prioritized Scanning and Temporal Prototypes for Brain Lesion Segmentation", "value": "author_of"}, {"source": "Zexi Gong", "target": "CenterMamba-SAM: Center-Prioritized Scanning and Temporal Prototypes for Brain Lesion Segmentation", "value": "author_of"}, {"source": "Jingyuan Xu", "target": "CenterMamba-SAM: Center-Prioritized Scanning and Temporal Prototypes for Brain Lesion Segmentation", "value": "author_of"}, {"source": "Yang Lu", "target": "IMobileTransformer: A fusion-based lightweight model for rice disease identification", "value": "author_of"}, {"source": "Haoyang Zhou", "target": "IMobileTransformer: A fusion-based lightweight model for rice disease identification", "value": "author_of"}, {"source": "Peng Wang", "target": "IMobileTransformer: A fusion-based lightweight model for rice disease identification", "value": "author_of"}, {"source": "Erzhi Wang", "target": "IMobileTransformer: A fusion-based lightweight model for rice disease identification", "value": "author_of"}, {"source": "Gongfa Li", "target": "IMobileTransformer: A fusion-based lightweight model for rice disease identification", "value": "author_of"}, {"source": "Tongjian Yu", "target": "IMobileTransformer: A fusion-based lightweight model for rice disease identification", "value": "author_of"}, {"source": "Isaac Robinson", "target": "RF-DETR: Neural Architecture Search for Real-Time Detection Transformers", "value": "author_of"}, {"source": "Peter Robicheaux", "target": "RF-DETR: Neural Architecture Search for Real-Time Detection Transformers", "value": "author_of"}, {"source": "Matvei Popov", "target": "RF-DETR: Neural Architecture Search for Real-Time Detection Transformers", "value": "author_of"}, {"source": "Deva Ramanan", "target": "RF-DETR: Neural Architecture Search for Real-Time Detection Transformers", "value": "author_of"}, {"source": "Neehar Peri", "target": "RF-DETR: Neural Architecture Search for Real-Time Detection Transformers", "value": "author_of"}, {"source": "Jinhui Yi", "target": "Non-invasive diagnosis of nutrient deficiencies in winter wheat and winter rye using UAV-based RGB images", "value": "author_of"}, {"source": "Gina Lopez", "target": "Non-invasive diagnosis of nutrient deficiencies in winter wheat and winter rye using UAV-based RGB images", "value": "author_of"}, {"source": "S. Hadir", "target": "Non-invasive diagnosis of nutrient deficiencies in winter wheat and winter rye using UAV-based RGB images", "value": "author_of"}, {"source": "Jan Weyler", "target": "Non-invasive diagnosis of nutrient deficiencies in winter wheat and winter rye using UAV-based RGB images", "value": "author_of"}, {"source": "Lasse Klingbeil", "target": "Non-invasive diagnosis of nutrient deficiencies in winter wheat and winter rye using UAV-based RGB images", "value": "author_of"}, {"source": "Marion Deichmann", "target": "Non-invasive diagnosis of nutrient deficiencies in winter wheat and winter rye using UAV-based RGB images", "value": "author_of"}, {"source": "Juergen Gall", "target": "Non-invasive diagnosis of nutrient deficiencies in winter wheat and winter rye using UAV-based RGB images", "value": "author_of"}, {"source": "S. J. Seidel", "target": "Non-invasive diagnosis of nutrient deficiencies in winter wheat and winter rye using UAV-based RGB images", "value": "author_of"}, {"source": "Haoding Xu", "target": "Deep learning models for efficient geotechnical predictions: reducing training effort and data requirements with transfer learning", "value": "author_of"}, {"source": "Xuzhen He", "target": "Deep learning models for efficient geotechnical predictions: reducing training effort and data requirements with transfer learning", "value": "author_of"}, {"source": "Shaoheng Dai", "target": "Deep learning models for efficient geotechnical predictions: reducing training effort and data requirements with transfer learning", "value": "author_of"}, {"source": "Caihui Zhu", "target": "Deep learning models for efficient geotechnical predictions: reducing training effort and data requirements with transfer learning", "value": "author_of"}, {"source": "F. Shan", "target": "Deep learning models for efficient geotechnical predictions: reducing training effort and data requirements with transfer learning", "value": "author_of"}, {"source": "Qin Zhao", "target": "Deep learning models for efficient geotechnical predictions: reducing training effort and data requirements with transfer learning", "value": "author_of"}, {"source": "Faning Dang", "target": "Deep learning models for efficient geotechnical predictions: reducing training effort and data requirements with transfer learning", "value": "author_of"}, {"source": "Daichao Sheng", "target": "Deep learning models for efficient geotechnical predictions: reducing training effort and data requirements with transfer learning", "value": "author_of"}, {"source": "Zhou Wang", "target": "Image quality assessment: from error visibility to structural similarity", "value": "author_of"}, {"source": "A. Bovik", "target": "Image quality assessment: from error visibility to structural similarity", "value": "author_of"}, {"source": "H. Sheikh", "target": "Image quality assessment: from error visibility to structural similarity", "value": "author_of"}, {"source": "Eero P. Simoncelli", "target": "Image quality assessment: from error visibility to structural similarity", "value": "author_of"}, {"source": "Wei Cao", "target": "FreeOrbit4D: Training-Free Arbitrary Camera Redirection for Monocular Videos via Geometry-Complete 4D Reconstruction", "value": "author_of"}, {"source": "Hao Zhang", "target": "FreeOrbit4D: Training-Free Arbitrary Camera Redirection for Monocular Videos via Geometry-Complete 4D Reconstruction", "value": "author_of"}, {"source": "Fengrui Tian", "target": "FreeOrbit4D: Training-Free Arbitrary Camera Redirection for Monocular Videos via Geometry-Complete 4D Reconstruction", "value": "author_of"}, {"source": "Yulun Wu", "target": "FreeOrbit4D: Training-Free Arbitrary Camera Redirection for Monocular Videos via Geometry-Complete 4D Reconstruction", "value": "author_of"}, {"source": "Yingying Li", "target": "FreeOrbit4D: Training-Free Arbitrary Camera Redirection for Monocular Videos via Geometry-Complete 4D Reconstruction", "value": "author_of"}, {"source": "Shenlong Wang", "target": "FreeOrbit4D: Training-Free Arbitrary Camera Redirection for Monocular Videos via Geometry-Complete 4D Reconstruction", "value": "author_of"}, {"source": "Ning Yu", "target": "FreeOrbit4D: Training-Free Arbitrary Camera Redirection for Monocular Videos via Geometry-Complete 4D Reconstruction", "value": "author_of"}, {"source": "Yaoyao Liu", "target": "FreeOrbit4D: Training-Free Arbitrary Camera Redirection for Monocular Videos via Geometry-Complete 4D Reconstruction", "value": "author_of"}, {"source": "Yuxue Yang", "target": "NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos", "value": "author_of"}, {"source": "Lue Fan", "target": "NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos", "value": "author_of"}, {"source": "Ziqi Shi", "target": "NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos", "value": "author_of"}, {"source": "Junran Peng", "target": "NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos", "value": "author_of"}, {"source": "Feng Wang", "target": "NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos", "value": "author_of"}, {"source": "Zhaoxiang Zhang", "target": "NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos", "value": "author_of"}, {"source": "William Peebles", "target": "Scalable Diffusion Models with Transformers", "value": "author_of"}, {"source": "Saining Xie", "target": "Scalable Diffusion Models with Transformers", "value": "author_of"}, {"source": "Jianlin Su", "target": "RoFormer: Enhanced Transformer with Rotary Position Embedding", "value": "author_of"}, {"source": "Yu Lu", "target": "RoFormer: Enhanced Transformer with Rotary Position Embedding", "value": "author_of"}, {"source": "Shengfeng Pan", "target": "RoFormer: Enhanced Transformer with Rotary Position Embedding", "value": "author_of"}, {"source": "Ahmed Murtadha", "target": "RoFormer: Enhanced Transformer with Rotary Position Embedding", "value": "author_of"}, {"source": "Bo Wen", "target": "RoFormer: Enhanced Transformer with Rotary Position Embedding", "value": "author_of"}, {"source": "Yunfeng Liu", "target": "RoFormer: Enhanced Transformer with Rotary Position Embedding", "value": "author_of"}, {"source": "Sifan Tu", "target": "The Role of World Models in Shaping Autonomous Driving: A Comprehensive Survey", "value": "author_of"}, {"source": "Xin Zhou", "target": "The Role of World Models in Shaping Autonomous Driving: A Comprehensive Survey", "value": "author_of"}, {"source": "Dingkang Liang", "target": "The Role of World Models in Shaping Autonomous Driving: A Comprehensive Survey", "value": "author_of"}, {"source": "Xingyu Jiang", "target": "The Role of World Models in Shaping Autonomous Driving: A Comprehensive Survey", "value": "author_of"}, {"source": "Yumeng Zhang", "target": "The Role of World Models in Shaping Autonomous Driving: A Comprehensive Survey", "value": "author_of"}, {"source": "Xiaofan Li", "target": "The Role of World Models in Shaping Autonomous Driving: A Comprehensive Survey", "value": "author_of"}, {"source": "Xiang Bai", "target": "The Role of World Models in Shaping Autonomous Driving: A Comprehensive Survey", "value": "author_of"}, {"source": "Andreas Geiger", "target": "Vision meets robotics: The KITTI dataset", "value": "author_of"}, {"source": "Philip Lenz", "target": "Vision meets robotics: The KITTI dataset", "value": "author_of"}, {"source": "C. Stiller", "target": "Vision meets robotics: The KITTI dataset", "value": "author_of"}, {"source": "R. Urtasun", "target": "Vision meets robotics: The KITTI dataset", "value": "author_of"}, {"source": "S. Umeyama", "target": "Least-Squares Estimation of Transformation Parameters Between Two Point Patterns", "value": "author_of"}, {"source": "Run Wang", "target": "FlexMap: Generalized HD Map Construction from Flexible Camera Configurations", "value": "author_of"}, {"source": "Chaoyi Zhou", "target": "FlexMap: Generalized HD Map Construction from Flexible Camera Configurations", "value": "author_of"}, {"source": "Amir Salarpour", "target": "FlexMap: Generalized HD Map Construction from Flexible Camera Configurations", "value": "author_of"}, {"source": "Xi Liu", "target": "FlexMap: Generalized HD Map Construction from Flexible Camera Configurations", "value": "author_of"}, {"source": "Zhi-Qi Cheng", "target": "FlexMap: Generalized HD Map Construction from Flexible Camera Configurations", "value": "author_of"}, {"source": "Feng Luo", "target": "FlexMap: Generalized HD Map Construction from Flexible Camera Configurations", "value": "author_of"}, {"source": "Mert D. Pes\u00e9", "target": "FlexMap: Generalized HD Map Construction from Flexible Camera Configurations", "value": "author_of"}, {"source": "Siyu Huang", "target": "FlexMap: Generalized HD Map Construction from Flexible Camera Configurations", "value": "author_of"}, {"source": "Xingbang Hao", "target": "Deep Learning", "value": "author_of"}, {"source": "Guigang Zhang", "target": "Deep Learning", "value": "author_of"}, {"source": "Shang Ma", "target": "Deep Learning", "value": "author_of"}, {"source": "Nikhil Keetha", "target": "MapAnything: Universal Feed-Forward Metric 3D Reconstruction", "value": "author_of"}, {"source": "Norman M\u00fcller", "target": "MapAnything: Universal Feed-Forward Metric 3D Reconstruction", "value": "author_of"}, {"source": "Johannes Sch\u00f6nberger", "target": "MapAnything: Universal Feed-Forward Metric 3D Reconstruction", "value": "author_of"}, {"source": "Lorenzo Porzi", "target": "MapAnything: Universal Feed-Forward Metric 3D Reconstruction", "value": "author_of"}, {"source": "Yuchen Zhang", "target": "MapAnything: Universal Feed-Forward Metric 3D Reconstruction", "value": "author_of"}, {"source": "Tobias Fischer", "target": "MapAnything: Universal Feed-Forward Metric 3D Reconstruction", "value": "author_of"}, {"source": "Arno Knapitsch", "target": "MapAnything: Universal Feed-Forward Metric 3D Reconstruction", "value": "author_of"}, {"source": "Duncan Zauss", "target": "MapAnything: Universal Feed-Forward Metric 3D Reconstruction", "value": "author_of"}, {"source": "Ethan Weber", "target": "MapAnything: Universal Feed-Forward Metric 3D Reconstruction", "value": "author_of"}, {"source": "Nelson Antunes", "target": "MapAnything: Universal Feed-Forward Metric 3D Reconstruction", "value": "author_of"}, {"source": "Jonathon Luiten", "target": "MapAnything: Universal Feed-Forward Metric 3D Reconstruction", "value": "author_of"}, {"source": "Manuel Lopez-Antequera", "target": "MapAnything: Universal Feed-Forward Metric 3D Reconstruction", "value": "author_of"}, {"source": "Samuel Rota Bul\u00f2", "target": "MapAnything: Universal Feed-Forward Metric 3D Reconstruction", "value": "author_of"}, {"source": "Christian Richardt", "target": "MapAnything: Universal Feed-Forward Metric 3D Reconstruction", "value": "author_of"}, {"source": "Deva Ramanan", "target": "MapAnything: Universal Feed-Forward Metric 3D Reconstruction", "value": "author_of"}, {"source": "Sebastian Scherer", "target": "MapAnything: Universal Feed-Forward Metric 3D Reconstruction", "value": "author_of"}, {"source": "Peter Kontschieder", "target": "MapAnything: Universal Feed-Forward Metric 3D Reconstruction", "value": "author_of"}, {"source": "Team Seedream", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": ":", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Yunpeng Chen", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Yu Gao", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Lixue Gong", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Meng Guo", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Qiushan Guo", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Zhiyao Guo", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Xiaoxia Hou", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Weilin Huang", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Yixuan Huang", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Xiaowen Jian", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Huafeng Kuang", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Zhichao Lai", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Fanshi Li", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Liang Li", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Xiaochen Lian", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Chao Liao", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Liyang Liu", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Wei Liu", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Yanzuo Lu", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Zhengxiong Luo", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Tongtong Ou", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Guang Shi", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Yichun Shi", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Shiqi Sun", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Yu Tian", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Zhi Tian", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Peng Wang", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Rui Wang", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Xun Wang", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Ye Wang", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Guofeng Wu", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Jie Wu", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Wenxu Wu", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Yonghui Wu", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Xin Xia", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Xuefeng Xiao", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Shuang Xu", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Xin Yan", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Ceyuan Yang", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Jianchao Yang", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Zhonghua Zhai", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Chenlin Zhang", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Heng Zhang", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Qi Zhang", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Xinyu Zhang", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Yuwei Zhang", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Shijia Zhao", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Wenliang Zhao", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Wenjia Zhu", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Junyan Ye", "target": "Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation", "value": "author_of"}, {"source": "Dongzhi Jiang", "target": "Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation", "value": "author_of"}, {"source": "Zihao Wang", "target": "Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation", "value": "author_of"}, {"source": "Leqi Zhu", "target": "Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation", "value": "author_of"}, {"source": "Zhenghao Hu", "target": "Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation", "value": "author_of"}, {"source": "Zilong Huang", "target": "Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation", "value": "author_of"}, {"source": "Jun He", "target": "Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation", "value": "author_of"}, {"source": "Zhiyuan Yan", "target": "Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation", "value": "author_of"}, {"source": "Jinghua Yu", "target": "Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation", "value": "author_of"}, {"source": "Hongsheng Li", "target": "Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation", "value": "author_of"}, {"source": "Conghui He", "target": "Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation", "value": "author_of"}, {"source": "Weijia Li", "target": "Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation", "value": "author_of"}, {"source": "Yi Xin", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Qi Qin", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Siqi Luo", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Kaiwen Zhu", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Juncheng Yan", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Yan Tai", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Jiayi Lei", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Yuewen Cao", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Keqi Wang", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Yibin Wang", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Jinbin Bai", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Qian Yu", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Dengyang Jiang", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Yuandong Pu", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Haoxing Chen", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Le Zhuo", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Junjun He", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Gen Luo", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Tianbin Li", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Ming Hu", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Jin Ye", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Shenglong Ye", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Bo Zhang", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Chang Xu", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Wenhai Wang", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Hongsheng Li", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Guangtao Zhai", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Tianfan Xue", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Bin Fu", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Xiaohong Liu", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Yu Qiao", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "Yihao Liu", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "author_of"}, {"source": "NextStep Team", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Chunrui Han", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Guopeng Li", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Jingwei Wu", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Quan Sun", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Yan Cai", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Yuang Peng", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Zheng Ge", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Deyu Zhou", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Haomiao Tang", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Hongyu Zhou", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Kenkun Liu", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Ailin Huang", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Bin Wang", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Changxin Miao", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Deshan Sun", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "En Yu", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Fukun Yin", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Gang Yu", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Hao Nie", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Haoran Lv", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Hanpeng Hu", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Jia Wang", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Jian Zhou", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Jianjian Sun", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Kaijun Tan", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Kang An", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Kangheng Lin", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Liang Zhao", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Mei Chen", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Peng Xing", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Rui Wang", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Shiyu Liu", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Shutao Xia", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Tianhao You", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Wei Ji", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Xianfang Zeng", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Xin Han", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Xuelin Zhang", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Yana Wei", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Yanming Xu", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Yimin Jiang", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Yingming Wang", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Yu Zhou", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Yucheng Han", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Ziyang Meng", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Binxing Jiao", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Daxin Jiang", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Xiangyu Zhang", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Yibo Zhu", "target": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "value": "author_of"}, {"source": "Yinhan Liu", "target": "RoBERTa: A Robustly Optimized BERT Pretraining Approach", "value": "author_of"}, {"source": "Myle Ott", "target": "RoBERTa: A Robustly Optimized BERT Pretraining Approach", "value": "author_of"}, {"source": "Naman Goyal", "target": "RoBERTa: A Robustly Optimized BERT Pretraining Approach", "value": "author_of"}, {"source": "Jingfei Du", "target": "RoBERTa: A Robustly Optimized BERT Pretraining Approach", "value": "author_of"}, {"source": "Mandar Joshi", "target": "RoBERTa: A Robustly Optimized BERT Pretraining Approach", "value": "author_of"}, {"source": "Danqi Chen", "target": "RoBERTa: A Robustly Optimized BERT Pretraining Approach", "value": "author_of"}, {"source": "Omer Levy", "target": "RoBERTa: A Robustly Optimized BERT Pretraining Approach", "value": "author_of"}, {"source": "Mike Lewis", "target": "RoBERTa: A Robustly Optimized BERT Pretraining Approach", "value": "author_of"}, {"source": "Luke Zettlemoyer", "target": "RoBERTa: A Robustly Optimized BERT Pretraining Approach", "value": "author_of"}, {"source": "Veselin Stoyanov", "target": "RoBERTa: A Robustly Optimized BERT Pretraining Approach", "value": "author_of"}, {"source": "DeepSeek-AI", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Daya Guo", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Dejian Yang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Haowei Zhang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Junxiao Song", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Peiyi Wang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Qihao Zhu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Runxin Xu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Ruoyu Zhang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Shirong Ma", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Xiao Bi", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Xiaokang Zhang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Xingkai Yu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yu Wu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Z. F. Wu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Zhibin Gou", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Zhihong Shao", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Zhuoshu Li", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Ziyi Gao", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Aixin Liu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Bing Xue", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Bingxuan Wang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Bochao Wu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Bei Feng", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Chengda Lu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Chenggang Zhao", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Chengqi Deng", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Chenyu Zhang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Chong Ruan", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Damai Dai", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Deli Chen", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Dongjie Ji", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Erhang Li", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Fangyun Lin", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Fucong Dai", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Fuli Luo", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Guangbo Hao", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Guanting Chen", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Guowei Li", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "H. Zhang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Han Bao", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Hanwei Xu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Haocheng Wang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Honghui Ding", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Huajian Xin", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Huazuo Gao", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Hui Qu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Hui Li", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Jianzhong Guo", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Jiashi Li", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Jiawei Wang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Jingchang Chen", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Jingyang Yuan", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Junjie Qiu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Junlong Li", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "J. L. Cai", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Jiaqi Ni", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Jian Liang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Jin Chen", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Kai Dong", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Kai Hu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Kaige Gao", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Kang Guan", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Kexin Huang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Kuai Yu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Lean Wang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Lecong Zhang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Liang Zhao", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Litong Wang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Liyue Zhang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Lei Xu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Leyi Xia", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Mingchuan Zhang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Minghua Zhang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Minghui Tang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Meng Li", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Miaojun Wang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Mingming Li", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Ning Tian", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Panpan Huang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Peng Zhang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Qiancheng Wang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Qinyu Chen", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Qiushi Du", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Ruiqi Ge", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Ruisong Zhang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Ruizhe Pan", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Runji Wang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "R. J. Chen", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "R. L. Jin", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Ruyi Chen", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Shanghao Lu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Shangyan Zhou", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Shanhuang Chen", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Shengfeng Ye", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Shiyu Wang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Shuiping Yu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Shunfeng Zhou", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Shuting Pan", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "S. S. Li", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Shuang Zhou", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Shaoqing Wu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Shengfeng Ye", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Tao Yun", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Tian Pei", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Tianyu Sun", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "T. Wang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Wangding Zeng", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Wanjia Zhao", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Wen Liu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Wenfeng Liang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Wenjun Gao", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Wenqin Yu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Wentao Zhang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "W. L. Xiao", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Wei An", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Xiaodong Liu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Xiaohan Wang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Xiaokang Chen", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Xiaotao Nie", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Xin Cheng", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Xin Liu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Xin Xie", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Xingchao Liu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Xinyu Yang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Xinyuan Li", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Xuecheng Su", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Xuheng Lin", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "X. Q. Li", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Xiangyue Jin", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Xiaojin Shen", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Xiaosha Chen", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Xiaowen Sun", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Xiaoxiang Wang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Xinnan Song", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Xinyi Zhou", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Xianzu Wang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Xinxia Shan", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Y. K. Li", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Y. Q. Wang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Y. X. Wei", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yang Zhang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yanhong Xu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yao Li", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yao Zhao", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yaofeng Sun", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yaohui Wang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yi Yu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yichao Zhang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yifan Shi", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yiliang Xiong", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Ying He", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yishi Piao", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yisong Wang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yixuan Tan", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yiyang Ma", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yiyuan Liu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yongqiang Guo", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yuan Ou", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yuduan Wang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yue Gong", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yuheng Zou", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yujia He", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yunfan Xiong", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yuxiang Luo", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yuxiang You", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yuxuan Liu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yuyang Zhou", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Y. X. Zhu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yanhong Xu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yanping Huang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yaohui Li", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yi Zheng", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yuchen Zhu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yunxian Ma", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Ying Tang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yukun Zha", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Yuting Yan", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Z. Z. Ren", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Zehui Ren", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Zhangli Sha", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Zhe Fu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Zhean Xu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Zhenda Xie", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Zhengyan Zhang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Zhewen Hao", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Zhicheng Ma", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Zhigang Yan", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Zhiyu Wu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Zihui Gu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Zijia Zhu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Zijun Liu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Zilin Li", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Ziwei Xie", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Ziyang Song", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Zizheng Pan", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Zhen Huang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Zhipeng Xu", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Zhongyu Zhang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Zhen Zhang", "target": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "value": "author_of"}, {"source": "Bowen Jin", "target": "Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning", "value": "author_of"}, {"source": "Hansi Zeng", "target": "Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning", "value": "author_of"}, {"source": "Zhenrui Yue", "target": "Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning", "value": "author_of"}, {"source": "Jinsung Yoon", "target": "Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning", "value": "author_of"}, {"source": "Sercan Arik", "target": "Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning", "value": "author_of"}, {"source": "Dong Wang", "target": "Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning", "value": "author_of"}, {"source": "Hamed Zamani", "target": "Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning", "value": "author_of"}, {"source": "Jiawei Han", "target": "Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning", "value": "author_of"}, {"source": "Karan Singhal", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Tao Tu", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Juraj Gottweis", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "R. Sayres", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Ellery Wulczyn", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Mohamed Amin", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Le Hou", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Kevin Clark", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Stephen R. Pfohl", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Heather Cole-Lewis", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Darlene Neal", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Q. Rashid", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Mike Schaekermann", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Amy Wang", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Dev Dash", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Jonathan H. Chen", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Nigam H. Shah", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Sami Lachgar", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "P. Mansfield", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Sushant Prakash", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Bradley Green", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Ewa Dominowska", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Blaise Ag\u00fcera y Arcas", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Nenad Toma\u0161ev", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Yun Liu", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Renee Wong", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Christopher Semturs", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "S. Mahdavi", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Joelle K. Barral", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Dale R. Webster", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "G. Corrado", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Yossi Matias", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Shekoofeh Azizi", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "A. Karthikesalingam", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Vivek Natarajan", "target": "Toward expert-level medical question answering with large language models", "value": "author_of"}, {"source": "Tianzhe Chu", "target": "SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training", "value": "author_of"}, {"source": "Yuexiang Zhai", "target": "SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training", "value": "author_of"}, {"source": "Jihan Yang", "target": "SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training", "value": "author_of"}, {"source": "Shengbang Tong", "target": "SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training", "value": "author_of"}, {"source": "Saining Xie", "target": "SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training", "value": "author_of"}, {"source": "Dale Schuurmans", "target": "SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training", "value": "author_of"}, {"source": "Quoc V. Le", "target": "SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training", "value": "author_of"}, {"source": "Sergey Levine", "target": "SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training", "value": "author_of"}, {"source": "Yi Ma", "target": "SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training", "value": "author_of"}, {"source": "Peijia Lin", "target": "Equivariant Diffusion for Crystal Structure Prediction", "value": "author_of"}, {"source": "Pin Chen", "target": "Equivariant Diffusion for Crystal Structure Prediction", "value": "author_of"}, {"source": "Rui Jiao", "target": "Equivariant Diffusion for Crystal Structure Prediction", "value": "author_of"}, {"source": "Qing Mo", "target": "Equivariant Diffusion for Crystal Structure Prediction", "value": "author_of"}, {"source": "Jianhuan Cen", "target": "Equivariant Diffusion for Crystal Structure Prediction", "value": "author_of"}, {"source": "Wenbing Huang", "target": "Equivariant Diffusion for Crystal Structure Prediction", "value": "author_of"}, {"source": "Yang Liu", "target": "Equivariant Diffusion for Crystal Structure Prediction", "value": "author_of"}, {"source": "Dan Huang", "target": "Equivariant Diffusion for Crystal Structure Prediction", "value": "author_of"}, {"source": "Yutong Lu", "target": "Equivariant Diffusion for Crystal Structure Prediction", "value": "author_of"}, {"source": "Wenqiang Sun", "target": "WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling", "value": "author_of"}, {"source": "Haiyu Zhang", "target": "WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling", "value": "author_of"}, {"source": "Haoyuan Wang", "target": "WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling", "value": "author_of"}, {"source": "Junta Wu", "target": "WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling", "value": "author_of"}, {"source": "Zehan Wang", "target": "WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling", "value": "author_of"}, {"source": "Zhenwei Wang", "target": "WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling", "value": "author_of"}, {"source": "Yunhong Wang", "target": "WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling", "value": "author_of"}, {"source": "Jun Zhang", "target": "WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling", "value": "author_of"}, {"source": "Tengfei Wang", "target": "WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling", "value": "author_of"}, {"source": "Chunchao Guo", "target": "WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling", "value": "author_of"}, {"source": "Jianfeng Xiang", "target": "Native and Compact Structured Latents for 3D Generation", "value": "author_of"}, {"source": "Xiaoxue Chen", "target": "Native and Compact Structured Latents for 3D Generation", "value": "author_of"}, {"source": "Sicheng Xu", "target": "Native and Compact Structured Latents for 3D Generation", "value": "author_of"}, {"source": "Ruicheng Wang", "target": "Native and Compact Structured Latents for 3D Generation", "value": "author_of"}, {"source": "Zelong Lv", "target": "Native and Compact Structured Latents for 3D Generation", "value": "author_of"}, {"source": "Yu Deng", "target": "Native and Compact Structured Latents for 3D Generation", "value": "author_of"}, {"source": "Hongyuan Zhu", "target": "Native and Compact Structured Latents for 3D Generation", "value": "author_of"}, {"source": "Yue Dong", "target": "Native and Compact Structured Latents for 3D Generation", "value": "author_of"}, {"source": "Hao Zhao", "target": "Native and Compact Structured Latents for 3D Generation", "value": "author_of"}, {"source": "Nicholas Jing Yuan", "target": "Native and Compact Structured Latents for 3D Generation", "value": "author_of"}, {"source": "Jiaolong Yang", "target": "Native and Compact Structured Latents for 3D Generation", "value": "author_of"}, {"source": "Basile Terver", "target": "What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?", "value": "author_of"}, {"source": "Tsung-Yen Yang", "target": "What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?", "value": "author_of"}, {"source": "Jean Ponce", "target": "What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?", "value": "author_of"}, {"source": "Adrien Bardes", "target": "What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?", "value": "author_of"}, {"source": "Yann LeCun", "target": "What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?", "value": "author_of"}, {"source": "Guangyi Zhang", "target": "Progressive Learned Image Transmission for Semantic Communication Using Hierarchical VAE", "value": "author_of"}, {"source": "Hanlei Li", "target": "Progressive Learned Image Transmission for Semantic Communication Using Hierarchical VAE", "value": "author_of"}, {"source": "Yunlong Cai", "target": "Progressive Learned Image Transmission for Semantic Communication Using Hierarchical VAE", "value": "author_of"}, {"source": "Qiyu Hu", "target": "Progressive Learned Image Transmission for Semantic Communication Using Hierarchical VAE", "value": "author_of"}, {"source": "Guanding Yu", "target": "Progressive Learned Image Transmission for Semantic Communication Using Hierarchical VAE", "value": "author_of"}, {"source": "Zhijing Qin", "target": "Progressive Learned Image Transmission for Semantic Communication Using Hierarchical VAE", "value": "author_of"}, {"source": "Wenjun Lin", "target": "STORM: Search-Guided Generative World Models for Robotic Manipulation", "value": "author_of"}, {"source": "Jensen Zhang", "target": "STORM: Search-Guided Generative World Models for Robotic Manipulation", "value": "author_of"}, {"source": "Kaitong Cai", "target": "STORM: Search-Guided Generative World Models for Robotic Manipulation", "value": "author_of"}, {"source": "Keze Wang", "target": "STORM: Search-Guided Generative World Models for Robotic Manipulation", "value": "author_of"}, {"source": "Takuya Akiba", "target": "Evolutionary Optimization of Model Merging Recipes", "value": "author_of"}, {"source": "Makoto Shing", "target": "Evolutionary Optimization of Model Merging Recipes", "value": "author_of"}, {"source": "Yujin Tang", "target": "Evolutionary Optimization of Model Merging Recipes", "value": "author_of"}, {"source": "Qi Sun", "target": "Evolutionary Optimization of Model Merging Recipes", "value": "author_of"}, {"source": "David Ha", "target": "Evolutionary Optimization of Model Merging Recipes", "value": "author_of"}, {"source": "Kyunghyun Cho", "target": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation", "value": "author_of"}, {"source": "Bart van Merrienboer", "target": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation", "value": "author_of"}, {"source": "Caglar Gulcehre", "target": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation", "value": "author_of"}, {"source": "Dzmitry Bahdanau", "target": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation", "value": "author_of"}, {"source": "Fethi Bougares", "target": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation", "value": "author_of"}, {"source": "Holger Schwenk", "target": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation", "value": "author_of"}, {"source": "Yoshua Bengio", "target": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation", "value": "author_of"}, {"source": "Erfei Cui", "target": "DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving", "value": "author_of"}, {"source": "Wenhai Wang", "target": "DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving", "value": "author_of"}, {"source": "Zhiqi Li", "target": "DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving", "value": "author_of"}, {"source": "Jiangwei Xie", "target": "DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving", "value": "author_of"}, {"source": "Haoming Zou", "target": "DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving", "value": "author_of"}, {"source": "Hanming Deng", "target": "DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving", "value": "author_of"}, {"source": "Gen Luo", "target": "DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving", "value": "author_of"}, {"source": "Lewei Lu", "target": "DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving", "value": "author_of"}, {"source": "Xizhou Zhu", "target": "DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving", "value": "author_of"}, {"source": "Jifeng Dai", "target": "DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving", "value": "author_of"}, {"source": "Haodong Duan", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Xinyu Fang", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Junming Yang", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Xiangyu Zhao", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Yuxuan Qiao", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Mo Li", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Amit Agarwal", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Zhe Chen", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Lin Chen", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Yuan Liu", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Yubo Ma", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Hailong Sun", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Yifan Zhang", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Shiyin Lu", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Tack Hwa Wong", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Weiyun Wang", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Peiheng Zhou", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Xiaozhe Li", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Chaoyou Fu", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Junbo Cui", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Jixuan Chen", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Enxin Song", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Song Mao", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Shengyuan Ding", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Tianhao Liang", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Zicheng Zhang", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Xiaoyi Dong", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Yuhang Zang", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Pan Zhang", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Jiaqi Wang", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Dahua Lin", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Kai Chen", "target": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "value": "author_of"}, {"source": "Jason Wei", "target": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models", "value": "author_of"}, {"source": "Xuezhi Wang", "target": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models", "value": "author_of"}, {"source": "Dale Schuurmans", "target": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models", "value": "author_of"}, {"source": "Maarten Bosma", "target": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models", "value": "author_of"}, {"source": "Brian Ichter", "target": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models", "value": "author_of"}, {"source": "Fei Xia", "target": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models", "value": "author_of"}, {"source": "Ed Chi", "target": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models", "value": "author_of"}, {"source": "Quoc Le", "target": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models", "value": "author_of"}, {"source": "Denny Zhou", "target": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models", "value": "author_of"}, {"source": "Ross Girshick", "target": "Rich feature hierarchies for accurate object detection and semantic segmentation", "value": "author_of"}, {"source": "Jeff Donahue", "target": "Rich feature hierarchies for accurate object detection and semantic segmentation", "value": "author_of"}, {"source": "Trevor Darrell", "target": "Rich feature hierarchies for accurate object detection and semantic segmentation", "value": "author_of"}, {"source": "Jitendra Malik", "target": "Rich feature hierarchies for accurate object detection and semantic segmentation", "value": "author_of"}, {"source": "Haotian Lv", "target": "Intelligent recognition of GPR road hidden defect images based on feature fusion and attention mechanism", "value": "author_of"}, {"source": "Yuhui Zhang", "target": "Intelligent recognition of GPR road hidden defect images based on feature fusion and attention mechanism", "value": "author_of"}, {"source": "Jiangbo Dai", "target": "Intelligent recognition of GPR road hidden defect images based on feature fusion and attention mechanism", "value": "author_of"}, {"source": "Hanli Wu", "target": "Intelligent recognition of GPR road hidden defect images based on feature fusion and attention mechanism", "value": "author_of"}, {"source": "Jiaji Wang", "target": "Intelligent recognition of GPR road hidden defect images based on feature fusion and attention mechanism", "value": "author_of"}, {"source": "Dawei Wang", "target": "Intelligent recognition of GPR road hidden defect images based on feature fusion and attention mechanism", "value": "author_of"}, {"source": "Anwesha Mukherjee", "target": "Federated Learning Architectures: A Performance Evaluation with Crop Yield Prediction Application", "value": "author_of"}, {"source": "Rajkumar Buyya", "target": "Federated Learning Architectures: A Performance Evaluation with Crop Yield Prediction Application", "value": "author_of"}, {"source": "Zhiyuan You", "target": "Enhancing Descriptive Image Quality Assessment with A Large-scale Multi-modal Dataset", "value": "author_of"}, {"source": "Jinjin Gu", "target": "Enhancing Descriptive Image Quality Assessment with A Large-scale Multi-modal Dataset", "value": "author_of"}, {"source": "Xin Cai", "target": "Enhancing Descriptive Image Quality Assessment with A Large-scale Multi-modal Dataset", "value": "author_of"}, {"source": "Zheyuan Li", "target": "Enhancing Descriptive Image Quality Assessment with A Large-scale Multi-modal Dataset", "value": "author_of"}, {"source": "Kaiwen Zhu", "target": "Enhancing Descriptive Image Quality Assessment with A Large-scale Multi-modal Dataset", "value": "author_of"}, {"source": "Chao Dong", "target": "Enhancing Descriptive Image Quality Assessment with A Large-scale Multi-modal Dataset", "value": "author_of"}, {"source": "Tianfan Xue", "target": "Enhancing Descriptive Image Quality Assessment with A Large-scale Multi-modal Dataset", "value": "author_of"}, {"source": "Matthew E. Peters", "target": "Deep contextualized word representations", "value": "author_of"}, {"source": "Mark Neumann", "target": "Deep contextualized word representations", "value": "author_of"}, {"source": "Mohit Iyyer", "target": "Deep contextualized word representations", "value": "author_of"}, {"source": "Matt Gardner", "target": "Deep contextualized word representations", "value": "author_of"}, {"source": "Christopher Clark", "target": "Deep contextualized word representations", "value": "author_of"}, {"source": "Kenton Lee", "target": "Deep contextualized word representations", "value": "author_of"}, {"source": "Luke Zettlemoyer", "target": "Deep contextualized word representations", "value": "author_of"}, {"source": "DeepSeek-AI", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Daya Guo", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Dejian Yang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Haowei Zhang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Junxiao Song", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Peiyi Wang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Qihao Zhu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Runxin Xu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Ruoyu Zhang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Shirong Ma", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Xiao Bi", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Xiaokang Zhang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Xingkai Yu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yu Wu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Z. F. Wu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Zhibin Gou", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Zhihong Shao", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Zhuoshu Li", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Ziyi Gao", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Aixin Liu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Bing Xue", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Bingxuan Wang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Bochao Wu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Bei Feng", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Chengda Lu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Chenggang Zhao", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Chengqi Deng", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Chenyu Zhang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Chong Ruan", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Damai Dai", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Deli Chen", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Dongjie Ji", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Erhang Li", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Fangyun Lin", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Fucong Dai", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Fuli Luo", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Guangbo Hao", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Guanting Chen", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Guowei Li", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "H. Zhang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Han Bao", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Hanwei Xu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Haocheng Wang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Honghui Ding", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Huajian Xin", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Huazuo Gao", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Hui Qu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Hui Li", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Jianzhong Guo", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Jiashi Li", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Jiawei Wang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Jingchang Chen", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Jingyang Yuan", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Junjie Qiu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Junlong Li", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "J. L. Cai", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Jiaqi Ni", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Jian Liang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Jin Chen", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Kai Dong", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Kai Hu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Kaige Gao", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Kang Guan", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Kexin Huang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Kuai Yu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Lean Wang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Lecong Zhang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Liang Zhao", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Litong Wang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Liyue Zhang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Lei Xu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Leyi Xia", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Mingchuan Zhang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Minghua Zhang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Minghui Tang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Meng Li", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Miaojun Wang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Mingming Li", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Ning Tian", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Panpan Huang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Peng Zhang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Qiancheng Wang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Qinyu Chen", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Qiushi Du", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Ruiqi Ge", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Ruisong Zhang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Ruizhe Pan", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Runji Wang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "R. J. Chen", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "R. L. Jin", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Ruyi Chen", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Shanghao Lu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Shangyan Zhou", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Shanhuang Chen", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Shengfeng Ye", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Shiyu Wang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Shuiping Yu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Shunfeng Zhou", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Shuting Pan", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "S. S. Li", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Shuang Zhou", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Shaoqing Wu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Shengfeng Ye", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Tao Yun", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Tian Pei", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Tianyu Sun", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "T. Wang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Wangding Zeng", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Wanjia Zhao", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Wen Liu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Wenfeng Liang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Wenjun Gao", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Wenqin Yu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Wentao Zhang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "W. L. Xiao", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Wei An", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Xiaodong Liu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Xiaohan Wang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Xiaokang Chen", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Xiaotao Nie", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Xin Cheng", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Xin Liu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Xin Xie", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Xingchao Liu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Xinyu Yang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Xinyuan Li", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Xuecheng Su", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Xuheng Lin", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "X. Q. Li", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Xiangyue Jin", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Xiaojin Shen", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Xiaosha Chen", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Xiaowen Sun", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Xiaoxiang Wang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Xinnan Song", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Xinyi Zhou", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Xianzu Wang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Xinxia Shan", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Y. K. Li", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Y. Q. Wang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Y. X. Wei", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yang Zhang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yanhong Xu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yao Li", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yao Zhao", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yaofeng Sun", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yaohui Wang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yi Yu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yichao Zhang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yifan Shi", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yiliang Xiong", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Ying He", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yishi Piao", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yisong Wang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yixuan Tan", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yiyang Ma", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yiyuan Liu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yongqiang Guo", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yuan Ou", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yuduan Wang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yue Gong", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yuheng Zou", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yujia He", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yunfan Xiong", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yuxiang Luo", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yuxiang You", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yuxuan Liu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yuyang Zhou", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Y. X. Zhu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yanhong Xu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yanping Huang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yaohui Li", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yi Zheng", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yuchen Zhu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yunxian Ma", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Ying Tang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yukun Zha", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Yuting Yan", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Z. Z. Ren", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Zehui Ren", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Zhangli Sha", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Zhe Fu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Zhean Xu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Zhenda Xie", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Zhengyan Zhang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Zhewen Hao", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Zhicheng Ma", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Zhigang Yan", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Zhiyu Wu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Zihui Gu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Zijia Zhu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Zijun Liu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Zilin Li", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Ziwei Xie", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Ziyang Song", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Zizheng Pan", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Zhen Huang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Zhipeng Xu", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Zhongyu Zhang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Zhen Zhang", "target": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "value": "author_of"}, {"source": "Attention Is All You Need", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "Attention Is All You Need", "target": "Adam: A Method for Stochastic Optimization", "value": "cites"}, {"source": "Attention Is All You Need", "target": "Long Short-Term Memory", "value": "cites"}, {"source": "Attention Is All You Need", "target": "Dropout: a simple way to prevent neural networks from overfitting", "value": "cites"}, {"source": "Attention Is All You Need", "target": "Rethinking the Inception Architecture for Computer Vision", "value": "cites"}, {"source": "A comprehensive review of recommender systems: Transitioning from theory to practice", "target": "Attention Is All You Need", "value": "cites"}, {"source": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "target": "Attention Is All You Need", "value": "cites"}, {"source": "CNC-VLM: An RLHF-optimized industrial large vision-language model with multimodal learning for imbalanced CNC fault detection", "target": "Attention Is All You Need", "value": "cites"}, {"source": "Enhanced Transformer-BiLSTM Deep Learning Framework for Day-Ahead Energy Price Forecasting", "target": "Attention Is All You Need", "value": "cites"}, {"source": "UAV-based quantitative crack measurement for bridges integrating four-point laser metric calibration and mamba segmentation", "target": "Attention Is All You Need", "value": "cites"}, {"source": "Deep Residual Learning for Image Recognition", "target": "ImageNet classification with deep convolutional neural networks", "value": "cites"}, {"source": "Deep Residual Learning for Image Recognition", "target": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "value": "cites"}, {"source": "Deep Residual Learning for Image Recognition", "target": "Long Short-Term Memory", "value": "cites"}, {"source": "Deep Residual Learning for Image Recognition", "target": "Et al", "value": "cites"}, {"source": "Deep Residual Learning for Image Recognition", "target": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "value": "cites"}, {"source": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "DiffusionEngine: Diffusion model is scalable data engine for object detection", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "Enhancing hyperspectral image prediction with contrastive learning in low-label regimes", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "WarmGait: Thermal Array-Based Gait Recognition for Privacy-Preserving Person Re-ID", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "Adam: A Method for Stochastic Optimization", "target": "ImageNet classification with deep convolutional neural networks", "value": "cites"}, {"source": "Adam: A Method for Stochastic Optimization", "target": "Auto-Encoding Variational Bayes", "value": "cites"}, {"source": "Adam: A Method for Stochastic Optimization", "target": "Supporting Online Material for Reducing the Dimensionality of Data with Neural Networks", "value": "cites"}, {"source": "Adam: A Method for Stochastic Optimization", "target": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization", "value": "cites"}, {"source": "Adam: A Method for Stochastic Optimization", "target": "Speech recognition with deep recurrent neural networks", "value": "cites"}, {"source": "Weakly Supervised Image Dehazing via Physics-Based Decomposition", "target": "Adam: A Method for Stochastic Optimization", "value": "cites"}, {"source": "A Machine Learning Approach for Face Mask Detection System with AdamW Optimizer", "target": "Adam: A Method for Stochastic Optimization", "value": "cites"}, {"source": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "target": "Adam: A Method for Stochastic Optimization", "value": "cites"}, {"source": "Probabilistic hierarchical interpolation and interpretable neural network configurations for flood prediction", "target": "Adam: A Method for Stochastic Optimization", "value": "cites"}, {"source": "Generating an annual 30\u00a0m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "target": "Adam: A Method for Stochastic Optimization", "value": "cites"}, {"source": "Rethinking the Inception Architecture for Computer Vision", "target": "ImageNet classification with deep convolutional neural networks", "value": "cites"}, {"source": "Rethinking the Inception Architecture for Computer Vision", "target": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "value": "cites"}, {"source": "Rethinking the Inception Architecture for Computer Vision", "target": "Going deeper with convolutions", "value": "cites"}, {"source": "Rethinking the Inception Architecture for Computer Vision", "target": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "value": "cites"}, {"source": "Rethinking the Inception Architecture for Computer Vision", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "cites"}, {"source": "Diffusion Transformers with Representation Autoencoders", "target": "Rethinking the Inception Architecture for Computer Vision", "value": "cites"}, {"source": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "target": "Rethinking the Inception Architecture for Computer Vision", "value": "cites"}, {"source": "HybridVisionNet: An advanced hybrid deep learning framework for automated multi-class ocular disease diagnosis using fundus imaging", "target": "Rethinking the Inception Architecture for Computer Vision", "value": "cites"}, {"source": "Revisiting Transferable Adversarial Images: Systemization, Evaluation, and New Insights", "target": "Rethinking the Inception Architecture for Computer Vision", "value": "cites"}, {"source": "Dataset Purification-Driven Lightweight Deep Learning Model Construction for Empty-Dish Recycling Robot", "target": "Rethinking the Inception Architecture for Computer Vision", "value": "cites"}, {"source": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "target": "Attention is All you Need", "value": "cites"}, {"source": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "cites"}, {"source": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "target": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium", "value": "cites"}, {"source": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "target": "nuScenes: A Multimodal Dataset for Autonomous Driving", "value": "cites"}, {"source": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "target": "CARLA: An Open Urban Driving Simulator", "value": "cites"}, {"source": "Sora as a World Model? A Complete Survey on Text-to-Video Generation", "target": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "value": "cites"}, {"source": "OmniNWM: Omniscient Driving Navigation World Models", "target": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "value": "cites"}, {"source": "ConsisDrive: Identity-Preserving Driving World Models for Video Generation by Instance Mask", "target": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "value": "cites"}, {"source": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "target": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "value": "cites"}, {"source": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "target": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "value": "cites"}, {"source": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "target": "I and J", "value": "cites"}, {"source": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "target": "ImageNet classification with deep convolutional neural networks", "value": "cites"}, {"source": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "target": "ImageNet: A large-scale hierarchical image database", "value": "cites"}, {"source": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "target": "A and V", "value": "cites"}, {"source": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "target": "Going deeper with convolutions", "value": "cites"}, {"source": "What matters for Representation Alignment: Global Information or Spatial Structure?", "target": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "value": "cites"}, {"source": "SCB-DETR: Multiscale Deformable Transformers for Occlusion-Resilient Student Learning Behavior Detection in Smart Classroom", "target": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "value": "cites"}, {"source": "Robust Deep Feature Ultrasound Image-Based Visual Servoing: Focus on Cardiac Examination", "target": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "value": "cites"}, {"source": "Bio-Inspired Fine-Tuning for Selective Transfer Learning in Image Classification", "target": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "value": "cites"}, {"source": "Hand Sign Language Detection Using Deep Learning", "target": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "value": "cites"}, {"source": "Auto-Encoding Variational Bayes", "target": "Representation Learning: A Review and New Perspectives", "value": "cites"}, {"source": "Auto-Encoding Variational Bayes", "target": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization", "value": "cites"}, {"source": "Auto-Encoding Variational Bayes", "target": "Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion", "value": "cites"}, {"source": "Auto-Encoding Variational Bayes", "target": "In Advances in Neural Information Processing Systems", "value": "cites"}, {"source": "Auto-Encoding Variational Bayes", "target": "Stochastic Backpropagation and Approximate Inference in Deep Generative Models", "value": "cites"}, {"source": "SDXL-Lightning: Progressive Adversarial Diffusion Distillation", "target": "Auto-Encoding Variational Bayes", "value": "cites"}, {"source": "EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditions", "target": "Auto-Encoding Variational Bayes", "value": "cites"}, {"source": "GenAD: Generative End-to-End Autonomous Driving", "target": "Auto-Encoding Variational Bayes", "value": "cites"}, {"source": "Ovis: Structural Embedding Alignment for Multimodal Large Language Model", "target": "Auto-Encoding Variational Bayes", "value": "cites"}, {"source": "Improving Video Generation with Human Feedback", "target": "Auto-Encoding Variational Bayes", "value": "cites"}, {"source": "Speech Recognition with Deep Recurrent Neural Networks", "target": "Long Short-Term Memory", "value": "cites"}, {"source": "Speech Recognition with Deep Recurrent Neural Networks", "target": "Learning representations by back-propagating errors", "value": "cites"}, {"source": "Speech Recognition with Deep Recurrent Neural Networks", "target": "Bidirectional recurrent neural networks", "value": "cites"}, {"source": "Speech Recognition with Deep Recurrent Neural Networks", "target": "Connectionist Temporal Classi\ufb01cation: Labelling Unsegmented Sequence Data with Recurrent Neural Networks", "value": "cites"}, {"source": "Speech Recognition with Deep Recurrent Neural Networks", "target": "2005 Special Issue: Framewise phoneme classification with bidirectional LSTM and other neural network architectures", "value": "cites"}, {"source": "A high-performance neuroprosthesis for speech decoding and avatar control", "target": "Speech Recognition with Deep Recurrent Neural Networks", "value": "cites"}, {"source": "Artificial Intelligence Meets Flexible Sensors: Emerging Smart Flexible Sensing Systems Driven by Machine Learning and Artificial Synapses", "target": "Speech Recognition with Deep Recurrent Neural Networks", "value": "cites"}, {"source": "A high-performance speech neuroprosthesis", "target": "Speech Recognition with Deep Recurrent Neural Networks", "value": "cites"}, {"source": "Loss of plasticity in deep continual learning", "target": "Speech Recognition with Deep Recurrent Neural Networks", "value": "cites"}, {"source": "An analog-AI chip for energy-efficient speech recognition and transcription", "target": "Speech Recognition with Deep Recurrent Neural Networks", "value": "cites"}, {"source": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "target": "Attention is All you Need", "value": "cites"}, {"source": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "target": "Adam: A Method for Stochastic Optimization", "value": "cites"}, {"source": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "target": "A Mathematical Theory of Communication", "value": "cites"}, {"source": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "target": "Going deeper with convolutions", "value": "cites"}, {"source": "LiteToken: Removing Intermediate Merge Residues From BPE Tokenizers", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "cites"}, {"source": "MeKi: Memory-based Expert Knowledge Injection for Efficient LLM Scaling", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "cites"}, {"source": "Beyond Conditional Computation: Retrieval-Augmented Genomic Foundation Models with Gengram", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "cites"}, {"source": "L$^3$: Large Lookup Layers", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "cites"}, {"source": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "target": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "value": "cites"}, {"source": "Going Deeper with Convolutions", "target": "ImageNet classification with deep convolutional neural networks", "value": "cites"}, {"source": "Going Deeper with Convolutions", "target": "ImageNet: A large-scale hierarchical image database", "value": "cites"}, {"source": "Going Deeper with Convolutions", "target": "Gradient-based learning applied to document recognition", "value": "cites"}, {"source": "Going Deeper with Convolutions", "target": "Regression Shrinkage and Selection via the Lasso", "value": "cites"}, {"source": "Going Deeper with Convolutions", "target": "Microsoft COCO: Common Objects in Context", "value": "cites"}, {"source": "LifeCLEF Plant Identification Task 2015", "target": "Going Deeper with Convolutions", "value": "cites"}, {"source": "FedMicro-IDA: A Federated Learning and Microservices-based Framework for IoT Data Analytics", "target": "Going Deeper with Convolutions", "value": "cites"}, {"source": "Enhancing pine wilt disease detection with synthetic data and external attention-based transformers", "target": "Going Deeper with Convolutions", "value": "cites"}, {"source": "A comprehensive review on YOLO versions for object detection", "target": "Going Deeper with Convolutions", "value": "cites"}, {"source": "Harnessing large vision and language models in agriculture: a review", "target": "Going Deeper with Convolutions", "value": "cites"}, {"source": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "target": "ImageNet classification with deep convolutional neural networks", "value": "cites"}, {"source": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "target": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "value": "cites"}, {"source": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "target": "Gradient-based learning applied to document recognition", "value": "cites"}, {"source": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "target": "Going deeper with convolutions", "value": "cites"}, {"source": "A comprehensive review on YOLO versions for object detection", "target": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "value": "cites"}, {"source": "A Machine Learning Approach for Face Mask Detection System with AdamW Optimizer", "target": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "value": "cites"}, {"source": "Multi-axis vision transformer for medical image segmentation", "target": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "value": "cites"}, {"source": "A comprehensive review of facial beauty prediction using deep learning techniques", "target": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "value": "cites"}, {"source": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes.", "target": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "value": "cites"}, {"source": "ImageNet Large Scale Visual Recognition Challenge", "target": "ImageNet classification with deep convolutional neural networks", "value": "cites"}, {"source": "ImageNet Large Scale Visual Recognition Challenge", "target": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "value": "cites"}, {"source": "ImageNet Large Scale Visual Recognition Challenge", "target": "ImageNet: A large-scale hierarchical image database", "value": "cites"}, {"source": "ImageNet Large Scale Visual Recognition Challenge", "target": "Microsoft COCO: Common Objects in Context", "value": "cites"}, {"source": "ImageNet Large Scale Visual Recognition Challenge", "target": "Distinctive Image Features from Scale-Invariant Keypoints", "value": "cites"}, {"source": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "cites"}, {"source": "Diffusion Transformers with Representation Autoencoders", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "cites"}, {"source": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "cites"}, {"source": "A comprehensive review on YOLO versions for object detection", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "cites"}, {"source": "Aligning machine and human visual representations across abstraction levels", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "cites"}, {"source": "Diffusion Transformers with Representation Autoencoders", "target": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "value": "cites"}, {"source": "Diffusion Transformers with Representation Autoencoders", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "cites"}, {"source": "Diffusion Transformers with Representation Autoencoders", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "cites"}, {"source": "Diffusion Transformers with Representation Autoencoders", "target": "GENERATIVE ADVERSARIAL NETS", "value": "cites"}, {"source": "Diffusion Transformers with Representation Autoencoders", "target": "Rethinking the Inception Architecture for Computer Vision", "value": "cites"}, {"source": "Improved Mean Flows: On the Challenges of Fastforward Generative Models", "target": "Diffusion Transformers with Representation Autoencoders", "value": "cites"}, {"source": "There is No VAE: End-to-End Pixel-Space Generative Modeling via Self-Supervised Pre-training", "target": "Diffusion Transformers with Representation Autoencoders", "value": "cites"}, {"source": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "target": "Diffusion Transformers with Representation Autoencoders", "value": "cites"}, {"source": "PixelDiT: Pixel Diffusion Transformers for Image Generation", "target": "Diffusion Transformers with Representation Autoencoders", "value": "cites"}, {"source": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "target": "Diffusion Transformers with Representation Autoencoders", "value": "cites"}, {"source": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "target": "Attention is All you Need", "value": "cites"}, {"source": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "target": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "value": "cites"}, {"source": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "target": "ImageNet: A large-scale hierarchical image database", "value": "cites"}, {"source": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "target": "Dropout: a simple way to prevent neural networks from overfitting", "value": "cites"}, {"source": "A comprehensive review of object detection with traditional and deep learning methods", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "cites"}, {"source": "Diffusion Language Models are Super Data Learners", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "cites"}, {"source": "DreamOn: Diffusion Language Models For Code Infilling Beyond Fixed-size Canvas", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "cites"}, {"source": "FLEX: Continuous Agent Evolution via Forward Learning from Experience", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "cites"}, {"source": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "cites"}, {"source": "OmniNWM: Omniscient Driving Navigation World Models", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "cites"}, {"source": "OmniNWM: Omniscient Driving Navigation World Models", "target": "Squeeze-and-Excitation Networks", "value": "cites"}, {"source": "OmniNWM: Omniscient Driving Navigation World Models", "target": "Decoupled Weight Decay Regularization", "value": "cites"}, {"source": "OmniNWM: Omniscient Driving Navigation World Models", "target": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks", "value": "cites"}, {"source": "OmniNWM: Omniscient Driving Navigation World Models", "target": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium", "value": "cites"}, {"source": "Light-X: Generative 4D Video Rendering with Camera and Illumination Control", "target": "OmniNWM: Omniscient Driving Navigation World Models", "value": "cites"}, {"source": "DriveLaW:Unifying Planning and Video Generation in a Latent Driving World", "target": "OmniNWM: Omniscient Driving Navigation World Models", "value": "cites"}, {"source": "DVGT: Driving Visual Geometry Transformer", "target": "OmniNWM: Omniscient Driving Navigation World Models", "value": "cites"}, {"source": "ConsisDrive: Identity-Preserving Driving World Models for Video Generation by Instance Mask", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "cites"}, {"source": "ConsisDrive: Identity-Preserving Driving World Models for Video Generation by Instance Mask", "target": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium", "value": "cites"}, {"source": "ConsisDrive: Identity-Preserving Driving World Models for Video Generation by Instance Mask", "target": "nuScenes: A Multimodal Dataset for Autonomous Driving", "value": "cites"}, {"source": "ConsisDrive: Identity-Preserving Driving World Models for Video Generation by Instance Mask", "target": "Adding Conditional Control to Text-to-Image Diffusion Models", "value": "cites"}, {"source": "ConsisDrive: Identity-Preserving Driving World Models for Video Generation by Instance Mask", "target": "Scaling Instruction-Finetuned Language Models", "value": "cites"}, {"source": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "target": "High-Resolution Image Synthesis with Latent Diffusion Models", "value": "cites"}, {"source": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "target": "AUTO-ENCODING VARIATIONAL BAYES", "value": "cites"}, {"source": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "target": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium", "value": "cites"}, {"source": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "target": "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric", "value": "cites"}, {"source": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "target": "nuScenes: A Multimodal Dataset for Autonomous Driving", "value": "cites"}, {"source": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "target": "Decoupled Weight Decay Regularization", "value": "cites"}, {"source": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "cites"}, {"source": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "target": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium", "value": "cites"}, {"source": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "target": "CARLA: An Open Urban Driving Simulator", "value": "cites"}, {"source": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "target": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "value": "cites"}, {"source": "What matters for Representation Alignment: Global Information or Spatial Structure?", "target": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "value": "cites"}, {"source": "What matters for Representation Alignment: Global Information or Spatial Structure?", "target": "ImageNet: A large-scale hierarchical image database", "value": "cites"}, {"source": "What matters for Representation Alignment: Global Information or Spatial Structure?", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "cites"}, {"source": "What matters for Representation Alignment: Global Information or Spatial Structure?", "target": "Histograms of oriented gradients for human detection", "value": "cites"}, {"source": "What matters for Representation Alignment: Global Information or Spatial Structure?", "target": "Generative Adversarial Networks", "value": "cites"}, {"source": "Generalization of Diffusion Models Arises with a Balanced Representation Space", "target": "What matters for Representation Alignment: Global Information or Spatial Structure?", "value": "cites"}, {"source": "Stable Velocity: A Variance Perspective on Flow Matching", "target": "What matters for Representation Alignment: Global Information or Spatial Structure?", "value": "cites"}, {"source": "Laminating Representation Autoencoders for Efficient Diffusion", "target": "What matters for Representation Alignment: Global Information or Spatial Structure?", "value": "cites"}, {"source": "Adaptive 1D Video Diffusion Autoencoder", "target": "What matters for Representation Alignment: Global Information or Spatial Structure?", "value": "cites"}, {"source": "Test-Time Conditioning with Representation-Aligned Visual Features", "target": "What matters for Representation Alignment: Global Information or Spatial Structure?", "value": "cites"}, {"source": "VGG Induced Deep Hand Sign Language Detection", "target": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "value": "cites"}, {"source": "VGG Induced Deep Hand Sign Language Detection", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "cites"}, {"source": "VGG Induced Deep Hand Sign Language Detection", "target": "MediaPipe: A Framework for Building Perception Pipelines", "value": "cites"}, {"source": "VGG Induced Deep Hand Sign Language Detection", "target": "Hand Pose Estimation and Hand Shape Classification Using Multi-layered Randomized Decision Forests", "value": "cites"}, {"source": "VGG Induced Deep Hand Sign Language Detection", "target": "A robust static hand gesture recognition system using geometry based normalizations and Krawtchouk moments", "value": "cites"}, {"source": "Hand signal classification system for sign language communication in Virtual Reality", "target": "VGG Induced Deep Hand Sign Language Detection", "value": "cites"}, {"source": "Real-Time Static Hand Sign Recognition System using MediaPipe and Fully Connected Neural Network", "target": "VGG Induced Deep Hand Sign Language Detection", "value": "cites"}, {"source": "Real-Time Gesture Recognition to Aid Communication in Children with Motor Impairments", "target": "VGG Induced Deep Hand Sign Language Detection", "value": "cites"}, {"source": "Representation Learning: A Review and New Perspectives", "target": "ImageNet classification with deep convolutional neural networks", "value": "cites"}, {"source": "Representation Learning: A Review and New Perspectives", "target": "Gradient-based learning applied to document recognition", "value": "cites"}, {"source": "Representation Learning: A Review and New Perspectives", "target": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper", "value": "cites"}, {"source": "Representation Learning: A Review and New Perspectives", "target": "Visualizing Data using t-SNE", "value": "cites"}, {"source": "Representation Learning: A Review and New Perspectives", "target": "Learning Multiple Layers of Features from Tiny Images", "value": "cites"}, {"source": "LLM Social Simulations Are a Promising Research Method", "target": "Representation Learning: A Review and New Perspectives", "value": "cites"}, {"source": "Federated Contrastive Learning With Feature-Based Distillation for Human Activity Recognition", "target": "Representation Learning: A Review and New Perspectives", "value": "cites"}, {"source": "Diffuse and Disperse: Image Generation with Representation Regularization", "target": "Representation Learning: A Review and New Perspectives", "value": "cites"}, {"source": "Deep Autoencoder Neural Networks: A Comprehensive Review and New Perspectives", "target": "Representation Learning: A Review and New Perspectives", "value": "cites"}, {"source": "KABB: Knowledge-Aware Bayesian Bandits for Dynamic Expert Coordination in Multi-Agent Systems", "target": "Representation Learning: A Review and New Perspectives", "value": "cites"}, {"source": "SDXL-Lightning: Progressive Adversarial Diffusion Distillation", "target": "U-Net: Convolutional Networks for Biomedical Image Segmentation", "value": "cites"}, {"source": "SDXL-Lightning: Progressive Adversarial Diffusion Distillation", "target": "Microsoft COCO: Common Objects in Context", "value": "cites"}, {"source": "SDXL-Lightning: Progressive Adversarial Diffusion Distillation", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "cites"}, {"source": "SDXL-Lightning: Progressive Adversarial Diffusion Distillation", "target": "Generative Adversarial Networks", "value": "cites"}, {"source": "SDXL-Lightning: Progressive Adversarial Diffusion Distillation", "target": "Decoupled Weight Decay Regularization", "value": "cites"}, {"source": "Improved Distribution Matching Distillation for Fast Image Synthesis", "target": "SDXL-Lightning: Progressive Adversarial Diffusion Distillation", "value": "cites"}, {"source": "Fast High-Resolution Image Synthesis with Latent Adversarial Diffusion Distillation", "target": "SDXL-Lightning: Progressive Adversarial Diffusion Distillation", "value": "cites"}, {"source": "Evolutionary optimization of model merging recipes", "target": "SDXL-Lightning: Progressive Adversarial Diffusion Distillation", "value": "cites"}, {"source": "From Slow Bidirectional to Fast Autoregressive Video Diffusion Models", "target": "SDXL-Lightning: Progressive Adversarial Diffusion Distillation", "value": "cites"}, {"source": "PuLID: Pure and Lightning ID Customization via Contrastive Alignment", "target": "SDXL-Lightning: Progressive Adversarial Diffusion Distillation", "value": "cites"}, {"source": "EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditions", "target": "U-Net: Convolutional Networks for Biomedical Image Segmentation", "value": "cites"}, {"source": "EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditions", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "cites"}, {"source": "EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditions", "target": "Denoising Diffusion Probabilistic Models", "value": "cites"}, {"source": "EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditions", "target": "High-Resolution Image Synthesis with Latent Diffusion Models", "value": "cites"}, {"source": "EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditions", "target": "Auto-Encoding Variational Bayes", "value": "cites"}, {"source": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "target": "EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditions", "value": "cites"}, {"source": "Loopy: Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency", "target": "EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditions", "value": "cites"}, {"source": "OmniHuman-1: Rethinking the Scaling-Up of One-Stage Conditioned Human Animation Models", "target": "EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditions", "value": "cites"}, {"source": "Hallo2: Long-Duration and High-Resolution Audio-Driven Portrait Image Animation", "target": "EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditions", "value": "cites"}, {"source": "EchoMimicV2: Towards Striking, Simplified, and Semi-Body Human Animation", "target": "EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditions", "value": "cites"}, {"source": "GenAD: Generative End-to-End Autonomous Driving", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "GenAD: Generative End-to-End Autonomous Driving", "target": "Attention is All you Need", "value": "cites"}, {"source": "GenAD: Generative End-to-End Autonomous Driving", "target": "Decoupled Weight Decay Regularization", "value": "cites"}, {"source": "GenAD: Generative End-to-End Autonomous Driving", "target": "Feature Pyramid Networks for Object Detection", "value": "cites"}, {"source": "GenAD: Generative End-to-End Autonomous Driving", "target": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation", "value": "cites"}, {"source": "DriveMLM: aligning multi-modal large language models with behavioral planning states for autonomous driving", "target": "GenAD: Generative End-to-End Autonomous Driving", "value": "cites"}, {"source": "Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability", "target": "GenAD: Generative End-to-End Autonomous Driving", "value": "cites"}, {"source": "DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving", "target": "GenAD: Generative End-to-End Autonomous Driving", "value": "cites"}, {"source": "How Far is Video Generation from World Model: A Physical Law Perspective", "target": "GenAD: Generative End-to-End Autonomous Driving", "value": "cites"}, {"source": "EMMA: End-to-End Multimodal Model for Autonomous Driving", "target": "GenAD: Generative End-to-End Autonomous Driving", "value": "cites"}, {"source": "Ovis: Structural Embedding Alignment for Multimodal Large Language Model", "target": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "value": "cites"}, {"source": "Ovis: Structural Embedding Alignment for Multimodal Large Language Model", "target": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "value": "cites"}, {"source": "Ovis: Structural Embedding Alignment for Multimodal Large Language Model", "target": "Language Models are Few-Shot Learners", "value": "cites"}, {"source": "Ovis: Structural Embedding Alignment for Multimodal Large Language Model", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "cites"}, {"source": "Ovis: Structural Embedding Alignment for Multimodal Large Language Model", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "cites"}, {"source": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "target": "Ovis: Structural Embedding Alignment for Multimodal Large Language Model", "value": "cites"}, {"source": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "target": "Ovis: Structural Embedding Alignment for Multimodal Large Language Model", "value": "cites"}, {"source": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "target": "Ovis: Structural Embedding Alignment for Multimodal Large Language Model", "value": "cites"}, {"source": "LLaVA-CoT: Let Vision Language Models Reason Step-by-Step", "target": "Ovis: Structural Embedding Alignment for Multimodal Large Language Model", "value": "cites"}, {"source": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency", "target": "Ovis: Structural Embedding Alignment for Multimodal Large Language Model", "value": "cites"}, {"source": "Improving Video Generation with Human Feedback", "target": "Adam: A Method for Stochastic Optimization", "value": "cites"}, {"source": "Improving Video Generation with Human Feedback", "target": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper", "value": "cites"}, {"source": "Improving Video Generation with Human Feedback", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "cites"}, {"source": "Improving Video Generation with Human Feedback", "target": "Denoising Diffusion Probabilistic Models", "value": "cites"}, {"source": "Improving Video Generation with Human Feedback", "target": "Proximal Policy Optimization Algorithms", "value": "cites"}, {"source": "Flow-GRPO: Training Flow Matching Models via Online RL", "target": "Improving Video Generation with Human Feedback", "value": "cites"}, {"source": "DanceGRPO: Unleashing GRPO on Visual Generation", "target": "Improving Video Generation with Human Feedback", "value": "cites"}, {"source": "Seedance 1.0: Exploring the Boundaries of Video Generation Models", "target": "Improving Video Generation with Human Feedback", "value": "cites"}, {"source": "SkyReels-V2: Infinite-length Film Generative Model", "target": "Improving Video Generation with Human Feedback", "value": "cites"}, {"source": "Unified Reward Model for Multimodal Understanding and Generation", "target": "Improving Video Generation with Human Feedback", "value": "cites"}, {"source": "LiteToken: Removing Intermediate Merge Residues From BPE Tokenizers", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "cites"}, {"source": "LiteToken: Removing Intermediate Merge Residues From BPE Tokenizers", "target": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding", "value": "cites"}, {"source": "LiteToken: Removing Intermediate Merge Residues From BPE Tokenizers", "target": "SQuAD: 100,000+ Questions for Machine Comprehension of Text", "value": "cites"}, {"source": "LiteToken: Removing Intermediate Merge Residues From BPE Tokenizers", "target": "Neural Machine Translation of Rare Words with Subword Units", "value": "cites"}, {"source": "LiteToken: Removing Intermediate Merge Residues From BPE Tokenizers", "target": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing", "value": "cites"}, {"source": "MeKi: Memory-based Expert Knowledge Injection for Efficient LLM Scaling", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "cites"}, {"source": "MeKi: Memory-based Expert Knowledge Injection for Efficient LLM Scaling", "target": "GPT-4 Technical Report", "value": "cites"}, {"source": "MeKi: Memory-based Expert Knowledge Injection for Efficient LLM Scaling", "target": "LLaMA: Open and Efficient Foundation Language Models", "value": "cites"}, {"source": "MeKi: Memory-based Expert Knowledge Injection for Efficient LLM Scaling", "target": "Chain of Thought Prompting Elicits Reasoning in Large Language Models", "value": "cites"}, {"source": "MeKi: Memory-based Expert Knowledge Injection for Efficient LLM Scaling", "target": "Training Verifiers to Solve Math Word Problems", "value": "cites"}, {"source": "Beyond Conditional Computation: Retrieval-Augmented Genomic Foundation Models with Gengram", "target": "Attention is All you Need", "value": "cites"}, {"source": "Beyond Conditional Computation: Retrieval-Augmented Genomic Foundation Models with Gengram", "target": "Crystal structure of the nucleosome core particle at 2.8\u2009\u00c5 resolution", "value": "cites"}, {"source": "Beyond Conditional Computation: Retrieval-Augmented Genomic Foundation Models with Gengram", "target": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces", "value": "cites"}, {"source": "Beyond Conditional Computation: Retrieval-Augmented Genomic Foundation Models with Gengram", "target": "A catalogue of splice junction sequences.", "value": "cites"}, {"source": "Beyond Conditional Computation: Retrieval-Augmented Genomic Foundation Models with Gengram", "target": "Origin of the Genetic Code", "value": "cites"}, {"source": "L$^3$: Large Lookup Layers", "target": "Decoupled Weight Decay Regularization", "value": "cites"}, {"source": "L$^3$: Large Lookup Layers", "target": "SGDR: Stochastic Gradient Descent with Warm Restarts", "value": "cites"}, {"source": "L$^3$: Large Lookup Layers", "target": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer", "value": "cites"}, {"source": "L$^3$: Large Lookup Layers", "target": "Compression of individual sequences via variable-rate coding", "value": "cites"}, {"source": "L$^3$: Large Lookup Layers", "target": "Pointer Sentinel Mixture Models", "value": "cites"}, {"source": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "target": "Training Verifiers to Solve Math Word Problems", "value": "cites"}, {"source": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "target": "Measuring Massive Multitask Language Understanding", "value": "cites"}, {"source": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "target": "Let's Verify Step by Step", "value": "cites"}, {"source": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "target": "GPQA: A Graduate-Level Google-Proof Q&A Benchmark", "value": "cites"}, {"source": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "target": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding", "value": "cites"}, {"source": "Microsoft COCO: Common Objects in Context", "target": "ImageNet classification with deep convolutional neural networks", "value": "cites"}, {"source": "Microsoft COCO: Common Objects in Context", "target": "ImageNet: A large-scale hierarchical image database", "value": "cites"}, {"source": "Microsoft COCO: Common Objects in Context", "target": "Learning Multiple Layers of Features from Tiny Images", "value": "cites"}, {"source": "Microsoft COCO: Common Objects in Context", "target": "Histograms of oriented gradients for human detection", "value": "cites"}, {"source": "Microsoft COCO: Common Objects in Context", "target": "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation", "value": "cites"}, {"source": "MuMu-LLaMA: Multi-modal music understanding and generation via large language models", "target": "Microsoft COCO: Common Objects in Context", "value": "cites"}, {"source": "Mass Concept Erasure in Diffusion Models with Concept Hierarchy", "target": "Microsoft COCO: Common Objects in Context", "value": "cites"}, {"source": "Intelligent Recognition of GPR Road Hidden Defect Images Based on Feature Fusion and Attention Mechanism", "target": "Microsoft COCO: Common Objects in Context", "value": "cites"}, {"source": "Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking", "target": "Microsoft COCO: Common Objects in Context", "value": "cites"}, {"source": "Flexible Partial Screen-Shooting Watermarking With Provable Robustness", "target": "Microsoft COCO: Common Objects in Context", "value": "cites"}, {"source": "LifeCLEF Plant Identification Task 2015", "target": "ImageNet classification with deep convolutional neural networks", "value": "cites"}, {"source": "LifeCLEF Plant Identification Task 2015", "target": "ImageNet: A large-scale hierarchical image database", "value": "cites"}, {"source": "LifeCLEF Plant Identification Task 2015", "target": "Going deeper with convolutions", "value": "cites"}, {"source": "LifeCLEF Plant Identification Task 2015", "target": "Pattern Recognition and Machine Learning", "value": "cites"}, {"source": "LifeCLEF Plant Identification Task 2015", "target": "Bagging Predictors", "value": "cites"}, {"source": "Automatic Image-Based Plant Disease Severity Estimation Using Deep Learning", "target": "LifeCLEF Plant Identification Task 2015", "value": "cites"}, {"source": "Plant identification using deep neural networks via optimization of transfer learning parameters", "target": "LifeCLEF Plant Identification Task 2015", "value": "cites"}, {"source": "New perspectives on plant disease characterization based on deep learning", "target": "LifeCLEF Plant Identification Task 2015", "value": "cites"}, {"source": "Deep Learning for Plant Identification in Natural Environment", "target": "LifeCLEF Plant Identification Task 2015", "value": "cites"}, {"source": "Going deeper in the automated identification of Herbarium specimens", "target": "LifeCLEF Plant Identification Task 2015", "value": "cites"}, {"source": "FedMicro-IDA: A Federated Learning and Microservices-based Framework for IoT Data Analytics", "target": "Going deeper with convolutions", "value": "cites"}, {"source": "FedMicro-IDA: A Federated Learning and Microservices-based Framework for IoT Data Analytics", "target": "Densely Connected Convolutional Networks", "value": "cites"}, {"source": "FedMicro-IDA: A Federated Learning and Microservices-based Framework for IoT Data Analytics", "target": "MobileNetV2: Inverted Residuals and Linear Bottlenecks", "value": "cites"}, {"source": "FedMicro-IDA: A Federated Learning and Microservices-based Framework for IoT Data Analytics", "target": "Communication-Efficient Learning of Deep Networks from Decentralized Data", "value": "cites"}, {"source": "FedMicro-IDA: A Federated Learning and Microservices-based Framework for IoT Data Analytics", "target": "A Comprehensive Survey on Transfer Learning", "value": "cites"}, {"source": "Privacy Preserved and Decentralized Smartphone Recommendation System", "target": "FedMicro-IDA: A Federated Learning and Microservices-based Framework for IoT Data Analytics", "value": "cites"}, {"source": "A Survey on Heterogeneity Taxonomy, Security and Privacy Preservation in the Integration of IoT, Wireless Sensor Networks and Federated Learning", "target": "FedMicro-IDA: A Federated Learning and Microservices-based Framework for IoT Data Analytics", "value": "cites"}, {"source": "A privacy-preserving federated learning with a secure collaborative for malware detection models using Internet of Things resources", "target": "FedMicro-IDA: A Federated Learning and Microservices-based Framework for IoT Data Analytics", "value": "cites"}, {"source": "Graph-based deep learning techniques for remote sensing applications: Techniques, taxonomy, and applications - A comprehensive review", "target": "FedMicro-IDA: A Federated Learning and Microservices-based Framework for IoT Data Analytics", "value": "cites"}, {"source": "Federated Learning Architectures: A Performance Evaluation With Crop Yield Prediction Application", "target": "FedMicro-IDA: A Federated Learning and Microservices-based Framework for IoT Data Analytics", "value": "cites"}, {"source": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "cites"}, {"source": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "cites"}, {"source": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "target": "Segment Anything", "value": "cites"}, {"source": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "target": "Visual Instruction Tuning", "value": "cites"}, {"source": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "target": "Improved Baselines with Visual Instruction Tuning", "value": "cites"}, {"source": "Enhancing Descriptive Image Quality Assessment With a Large-Scale Multi-Modal Dataset", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "cites"}, {"source": "Adaptive Chain-of-Focus Reasoning via Dynamic Visual Search and Zooming for Efficient VLMs", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "cites"}, {"source": "Think with 3D: Geometric Imagination Grounded Spatial Reasoning from Limited Views", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "cites"}, {"source": "UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "cites"}, {"source": "OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe", "target": "LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training", "value": "cites"}, {"source": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "target": "Attention is All you Need", "value": "cites"}, {"source": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "target": "Long Short-Term Memory", "value": "cites"}, {"source": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "target": "ImageNet: A large-scale hierarchical image database", "value": "cites"}, {"source": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "target": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "value": "cites"}, {"source": "Vision-Language-Action (VLA) Models: Concepts, Progress, Applications and Challenges", "target": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "value": "cites"}, {"source": "Leave No Observation Behind: Real-time Correction for VLA Action Chunks", "target": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "value": "cites"}, {"source": "Latent Chain-of-Thought World Modeling for End-to-End Driving", "target": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "value": "cites"}, {"source": "HyperVLA: Efficient Inference in Vision-Language-Action Models via Hypernetworks", "target": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "value": "cites"}, {"source": "Token Expand-Merge: Training-Free Token Compression for Vision-Language-Action Models", "target": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "value": "cites"}, {"source": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "target": "Attention is All you Need", "value": "cites"}, {"source": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "target": "Adam: A Method for Stochastic Optimization", "value": "cites"}, {"source": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "target": "ImageNet classification with deep convolutional neural networks", "value": "cites"}, {"source": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "target": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "value": "cites"}, {"source": "A comprehensive survey for real-world industrial surface defect detection: Challenges, approaches, and prospects", "target": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "value": "cites"}, {"source": "TransSIL: A Silhouette Cue-Aware Image Classification Framework for Bird Ecological Monitoring Systems", "target": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "value": "cites"}, {"source": "CBRFormer: rendering technology-based transformer for refinement segmentation of bridge crack images", "target": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "value": "cites"}, {"source": "UAV-based quantitative crack measurement for bridges integrating four-point laser metric calibration and mamba segmentation", "target": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "value": "cites"}, {"source": "A Fast and Compact Threshold Switch-Based Cellular Nonlinear Network Cell", "target": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "value": "cites"}, {"source": "Learning Transferable Visual Models From Natural Language Supervision", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "Learning Transferable Visual Models From Natural Language Supervision", "target": "Attention is All you Need", "value": "cites"}, {"source": "Learning Transferable Visual Models From Natural Language Supervision", "target": "Adam: A Method for Stochastic Optimization", "value": "cites"}, {"source": "Learning Transferable Visual Models From Natural Language Supervision", "target": "ImageNet classification with deep convolutional neural networks", "value": "cites"}, {"source": "Learning Transferable Visual Models From Natural Language Supervision", "target": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "value": "cites"}, {"source": "Deep contrastive learning enables genome-wide virtual screening.", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "cites"}, {"source": "LLaVA-based semantic feature modulation diffusion model for underwater image enhancement", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "cites"}, {"source": "Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "cites"}, {"source": "3DGS-Drag: Dragging Gaussians for Intuitive Point-Based 3D Editing", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "cites"}, {"source": "LILaC: Late Interacting in Layered Component Graph for Open-domain Multimodal Multihop Retrieval", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "cites"}, {"source": "Improved Mean Flows: On the Challenges of Fastforward Generative Models", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "Improved Mean Flows: On the Challenges of Fastforward Generative Models", "target": "Attention is All you Need", "value": "cites"}, {"source": "Improved Mean Flows: On the Challenges of Fastforward Generative Models", "target": "ImageNet: A large-scale hierarchical image database", "value": "cites"}, {"source": "Improved Mean Flows: On the Challenges of Fastforward Generative Models", "target": "Denoising Diffusion Probabilistic Models", "value": "cites"}, {"source": "Improved Mean Flows: On the Challenges of Fastforward Generative Models", "target": "High-Resolution Image Synthesis with Latent Diffusion Models", "value": "cites"}, {"source": "Bidirectional Normalizing Flow: From Data to Noise and Back", "target": "Improved Mean Flows: On the Challenges of Fastforward Generative Models", "value": "cites"}, {"source": "One-step Latent-free Image Generation with Pixel Mean Flows", "target": "Improved Mean Flows: On the Challenges of Fastforward Generative Models", "value": "cites"}, {"source": "Meta Flow Maps enable scalable reward alignment", "target": "Improved Mean Flows: On the Challenges of Fastforward Generative Models", "value": "cites"}, {"source": "Accelerated Sequential Flow Matching: A Bayesian Filtering Perspective", "target": "Improved Mean Flows: On the Challenges of Fastforward Generative Models", "value": "cites"}, {"source": "Generative Modeling via Drifting", "target": "Improved Mean Flows: On the Challenges of Fastforward Generative Models", "value": "cites"}, {"source": "There is No VAE: End-to-End Pixel-Space Generative Modeling via Self-Supervised Pre-training", "target": "Attention is All you Need", "value": "cites"}, {"source": "There is No VAE: End-to-End Pixel-Space Generative Modeling via Self-Supervised Pre-training", "target": "ImageNet: A large-scale hierarchical image database", "value": "cites"}, {"source": "There is No VAE: End-to-End Pixel-Space Generative Modeling via Self-Supervised Pre-training", "target": "Denoising Diffusion Probabilistic Models", "value": "cites"}, {"source": "There is No VAE: End-to-End Pixel-Space Generative Modeling via Self-Supervised Pre-training", "target": "A Simple Framework for Contrastive Learning of Visual Representations", "value": "cites"}, {"source": "There is No VAE: End-to-End Pixel-Space Generative Modeling via Self-Supervised Pre-training", "target": "High-Resolution Image Synthesis with Latent Diffusion Models", "value": "cites"}, {"source": "PixelDiT: Pixel Diffusion Transformers for Image Generation", "target": "There is No VAE: End-to-End Pixel-Space Generative Modeling via Self-Supervised Pre-training", "value": "cites"}, {"source": "Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning", "target": "There is No VAE: End-to-End Pixel-Space Generative Modeling via Self-Supervised Pre-training", "value": "cites"}, {"source": "ImagerySearch: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints", "target": "There is No VAE: End-to-End Pixel-Space Generative Modeling via Self-Supervised Pre-training", "value": "cites"}, {"source": "One-step Latent-free Image Generation with Pixel Mean Flows", "target": "There is No VAE: End-to-End Pixel-Space Generative Modeling via Self-Supervised Pre-training", "value": "cites"}, {"source": "Generative Modeling via Drifting", "target": "There is No VAE: End-to-End Pixel-Space Generative Modeling via Self-Supervised Pre-training", "value": "cites"}, {"source": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "target": "ImageNet: A large-scale hierarchical image database", "value": "cites"}, {"source": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "target": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "value": "cites"}, {"source": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "target": "GENERATIVE ADVERSARIAL NETS", "value": "cites"}, {"source": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "target": "Denoising Diffusion Probabilistic Models", "value": "cites"}, {"source": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "target": "High-Resolution Image Synthesis with Latent Diffusion Models", "value": "cites"}, {"source": "Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders", "target": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "value": "cites"}, {"source": "Simulating the Visual World with Artificial Intelligence: A Roadmap", "target": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "value": "cites"}, {"source": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "target": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "value": "cites"}, {"source": "RecTok: Reconstruction Distillation along Rectified Flow", "target": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "value": "cites"}, {"source": "RePack then Refine: Efficient Diffusion Transformer with Vision Foundation Model", "target": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "value": "cites"}, {"source": "PixelDiT: Pixel Diffusion Transformers for Image Generation", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "cites"}, {"source": "PixelDiT: Pixel Diffusion Transformers for Image Generation", "target": "Decoupled Weight Decay Regularization", "value": "cites"}, {"source": "PixelDiT: Pixel Diffusion Transformers for Image Generation", "target": "High-Resolution Image Synthesis with Latent Diffusion Models", "value": "cites"}, {"source": "PixelDiT: Pixel Diffusion Transformers for Image Generation", "target": "Diffusion Models Beat GANs on Image Synthesis", "value": "cites"}, {"source": "PixelDiT: Pixel Diffusion Transformers for Image Generation", "target": "DINOv2: Learning Robust Visual Features without Supervision", "value": "cites"}, {"source": "One-step Latent-free Image Generation with Pixel Mean Flows", "target": "PixelDiT: Pixel Diffusion Transformers for Image Generation", "value": "cites"}, {"source": "Generative Modeling via Drifting", "target": "PixelDiT: Pixel Diffusion Transformers for Image Generation", "value": "cites"}, {"source": "Laminating Representation Autoencoders for Efficient Diffusion", "target": "PixelDiT: Pixel Diffusion Transformers for Image Generation", "value": "cites"}, {"source": "PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss", "target": "PixelDiT: Pixel Diffusion Transformers for Image Generation", "value": "cites"}, {"source": "RePack then Refine: Efficient Diffusion Transformer with Vision Foundation Model", "target": "PixelDiT: Pixel Diffusion Transformers for Image Generation", "value": "cites"}, {"source": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "target": "U-Net: Convolutional Networks for Biomedical Image Segmentation", "value": "cites"}, {"source": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "cites"}, {"source": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "target": "Decoupled Weight Decay Regularization", "value": "cites"}, {"source": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "target": "Denoising Diffusion Probabilistic Models", "value": "cites"}, {"source": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "target": "High-Resolution Image Synthesis with Latent Diffusion Models", "value": "cites"}, {"source": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "cites"}, {"source": "MentisOculi: Revealing the Limits of Reasoning with Mental Imagery", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "cites"}, {"source": "OpenVision 3: A Family of Unified Visual Encoder for Both Understanding and Generation", "target": "TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models", "value": "cites"}, {"source": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "target": "Attention is All you Need", "value": "cites"}, {"source": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "target": "ImageNet: A large-scale hierarchical image database", "value": "cites"}, {"source": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "target": "Distributed Representations of Words and Phrases and their Compositionality", "value": "cites"}, {"source": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "target": "GloVe: Global Vectors for Word Representation", "value": "cites"}, {"source": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "target": "Deep Contextualized Word Representations", "value": "cites"}, {"source": "Protein Language Models: Is Scaling Necessary?", "target": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "value": "cites"}, {"source": "Relating Word Embedding Gender Biases to Gender Gaps: A Cross-Cultural Analysis", "target": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "value": "cites"}, {"source": "SegMamba-V2: Long-Range Sequential Modeling Mamba for General 3-D Medical Image Segmentation", "target": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "value": "cites"}, {"source": "Generative Classifiers Avoid Shortcut Solutions", "target": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "value": "cites"}, {"source": "Edge Large AI Model Agent-Empowered Cognitive Multimodal Semantic Communication", "target": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "value": "cites"}, {"source": "Diffusion Language Models are Super Data Learners", "target": "Language Models are Few-Shot Learners", "value": "cites"}, {"source": "Diffusion Language Models are Super Data Learners", "target": "Language Models are Unsupervised Multitask Learners", "value": "cites"}, {"source": "Diffusion Language Models are Super Data Learners", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "cites"}, {"source": "Diffusion Language Models are Super Data Learners", "target": "The Llama 3 Herd of Models", "value": "cites"}, {"source": "Diffusion Language Models are Super Data Learners", "target": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer", "value": "cites"}, {"source": "A Survey on Diffusion Language Models", "target": "Diffusion Language Models are Super Data Learners", "value": "cites"}, {"source": "Training Optimal Large Diffusion Language Models", "target": "Diffusion Language Models are Super Data Learners", "value": "cites"}, {"source": "Inpainting-Guided Policy Optimization for Diffusion Large Language Models", "target": "Diffusion Language Models are Super Data Learners", "value": "cites"}, {"source": "Encoder-Decoder Diffusion Language Models for Efficient Training and Inference", "target": "Diffusion Language Models are Super Data Learners", "value": "cites"}, {"source": "Stable-DiffCoder: Pushing the Frontier of Code Diffusion Large Language Model", "target": "Diffusion Language Models are Super Data Learners", "value": "cites"}, {"source": "FLEX: Continuous Agent Evolution via Forward Learning from Experience", "target": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "value": "cites"}, {"source": "FLEX: Continuous Agent Evolution via Forward Learning from Experience", "target": "Language Models are Few-Shot Learners", "value": "cites"}, {"source": "FLEX: Continuous Agent Evolution via Forward Learning from Experience", "target": "Learning representations by back-propagating errors", "value": "cites"}, {"source": "FLEX: Continuous Agent Evolution via Forward Learning from Experience", "target": "Language Models are Unsupervised Multitask Learners", "value": "cites"}, {"source": "FLEX: Continuous Agent Evolution via Forward Learning from Experience", "target": "Proximal Policy Optimization Algorithms", "value": "cites"}, {"source": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "target": "FLEX: Continuous Agent Evolution via Forward Learning from Experience", "value": "cites"}, {"source": "Empirical-MCTS: Continuous Agent Evolution via Dual-Experience Monte Carlo Tree Search", "target": "FLEX: Continuous Agent Evolution via Forward Learning from Experience", "value": "cites"}, {"source": "TAME: A Trustworthy Test-Time Evolution of Agent Memory with Systematic Benchmarking", "target": "FLEX: Continuous Agent Evolution via Forward Learning from Experience", "value": "cites"}, {"source": "ProcMEM: Learning Reusable Procedural Memory from Experience via Non-Parametric PPO for LLM Agents", "target": "FLEX: Continuous Agent Evolution via Forward Learning from Experience", "value": "cites"}, {"source": "Position: Beyond Model-Centric Prediction -- Agentic Time Series Forecasting", "target": "FLEX: Continuous Agent Evolution via Forward Learning from Experience", "value": "cites"}, {"source": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "target": "Language Models are Few-Shot Learners", "value": "cites"}, {"source": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "cites"}, {"source": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "target": "Training language models to follow instructions with human feedback", "value": "cites"}, {"source": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "target": "PaLM: Scaling Language Modeling with Pathways", "value": "cites"}, {"source": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "target": "ReAct: Synergizing Reasoning and Acting in Language Models", "value": "cites"}, {"source": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "target": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "value": "cites"}, {"source": "Deep Research Agents: A Systematic Examination And Roadmap", "target": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "value": "cites"}, {"source": "Table-R1: Inference-Time Scaling for Table Reasoning", "target": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "value": "cites"}, {"source": "Mind2Report: A Cognitive Deep Research Agent for Expert-Level Commercial Report Synthesis", "target": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "value": "cites"}, {"source": "PaperScout: An Autonomous Agent for Academic Paper Search with Process-Aware Sequence-Level Policy Optimization", "target": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "value": "cites"}, {"source": "Squeeze-and-Excitation Networks", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "Squeeze-and-Excitation Networks", "target": "Attention is All you Need", "value": "cites"}, {"source": "Squeeze-and-Excitation Networks", "target": "ImageNet classification with deep convolutional neural networks", "value": "cites"}, {"source": "Squeeze-and-Excitation Networks", "target": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "value": "cites"}, {"source": "Squeeze-and-Excitation Networks", "target": "Long Short-Term Memory", "value": "cites"}, {"source": "Gradient-Guided Learning Network for Infrared Small Target Detection", "target": "Squeeze-and-Excitation Networks", "value": "cites"}, {"source": "Intelligent Recognition of GPR Road Hidden Defect Images Based on Feature Fusion and Attention Mechanism", "target": "Squeeze-and-Excitation Networks", "value": "cites"}, {"source": "A Retrieval-Augmented Generation Approach to Extracting Algorithmic Logic from Neural Networks", "target": "Squeeze-and-Excitation Networks", "value": "cites"}, {"source": "Flexible Partial Screen-Shooting Watermarking With Provable Robustness", "target": "Squeeze-and-Excitation Networks", "value": "cites"}, {"source": "UAV-based quantitative crack measurement for bridges integrating four-point laser metric calibration and mamba segmentation", "target": "Squeeze-and-Excitation Networks", "value": "cites"}, {"source": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks", "target": "Deep Residual Learning for Image Recognition", "value": "cites"}, {"source": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks", "target": "ImageNet classification with deep convolutional neural networks", "value": "cites"}, {"source": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks", "target": "Going deeper with convolutions", "value": "cites"}, {"source": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks", "target": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "value": "cites"}, {"source": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks", "target": "Dropout: a simple way to prevent neural networks from overfitting", "value": "cites"}, {"source": "CenterMamba-SAM: Center-Prioritized Scanning and Temporal Prototypes for Brain Lesion Segmentation", "target": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks", "value": "cites"}, {"source": "IMobileTransformer: A fusion-based lightweight model for rice disease identification", "target": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks", "value": "cites"}, {"source": "RF-DETR: Neural Architecture Search for Real-Time Detection Transformers", "target": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks", "value": "cites"}, {"source": "Non-invasive diagnosis of nutrient deficiencies in winter wheat and winter rye using UAV-based RGB images", "target": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks", "value": "cites"}, {"source": "Deep learning models for efficient geotechnical predictions: reducing training effort and data requirements with transfer learning", "target": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks", "value": "cites"}, {"source": "Light-X: Generative 4D Video Rendering with Camera and Illumination Control", "target": "Image quality assessment: from error visibility to structural similarity", "value": "cites"}, {"source": "Light-X: Generative 4D Video Rendering with Camera and Illumination Control", "target": "Microsoft COCO: Common Objects in Context", "value": "cites"}, {"source": "Light-X: Generative 4D Video Rendering with Camera and Illumination Control", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "cites"}, {"source": "Light-X: Generative 4D Video Rendering with Camera and Illumination Control", "target": "Generative Adversarial Networks", "value": "cites"}, {"source": "Light-X: Generative 4D Video Rendering with Camera and Illumination Control", "target": "Denoising Diffusion Probabilistic Models", "value": "cites"}, {"source": "FreeOrbit4D: Training-Free Arbitrary Camera Redirection for Monocular Videos via Geometry-Complete 4D Reconstruction", "target": "Light-X: Generative 4D Video Rendering with Camera and Illumination Control", "value": "cites"}, {"source": "NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos", "target": "Light-X: Generative 4D Video Rendering with Camera and Illumination Control", "value": "cites"}, {"source": "DriveLaW:Unifying Planning and Video Generation in a Latent Driving World", "target": "Attention is All you Need", "value": "cites"}, {"source": "DriveLaW:Unifying Planning and Video Generation in a Latent Driving World", "target": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium", "value": "cites"}, {"source": "DriveLaW:Unifying Planning and Video Generation in a Latent Driving World", "target": "nuScenes: A Multimodal Dataset for Autonomous Driving", "value": "cites"}, {"source": "DriveLaW:Unifying Planning and Video Generation in a Latent Driving World", "target": "Scalable Diffusion Models with Transformers", "value": "cites"}, {"source": "DriveLaW:Unifying Planning and Video Generation in a Latent Driving World", "target": "RoFormer: Enhanced Transformer with Rotary Position Embedding", "value": "cites"}, {"source": "The Role of World Models in Shaping Autonomous Driving: A Comprehensive Survey", "target": "DriveLaW:Unifying Planning and Video Generation in a Latent Driving World", "value": "cites"}, {"source": "DVGT: Driving Visual Geometry Transformer", "target": "Decoupled Weight Decay Regularization", "value": "cites"}, {"source": "DVGT: Driving Visual Geometry Transformer", "target": "Vision meets robotics: The KITTI dataset", "value": "cites"}, {"source": "DVGT: Driving Visual Geometry Transformer", "target": "nuScenes: A Multimodal Dataset for Autonomous Driving", "value": "cites"}, {"source": "DVGT: Driving Visual Geometry Transformer", "target": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "value": "cites"}, {"source": "DVGT: Driving Visual Geometry Transformer", "target": "Least-Squares Estimation of Transformation Parameters Between Two Point Patterns", "value": "cites"}, {"source": "FlexMap: Generalized HD Map Construction from Flexible Camera Configurations", "target": "DVGT: Driving Visual Geometry Transformer", "value": "cites"}, {"source": "Adding Conditional Control to Text-to-Image Diffusion Models", "target": "U-Net: Convolutional Networks for Biomedical Image Segmentation", "value": "cites"}, {"source": "Adding Conditional Control to Text-to-Image Diffusion Models", "target": "Et al", "value": "cites"}, {"source": "Adding Conditional Control to Text-to-Image Diffusion Models", "target": "Deep Learning", "value": "cites"}, {"source": "Adding Conditional Control to Text-to-Image Diffusion Models", "target": "Gradient-based learning applied to document recognition", "value": "cites"}, {"source": "Adding Conditional Control to Text-to-Image Diffusion Models", "target": "Learning Transferable Visual Models From Natural Language Supervision", "value": "cites"}, {"source": "MapAnything: Universal Feed-Forward Metric 3D Reconstruction", "target": "Adding Conditional Control to Text-to-Image Diffusion Models", "value": "cites"}, {"source": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "target": "Adding Conditional Control to Text-to-Image Diffusion Models", "value": "cites"}, {"source": "Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation", "target": "Adding Conditional Control to Text-to-Image Diffusion Models", "value": "cites"}, {"source": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "target": "Adding Conditional Control to Text-to-Image Diffusion Models", "value": "cites"}, {"source": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "target": "Adding Conditional Control to Text-to-Image Diffusion Models", "value": "cites"}, {"source": "Scaling Instruction-Finetuned Language Models", "target": "Language Models are Few-Shot Learners", "value": "cites"}, {"source": "Scaling Instruction-Finetuned Language Models", "target": "RoBERTa: A Robustly Optimized BERT Pretraining Approach", "value": "cites"}, {"source": "Scaling Instruction-Finetuned Language Models", "target": "Language Models are Unsupervised Multitask Learners", "value": "cites"}, {"source": "Scaling Instruction-Finetuned Language Models", "target": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "value": "cites"}, {"source": "Scaling Instruction-Finetuned Language Models", "target": "Training language models to follow instructions with human feedback", "value": "cites"}, {"source": "DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning", "target": "Scaling Instruction-Finetuned Language Models", "value": "cites"}, {"source": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "target": "Scaling Instruction-Finetuned Language Models", "value": "cites"}, {"source": "Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning", "target": "Scaling Instruction-Finetuned Language Models", "value": "cites"}, {"source": "Toward expert-level medical question answering with large language models", "target": "Scaling Instruction-Finetuned Language Models", "value": "cites"}, {"source": "SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training", "target": "Scaling Instruction-Finetuned Language Models", "value": "cites"}, {"source": "High-Resolution Image Synthesis with Latent Diffusion Models", "target": "Attention is All you Need", "value": "cites"}, {"source": "High-Resolution Image Synthesis with Latent Diffusion Models", "target": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "value": "cites"}, {"source": "High-Resolution Image Synthesis with Latent Diffusion Models", "target": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "value": "cites"}, {"source": "High-Resolution Image Synthesis with Latent Diffusion Models", "target": "U-Net: Convolutional Networks for Biomedical Image Segmentation", "value": "cites"}, {"source": "High-Resolution Image Synthesis with Latent Diffusion Models", "target": "ImageNet: A large-scale hierarchical image database", "value": "cites"}, {"source": "Equivariant Diffusion for Crystal Structure Prediction", "target": "High-Resolution Image Synthesis with Latent Diffusion Models", "value": "cites"}, {"source": "Generative Classifiers Avoid Shortcut Solutions", "target": "High-Resolution Image Synthesis with Latent Diffusion Models", "value": "cites"}, {"source": "WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling", "target": "High-Resolution Image Synthesis with Latent Diffusion Models", "value": "cites"}, {"source": "Native and Compact Structured Latents for 3D Generation", "target": "High-Resolution Image Synthesis with Latent Diffusion Models", "value": "cites"}, {"source": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "target": "High-Resolution Image Synthesis with Latent Diffusion Models", "value": "cites"}, {"source": "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric", "target": "ImageNet classification with deep convolutional neural networks", "value": "cites"}, {"source": "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric", "target": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "value": "cites"}, {"source": "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric", "target": "and as an in", "value": "cites"}, {"source": "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric", "target": "Et al", "value": "cites"}, {"source": "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric", "target": "Image quality assessment: from error visibility to structural similarity", "value": "cites"}, {"source": "What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?", "target": "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric", "value": "cites"}, {"source": "Flexible Partial Screen-Shooting Watermarking With Provable Robustness", "target": "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric", "value": "cites"}, {"source": "Progressive Learned Image Transmission for Semantic Communication Using Hierarchical VAE", "target": "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric", "value": "cites"}, {"source": "3DGS-Drag: Dragging Gaussians for Intuitive Point-Based 3D Editing", "target": "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric", "value": "cites"}, {"source": "STORM: Search-Guided Generative World Models for Robotic Manipulation", "target": "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric", "value": "cites"}, {"source": "Attention Is All You Need", "target": "Transformer", "value": "proposed_model"}, {"source": "Transformer", "target": "WMT 2014 English-to-German translation task", "value": "evaluated_on"}, {"source": "Transformer", "target": "WMT 2014 English-to-French translation task", "value": "evaluated_on"}, {"source": "Transformer", "target": "English constituency parsing", "value": "evaluated_on"}, {"source": "Transformer", "target": "BLEU", "value": "uses_metric"}, {"source": "Deep Residual Learning for Image Recognition", "target": "residual learning framework", "value": "proposed_model"}, {"source": "Deep Residual Learning for Image Recognition", "target": "residual networks", "value": "proposed_model"}, {"source": "Deep Residual Learning for Image Recognition", "target": "VGG nets", "value": "baseline_model"}, {"source": "residual networks", "target": "ImageNet dataset", "value": "evaluated_on"}, {"source": "residual networks", "target": "CIFAR-10", "value": "evaluated_on"}, {"source": "residual networks", "target": "COCO object detection dataset", "value": "evaluated_on"}, {"source": "residual networks", "target": "ILSVRC 2015 classification task", "value": "evaluated_on"}, {"source": "residual networks", "target": "ILSVRC & COCO 2015 competitions", "value": "evaluated_on"}, {"source": "residual networks", "target": "ImageNet detection", "value": "evaluated_on"}, {"source": "residual networks", "target": "ImageNet localization", "value": "evaluated_on"}, {"source": "residual networks", "target": "COCO detection", "value": "evaluated_on"}, {"source": "residual networks", "target": "COCO segmentation", "value": "evaluated_on"}, {"source": "Adam: A Method for Stochastic Optimization", "target": "Adam", "value": "proposed_model"}, {"source": "Adam: A Method for Stochastic Optimization", "target": "AdaMax", "value": "proposed_model"}, {"source": "Adam: A Method for Stochastic Optimization", "target": "other stochastic optimization methods", "value": "cites"}, {"source": "Dropout: a simple way to prevent neural networks from overfitting", "target": "Dropout", "value": "proposed_model"}, {"source": "Dropout", "target": "neural networks", "value": "evalu_on"}, {"source": "Rethinking the Inception Architecture for Computer Vision", "target": "Inception Architecture", "value": "proposed_model"}, {"source": "Rethinking the Inception Architecture for Computer Vision", "target": "ILSVRC 2012 classification challenge validation set", "value": "evaluated_on"}, {"source": "Rethinking the Inception Architecture for Computer Vision", "target": "top-1 error", "value": "uses_metric"}, {"source": "Rethinking the Inception Architecture for Computer Vision", "target": "top-5 error", "value": "uses_metric"}, {"source": "Rethinking the Inception Architecture for Computer Vision", "target": "convolutional networks", "value": "cites"}, {"source": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "target": "InstaDrive", "value": "proposed_model"}, {"source": "InstaDrive", "target": "nuScenes dataset", "value": "uses_metric"}, {"source": "InstaDrive", "target": "nuScenes dataset", "value": "evaluated_on"}, {"source": "InstaDrive", "target": "CARLA", "value": "cites"}, {"source": "CNC-VLM", "target": "CNC-VLM: An RLHF-optimized industrial large vision-language model with multimodal learning for imbalanced CNC fault detection", "value": "proposed_model"}, {"source": "CNC-VLM", "target": "CNC fault detection", "value": "uses_metric"}, {"source": "CNC-VLM", "target": "CNC fault detection", "value": "evaluated_on"}, {"source": "Enhanced Transformer-BiLSTM Deep Learning Framework for Day-Ahead Energy Price Forecasting", "target": "Transformer", "value": "proposed_model"}, {"source": "Enhanced Transformer-BiLSTM Deep Learning Framework for Day-Ahead Energy Price Forecasting", "target": "Bidirectional Long Short-Term Memory (BiLSTM)", "value": "proposed_model"}, {"source": "Enhanced Transformer-BiLSTM Deep Learning Framework for Day-Ahead Energy Price Forecasting", "target": "New York Independent System Operator", "value": "evaluated_on"}, {"source": "Enhanced Transformer-BiLSTM Deep Learning Framework for Day-Ahead Energy Price Forecasting", "target": "MAE", "value": "uses_metric"}, {"source": "Enhanced Transformer-BiLSTM Deep Learning Framework for Day-Ahead Energy Price Forecasting", "target": "RMSE", "value": "uses_metric"}, {"source": "Enhanced Transformer-BiLSTM Deep Learning Framework for Day-Ahead Energy Price Forecasting", "target": "sMAPE", "value": "uses_metric"}, {"source": "Enhanced Transformer-BiLSTM Deep Learning Framework for Day-Ahead Energy Price Forecasting", "target": "MAPE", "value": "uses_metric"}, {"source": "Enhanced Transformer-BiLSTM Deep Learning Framework for Day-Ahead Energy Price Forecasting", "target": "R\u00b2", "value": "uses_metric"}, {"source": "UAV-based quantitative crack measurement for bridges integrating four-point laser metric calibration and mamba segmentation", "target": "four-point laser metric calibration", "value": "uses_metric"}, {"source": "UAV-based quantitative crack measurement for bridges integrating four-point laser metric calibration and mamba segmentation", "target": "mamba segmentation", "value": "evaluated_on"}, {"source": "Alex Krizhevsky", "target": "ImageNet classification with deep convolutional neural networks", "value": "author_of"}, {"source": "Ilya Sutskever", "target": "ImageNet classification with deep convolutional neural networks", "value": "author_of"}, {"source": "Geoffrey E. Hinton", "target": "ImageNet classification with deep convolutional neural networks", "value": "author_of"}, {"source": "ImageNet classification with deep convolutional neural networks", "target": "ImageNet", "value": "evaluated_on"}, {"source": "ImageNet classification with deep convolutional neural networks", "target": "deep convolutional neural network", "value": "proposed_model"}, {"source": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "target": "ImageNet Challenge 2014", "value": "evaluated_on"}, {"source": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "target": "ConvNet models", "value": "proposed_model"}, {"source": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "target": "Faster R-CNN", "value": "proposed_model"}, {"source": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "target": "Region Proposal Network (RPN)", "value": "proposed_model"}, {"source": "Faster R-CNN", "target": "SPPnet", "value": "cites"}, {"source": "Faster R-CNN", "target": "Fast R-CNN", "value": "cites"}, {"source": "Faster R-CNN", "target": "PASCAL VOC 2007", "value": "evaluated_on"}, {"source": "Faster R-CNN", "target": "PASCAL VOC 2012", "value": "evaluated_on"}, {"source": "Faster R-CNN", "target": "MS COCO", "value": "evaluated_on"}, {"source": "Faster R-CNN", "target": "Fast R-CNN", "value": "baseline_model"}, {"source": "Region Proposal Network (RPN)", "target": "Fast R-CNN", "value": "baseline_model"}, {"source": "Optimal Transport Barycentric Aggregation for Byzantine-Resilient Federated Learning", "target": "Federated Learning Optimal Transport (FLOT)", "value": "proposed_model"}, {"source": "Federated Learning Optimal Transport (FLOT)", "target": "GTSRB", "value": "evaluated_on"}, {"source": "Federated Learning Optimal Transport (FLOT)", "target": "KBTS", "value": "evaluated_on"}, {"source": "Federated Learning Optimal Transport (FLOT)", "target": "CIFAR10", "value": "evaluated_on"}, {"source": "Federated Learning Optimal Transport (FLOT)", "target": "EMNIST", "value": "evaluated_on"}, {"source": "DiffusionEngine: Diffusion model is scalable data engine for object detection", "target": "DiffusionEngine", "value": "proposed_model"}, {"source": "DiffusionEngine: Diffusion model is scalable data engine for object detection", "target": "object detection", "value": "evaluated_on"}, {"source": "Enhancing hyperspectral image prediction with contrastive learning in low-label regimes", "target": "contrastive learning", "value": "proposed_model"}, {"source": "Enhancing hyperspectral image prediction with contrastive learning in low-label regimes", "target": "hyperspectral image prediction", "value": "evaluated_on"}, {"source": "WarmGait", "target": "thermal array sensors", "value": "proposed_model"}, {"source": "WarmGait", "target": "average recognition accuracy of 87.3%", "value": "uses_metric"}, {"source": "WarmGait", "target": "average recognition accuracy of 87.3%", "value": "evaluated_on"}, {"source": "edge module", "target": "Taylor Finite Difference (TFD)", "value": "cites"}, {"source": "WarmGait", "target": "gait recognition", "value": "baseline_model"}, {"source": "WarmGait", "target": "Person re-identification (Re-ID)", "value": "author_of"}, {"source": "Auto-Encoding Variational Bayes", "target": "stochastic variational inference and learning algorithm", "value": "proposed_model"}, {"source": "stochastic variational inference and learning algorithm", "target": "variational lower bound", "value": "uses_metric"}, {"source": "stochastic variational inference and learning algorithm", "target": "i.i.d. datasets", "value": "evaluated_on"}, {"source": "stochastic variational inference and learning algorithm", "target": "lower bound estimator", "value": "proposed_model"}, {"source": "lower bound estimator", "target": "variational lower bound", "value": "uses_metric"}, {"source": "lower bound estimator", "target": "standard stochastic gradient methods", "value": "baseline_model"}, {"source": "stochastic variational inference and learning algorithm", "target": "approximate inference model", "value": "proposed_model"}, {"source": "approximate inference model", "target": "recognition model", "value": "cites"}, {"source": "Supporting Online Material for Reducing the Dimensionality of Data with Neural Networks", "target": "Reducing the Dimensionality of Data with Neural Networks", "value": "cites"}, {"source": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization", "target": "Online Learning", "value": "evaluated_on"}, {"source": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization", "target": "Stochastic Optimization", "value": "evaluated_on"}, {"source": "Speech recognition with deep recurrent neural networks", "target": "deep recurrent neural networks", "value": "proposed_model"}, {"source": "Speech recognition with deep recurrent neural networks", "target": "deep Long Short-term Memory RNNs", "value": "proposed_model"}, {"source": "deep Long Short-term Memory RNNs", "target": "TIMIT phoneme recognition benchmark", "value": "evaluated_on"}, {"source": "Speech recognition with deep recurrent neural networks", "target": "Recurrent neural networks", "value": "cites"}, {"source": "Speech recognition with deep recurrent neural networks", "target": "Connectionist Temporal Classification", "value": "cites"}, {"source": "Speech recognition with deep recurrent neural networks", "target": "Long Short-term Memory", "value": "cites"}, {"source": "Weakly Supervised Image Dehazing via Physics-Based Decomposition", "target": "PBD", "value": "proposed_model"}, {"source": "Weakly Supervised Image Dehazing via Physics-Based Decomposition", "target": "NianWang-HJJGCDX", "value": "author_of"}, {"source": "PBD", "target": "seven benchmarks", "value": "evaluated_on"}, {"source": "PBD", "target": "GAN", "value": "baseline_model"}, {"source": "PBD", "target": "GAN", "value": "cites"}, {"source": "A Machine Learning Approach for Face Mask Detection System with AdamW Optimizer", "target": "face mask detection model", "value": "proposed_model"}, {"source": "A Machine Learning Approach for Face Mask Detection System with AdamW Optimizer", "target": "Adam optimizer", "value": "baseline_model"}, {"source": "A Machine Learning Approach for Face Mask Detection System with AdamW Optimizer", "target": "face mask detection model", "value": "evaluated_on"}, {"source": "A Machine Learning Approach for Face Mask Detection System with AdamW Optimizer", "target": "AdamW optimizer", "value": "cites"}, {"source": "A Machine Learning Approach for Face Mask Detection System with AdamW Optimizer", "target": "Adam optimizer", "value": "cites"}, {"source": "A Machine Learning Approach for Face Mask Detection System with AdamW Optimizer", "target": "Adam with L2-regularization", "value": "cites"}, {"source": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "target": "Engram", "value": "proposed_model"}, {"source": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "target": "Mixture-of-Experts (MoE)", "value": "baseline_model"}, {"source": "Engram", "target": "MMLU", "value": "evaluated_on"}, {"source": "Engram", "target": "CMMLU", "value": "evaluated_on"}, {"source": "Engram", "target": "BBH", "value": "evaluated_on"}, {"source": "Engram", "target": "ARC-Challenge", "value": "evaluated_on"}, {"source": "Engram", "target": "HumanEval", "value": "evaluated_on"}, {"source": "Engram", "target": "MATH", "value": "evaluated_on"}, {"source": "Engram", "target": "Multi-Query NIAH", "value": "evaluated_on"}, {"source": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models", "target": "Transformers", "value": "cites"}, {"source": "Probabilistic hierarchical interpolation and interpretable neural network configurations for flood prediction", "target": "Neural Hierarchical Interpolation for Time Series Forecasting (N-HiTS)", "value": "proposed_model"}, {"source": "Probabilistic hierarchical interpolation and interpretable neural network configurations for flood prediction", "target": "Network-Based Expansion Analysis for Interpretable Time Series Forecasting (N-BEATS)", "value": "proposed_model"}, {"source": "Probabilistic hierarchical interpolation and interpretable neural network configurations for flood prediction", "target": "long short-term memory (LSTM)", "value": "baseline_model"}, {"source": "Neural Hierarchical Interpolation for Time Series Forecasting (N-HiTS)", "target": "flood prediction", "value": "evaluated_on"}, {"source": "Network-Based Expansion Analysis for Interpretable Time Series Forecasting (N-BEATS)", "target": "flood prediction", "value": "evaluated_on"}, {"source": "long short-term memory (LSTM)", "target": "flood prediction", "value": "evaluated_on"}, {"source": "Neural Hierarchical Interpolation for Time Series Forecasting (N-HiTS)", "target": "headwater streams in Georgia and North Carolina, USA", "value": "evaluated_on"}, {"source": "Network-Based Expansion Analysis for Interpretable Time Series Forecasting (N-BEATS)", "target": "headwater streams in Georgia and North Carolina, USA", "value": "evaluated_on"}, {"source": "long short-term memory (LSTM)", "target": "headwater streams in Georgia and North Carolina, USA", "value": "evaluated_on"}, {"source": "Neural Hierarchical Interpolation for Time Series Forecasting (N-HiTS)", "target": "Multi-Quantile Loss", "value": "uses_metric"}, {"source": "Network-Based Expansion Analysis for Interpretable Time Series Forecasting (N-BEATS)", "target": "Multi-Quantile Loss", "value": "uses_metric"}, {"source": "Multi-Quantile Loss", "target": "95th percentile prediction uncertainty (95 PPU)", "value": "uses_metric"}, {"source": "Generating an annual 30 m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "target": "harmonized Landsat and Sentinel-2 data", "value": "uses_metric"}, {"source": "Generating an annual 30 m rice cover product for monsoon Asia (2018\u20132023) using harmonized Landsat and Sentinel-2 data and the NASA-IBM geospatial foundation model", "target": "NASA-IBM geospatial foundation model", "value": "proposed_model"}, {"source": "Going deeper with convolutions", "target": "Inception", "value": "proposed_model"}, {"source": "Going deeper with convolutions", "target": "GoogLeNet", "value": "proposed_model"}, {"source": "Inception", "target": "ImageNet Large-Scale Visual Recognition Challenge 2014", "value": "evaluated_on"}, {"source": "Inception", "target": "ILSVRC 2014", "value": "evaluated_on"}, {"source": "GoogLeNet", "target": "ImageNet Large-Scale Visual Recognition Challenge 2014", "value": "evaluated_on"}, {"source": "GoogLeNet", "target": "ILSVRC 2014", "value": "evaluated_on"}, {"source": "Batch Normalization", "target": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "value": "proposed_model"}, {"source": "Batch Normalization", "target": "ImageNet", "value": "evaluated_on"}, {"source": "Batch Normalization", "target": "state-of-the-art image classification model", "value": "baseline_model"}, {"source": "Batch Normalization", "target": "Dropout", "value": "cites"}, {"source": "This paper", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "author_of"}, {"source": "This paper", "target": "ImageNet Large Scale Visual Recognition Challenge", "value": "cites"}, {"source": "Diffusion Transformers with Representation Autoencoders", "target": "Representation Autoencoders (RAEs)", "value": "proposed_model"}, {"source": "Diffusion Transformers with Representation Autoencoders", "target": "VAE encoder", "value": "baseline_model"}, {"source": "Diffusion Transformers with Representation Autoencoders", "target": "ImageNet", "value": "evaluated_on"}, {"source": "Diffusion Transformers with Representation Autoencoders", "target": "FID", "value": "uses_metric"}, {"source": "Representation Autoencoders (RAEs)", "target": "DINO", "value": "cites"}, {"source": "Representation Autoencoders (RAEs)", "target": "SigLIP", "value": "cites"}, {"source": "Representation Autoencoders (RAEs)", "target": "MAE", "value": "cites"}, {"source": "Diffusion Transformers (DiT)", "target": "VAE encoder", "value": "cites"}, {"source": "Diffusion Transformers with Representation Autoencoders", "target": "Diffusion Transformers (DiT)", "value": "cites"}, {"source": "Diffusion Transformers with Representation Autoencoders", "target": "DDT head", "value": "cites"}, {"source": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "target": "C2S-Scale", "value": "proposed_model"}, {"source": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "target": "Cell2Sentence (C2S) framework", "value": "baseline_model"}, {"source": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "target": "Large Language Models (LLMs)", "value": "baseline_model"}, {"source": "C2S-Scale", "target": "single-cell RNA sequencing", "value": "evaluated_on"}, {"source": "C2S-Scale", "target": "transcriptomic data", "value": "evaluated_on"}, {"source": "C2S-Scale", "target": "biological text", "value": "evaluated_on"}, {"source": "C2S-Scale", "target": "metadata", "value": "evaluated_on"}, {"source": "C2S-Scale", "target": "human cell models", "value": "evaluated_on"}, {"source": "Scaling Large Language Models for Next-Generation Single-Cell Analysis", "target": "Cell2Sentence (C2S) framework", "value": "cites"}, {"source": "C2S-Scale", "target": "silmitasertib (CX-4945)", "value": "cites"}, {"source": "HybridVisionNet: An advanced hybrid deep learning framework for automated multi-class ocular disease diagnosis using fundus imaging", "target": "HybridVisionNet", "value": "proposed_model"}, {"source": "HybridVisionNet", "target": "fundus imaging", "value": "evaluated_on"}, {"source": "Revisiting Transferable Adversarial Images: Systemization, Evaluation, and New Insights", "target": "authors", "value": "author_of"}, {"source": "Revisiting Transferable Adversarial Images: Systemization, Evaluation, and New Insights", "target": "transfer attacks", "value": "proposed_model"}, {"source": "Revisiting Transferable Adversarial Images: Systemization, Evaluation, and New Insights", "target": "adversarial images", "value": "evaluated_on"}, {"source": "Revisiting Transferable Adversarial Images: Systemization, Evaluation, and New Insights", "target": "defenses", "value": "evaluated_on"}, {"source": "Revisiting Transferable Adversarial Images: Systemization, Evaluation, and New Insights", "target": "DI", "value": "cites"}, {"source": "Revisiting Transferable Adversarial Images: Systemization, Evaluation, and New Insights", "target": "DiffPure", "value": "cites"}, {"source": "Revisiting Transferable Adversarial Images: Systemization, Evaluation, and New Insights", "target": "Google Cloud Vision", "value": "cites"}, {"source": "transfer attacks", "target": "DI", "value": "baseline_model"}, {"source": "transfer attacks", "target": "defenses", "value": "evaluated_on"}, {"source": "transfer attacks", "target": "imperceptibility metrics", "value": "uses_metric"}, {"source": "transfer attacks", "target": "user study", "value": "uses_metric"}, {"source": "transfer attacks", "target": "Lp constraint", "value": "uses_metric"}, {"source": "defenses", "target": "adversarial images", "value": "evaluated_on"}, {"source": "defenses", "target": "DiffPure", "value": "includes"}, {"source": "defenses", "target": "Google Cloud Vision", "value": "includes"}, {"source": "DI", "target": "adversarial images", "value": "evaluated_on"}, {"source": "DiffPure", "target": "adversarial images", "value": "evaluated_on"}, {"source": "Dataset Purification-Driven Lightweight Deep Learning Model Construction for Empty-Dish Recycling Robot", "target": "YOLO-OG", "value": "proposed_model"}, {"source": "Dataset Purification-Driven Lightweight Deep Learning Model Construction for Empty-Dish Recycling Robot", "target": "OGNet", "value": "proposed_model"}, {"source": "OGNet", "target": "Dish-10", "value": "evaluated_on"}, {"source": "YOLO-OG", "target": "Dish-10", "value": "evaluated_on"}, {"source": "YOLO-OG", "target": "Dish-20", "value": "evaluated_on"}, {"source": "YOLO-OG", "target": "mean Average Precision (mAP)", "value": "uses_metric"}, {"source": "Dataset Purification-Driven Lightweight Deep Learning Model Construction for Empty-Dish Recycling Robot", "target": "Empty-dish Recycling Robot", "value": "cites"}, {"source": "Attention is All you Need", "target": "Transformer", "value": "proposed_model"}, {"source": "Transformer", "target": "WMT 2014 English-to-German translation task", "value": "evaluated_on"}, {"source": "Transformer", "target": "WMT 2014 English-to-French translation task", "value": "evaluated_on"}, {"source": "Transformer", "target": "English constituency parsing", "value": "evaluated_on"}, {"source": "Transformer", "target": "BLEU", "value": "uses_metric"}, {"source": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "target": "transfer learning", "value": "cites"}, {"source": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "target": "we", "value": "author_of"}, {"source": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium", "target": "Two Time-Scale Update Rule", "value": "proposed_model"}, {"source": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium", "target": "Local Nash Equilibrium", "value": "evaluated_on"}, {"source": "nuScenes", "target": "baselines for lidar and image based detection and tracking", "value": "baseline_model"}, {"source": "nuScenes", "target": "3D detection and tracking metrics", "value": "evaluated_on"}, {"source": "nuScenes", "target": "KITTI dataset", "value": "cites"}, {"source": "nuScenes", "target": "Robust detection and tracking of objects", "value": "author_of"}, {"source": "nuScenes", "target": "nuTonomy scenes", "value": "proposed_model"}, {"source": "Image based benchmark datasets", "target": "computer vision tasks", "value": "uses_metric"}, {"source": "autonomous vehicle technology", "target": "machine learning based methods for detection and tracking", "value": "cites"}, {"source": "CARLA: An Open Urban Driving Simulator", "target": "CARLA", "value": "proposed_model"}, {"source": "CARLA", "target": "autonomous driving research", "value": "evaluated_on"}, {"source": "CARLA", "target": "autonomous driving research", "value": "uses_metric"}, {"source": "classic modular pipeline", "target": "CARLA", "value": "baseline_model"}, {"source": "end-to-end model trained via imitation learning", "target": "CARLA", "value": "baseline_model"}, {"source": "end-to-end model trained via reinforcement learning", "target": "CARLA", "value": "baseline_model"}, {"source": "Sora", "target": "world modeling", "value": "proposed_model"}, {"source": "text-to-video generation", "target": "world modeling", "value": "evaluated_on"}, {"source": "OmniNWM: Omniscient Driving Navigation World Models", "target": "OmniNWM", "value": "proposed_model"}, {"source": "OmniNWM", "target": "autonomous driving world models", "value": "baseline_model"}, {"source": "OmniNWM", "target": "panoramic videos", "value": "evaluated_on"}, {"source": "OmniNWM", "target": "3D occupancy", "value": "evaluated_on"}, {"source": "OmniNWM", "target": "occupancy-grounded rewards", "value": "uses_metric"}, {"source": "OmniNWM", "target": "autonomous driving world models", "value": "cites"}, {"source": "ConsisDrive: Identity-Preserving Driving World Models for Video Generation by Instance Mask", "target": "ConsisDrive", "value": "proposed_model"}, {"source": "ConsisDrive", "target": "Instance-Masked Attention", "value": "uses_metric"}, {"source": "ConsisDrive", "target": "Instance-Masked Loss", "value": "uses_metric"}, {"source": "ConsisDrive", "target": "nuScenes", "value": "evaluated_on"}, {"source": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "target": "UniDriveDreamer", "value": "proposed_model"}, {"source": "UniDriveDreamer", "target": "multi-camera video", "value": "uses_metric"}, {"source": "UniDriveDreamer", "target": "LiDAR sequence", "value": "uses_metric"}, {"source": "UniDriveDreamer", "target": "autonomous driving", "value": "evaluated_on"}, {"source": "UniDriveDreamer", "target": "World models", "value": "cites"}, {"source": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "target": "MAD-LTX", "value": "proposed_model"}, {"source": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "target": "SVD", "value": "baseline_model"}, {"source": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "target": "autonomous driving", "value": "evaluated_on"}, {"source": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "target": "video diffusion models", "value": "cites"}, {"source": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "target": "driving world models", "value": "cites"}, {"source": "REPA", "target": "What matters for Representation Alignment: Global Information or Spatial Structure?", "value": "proposed_model"}, {"source": "iREPA", "target": "What matters for Representation Alignment: Global Information or Spatial Structure?", "value": "proposed_model"}, {"source": "REPA", "target": "ImageNet-1K", "value": "evaluated_on"}, {"source": "iREPA", "target": "ImageNet-1K", "value": "evaluated_on"}, {"source": "iREPA", "target": "REPA", "value": "baseline_model"}, {"source": "iREPA", "target": "REPA-E", "value": "baseline_model"}, {"source": "iREPA", "target": "Meanflow", "value": "baseline_model"}, {"source": "iREPA", "target": "JiT", "value": "baseline_model"}, {"source": "SCB-DETR", "target": "SCB-DETR: Multiscale Deformable Transformers for Occlusion-Resilient Student Learning Behavior Detection in Smart Classroom", "value": "proposed_model"}, {"source": "SCB-DETR: Multiscale Deformable Transformers for Occlusion-Resilient Student Learning Behavior Detection in Smart Classroom", "target": "We", "value": "author_of"}, {"source": "SCB-DETR", "target": "SCBehavior dataset", "value": "evaluated_on"}, {"source": "SCB-DETR", "target": "mean Average Precision (mAP)", "value": "uses_metric"}, {"source": "SCB-DETR", "target": "AP50", "value": "uses_metric"}, {"source": "SCB-DETR", "target": "baseline model", "value": "baseline_model"}, {"source": "Robust Deep Feature Ultrasound Image-Based Visual Servoing: Focus on Cardiac Examination", "target": "ultrasound-cardiac-feature-net (UCF-Net)", "value": "proposed_model"}, {"source": "Robust Deep Feature Ultrasound Image-Based Visual Servoing: Focus on Cardiac Examination", "target": "filtered integral quasi-super-twisting algorithm (FIQSTA)", "value": "proposed_model"}, {"source": "Robust Deep Feature Ultrasound Image-Based Visual Servoing: Focus on Cardiac Examination", "target": "proportional (P) controller", "value": "baseline_model"}, {"source": "Robust Deep Feature Ultrasound Image-Based Visual Servoing: Focus on Cardiac Examination", "target": "sliding mode controller", "value": "baseline_model"}, {"source": "Robust Deep Feature Ultrasound Image-Based Visual Servoing: Focus on Cardiac Examination", "target": "super-twisting algorithm (STA)", "value": "baseline_model"}, {"source": "Robust Deep Feature Ultrasound Image-Based Visual Servoing: Focus on Cardiac Examination", "target": "integral quasi-STA", "value": "baseline_model"}, {"source": "Robust Deep Feature Ultrasound Image-Based Visual Servoing: Focus on Cardiac Examination", "target": "cardiac phantom", "value": "evaluated_on"}, {"source": "ultrasound-cardiac-feature-net (UCF-Net)", "target": "deep ultrasound image features", "value": "uses_metric"}, {"source": "Robust Deep Feature Ultrasound Image-Based Visual Servoing: Focus on Cardiac Examination", "target": "proportional (P) controller", "value": "cites"}, {"source": "Robust Deep Feature Ultrasound Image-Based Visual Servoing: Focus on Cardiac Examination", "target": "sliding mode controller", "value": "cites"}, {"source": "Robust Deep Feature Ultrasound Image-Based Visual Servoing: Focus on Cardiac Examination", "target": "super-twisting algorithm (STA)", "value": "cites"}, {"source": "Robust Deep Feature Ultrasound Image-Based Visual Servoing: Focus on Cardiac Examination", "target": "integral quasi-STA", "value": "cites"}, {"source": "BioTune", "target": "Bio-Inspired Fine-Tuning for Selective Transfer Learning in Image Classification", "value": "proposed_model"}, {"source": "BioTune", "target": "nine image classification datasets", "value": "evaluated_on"}, {"source": "BioTune", "target": "medical imaging", "value": "evaluated_on"}, {"source": "BioTune", "target": "four different CNN architectures", "value": "evaluated_on"}, {"source": "BioTune", "target": "AutoRGN", "value": "baseline_model"}, {"source": "BioTune", "target": "LoRA", "value": "baseline_model"}, {"source": "Hand Sign Language Detection Using Deep Learning", "target": "VGG-16 net", "value": "proposed_model"}, {"source": "Hand Sign Language Detection Using Deep Learning", "target": "NUS dataset", "value": "evaluated_on"}, {"source": "VGG-16 net", "target": "convolutional neural network", "value": "baseline_model"}, {"source": "VGG-16 net", "target": "Google's open source Application Programming Interface (API)", "value": "evaluated_on"}, {"source": "Representation Learning: A Review and New Perspectives", "target": "unsupervised feature learning", "value": "cites"}, {"source": "Representation Learning: A Review and New Perspectives", "target": "deep learning", "value": "cites"}, {"source": "Representation Learning: A Review and New Perspectives", "target": "probabilistic models", "value": "cites"}, {"source": "Representation Learning: A Review and New Perspectives", "target": "auto-encoders", "value": "cites"}, {"source": "Representation Learning: A Review and New Perspectives", "target": "manifold learning", "value": "cites"}, {"source": "Representation Learning: A Review and New Perspectives", "target": "deep networks", "value": "cites"}, {"source": "representation learning", "target": "machine learning algorithms", "value": "proposed_model"}, {"source": "representation learning", "target": "density estimation", "value": "evaluated_on"}, {"source": "representation learning", "target": "manifold learning", "value": "evaluated_on"}, {"source": "Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion", "target": "Stacked Denoising Autoencoders", "value": "proposed_model"}, {"source": "Stochastic Backpropagation and Approximate Inference in Deep Generative Models", "target": "Stochastic Backpropagation", "value": "proposed_model"}, {"source": "Stochastic Backpropagation and Approximate Inference in Deep Generative Models", "target": "Deep Generative Models", "value": "proposed_model"}, {"source": "SDXL-Lightning: Progressive Adversarial Diffusion Distillation", "target": "SDXL-Lightning models", "value": "proposed_model"}, {"source": "SDXL-Lightning models", "target": "SDXL", "value": "baseline_model"}, {"source": "EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditions", "target": "EchoMimic", "value": "proposed_model"}, {"source": "EchoMimic", "target": "audios", "value": "uses_metric"}, {"source": "EchoMimic", "target": "facial landmarks", "value": "uses_metric"}, {"source": "EchoMimic", "target": "public datasets", "value": "evaluated_on"}, {"source": "EchoMimic", "target": "collected dataset", "value": "evaluated_on"}, {"source": "EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditions", "target": "portrait image animation", "value": "cites"}, {"source": "GenAD: Generative End-to-End Autonomous Driving", "target": "GenAD", "value": "proposed_model"}, {"source": "GenAD: Generative End-to-End Autonomous Driving", "target": "nuScenes", "value": "evaluated_on"}, {"source": "GenAD", "target": "end-to-end autonomous driving methods", "value": "baseline_model"}, {"source": "GenAD", "target": "end-to-end autonomous driving methods", "value": "cites"}, {"source": "Ovis: Structural Embedding Alignment for Multimodal Large Language Model", "target": "Ovis", "value": "proposed_model"}, {"source": "Ovis", "target": "Qwen-VL-Plus", "value": "baseline_model"}, {"source": "Ovis", "target": "various multimodal benchmarks", "value": "evaluated_on"}, {"source": "Ovis", "target": "Multimodal Large Language Models (MLLMs)", "value": "cites"}, {"source": "Improving Video Generation with Human Feedback", "target": "VideoReward", "value": "proposed_model"}, {"source": "Improving Video Generation with Human Feedback", "target": "Flow-DPO", "value": "proposed_model"}, {"source": "Improving Video Generation with Human Feedback", "target": "Flow-RWR", "value": "proposed_model"}, {"source": "Improving Video Generation with Human Feedback", "target": "Flow-NRG", "value": "proposed_model"}, {"source": "Improving Video Generation with Human Feedback", "target": "rectified flow techniques", "value": "baseline_model"}, {"source": "Improving Video Generation with Human Feedback", "target": "supervised fine-tuning methods", "value": "baseline_model"}, {"source": "VideoReward", "target": "large-scale human preference dataset", "value": "evaluated_on"}, {"source": "Flow-DPO", "target": "large-scale human preference dataset", "value": "evaluated_on"}, {"source": "Flow-RWR", "target": "large-scale human preference dataset", "value": "evaluated_on"}, {"source": "Flow-NRG", "target": "large-scale human preference dataset", "value": "evaluated_on"}, {"source": "Improving Video Generation with Human Feedback", "target": "rectified flow techniques", "value": "cites"}, {"source": "Improving Video Generation with Human Feedback", "target": "modern video generation models", "value": "cites"}, {"source": "Speech Recognition with Deep Recurrent Neural Networks", "target": "deep recurrent neural networks", "value": "proposed_model"}, {"source": "Speech Recognition with Deep Recurrent Neural Networks", "target": "deep Long Short-term Memory RNNs", "value": "proposed_model"}, {"source": "Speech Recognition with Deep Recurrent Neural Networks", "target": "TIMIT phoneme recognition benchmark", "value": "evaluated_on"}, {"source": "deep recurrent neural networks", "target": "Recurrent neural networks", "value": "cites"}, {"source": "deep recurrent neural networks", "target": "Long Short-term Memory RNN", "value": "cites"}, {"source": "Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks", "target": "Connectionist Temporal Classification", "value": "proposed_model"}, {"source": "Connectionist Temporal Classification", "target": "Recurrent Neural Networks", "value": "uses_metric"}, {"source": "Framewise phoneme classification with bidirectional LSTM and other neural network architectures", "target": "bidirectional LSTM", "value": "proposed_model"}, {"source": "Framewise phoneme classification with bidirectional LSTM and other neural network architectures", "target": "neural network architectures", "value": "proposed_model"}, {"source": "Artificial Intelligence Meets Flexible Sensors: Emerging Smart Flexible Sensing Systems Driven by Machine Learning and Artificial Synapses", "target": "machine learning", "value": "proposed_model"}, {"source": "Artificial Intelligence Meets Flexible Sensors: Emerging Smart Flexible Sensing Systems Driven by Machine Learning and Artificial Synapses", "target": "artificial synapses", "value": "proposed_model"}, {"source": "Artificial Intelligence Meets Flexible Sensors: Emerging Smart Flexible Sensing Systems Driven by Machine Learning and Artificial Synapses", "target": "flexible sensors", "value": "evaluated_on"}, {"source": "Artificial Intelligence Meets Flexible Sensors: Emerging Smart Flexible Sensing Systems Driven by Machine Learning and Artificial Synapses", "target": "flexible sensory systems", "value": "evaluated_on"}, {"source": "Artificial Intelligence Meets Flexible Sensors: Emerging Smart Flexible Sensing Systems Driven by Machine Learning and Artificial Synapses", "target": "soft/humanoid robotics", "value": "evaluated_on"}, {"source": "Artificial Intelligence Meets Flexible Sensors: Emerging Smart Flexible Sensing Systems Driven by Machine Learning and Artificial Synapses", "target": "human activity monitoring", "value": "evaluated_on"}, {"source": "A high-performance speech neuroprosthesis", "target": "speech-to-text BCI", "value": "proposed_model"}, {"source": "speech-to-text BCI", "target": "word error rate", "value": "uses_metric"}, {"source": "speech-to-text BCI", "target": "50-word vocabulary", "value": "evaluated_on"}, {"source": "speech-to-text BCI", "target": "125,000-word vocabulary", "value": "evaluated_on"}, {"source": "speech-to-text BCI", "target": "speech brain\u2013computer interfaces (BCIs)", "value": "cites"}, {"source": "A high-performance speech neuroprosthesis", "target": "study participant", "value": "author_of"}, {"source": "Loss of plasticity in deep continual learning", "target": "artificial neural networks", "value": "author_of"}, {"source": "Loss of plasticity in deep continual learning", "target": "ImageNet dataset", "value": "evaluated_on"}, {"source": "Loss of plasticity in deep continual learning", "target": "continual backpropagation algorithm", "value": "proposed_model"}, {"source": "Loss of plasticity in deep continual learning", "target": "deep-learning methods", "value": "cites"}, {"source": "Loss of plasticity in deep continual learning", "target": "backpropagation algorithm", "value": "cites"}, {"source": "Loss of plasticity in deep continual learning", "target": "gradient descent", "value": "cites"}, {"source": "continual backpropagation algorithm", "target": "backpropagation algorithm", "value": "baseline_model"}, {"source": "An analog-AI chip for energy-efficient speech recognition and transcription", "target": "analog-AI chip", "value": "proposed_model"}, {"source": "analog-AI chip", "target": "speech-recognition tasks", "value": "evaluated_on"}, {"source": "analog-AI chip", "target": "MLPerf", "value": "evaluated_on"}, {"source": "analog-AI chip", "target": "graphics processing units", "value": "baseline_model"}, {"source": "analog-AI chip", "target": "central processing units", "value": "baseline_model"}, {"source": "analog-AI chip", "target": "analog in-memory computing (analog-AI)", "value": "cites"}, {"source": "keyword-spotting network", "target": "speech-recognition tasks", "value": "evaluated_on"}, {"source": "recurrent neural-network transducer (RNNT)", "target": "MLPerf", "value": "evaluated_on"}, {"source": "LiteToken: Removing Intermediate Merge Residues From BPE Tokenizers", "target": "LiteToken", "value": "proposed_model"}, {"source": "LiteToken: Removing Intermediate Merge Residues From BPE Tokenizers", "target": "intermediate merge residues", "value": "evaluated_on"}, {"source": "LiteToken: Removing Intermediate Merge Residues From BPE Tokenizers", "target": "token fragmentation", "value": "evaluated_on"}, {"source": "LiteToken: Removing Intermediate Merge Residues From BPE Tokenizers", "target": "noisy or misspelled inputs", "value": "evaluated_on"}, {"source": "LiteToken", "target": "BPE tokenizers", "value": "baseline_model"}, {"source": "MeKi: Memory-based Expert Knowledge Injection for Efficient LLM Scaling", "target": "MeKi", "value": "proposed_model"}, {"source": "MeKi", "target": "dense LLM baselines", "value": "baseline_model"}, {"source": "MeKi", "target": "Large Language Models", "value": "evaluated_on"}, {"source": "Beyond Conditional Computation: Retrieval-Augmented Genomic Foundation Models with Gengram", "target": "Gengram", "value": "proposed_model"}, {"source": "Gengram", "target": "functional genomics tasks", "value": "evaluated_on"}, {"source": "Gengram", "target": "genomic foundation models", "value": "baseline_model"}, {"source": "L$^3$: Large Lookup Layers", "target": "Large Lookup Layer (L$^3$)", "value": "proposed_model"}, {"source": "L$^3$: Large Lookup Layers", "target": "Mixture-of-Experts (MoE)", "value": "baseline_model"}, {"source": "L$^3$: Large Lookup Layers", "target": "dense models", "value": "baseline_model"}, {"source": "L$^3$: Large Lookup Layers", "target": "iso-sparse MoEs", "value": "baseline_model"}, {"source": "Large Lookup Layer (L$^3$)", "target": "language modeling", "value": "evaluated_on"}, {"source": "Large Lookup Layer (L$^3$)", "target": "downstream tasks", "value": "evaluated_on"}, {"source": "Large Lookup Layer (L$^3$)", "target": "tokenizer embedding table", "value": "cites"}, {"source": "Large Lookup Layer (L$^3$)", "target": "language modeling", "value": "uses_metric"}, {"source": "Large Lookup Layer (L$^3$)", "target": "downstream tasks", "value": "uses_metric"}, {"source": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "target": "LongCat-Flash-Lite", "value": "proposed_model"}, {"source": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "target": "parameter-equivalent MoE baselines", "value": "evaluated_on"}, {"source": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "target": "existing models of comparable scale", "value": "evaluated_on"}, {"source": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "target": "Mixture-of-Experts (MoE) architectures", "value": "cites"}, {"source": "embedding scaling", "target": "expert scaling", "value": "baseline_model"}, {"source": "Going Deeper with Convolutions", "target": "Inception", "value": "proposed_model"}, {"source": "Inception", "target": "ImageNet Large-Scale Visual Recognition Challenge 2014", "value": "evaluated_on"}, {"source": "Inception", "target": "ILSVRC 2014", "value": "evaluated_on"}, {"source": "Going Deeper with Convolutions", "target": "GoogLeNet", "value": "proposed_model"}, {"source": "GoogLeNet", "target": "ImageNet Large-Scale Visual Recognition Challenge 2014", "value": "evaluated_on"}, {"source": "GoogLeNet", "target": "ILSVRC 2014", "value": "evaluated_on"}, {"source": "Gradient-based learning applied to document recognition", "target": "LeNet", "value": "proposed_model"}, {"source": "Gradient-based learning applied to document recognition", "target": "MNIST", "value": "evaluated_on"}, {"source": "Regression Shrinkage and Selection via the Lasso", "target": "Lasso", "value": "proposed_model"}, {"source": "Microsoft COCO: Common Objects in Context", "target": "PASCAL", "value": "evaluated_on"}, {"source": "Microsoft COCO: Common Objects in Context", "target": "ImageNet", "value": "evaluated_on"}, {"source": "Microsoft COCO: Common Objects in Context", "target": "SUN", "value": "evaluated_on"}, {"source": "Microsoft COCO: Common Objects in Context", "target": "Deformable Parts Model", "value": "baseline_model"}, {"source": "LifeCLEF plant identification challenge", "target": "dataset", "value": "evaluated_on"}, {"source": "dataset", "target": "participatory sensing plateform", "value": "uses_metric"}, {"source": "FedMicro-IDA: A Federated Learning and Microservices-based Framework for IoT Data Analytics", "target": "FedMicro-IDA", "value": "proposed_model"}, {"source": "FedMicro-IDA: A Federated Learning and Microservices-based Framework for IoT Data Analytics", "target": "IoT-malware detection and classification use case", "value": "evaluated_on"}, {"source": "FedMicro-IDA: A Federated Learning and Microservices-based Framework for IoT Data Analytics", "target": "MaleVis", "value": "evaluated_on"}, {"source": "FedMicro-IDA: A Federated Learning and Microservices-based Framework for IoT Data Analytics", "target": "federated learning", "value": "cites"}, {"source": "FedMicro-IDA: A Federated Learning and Microservices-based Framework for IoT Data Analytics", "target": "microservices-based architecture", "value": "cites"}, {"source": "FedMicro-IDA: A Federated Learning and Microservices-based Framework for IoT Data Analytics", "target": "existing state-of-the-art methods", "value": "baseline_model"}, {"source": "Harnessing large vision and language models in agriculture: a review", "target": "large language models", "value": "cites"}, {"source": "Harnessing large vision and language models in agriculture: a review", "target": "large vision models", "value": "cites"}, {"source": "Harnessing large vision and language models in agriculture: a review", "target": "multimodal large language models", "value": "cites"}, {"source": "Harnessing large vision and language models in agriculture: a review", "target": "Web of Science", "value": "evaluated_on"}, {"source": "Harnessing large vision and language models in agriculture: a review", "target": "arXiv", "value": "evaluated_on"}, {"source": "Harnessing large vision and language models in agriculture: a review", "target": "agricultural question-answering", "value": "proposed_model"}, {"source": "Harnessing large vision and language models in agriculture: a review", "target": "robotic automation", "value": "proposed_model"}, {"source": "Harnessing large vision and language models in agriculture: a review", "target": "advanced image analysis", "value": "proposed_model"}, {"source": "advanced image analysis", "target": "remote sensing", "value": "uses_metric"}, {"source": "advanced image analysis", "target": "spectral data", "value": "uses_metric"}, {"source": "Harnessing large vision and language models in agriculture: a review", "target": "pragmatic framework", "value": "proposed_model"}, {"source": "Multi-axis vision transformer for medical image segmentation", "target": "Multi-axis vision transformer", "value": "proposed_model"}, {"source": "Multi-axis vision transformer", "target": "medical image segmentation", "value": "evaluated_on"}, {"source": "We", "target": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes", "value": "author_of"}, {"source": "active deep-learning framework", "target": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes", "value": "proposed_model"}, {"source": "active deep-learning framework", "target": "classical recall", "value": "uses_metric"}, {"source": "generalizable algorithm", "target": "Active learning framework leveraging transcriptomics identifies modulators of disease phenotypes", "value": "proposed_model"}, {"source": "generalizable algorithm", "target": "hematological discovery campaigns", "value": "evaluated_on"}, {"source": "generalizable algorithm", "target": "state-of-the-art models", "value": "baseline_model"}, {"source": "generalizable algorithm", "target": "classical recall", "value": "uses_metric"}, {"source": "active deep-learning framework", "target": "omics", "value": "cites"}, {"source": "LLaVA-OneVision-1.5", "target": "LLaVA-OneVision-1.5", "value": "proposed_model"}, {"source": "LLaVA-OneVision-1.5", "target": "LLaVA-OneVision-1.5-Mid-Traning", "value": "uses_metric"}, {"source": "LLaVA-OneVision-1.5", "target": "LLaVA-OneVision-1.5-Instruct", "value": "uses_metric"}, {"source": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "target": "robotics community", "value": "author_of"}, {"source": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "target": "large language models (LLMs)", "value": "cites"}, {"source": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "target": "vision-language models (VLMs)", "value": "cites"}, {"source": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "target": "Vision-Language-Action (VLA) models", "value": "proposed_model"}, {"source": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "target": "publicly available datasets", "value": "evaluated_on"}, {"source": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "target": "evaluation benchmarks", "value": "evaluated_on"}, {"source": "teacher model", "target": "Aligning machine and human visual representations across abstraction levels", "value": "proposed_model"}, {"source": "human-aligned models", "target": "Aligning machine and human visual representations across abstraction levels", "value": "proposed_model"}, {"source": "Aligning machine and human visual representations across abstraction levels", "target": "dataset of human judgements spanning multiple levels of semantic abstractions", "value": "evaluated_on"}, {"source": "Aligning machine and human visual representations across abstraction levels", "target": "human judgements", "value": "evaluated_on"}, {"source": "human-aligned models", "target": "human judgements", "value": "uses_metric"}, {"source": "teacher model", "target": "human judgements", "value": "uses_metric"}, {"source": "human-aligned models", "target": "pretrained state-of-the-art vision foundation models", "value": "baseline_model"}, {"source": "Vision Transformer (ViT)", "target": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "value": "proposed_model"}, {"source": "Vision Transformer (ViT)", "target": "ImageNet", "value": "evaluated_on"}, {"source": "Vision Transformer (ViT)", "target": "CIFAR-100", "value": "evaluated_on"}, {"source": "Vision Transformer (ViT)", "target": "VTAB", "value": "evaluated_on"}, {"source": "Vision Transformer (ViT)", "target": "convolutional networks", "value": "baseline_model"}, {"source": "Vision Transformer (ViT)", "target": "Transformer architecture", "value": "cites"}, {"source": "Learning Transferable Visual Models From Natural Language Supervision", "target": "CLIP", "value": "proposed_model"}, {"source": "Learning Transferable Visual Models From Natural Language Supervision", "target": "ResNet-50", "value": "baseline_model"}, {"source": "Learning Transferable Visual Models From Natural Language Supervision", "target": "ImageNet", "value": "evaluated_on"}, {"source": "CLIP", "target": "OpenAI", "value": "author_of"}, {"source": "Improved Mean Flows: On the Challenges of Fastforward Generative Models", "target": "improved MeanFlow", "value": "proposed_model"}, {"source": "Improved Mean Flows: On the Challenges of Fastforward Generative Models", "target": "iMF", "value": "proposed_model"}, {"source": "improved MeanFlow", "target": "MeanFlow", "value": "baseline_model"}, {"source": "iMF", "target": "MeanFlow", "value": "baseline_model"}, {"source": "improved MeanFlow", "target": "ImageNet 256\u00d7256", "value": "evaluated_on"}, {"source": "iMF", "target": "ImageNet 256\u00d7256", "value": "evaluated_on"}, {"source": "improved MeanFlow", "target": "FID", "value": "uses_metric"}, {"source": "iMF", "target": "FID", "value": "uses_metric"}, {"source": "There is No VAE: End-to-End Pixel-Space Generative Modeling via Self-Supervised Pre-training", "target": "two-stage training framework", "value": "proposed_model"}, {"source": "There is No VAE: End-to-End Pixel-Space Generative Modeling via Self-Supervised Pre-training", "target": "diffusion model", "value": "proposed_model"}, {"source": "There is No VAE: End-to-End Pixel-Space Generative Modeling via Self-Supervised Pre-training", "target": "consistency model", "value": "proposed_model"}, {"source": "two-stage training framework", "target": "ImageNet", "value": "evaluated_on"}, {"source": "diffusion model", "target": "ImageNet-256", "value": "evaluated_on"}, {"source": "diffusion model", "target": "ImageNet-512", "value": "evaluated_on"}, {"source": "diffusion model", "target": "FID", "value": "uses_metric"}, {"source": "There is No VAE: End-to-End Pixel-Space Generative Modeling via Self-Supervised Pre-training", "target": "DiT", "value": "cites"}, {"source": "There is No VAE: End-to-End Pixel-Space Generative Modeling via Self-Supervised Pre-training", "target": "VAE", "value": "cites"}, {"source": "two-stage training framework", "target": "pixel-space diffusion", "value": "baseline_model"}, {"source": "two-stage training framework", "target": "pixel-space consistency models", "value": "baseline_model"}, {"source": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "target": "SVG (Self-supervised representations for Visual Generation)", "value": "baseline_model"}, {"source": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "target": "GenEval", "value": "evaluated_on"}, {"source": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "target": "DPG-Bench", "value": "evaluated_on"}, {"source": "SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder", "target": "Visual Foundation Model (VFM)", "value": "cites"}, {"source": "PixelDiT", "target": "PixelDiT: Pixel Diffusion Transformers for Image Generation", "value": "proposed_model"}, {"source": "PixelDiT", "target": "Diffusion Transformers (DiTs)", "value": "baseline_model"}, {"source": "PixelDiT", "target": "ImageNet 256x256", "value": "evaluated_on"}, {"source": "PixelDiT", "target": "GenEval", "value": "evaluated_on"}, {"source": "PixelDiT", "target": "DPG-bench", "value": "evaluated_on"}, {"source": "PixelDiT", "target": "FID", "value": "uses_metric"}, {"source": "PixelDiT", "target": "latent diffusion models", "value": "cites"}, {"source": "TUNA", "target": "Unified multimodal models (UMMs)", "value": "proposed_model"}, {"source": "TUNA", "target": "multimodal understanding and generation benchmarks", "value": "evaluated_on"}, {"source": "TUNA", "target": "image and video understanding", "value": "evaluated_on"}, {"source": "TUNA", "target": "image and video generation", "value": "evaluated_on"}, {"source": "TUNA", "target": "image editing", "value": "evaluated_on"}, {"source": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "target": "BERT", "value": "proposed_model"}, {"source": "BERT", "target": "GLUE", "value": "evaluated_on"}, {"source": "BERT", "target": "MultiNLI", "value": "evaluated_on"}, {"source": "BERT", "target": "SQuAD v1.1", "value": "evaluated_on"}, {"source": "BERT", "target": "SQuAD v2.0", "value": "evaluated_on"}, {"source": "A comprehensive review of object detection with traditional and deep learning methods", "target": "object detection", "value": "author_of"}, {"source": "A comprehensive review of object detection with traditional and deep learning methods", "target": "traditional methods", "value": "cites"}, {"source": "A comprehensive review of object detection with traditional and deep learning methods", "target": "deep learning methods", "value": "cites"}, {"source": "Diffusion Language Models are Super Data Learners", "target": "diffusion language models (DLMs)", "value": "proposed_model"}, {"source": "Diffusion Language Models are Super Data Learners", "target": "autoregressive (AR) models", "value": "baseline_model"}, {"source": "diffusion language models (DLMs)", "target": "HellaSwag", "value": "evaluated_on"}, {"source": "diffusion language models (DLMs)", "target": "MMLU", "value": "evaluated_on"}, {"source": "diffusion language models (DLMs)", "target": "Python tokens", "value": "evaluated_on"}, {"source": "AR coder", "target": "Python tokens", "value": "evaluated_on"}, {"source": "DreamOn: Diffusion Language Models For Code Infilling Beyond Fixed-size Canvas", "target": "DreamOn", "value": "proposed_model"}, {"source": "DreamOn", "target": "Diffusion Language Models (DLMs)", "value": "baseline_model"}, {"source": "DreamOn", "target": "HumanEval-Infilling", "value": "evaluated_on"}, {"source": "DreamOn", "target": "SantaCoder-FIM", "value": "evaluated_on"}, {"source": "DreamOn", "target": "Dream-Coder-7B", "value": "cites"}, {"source": "DreamOn", "target": "DiffuCoder-7B", "value": "cites"}, {"source": "FLEX: Continuous Agent Evolution via Forward Learning from Experience", "target": "Forward Learning with EXperience (FLEX)", "value": "proposed_model"}, {"source": "Forward Learning with EXperience (FLEX)", "target": "AIME25", "value": "evaluated_on"}, {"source": "Forward Learning with EXperience (FLEX)", "target": "USPTO50k", "value": "evaluated_on"}, {"source": "Forward Learning with EXperience (FLEX)", "target": "ProteinGym", "value": "evaluated_on"}, {"source": "Forward Learning with EXperience (FLEX)", "target": "mathematical reasoning", "value": "uses_metric"}, {"source": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "target": "Agent-R1", "value": "proposed_model"}, {"source": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "target": "Large Language Models (LLMs)", "value": "cites"}, {"source": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "target": "Reinforcement Learning (RL)", "value": "cites"}, {"source": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "target": "Markov Decision Process (MDP)", "value": "cites"}, {"source": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "target": "Multihop QA benchmark tasks", "value": "evaluated_on"}, {"source": "nuScenes", "target": "nuScenes", "value": "evaluated_on"}, {"source": "nuScenes", "target": "KITTI dataset", "value": "baseline_model"}, {"source": "nuScenes", "target": "KITTI dataset", "value": "cites"}, {"source": "Squeeze-and-Excitation Networks", "target": "Squeeze-and-Excitation block", "value": "proposed_model"}, {"source": "Squeeze-and-Excitation block", "target": "SENet", "value": "author_of"}, {"source": "SENet", "target": "ILSVRC 2017 classification submission", "value": "evaluated_on"}, {"source": "Squeeze-and-Excitation Networks", "target": "prior research", "value": "cites"}, {"source": "Squeeze-and-Excitation block", "target": "convolutional neural networks", "value": "uses_metric"}, {"source": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks", "target": "EfficientNets", "value": "proposed_model"}, {"source": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks", "target": "MobileNets", "value": "baseline_model"}, {"source": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks", "target": "ResNet", "value": "baseline_model"}, {"source": "EfficientNet-B7", "target": "ImageNet", "value": "evaluated_on"}, {"source": "EfficientNets", "target": "CIFAR-100", "value": "evaluated_on"}, {"source": "EfficientNets", "target": "Flowers", "value": "evaluated_on"}, {"source": "Light-X: Generative 4D Video Rendering with Camera and Illumination Control", "target": "Light-X", "value": "proposed_model"}, {"source": "Light-X: Generative 4D Video Rendering with Camera and Illumination Control", "target": "Light-X", "value": "author_of"}, {"source": "Light-X", "target": "Light-Syn", "value": "evaluated_on"}, {"source": "DriveLaW", "target": "DriveLaW-Video", "value": "proposed_model"}, {"source": "DriveLaW", "target": "DriveLaW-Act", "value": "proposed_model"}, {"source": "DriveLaW", "target": "NAVSIM", "value": "evaluated_on"}, {"source": "DriveLaW", "target": "FID", "value": "uses_metric"}, {"source": "DriveLaW", "target": "FVD", "value": "uses_metric"}, {"source": "DVGT: Driving Visual Geometry Transformer", "target": "DVGT: Driving Visual Geometry Transformer", "value": "proposed_model"}, {"source": "DVGT: Driving Visual Geometry Transformer", "target": "nuScenes", "value": "evaluated_on"}, {"source": "DVGT: Driving Visual Geometry Transformer", "target": "OpenScene", "value": "evaluated_on"}, {"source": "DVGT: Driving Visual Geometry Transformer", "target": "Waymo", "value": "evaluated_on"}, {"source": "DVGT: Driving Visual Geometry Transformer", "target": "KITTI", "value": "evaluated_on"}, {"source": "DVGT: Driving Visual Geometry Transformer", "target": "DDAD", "value": "evaluated_on"}, {"source": "DVGT: Driving Visual Geometry Transformer", "target": "existing models", "value": "baseline_model"}, {"source": "Adding Conditional Control to Text-to-Image Diffusion Models", "target": "ControlNet", "value": "proposed_model"}, {"source": "ControlNet", "target": "Stable Diffusion", "value": "evaluated_on"}, {"source": "ControlNet", "target": "Stable Diffusion", "value": "baseline_model"}, {"source": "ControlNet", "target": "Stable Diffusion", "value": "cites"}, {"source": "Scaling Instruction-Finetuned Language Models", "target": "Flan-PaLM 540B", "value": "proposed_model"}, {"source": "Scaling Instruction-Finetuned Language Models", "target": "Flan-T5", "value": "proposed_model"}, {"source": "Scaling Instruction-Finetuned Language Models", "target": "PALM 540B", "value": "baseline_model"}, {"source": "Scaling Instruction-Finetuned Language Models", "target": "PaLM 62B", "value": "baseline_model"}, {"source": "Scaling Instruction-Finetuned Language Models", "target": "MMLU", "value": "evaluated_on"}, {"source": "Scaling Instruction-Finetuned Language Models", "target": "BBH", "value": "evaluated_on"}, {"source": "Scaling Instruction-Finetuned Language Models", "target": "TyDiQA", "value": "evaluated_on"}, {"source": "Scaling Instruction-Finetuned Language Models", "target": "MGSM", "value": "evaluated_on"}, {"source": "Flan-PaLM 540B", "target": "MMLU", "value": "uses_metric"}, {"source": "Flan-PaLM 540B", "target": "PaLM", "value": "cites"}, {"source": "Flan-PaLM 540B", "target": "T5", "value": "cites"}, {"source": "Flan-PaLM 540B", "target": "U-PaLM", "value": "cites"}, {"source": "Flan-T5", "target": "T5", "value": "cites"}, {"source": "High-Resolution Image Synthesis with Latent Diffusion Models", "target": "latent diffusion models", "value": "proposed_model"}, {"source": "latent diffusion models", "target": "diffusion models", "value": "baseline_model"}, {"source": "latent diffusion models", "target": "image inpainting", "value": "evaluated_on"}, {"source": "latent diffusion models", "target": "unconditional image generation", "value": "evaluated_on"}, {"source": "latent diffusion models", "target": "semantic scene synthesis", "value": "evaluated_on"}, {"source": "latent diffusion models", "target": "super-resolution", "value": "evaluated_on"}, {"source": "High-Resolution Image Synthesis with Latent Diffusion Models", "target": "diffusion models", "value": "cites"}, {"source": "High-Resolution Image Synthesis with Latent Diffusion Models", "target": "CompVis/latent-diffusion", "value": "author_of"}, {"source": "AUTO-ENCODING VARIATIONAL BAYES", "target": "Variational Auto-Encoder", "value": "proposed_model"}, {"source": "Diederik P. Kingma", "target": "AUTO-ENCODING VARIATIONAL BAYES", "value": "author_of"}, {"source": "Max Welling", "target": "AUTO-ENCODING VARIATIONAL BAYES", "value": "author_of"}, {"source": "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric", "target": "new dataset of human perceptual similarity judgments", "value": "evaluated_on"}, {"source": "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric", "target": "PSNR", "value": "uses_metric"}, {"source": "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric", "target": "SSIM", "value": "uses_metric"}, {"source": "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric", "target": "VGG network", "value": "cites"}, {"source": "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric", "target": "ImageNet", "value": "cites"}, {"source": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "target": "we", "value": "author_of"}, {"source": "Waymo Open Dataset", "target": "we", "value": "author_of"}, {"source": "Waymo Open Dataset", "target": "2D detection and tracking tasks", "value": "evaluated_on"}, {"source": "Waymo Open Dataset", "target": "3D detection and tracking tasks", "value": "evaluated_on"}, {"source": "Waymo Open Dataset", "target": "3D detection methods", "value": "evaluated_on"}, {"source": "Waymo Open Dataset", "target": "diversity metric", "value": "uses_metric"}, {"source": "research community", "target": "Waymo Open Dataset", "value": "cites"}, {"source": "Histograms of oriented gradients for human detection", "target": "human detection", "value": "evaluated_on"}, {"source": "Generative Adversarial Networks", "target": "Generative Adversarial Networks (GANs)", "value": "proposed_model"}, {"source": "Generative Adversarial Networks (GANs)", "target": "GANs", "value": "cites"}, {"source": "GANs", "target": "Data augmentation", "value": "evaluated_on"}, {"source": "GANs", "target": "face images generation", "value": "evaluated_on"}, {"source": "Generalization of Diffusion Models Arises with a Balanced Representation Space", "target": "diffusion models", "value": "author_of"}, {"source": "Generalization of Diffusion Models Arises with a Balanced Representation Space", "target": "two-layer ReLU denoising autoencoder (DAE)", "value": "proposed_model"}, {"source": "Generalization of Diffusion Models Arises with a Balanced Representation Space", "target": "real-world unconditional and text-to-image diffusion models", "value": "evaluated_on"}, {"source": "Generalization of Diffusion Models Arises with a Balanced Representation Space", "target": "representation-based method for detecting memorization", "value": "proposed_model"}, {"source": "Generalization of Diffusion Models Arises with a Balanced Representation Space", "target": "training-free editing technique", "value": "proposed_model"}, {"source": "Generalization of Diffusion Models Arises with a Balanced Representation Space", "target": "representation learning", "value": "cites"}, {"source": "Generalization of Diffusion Models Arises with a Balanced Representation Space", "target": "memorization", "value": "cites"}, {"source": "Generalization of Diffusion Models Arises with a Balanced Representation Space", "target": "generalization", "value": "cites"}, {"source": "Generalization of Diffusion Models Arises with a Balanced Representation Space", "target": "balanced representations", "value": "cites"}, {"source": "Generalization of Diffusion Models Arises with a Balanced Representation Space", "target": "localized spiky representations", "value": "cites"}, {"source": "Generalization of Diffusion Models Arises with a Balanced Representation Space", "target": "local data statistics", "value": "cites"}, {"source": "Generalization of Diffusion Models Arises with a Balanced Representation Space", "target": "deep generative models", "value": "cites"}, {"source": "Generalization of Diffusion Models Arises with a Balanced Representation Space", "target": "generative modeling", "value": "cites"}, {"source": "two-layer ReLU denoising autoencoder (DAE)", "target": "diffusion models", "value": "baseline_model"}, {"source": "representation-based method for detecting memorization", "target": "memorization", "value": "uses_metric"}, {"source": "training-free editing technique", "target": "balanced representations", "value": "uses_metric"}, {"source": "Stable Velocity", "target": "Stable Velocity: A Variance Perspective on Flow Matching", "value": "proposed_model"}, {"source": "Stable Velocity", "target": "flow matching", "value": "baseline_model"}, {"source": "Stable Velocity", "target": "ImageNet 256\u00d7256", "value": "evaluated_on"}, {"source": "Stable Velocity", "target": "SD3.5", "value": "evaluated_on"}, {"source": "Stable Velocity", "target": "Flux", "value": "evaluated_on"}, {"source": "Stable Velocity", "target": "Qwen-Image", "value": "evaluated_on"}, {"source": "Stable Velocity", "target": "Wan2.2", "value": "evaluated_on"}, {"source": "Stable Velocity", "target": "flow matching", "value": "cites"}, {"source": "FlatDINO", "target": "Laminating Representation Autoencoders for Efficient Diffusion", "value": "proposed_model"}, {"source": "DINOv2", "target": "Laminating Representation Autoencoders for Efficient Diffusion", "value": "baseline_model"}, {"source": "Laminating Representation Autoencoders for Efficient Diffusion", "target": "ImageNet 256x256", "value": "evaluated_on"}, {"source": "Laminating Representation Autoencoders for Efficient Diffusion", "target": "gFID", "value": "uses_metric"}, {"source": "Laminating Representation Autoencoders for Efficient Diffusion", "target": "DINOv2", "value": "cites"}, {"source": "Laminating Representation Autoencoders for Efficient Diffusion", "target": "DiT-XL", "value": "cites"}, {"source": "Adaptive 1D Video Diffusion Autoencoder", "target": "One-Dimensional Diffusion Video Autoencoder (One-DVA)", "value": "proposed_model"}, {"source": "One-Dimensional Diffusion Video Autoencoder (One-DVA)", "target": "3D-CNN VAEs", "value": "baseline_model"}, {"source": "One-Dimensional Diffusion Video Autoencoder (One-DVA)", "target": "reconstruction metrics", "value": "evaluated_on"}, {"source": "One-Dimensional Diffusion Video Autoencoder (One-DVA)", "target": "reconstruction metrics", "value": "uses_metric"}, {"source": "One-Dimensional Diffusion Video Autoencoder (One-DVA)", "target": "video autoencoders", "value": "cites"}, {"source": "One-Dimensional Diffusion Video Autoencoder (One-DVA)", "target": "video generation models", "value": "cites"}, {"source": "One-Dimensional Diffusion Video Autoencoder (One-DVA)", "target": "Adaptive 1D Video Diffusion Autoencoder", "value": "author_of"}, {"source": "One-Dimensional Diffusion Video Autoencoder (One-DVA)", "target": "transformer-based framework", "value": "proposed_model"}, {"source": "One-Dimensional Diffusion Video Autoencoder (One-DVA)", "target": "query-based vision transformers", "value": "proposed_model"}, {"source": "One-Dimensional Diffusion Video Autoencoder (One-DVA)", "target": "pixel-space diffusion transformer", "value": "proposed_model"}, {"source": "One-Dimensional Diffusion Video Autoencoder (One-DVA)", "target": "two-stage training strategy", "value": "proposed_model"}, {"source": "One-Dimensional Diffusion Video Autoencoder (One-DVA)", "target": "variable-length dropout mechanism", "value": "proposed_model"}, {"source": "One-Dimensional Diffusion Video Autoencoder (One-DVA)", "target": "generative modeling", "value": "proposed_model"}, {"source": "One-Dimensional Diffusion Video Autoencoder (One-DVA)", "target": "latent distribution", "value": "proposed_model"}, {"source": "One-Dimensional Diffusion Video Autoencoder (One-DVA)", "target": "decoder", "value": "proposed_model"}, {"source": "One-Dimensional Diffusion Video Autoencoder (One-DVA)", "target": "encoder", "value": "proposed_model"}, {"source": "Test-Time Conditioning with Representation-Aligned Visual Features", "target": "REPA-G", "value": "proposed_model"}, {"source": "REPA-G", "target": "ImageNet", "value": "evaluated_on"}, {"source": "REPA-G", "target": "COCO", "value": "evaluated_on"}, {"source": "Bio-inspired fine-tuning for selective transfer learning in image classification", "target": "BioTune", "value": "proposed_model"}, {"source": "Bio-inspired fine-tuning for selective transfer learning in image classification", "target": "nine image classification datasets", "value": "evaluated_on"}, {"source": "Bio-inspired fine-tuning for selective transfer learning in image classification", "target": "medical imaging", "value": "evaluated_on"}, {"source": "Bio-inspired fine-tuning for selective transfer learning in image classification", "target": "four different CNN architectures", "value": "evaluated_on"}, {"source": "BioTune", "target": "AutoRGN", "value": "baseline_model"}, {"source": "BioTune", "target": "LoRA", "value": "baseline_model"}, {"source": "BioTune", "target": "evolutionary optimization", "value": "cites"}, {"source": "VGG Induced Deep Hand Sign Language Detection", "target": "VGG-16 net", "value": "proposed_model"}, {"source": "VGG Induced Deep Hand Sign Language Detection", "target": "NUS dataset", "value": "evaluated_on"}, {"source": "MediaPipe: A Framework for Building Perception Pipelines", "target": "MediaPipe", "value": "proposed_model"}, {"source": "Hand Pose Estimation and Hand Shape Classification Using Multi-layered Randomized Decision Forests", "target": "Multi-layered Randomized Decision Forests", "value": "proposed_model"}, {"source": "A robust static hand gesture recognition system using geometry based normalizations and Krawtchouk moments", "target": "geometry based normalizations", "value": "proposed_model"}, {"source": "A robust static hand gesture recognition system using geometry based normalizations and Krawtchouk moments", "target": "Krawtchouk moments", "value": "proposed_model"}, {"source": "Hand signal classification system for sign language communication in Virtual Reality", "target": "machine learning model", "value": "proposed_model"}, {"source": "Hand signal classification system for sign language communication in Virtual Reality", "target": "virtual reality headset", "value": "uses_metric"}, {"source": "Hand signal classification system for sign language communication in Virtual Reality", "target": "system meant to facilitate communication with hearing impaired individuals", "value": "evaluated_on"}, {"source": "Real-Time Static Hand Sign Recognition System using MediaPipe and Fully Connected Neural Network", "target": "fully connected neural network (FCNN)", "value": "proposed_model"}, {"source": "Real-Time Static Hand Sign Recognition System using MediaPipe and Fully Connected Neural Network", "target": "American Sign Language (ASL)", "value": "evaluated_on"}, {"source": "Real-Time Static Hand Sign Recognition System using MediaPipe and Fully Connected Neural Network", "target": "World Health Organization", "value": "cites"}, {"source": "Real-Time Static Hand Sign Recognition System using MediaPipe and Fully Connected Neural Network", "target": "Sign Language Recognition (SLR)", "value": "cites"}, {"source": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper", "target": "EM algorithm", "value": "proposed_model"}, {"source": "LLM Social Simulations Are a Promising Research Method", "target": "LLM social simulations", "value": "author_of"}, {"source": "LLM social simulations", "target": "human research subjects", "value": "evaluated_on"}, {"source": "LLM social simulations", "target": "LLMs", "value": "proposed_model"}, {"source": "LLM social simulations", "target": "social science datasets", "value": "uses_metric"}, {"source": "LLM social simulations", "target": "conceptual models", "value": "cites"}, {"source": "LLM social simulations", "target": "iterative evaluations", "value": "cites"}, {"source": "Federated Contrastive Learning With Feature-Based Distillation for Human Activity Recognition", "target": "FCLFD", "value": "proposed_model"}, {"source": "FCLFD", "target": "WISDM", "value": "evaluated_on"}, {"source": "FCLFD", "target": "PAMAP2", "value": "evaluated_on"}, {"source": "Diffuse and Disperse: Image Generation with Representation Regularization", "target": "Dispersive Loss", "value": "proposed_model"}, {"source": "Diffuse and Disperse: Image Generation with Representation Regularization", "target": "ImageNet", "value": "evaluated_on"}, {"source": "Dispersive Loss", "target": "ImageNet", "value": "uses_metric"}, {"source": "Dispersive Loss", "target": "representation alignment (REPA)", "value": "baseline_model"}, {"source": "Dispersive Loss", "target": "diffusion-based generative models", "value": "baseline_model"}, {"source": "KABB: Knowledge-Aware Bayesian Bandits for Dynamic Expert Coordination in Multi-Agent Systems", "target": "Knowledge-Aware Bayesian Bandits (KABB)", "value": "proposed_model"}, {"source": "Knowledge-Aware Bayesian Bandits (KABB)", "target": "three-dimensional knowledge distance model", "value": "uses_metric"}, {"source": "Knowledge-Aware Bayesian Bandits (KABB)", "target": "dual-adaptation mechanism", "value": "uses_metric"}, {"source": "Knowledge-Aware Bayesian Bandits (KABB)", "target": "knowledge-aware Thompson Sampling strategy", "value": "uses_metric"}, {"source": "Knowledge-Aware Bayesian Bandits (KABB)", "target": "multi-agent systems", "value": "evaluated_on"}, {"source": "multi-agent systems", "target": "large language models", "value": "cites"}, {"source": "U-Net: Convolutional Networks for Biomedical Image Segmentation", "target": "U-Net: Convolutional Networks for Biomedical Image Segmentation", "value": "proposed_model"}, {"source": "U-Net: Convolutional Networks for Biomedical Image Segmentation", "target": "sliding-window convolutional network", "value": "baseline_model"}, {"source": "U-Net: Convolutional Networks for Biomedical Image Segmentation", "target": "ISBI challenge for segmentation of neuronal structures in electron microscopic stacks", "value": "evaluated_on"}, {"source": "U-Net: Convolutional Networks for Biomedical Image Segmentation", "target": "ISBI cell tracking challenge 2015", "value": "evaluated_on"}, {"source": "U-Net: Convolutional Networks for Biomedical Image Segmentation", "target": "ISBI challenge for segmentation of neuronal structures in electron microscopic stacks", "value": "uses_metric"}, {"source": "U-Net: Convolutional Networks for Biomedical Image Segmentation", "target": "ISBI cell tracking challenge 2015", "value": "uses_metric"}, {"source": "U-Net: Convolutional Networks for Biomedical Image Segmentation", "target": "Caffe", "value": "cites"}, {"source": "DMD2", "target": "Improved Distribution Matching Distillation for Fast Image Synthesis", "value": "proposed_model"}, {"source": "DMD2", "target": "Distribution Matching Distillation (DMD)", "value": "baseline_model"}, {"source": "DMD2", "target": "ImageNet-64x64", "value": "evaluated_on"}, {"source": "DMD2", "target": "COCO 2014", "value": "evaluated_on"}, {"source": "DMD2", "target": "FID", "value": "uses_metric"}, {"source": "Improved Distribution Matching Distillation for Fast Image Synthesis", "target": "Distribution Matching Distillation (DMD)", "value": "cites"}, {"source": "Latent Adversarial Diffusion Distillation (LADD)", "target": "Fast High-Resolution Image Synthesis with Latent Adversarial Diffusion Distillation", "value": "proposed_model"}, {"source": "adversarial diffusion distillation (ADD)", "target": "Latent Adversarial Diffusion Distillation (LADD)", "value": "baseline_model"}, {"source": "adversarial diffusion distillation (ADD)", "target": "DINOv2", "value": "uses_metric"}, {"source": "Latent Adversarial Diffusion Distillation (LADD)", "target": "Stable Diffusion 3 (8B)", "value": "evaluated_on"}, {"source": "Latent Adversarial Diffusion Distillation (LADD)", "target": "We", "value": "author_of"}, {"source": "Fast High-Resolution Image Synthesis with Latent Adversarial Diffusion Distillation", "target": "We", "value": "author_of"}, {"source": "SD3-Turbo", "target": "Stable Diffusion 3 (8B)", "value": "cites"}, {"source": "Evolutionary optimization of model merging recipes", "target": "evolutionary approach", "value": "proposed_model"}, {"source": "evolutionary approach", "target": "Japanese LLM with Math reasoning capabilities", "value": "proposed_model"}, {"source": "evolutionary approach", "target": "culturally-aware Japanese VLM", "value": "proposed_model"}, {"source": "Japanese Math LLM", "target": "Japanese LLM benchmarks", "value": "evaluated_on"}, {"source": "culturally-aware Japanese VLM", "target": "Japanese culture-specific content", "value": "evaluated_on"}, {"source": "evolutionary approach", "target": "model merging", "value": "baseline_model"}, {"source": "evolutionary approach", "target": "previous Japanese VLMs", "value": "baseline_model"}, {"source": "evolutionary approach", "target": "Japanese LLM benchmarks", "value": "uses_metric"}, {"source": "evolutionary approach", "target": "Japanese culture-specific content", "value": "uses_metric"}, {"source": "evolutionary approach", "target": "Large language models (LLMs)", "value": "cites"}, {"source": "evolutionary approach", "target": "open-source models", "value": "cites"}, {"source": "From Slow Bidirectional to Fast Autoregressive Video Diffusion Models", "target": "autoregressive transformer", "value": "proposed_model"}, {"source": "From Slow Bidirectional to Fast Autoregressive Video Diffusion Models", "target": "student initialization scheme", "value": "proposed_model"}, {"source": "From Slow Bidirectional to Fast Autoregressive Video Diffusion Models", "target": "asymmetric distillation strategy", "value": "proposed_model"}, {"source": "From Slow Bidirectional to Fast Autoregressive Video Diffusion Models", "target": "bidirectional diffusion transformer", "value": "baseline_model"}, {"source": "From Slow Bidirectional to Fast Autoregressive Video Diffusion Models", "target": "VBench-Long benchmark", "value": "evaluated_on"}, {"source": "autoregressive transformer", "target": "distribution matching distillation (DMD)", "value": "cites"}, {"source": "distribution matching distillation (DMD)", "target": "diffusion model", "value": "cites"}, {"source": "distribution matching distillation (DMD)", "target": "generator", "value": "cites"}, {"source": "asymmetric distillation strategy", "target": "causal student model", "value": "cites"}, {"source": "asymmetric distillation strategy", "target": "bidirectional teacher", "value": "cites"}, {"source": "autoregressive transformer", "target": "KV caching", "value": "cites"}, {"source": "autoregressive transformer", "target": "streaming video-to-video translation", "value": "cites"}, {"source": "autoregressive transformer", "target": "image-to-video", "value": "cites"}, {"source": "autoregressive transformer", "target": "dynamic prompting", "value": "cites"}, {"source": "PuLID: Pure and Lightning ID Customization via Contrastive Alignment", "target": "PuLID", "value": "proposed_model"}, {"source": "PuLID", "target": "ToTheBeginning", "value": "author_of"}, {"source": "PuLID", "target": "ID fidelity", "value": "uses_metric"}, {"source": "PuLID", "target": "editability", "value": "uses_metric"}, {"source": "PuLID", "target": "text-to-image generation", "value": "evaluated_on"}, {"source": "PuLID", "target": "standard diffusion", "value": "baseline_model"}, {"source": "PuLID", "target": "Lightning T2I branch", "value": "cites"}, {"source": "PuLID", "target": "contrastive alignment loss", "value": "cites"}, {"source": "PuLID", "target": "accurate ID loss", "value": "cites"}, {"source": "PuLID", "target": "image elements", "value": "cites"}, {"source": "Denoising Diffusion Probabilistic Models", "target": "diffusion probabilistic models", "value": "proposed_model"}, {"source": "Denoising Diffusion Probabilistic Models", "target": "CIFAR10", "value": "evaluated_on"}, {"source": "Denoising Diffusion Probabilistic Models", "target": "LSUN", "value": "evaluated_on"}, {"source": "Denoising Diffusion Probabilistic Models", "target": "Inception score", "value": "uses_metric"}, {"source": "Denoising Diffusion Probabilistic Models", "target": "FID score", "value": "uses_metric"}, {"source": "Denoising Diffusion Probabilistic Models", "target": "ProgressiveGAN", "value": "cites"}, {"source": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "target": "HunyuanVideo", "value": "proposed_model"}, {"source": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "target": "Runway Gen-3", "value": "evaluated_on"}, {"source": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "target": "Luma 1.6", "value": "evaluated_on"}, {"source": "Tencent", "target": "HunyuanVideo: A Systematic Framework For Large Video Generative Models", "value": "author_of"}, {"source": "Loopy: Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency", "target": "Loopy", "value": "proposed_model"}, {"source": "Loopy: Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency", "target": "audio-only conditioned video diffusion model", "value": "proposed_model"}, {"source": "Loopy", "target": "long-term motion information", "value": "uses_metric"}, {"source": "Loopy", "target": "audio-portrait movement correlation", "value": "uses_metric"}, {"source": "Loopy", "target": "various scenarios", "value": "evaluated_on"}, {"source": "Loopy", "target": "audio-driven portrait diffusion models", "value": "baseline_model"}, {"source": "Loopy", "target": "diffusion-based video generation techniques", "value": "cites"}, {"source": "Loopy", "target": "audio-conditioned human video generation", "value": "cites"}, {"source": "audio-only conditioned video diffusion model", "target": "inter- and intra-clip temporal module", "value": "author_of"}, {"source": "audio-only conditioned video diffusion model", "target": "audio-to-latents module", "value": "author_of"}, {"source": "audio-driven portrait diffusion models", "target": "spatial motion templates", "value": "uses_metric"}, {"source": "OmniHuman-1: Rethinking the Scaling-Up of One-Stage Conditioned Human Animation Models", "target": "OmniHuman", "value": "proposed_model"}, {"source": "OmniHuman", "target": "existing end-to-end audio-driven methods", "value": "baseline_model"}, {"source": "OmniHuman", "target": "large general video generation models", "value": "evaluated_on"}, {"source": "OmniHuman", "target": "Diffusion Transformer-based framework", "value": "cites"}, {"source": "Hallo2: Long-Duration and High-Resolution Audio-Driven Portrait Image Animation", "target": "Hallo", "value": "baseline_model"}, {"source": "Hallo2: Long-Duration and High-Resolution Audio-Driven Portrait Image Animation", "target": "HDTF", "value": "evaluated_on"}, {"source": "Hallo2: Long-Duration and High-Resolution Audio-Driven Portrait Image Animation", "target": "CelebV", "value": "evaluated_on"}, {"source": "Hallo2: Long-Duration and High-Resolution Audio-Driven Portrait Image Animation", "target": "Wild", "value": "evaluated_on"}, {"source": "Hallo2: Long-Duration and High-Resolution Audio-Driven Portrait Image Animation", "target": "Hallo", "value": "cites"}, {"source": "EchoMimicV2", "target": "Audio-Pose Dynamic Harmonization strategy", "value": "proposed_model"}, {"source": "Audio-Pose Dynamic Harmonization strategy", "target": "Pose Sampling", "value": "uses_metric"}, {"source": "Audio-Pose Dynamic Harmonization strategy", "target": "Audio Diffusion", "value": "uses_metric"}, {"source": "EchoMimicV2", "target": "Head Partial Attention", "value": "uses_metric"}, {"source": "EchoMimicV2", "target": "Phase-specific Denoising Loss", "value": "uses_metric"}, {"source": "EchoMimicV2", "target": "novel benchmark for evaluating the effectiveness of half-body human animation", "value": "evaluated_on"}, {"source": "EchoMimicV2", "target": "Recent work on human animation", "value": "cites"}, {"source": "Towards Striking, Simplified, and Semi-Body Human Animation", "target": "EchoMimicV2", "value": "author_of"}, {"source": "Feature Pyramid Networks for Object Detection", "target": "Feature Pyramid Network (FPN)", "value": "proposed_model"}, {"source": "Feature Pyramid Networks for Object Detection", "target": "Faster R-CNN", "value": "baseline_model"}, {"source": "Feature Pyramid Networks for Object Detection", "target": "COCO detection benchmark", "value": "evaluated_on"}, {"source": "Feature Pyramid Networks for Object Detection", "target": "COCO 2016 challenge winners", "value": "cites"}, {"source": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation", "target": "RNN Encoder-Decoder", "value": "proposed_model"}, {"source": "RNN Encoder-Decoder", "target": "statistical machine translation system", "value": "evaluated_on"}, {"source": "RNN Encoder-Decoder", "target": "log-linear model", "value": "uses_metric"}, {"source": "DriveMLM: aligning multi-modal large language models with behavioral planning states for autonomous driving", "target": "DriveMLM", "value": "proposed_model"}, {"source": "DriveMLM: aligning multi-modal large language models with behavioral planning states for autonomous driving", "target": "Large language models (LLMs)", "value": "baseline_model"}, {"source": "DriveMLM", "target": "CARLA Town05 Long", "value": "evaluated_on"}, {"source": "DriveMLM", "target": "Autopilot", "value": "cites"}, {"source": "DriveMLM", "target": "Apollo", "value": "cites"}, {"source": "DriveMLM", "target": "DriveMLM: aligning multi-modal large language models with behavioral planning states for autonomous driving", "value": "author_of"}, {"source": "DriveMLM", "target": "multimodal LLM (MLLM)", "value": "proposed_model"}, {"source": "Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability", "target": "Vista", "value": "proposed_model"}, {"source": "Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability", "target": "multiple datasets", "value": "evaluated_on"}, {"source": "Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability", "target": "FID", "value": "uses_metric"}, {"source": "Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability", "target": "FVD", "value": "uses_metric"}, {"source": "Vista", "target": "general-purpose video generator", "value": "baseline_model"}, {"source": "Vista", "target": "driving world model", "value": "baseline_model"}, {"source": "DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving", "target": "DiffusionDrive", "value": "proposed_model"}, {"source": "DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving", "target": "vanilla diffusion policy", "value": "baseline_model"}, {"source": "DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving", "target": "NAVSIM dataset", "value": "evaluated_on"}, {"source": "DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving", "target": "ResNet-34", "value": "cites"}, {"source": "How Far is Video Generation from World Model: A Physical Law Perspective", "target": "OpenAI", "value": "author_of"}, {"source": "How Far is Video Generation from World Model: A Physical Law Perspective", "target": "diffusion-based video generation models", "value": "proposed_model"}, {"source": "How Far is Video Generation from World Model: A Physical Law Perspective", "target": "2D simulation testbed for object movement and collisions", "value": "evaluated_on"}, {"source": "How Far is Video Generation from World Model: A Physical Law Perspective", "target": "Sora", "value": "cites"}, {"source": "EMMA: End-to-End Multimodal Model for Autonomous Driving", "target": "nuScenes", "value": "evaluated_on"}, {"source": "EMMA: End-to-End Multimodal Model for Autonomous Driving", "target": "Waymo Open Motion Dataset (WOMD)", "value": "evaluated_on"}, {"source": "EMMA: End-to-End Multimodal Model for Autonomous Driving", "target": "Waymo Open Dataset (WOD)", "value": "evaluated_on"}, {"source": "Language Models are Few-Shot Learners", "target": "GPT-3", "value": "proposed_model"}, {"source": "GPT-3", "target": "NLP tasks and benchmarks", "value": "evaluated_on"}, {"source": "GPT-3", "target": "translation, question-answering, and cloze tasks", "value": "evaluated_on"}, {"source": "GPT-3", "target": "unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic", "value": "evaluated_on"}, {"source": "GPT-3", "target": "news articles", "value": "evaluated_on"}, {"source": "InternVL 2.5", "target": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling", "value": "proposed_model"}, {"source": "InternVL 2.5", "target": "InternVL 2.0", "value": "baseline_model"}, {"source": "InternVL 2.5", "target": "MMMU benchmark", "value": "evaluated_on"}, {"source": "InternVL 2.5", "target": "GPT-4o", "value": "cites"}, {"source": "InternVL 2.5", "target": "Claude-3.5-Sonnet", "value": "cites"}, {"source": "InternVL3", "target": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "value": "proposed_model"}, {"source": "InternVL3", "target": "MMMU benchmark", "value": "evaluated_on"}, {"source": "InternVL3-78B", "target": "MMMU benchmark", "value": "evaluated_on"}, {"source": "InternVL3", "target": "ChatGPT-4o", "value": "cites"}, {"source": "InternVL3", "target": "Claude 3.5 Sonnet", "value": "cites"}, {"source": "InternVL3", "target": "Gemini 2.5 Pro", "value": "cites"}, {"source": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "target": "multi-modal benchmarks", "value": "uses_metric"}, {"source": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "target": "large multi-modality models", "value": "evaluated_on"}, {"source": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "target": "OpenVLM Leaderboard", "value": "proposed_model"}, {"source": "VLMEvalKit: An Open-Source ToolKit for Evaluating Large Multi-Modality Models", "target": "large multi-modality models", "value": "baseline_model"}, {"source": "LLaVA-CoT: Let Vision Language Models Reason Step-by-Step", "target": "LLaVA-CoT", "value": "proposed_model"}, {"source": "LLaVA-CoT: Let Vision Language Models Reason Step-by-Step", "target": "Gemini-1.5-pro", "value": "baseline_model"}, {"source": "LLaVA-CoT: Let Vision Language Models Reason Step-by-Step", "target": "GPT-4o-mini", "value": "baseline_model"}, {"source": "LLaVA-CoT: Let Vision Language Models Reason Step-by-Step", "target": "Llama-3.2-90B-Vision-Instruct", "value": "baseline_model"}, {"source": "LLaVA-CoT", "target": "chain-of-thought prompting", "value": "cites"}, {"source": "InternVL 3.5", "target": "Cascade Reinforcement Learning (Cascade RL) framework", "value": "proposed_model"}, {"source": "InternVL 3.5", "target": "Visual Resolution Router (ViR)", "value": "proposed_model"}, {"source": "InternVL 3.5", "target": "Decoupled Vision-Language Deployment (DvD) strategy", "value": "proposed_model"}, {"source": "InternVL 3.5", "target": "MMMU", "value": "evaluated_on"}, {"source": "InternVL 3.5", "target": "MathVista", "value": "evaluated_on"}, {"source": "InternVL 3.5", "target": "InternVL3", "value": "cites"}, {"source": "InternVL3.5-241B-A28B", "target": "GPT-5", "value": "cites"}, {"source": "Proximal Policy Optimization Algorithms", "target": "proximal policy optimization (PPO)", "value": "proposed_model"}, {"source": "proximal policy optimization (PPO)", "target": "trust region policy optimization (TRPO)", "value": "baseline_model"}, {"source": "proximal policy optimization (PPO)", "target": "simulated robotic locomotion", "value": "evaluated_on"}, {"source": "proximal policy optimization (PPO)", "target": "Atari game playing", "value": "evaluated_on"}, {"source": "Flow-GRPO", "target": "Flow-GRPO: Training Flow Matching Models via Online RL", "value": "proposed_model"}, {"source": "Flow-GRPO", "target": "GenEval", "value": "uses_metric"}, {"source": "Flow-GRPO", "target": "text-to-image tasks", "value": "evaluated_on"}, {"source": "Flow-GRPO", "target": "compositional generation", "value": "evaluated_on"}, {"source": "Flow-GRPO", "target": "visual text rendering", "value": "evaluated_on"}, {"source": "Flow-GRPO", "target": "human preference alignment", "value": "evaluated_on"}, {"source": "Flow-GRPO", "target": "SD3.5-M", "value": "baseline_model"}, {"source": "Flow-GRPO", "target": "online policy gradient reinforcement learning (RL)", "value": "cites"}, {"source": "Flow-GRPO", "target": "flow matching models", "value": "cites"}, {"source": "Flow-GRPO", "target": "ODE-to-SDE conversion", "value": "cites"}, {"source": "Flow-GRPO", "target": "Denoising Reduction strategy", "value": "cites"}, {"source": "ODE-to-SDE conversion", "target": "Ordinary Differential Equation (ODE)", "value": "cites"}, {"source": "ODE-to-SDE conversion", "target": "Stochastic Differential Equation (SDE)", "value": "cites"}, {"source": "DanceGRPO", "target": "Group Relative Policy Optimization (GRPO)", "value": "proposed_model"}, {"source": "DanceGRPO", "target": "DDPO", "value": "baseline_model"}, {"source": "DanceGRPO", "target": "DPOK", "value": "baseline_model"}, {"source": "DanceGRPO", "target": "HPS-v2.1", "value": "evaluated_on"}, {"source": "DanceGRPO", "target": "CLIP Score", "value": "evaluated_on"}, {"source": "DanceGRPO", "target": "VideoAlign", "value": "evaluated_on"}, {"source": "DanceGRPO", "target": "GenEval", "value": "evaluated_on"}, {"source": "DanceGRPO", "target": "HPS-v2.1", "value": "uses_metric"}, {"source": "DanceGRPO", "target": "CLIP Score", "value": "uses_metric"}, {"source": "DanceGRPO", "target": "VideoAlign", "value": "uses_metric"}, {"source": "DanceGRPO", "target": "GenEval", "value": "uses_metric"}, {"source": "DanceGRPO", "target": "Reinforcement Learning from Human Feedback (RLHF)", "value": "cites"}, {"source": "DanceGRPO: Unleashing GRPO on Visual Generation", "target": "DanceGRPO", "value": "author_of"}, {"source": "Seedance 1.0", "target": "diffusion modeling", "value": "proposed_model"}, {"source": "Seedance 1.0", "target": "video generation models", "value": "baseline_model"}, {"source": "Seedance 1.0", "target": "precision and meaningful video captioning", "value": "uses_metric"}, {"source": "Seedance 1.0", "target": "multi-dimensional reward mechanisms", "value": "uses_metric"}, {"source": "Seedance 1.0", "target": "multi-source data curation", "value": "evaluated_on"}, {"source": "Seedance 1.0", "target": "NVIDIA-L20", "value": "evaluated_on"}, {"source": "efficient architecture design", "target": "proposed training paradigm", "value": "proposed_model"}, {"source": "proposed training paradigm", "target": "multi-shot generation", "value": "proposed_model"}, {"source": "proposed training paradigm", "target": "text-to-video", "value": "proposed_model"}, {"source": "proposed training paradigm", "target": "image-to-video", "value": "proposed_model"}, {"source": "fine-grained supervised fine-tuning", "target": "video-specific RLHF", "value": "proposed_model"}, {"source": "multi-stage distillation strategies", "target": "system-level optimizations", "value": "proposed_model"}, {"source": "SkyReels-V2: Infinite-length Film Generative Model", "target": "SkyReels-V2", "value": "proposed_model"}, {"source": "SkyReels-V2", "target": "Multi-modal Large Language Model (MLLM)", "value": "uses_metric"}, {"source": "SkyReels-V2", "target": "Multi-stage Pretraining", "value": "uses_metric"}, {"source": "SkyReels-V2", "target": "Reinforcement Learning", "value": "uses_metric"}, {"source": "SkyReels-V2", "target": "Diffusion Forcing Framework", "value": "uses_metric"}, {"source": "SkyReels-V2", "target": "Supervised Fine-Tuning (SFT)", "value": "baseline_model"}, {"source": "SkyReels-V2", "target": "Motion-specific Reinforcement Learning (RL) training", "value": "evaluated_on"}, {"source": "SkyReels-V2", "target": "diffusion forcing framework with non-decreasing noise schedules", "value": "evaluated_on"}, {"source": "SkyReels-V2", "target": "SkyCaptioner-V1", "value": "author_of"}, {"source": "Unified Reward Model for Multimodal Understanding and Generation", "target": "UnifiedReward", "value": "proposed_model"}, {"source": "UnifiedReward", "target": "large-scale human preference dataset", "value": "evaluated_on"}, {"source": "UnifiedReward", "target": "Direct Preference Optimization (DPO)", "value": "cites"}, {"source": "Jacob Devlin", "target": "BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding", "value": "author_of"}, {"source": "SQuAD: 100,000+ Questions for Machine Comprehension of Text", "target": "Stanford Question Answering Dataset (SQuAD)", "value": "author_of"}, {"source": "logistic regression model", "target": "Stanford Question Answering Dataset (SQuAD)", "value": "evaluated_on"}, {"source": "simple baseline", "target": "Stanford Question Answering Dataset (SQuAD)", "value": "evaluated_on"}, {"source": "Neural Machine Translation of Rare Words with Subword Units", "target": "subword models", "value": "proposed_model"}, {"source": "Neural Machine Translation of Rare Words with Subword Units", "target": "back-off dictionary baseline", "value": "baseline_model"}, {"source": "subword models", "target": "WMT 15 translation tasks English-German and English-Russian", "value": "evaluated_on"}, {"source": "subword models", "target": "BLEU", "value": "uses_metric"}, {"source": "This paper", "target": "SentencePiece", "value": "proposed_model"}, {"source": "SentencePiece", "target": "English-Japanese machine translation", "value": "evaluated_on"}, {"source": "This paper", "target": "Neural Machine Translation", "value": "cites"}, {"source": "GPT-4 Technical Report", "target": "GPT-4", "value": "author_of"}, {"source": "GPT-4", "target": "Transformer-based model", "value": "proposed_model"}, {"source": "GPT-4", "target": "bar exam", "value": "evaluated_on"}, {"source": "GPT-4", "target": "professional and academic benchmarks", "value": "evaluated_on"}, {"source": "LLaMA: Open and Efficient Foundation Language Models", "target": "LLaMA", "value": "proposed_model"}, {"source": "LLaMA", "target": "GPT-3", "value": "evaluated_on"}, {"source": "LLaMA", "target": "Chinchilla-70B", "value": "evaluated_on"}, {"source": "LLaMA", "target": "PaLM-540B", "value": "evaluated_on"}, {"source": "Chain of Thought Prompting Elicits Reasoning in Large Language Models", "target": "chain of thought", "value": "proposed_model"}, {"source": "Chain of Thought Prompting Elicits Reasoning in Large Language Models", "target": "GSM8K benchmark", "value": "evaluated_on"}, {"source": "chain of thought", "target": "GPT-3", "value": "baseline_model"}, {"source": "Training Verifiers to Solve Math Word Problems", "target": "verifiers", "value": "proposed_model"}, {"source": "Training Verifiers to Solve Math Word Problems", "target": "finetuning baseline", "value": "baseline_model"}, {"source": "Training Verifiers to Solve Math Word Problems", "target": "GSM8K", "value": "evaluated_on"}, {"source": "transformer models", "target": "GSM8K", "value": "evaluated_on"}, {"source": "Mamba", "target": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces", "value": "proposed_model"}, {"source": "Mamba", "target": "Transformer", "value": "baseline_model"}, {"source": "Mamba", "target": "language", "value": "evaluated_on"}, {"source": "Mamba", "target": "audio", "value": "evaluated_on"}, {"source": "Mamba", "target": "genomics", "value": "evaluated_on"}, {"source": "Mamba", "target": "structured state space models (SSMs)", "value": "cites"}, {"source": "Mamba", "target": "linear attention", "value": "cites"}, {"source": "Mamba", "target": "gated convolution", "value": "cites"}, {"source": "Mamba", "target": "recurrent models", "value": "cites"}, {"source": "Mamba-3B", "target": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces", "value": "proposed_model"}, {"source": "SGDR: Stochastic Gradient Descent with Warm Restarts", "target": "stochastic gradient descent", "value": "proposed_model"}, {"source": "SGDR: Stochastic Gradient Descent with Warm Restarts", "target": "CIFAR-10", "value": "evaluated_on"}, {"source": "SGDR: Stochastic Gradient Descent with Warm Restarts", "target": "CIFAR-100", "value": "evaluated_on"}, {"source": "SGDR: Stochastic Gradient Descent with Warm Restarts", "target": "EEG recordings", "value": "evaluated_on"}, {"source": "SGDR: Stochastic Gradient Descent with Warm Restarts", "target": "ImageNet", "value": "evaluated_on"}, {"source": "loshchil", "target": "SGDR: Stochastic Gradient Descent with Warm Restarts", "value": "author_of"}, {"source": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer", "target": "Sparsely-Gated Mixture-of-Experts layer (MoE)", "value": "proposed_model"}, {"source": "Sparsely-Gated Mixture-of-Experts layer (MoE)", "target": "language modeling", "value": "evaluated_on"}, {"source": "Sparsely-Gated Mixture-of-Experts layer (MoE)", "target": "machine translation", "value": "evaluated_on"}, {"source": "Sparsely-Gated Mixture-of-Experts layer (MoE)", "target": "large language modeling benchmarks", "value": "uses_metric"}, {"source": "Sparsely-Gated Mixture-of-Experts layer (MoE)", "target": "machine translation benchmarks", "value": "uses_metric"}, {"source": "Sparsely-Gated Mixture-of-Experts layer (MoE)", "target": "LSTM layers", "value": "baseline_model"}, {"source": "Pointer Sentinel Mixture Models", "target": "pointer sentinel mixture architecture", "value": "proposed_model"}, {"source": "pointer sentinel mixture architecture", "target": "pointer sentinel-LSTM model", "value": "proposed_model"}, {"source": "pointer sentinel-LSTM model", "target": "Penn Treebank", "value": "evaluated_on"}, {"source": "Pointer Sentinel Mixture Models", "target": "pointer sentinel mixture architecture", "value": "author_of"}, {"source": "Pointer Sentinel Mixture Models", "target": "pointer sentinel-LSTM model", "value": "author_of"}, {"source": "Pointer Sentinel Mixture Models", "target": "WikiText corpus", "value": "author_of"}, {"source": "Measuring Massive Multitask Language Understanding", "target": "GPT-3", "value": "proposed_model"}, {"source": "Measuring Massive Multitask Language Understanding", "target": "GPT-3", "value": "evaluated_on"}, {"source": "Let's Verify Step by Step", "target": "MATH dataset", "value": "evaluated_on"}, {"source": "Let's Verify Step by Step", "target": "process-supervised model", "value": "proposed_model"}, {"source": "process-supervised model", "target": "MATH dataset", "value": "evaluated_on"}, {"source": "reward model", "target": "PRM800K", "value": "evaluated_on"}, {"source": "We", "target": "GPQA", "value": "author_of"}, {"source": "GPQA", "target": "GPT-4", "value": "evaluated_on"}, {"source": "GPT-4", "target": "GPQA", "value": "baseline_model"}, {"source": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding", "target": "GShard", "value": "proposed_model"}, {"source": "GShard", "target": "multilingual neural machine translation Transformer model with Sparsely-Gated Mixture-of-Experts", "value": "evaluated_on"}, {"source": "GShard", "target": "TPU v3 accelerators", "value": "evaluated_on"}, {"source": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding", "target": "prior art", "value": "cites"}, {"source": "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation", "target": "R-CNN", "value": "proposed_model"}, {"source": "R-CNN", "target": "PASCAL VOC dataset", "value": "evaluated_on"}, {"source": "R-CNN", "target": "ILSVRC2013 detection dataset", "value": "evaluated_on"}, {"source": "R-CNN", "target": "mean average precision (mAP)", "value": "uses_metric"}, {"source": "R-CNN", "target": "OverFeat", "value": "baseline_model"}, {"source": "Mass Concept Erasure in Diffusion Models with Concept Hierarchy", "target": "supertype-subtype concept hierarchy", "value": "proposed_model"}, {"source": "Mass Concept Erasure in Diffusion Models with Concept Hierarchy", "target": "group-wise suppression method", "value": "proposed_model"}, {"source": "Mass Concept Erasure in Diffusion Models with Concept Hierarchy", "target": "Supertype-Preserving Low-Rank Adaptation (SuPLoRA)", "value": "proposed_model"}, {"source": "Mass Concept Erasure in Diffusion Models with Concept Hierarchy", "target": "benchmark", "value": "evaluated_on"}, {"source": "Mass Concept Erasure in Diffusion Models with Concept Hierarchy", "target": "concept erasure approaches", "value": "cites"}, {"source": "Mass Concept Erasure in Diffusion Models with Concept Hierarchy", "target": "diffusion models", "value": "cites"}, {"source": "Mass Concept Erasure in Diffusion Models with Concept Hierarchy", "target": "standard diffusion regularization", "value": "uses_metric"}, {"source": "Intelligent Recognition of GPR Road Hidden Defect Images Based on Feature Fusion and Attention Mechanism", "target": "Multi-modal Chain and Global Attention Network (MCGA-Net)", "value": "proposed_model"}, {"source": "Intelligent Recognition of GPR Road Hidden Defect Images Based on Feature Fusion and Attention Mechanism", "target": "DCGAN-based data augmentation strategy", "value": "proposed_model"}, {"source": "Intelligent Recognition of GPR Road Hidden Defect Images Based on Feature Fusion and Attention Mechanism", "target": "Multi-modal Chain Feature Fusion (MCFF)", "value": "proposed_model"}, {"source": "Intelligent Recognition of GPR Road Hidden Defect Images Based on Feature Fusion and Attention Mechanism", "target": "Global Attention Mechanism (GAM)", "value": "proposed_model"}, {"source": "Multi-modal Chain and Global Attention Network (MCGA-Net)", "target": "Precision", "value": "uses_metric"}, {"source": "Multi-modal Chain and Global Attention Network (MCGA-Net)", "target": "Recall", "value": "uses_metric"}, {"source": "Multi-modal Chain and Global Attention Network (MCGA-Net)", "target": "mAP@50", "value": "uses_metric"}, {"source": "Multi-modal Chain and Global Attention Network (MCGA-Net)", "target": "GPR images", "value": "evaluated_on"}, {"source": "Multi-modal Chain and Global Attention Network (MCGA-Net)", "target": "MS COCO", "value": "cites"}, {"source": "Qwen3-VL-Embedding", "target": "Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking", "value": "proposed_model"}, {"source": "Qwen3-VL-Reranker", "target": "Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking", "value": "proposed_model"}, {"source": "Qwen3-VL-Embedding", "target": "MMEB-V2", "value": "evaluated_on"}, {"source": "Flexible Partial Screen-Shooting Watermarking With Provable Robustness", "target": "FPSMark", "value": "proposed_model"}, {"source": "FPSMark", "target": "existing methods", "value": "baseline_model"}, {"source": "FPSMark", "target": "existing methods", "value": "cites"}, {"source": "Pattern Recognition and Machine Learning", "target": "Probability Distributions", "value": "cites"}, {"source": "Pattern Recognition and Machine Learning", "target": "Linear Models for Regression", "value": "cites"}, {"source": "Pattern Recognition and Machine Learning", "target": "Linear Models for Classification", "value": "cites"}, {"source": "Pattern Recognition and Machine Learning", "target": "Neural Networks", "value": "cites"}, {"source": "Pattern Recognition and Machine Learning", "target": "Kernel Methods", "value": "cites"}, {"source": "Pattern Recognition and Machine Learning", "target": "Sparse Kernel Machines", "value": "cites"}, {"source": "Pattern Recognition and Machine Learning", "target": "Graphical Models", "value": "cites"}, {"source": "Pattern Recognition and Machine Learning", "target": "Mixture Models and EM", "value": "cites"}, {"source": "Pattern Recognition and Machine Learning", "target": "Approximate Inference", "value": "cites"}, {"source": "Pattern Recognition and Machine Learning", "target": "Sampling Methods", "value": "cites"}, {"source": "Pattern Recognition and Machine Learning", "target": "Continuous Latent Variables", "value": "cites"}, {"source": "Pattern Recognition and Machine Learning", "target": "Sequential Data", "value": "cites"}, {"source": "Pattern Recognition and Machine Learning", "target": "Combining Models", "value": "cites"}, {"source": "Automatic Image-Based Plant Disease Severity Estimation Using Deep Learning", "target": "deep VGG16 model", "value": "proposed_model"}, {"source": "Automatic Image-Based Plant Disease Severity Estimation Using Deep Learning", "target": "PlantVillage dataset", "value": "evaluated_on"}, {"source": "deep VGG16 model", "target": "deep convolutional neural networks", "value": "baseline_model"}, {"source": "PlantVillage dataset", "target": "botanists", "value": "author_of"}, {"source": "Plant identification using deep neural networks via optimization of transfer learning parameters", "target": "deep neural networks", "value": "proposed_model"}, {"source": "Plant identification using deep neural networks via optimization of transfer learning parameters", "target": "transfer learning parameters", "value": "evaluated_on"}, {"source": "Deep Learning for Plant Identification in Natural Environment", "target": "A 26-layer deep learning model consisting of 8 residual building blocks", "value": "proposed_model"}, {"source": "A 26-layer deep learning model consisting of 8 residual building blocks", "target": "BJFU100 dataset", "value": "evaluated_on"}, {"source": "Deep Learning for Plant Identification in Natural Environment", "target": "Plant image identification", "value": "author_of"}, {"source": "Going deeper in the automated identification of Herbarium specimens", "target": "Deep Learning", "value": "proposed_model"}, {"source": "Going deeper in the automated identification of Herbarium specimens", "target": "herbarium images", "value": "evaluated_on"}, {"source": "Going deeper in the automated identification of Herbarium specimens", "target": "photos of plants in the field", "value": "evaluated_on"}, {"source": "Going deeper in the automated identification of Herbarium specimens", "target": "big dataset with thousands of species from herbaria", "value": "evaluated_on"}, {"source": "Going deeper in the automated identification of Herbarium specimens", "target": "different datasets from different herbaria", "value": "evaluated_on"}, {"source": "Deep Learning", "target": "automated system", "value": "proposed_model"}, {"source": "Densely Connected Convolutional Networks", "target": "Dense Convolutional Network (DenseNet)", "value": "proposed_model"}, {"source": "Dense Convolutional Network (DenseNet)", "target": "CIFAR-10", "value": "evaluated_on"}, {"source": "Dense Convolutional Network (DenseNet)", "target": "CIFAR-100", "value": "evaluated_on"}, {"source": "Dense Convolutional Network (DenseNet)", "target": "SVHN", "value": "evaluated_on"}, {"source": "Dense Convolutional Network (DenseNet)", "target": "ImageNet", "value": "evaluated_on"}, {"source": "MobileNetV2: Inverted Residuals and Linear Bottlenecks", "target": "MobileNetV2", "value": "proposed_model"}, {"source": "MobileNetV2: Inverted Residuals and Linear Bottlenecks", "target": "SSDLite", "value": "proposed_model"}, {"source": "MobileNetV2: Inverted Residuals and Linear Bottlenecks", "target": "Mobile DeepLabv3", "value": "proposed_model"}, {"source": "MobileNetV2", "target": "Imagenet", "value": "evaluated_on"}, {"source": "MobileNetV2", "target": "COCO", "value": "evaluated_on"}, {"source": "MobileNetV2", "target": "VOC", "value": "evaluated_on"}, {"source": "MobileNetV2", "target": "multiply-adds (MAdd)", "value": "uses_metric"}, {"source": "Communication-Efficient Learning of Deep Networks from Decentralized Data", "target": "Federated Learning", "value": "proposed_model"}, {"source": "Communication-Efficient Learning of Deep Networks from Decentralized Data", "target": "five different model architectures", "value": "evaluated_on"}, {"source": "Communication-Efficient Learning of Deep Networks from Decentralized Data", "target": "four datasets", "value": "evaluated_on"}, {"source": "Federated Learning", "target": "synchronized stochastic gradient descent", "value": "baseline_model"}, {"source": "A Comprehensive Survey on Transfer Learning", "target": "Amazon Reviews", "value": "evaluated_on"}, {"source": "A Comprehensive Survey on Transfer Learning", "target": "Reuters-21578", "value": "evaluated_on"}, {"source": "A Comprehensive Survey on Transfer Learning", "target": "Office-31", "value": "evaluated_on"}, {"source": "Privacy Preserved and Decentralized Smartphone Recommendation System", "target": "federated deep neural network (FDNN)", "value": "proposed_model"}, {"source": "Privacy Preserved and Decentralized Smartphone Recommendation System", "target": "Flipkart dataset", "value": "evaluated_on"}, {"source": "Privacy Preserved and Decentralized Smartphone Recommendation System", "target": "We", "value": "author_of"}, {"source": "federated deep neural network (FDNN)", "target": "Term Frequency-Inverse Document Frequency (TF-IDF)", "value": "uses_metric"}, {"source": "federated deep neural network (FDNN)", "target": "federated learning", "value": "baseline_model"}, {"source": "A Survey on Heterogeneity Taxonomy, Security and Privacy Preservation in the Integration of IoT, Wireless Sensor Networks and Federated Learning", "target": "Federated learning", "value": "author_of"}, {"source": "A Survey on Heterogeneity Taxonomy, Security and Privacy Preservation in the Integration of IoT, Wireless Sensor Networks and Federated Learning", "target": "Federated learning", "value": "cites"}, {"source": "A Survey on Heterogeneity Taxonomy, Security and Privacy Preservation in the Integration of IoT, Wireless Sensor Networks and Federated Learning", "target": "Internet of Things", "value": "cites"}, {"source": "A Survey on Heterogeneity Taxonomy, Security and Privacy Preservation in the Integration of IoT, Wireless Sensor Networks and Federated Learning", "target": "Wireless Sensor Networks", "value": "cites"}, {"source": "Federated learning", "target": "Internet of Things", "value": "evaluated_on"}, {"source": "Federated learning", "target": "Wireless Sensor Networks", "value": "evaluated_on"}, {"source": "A privacy-preserving federated learning with a secure collaborative for malware detection models using Internet of Things resources", "target": "privacy-preserving federated learning", "value": "proposed_model"}, {"source": "privacy-preserving federated learning", "target": "Internet of Things resources", "value": "evaluated_on"}, {"source": "privacy-preserving federated learning", "target": "malware detection models", "value": "uses_metric"}, {"source": "Federated Learning Architectures: A Performance Evaluation With Crop Yield Prediction Application", "target": "centralized federated learning framework", "value": "proposed_model"}, {"source": "Federated Learning Architectures: A Performance Evaluation With Crop Yield Prediction Application", "target": "decentralized federated learning framework", "value": "proposed_model"}, {"source": "centralized federated learning framework", "target": "prediction accuracy", "value": "uses_metric"}, {"source": "centralized federated learning framework", "target": "precision", "value": "uses_metric"}, {"source": "centralized federated learning framework", "target": "recall", "value": "uses_metric"}, {"source": "centralized federated learning framework", "target": "F1-Score", "value": "uses_metric"}, {"source": "centralized federated learning framework", "target": "training time", "value": "uses_metric"}, {"source": "decentralized federated learning framework", "target": "prediction accuracy", "value": "uses_metric"}, {"source": "decentralized federated learning framework", "target": "precision", "value": "uses_metric"}, {"source": "decentralized federated learning framework", "target": "recall", "value": "uses_metric"}, {"source": "decentralized federated learning framework", "target": "F1-Score", "value": "uses_metric"}, {"source": "decentralized federated learning framework", "target": "training time", "value": "uses_metric"}, {"source": "centralized federated learning framework", "target": "crop yield prediction", "value": "evaluated_on"}, {"source": "decentralized federated learning framework", "target": "crop yield prediction", "value": "evaluated_on"}, {"source": "centralized federated learning framework", "target": "cloud-only framework", "value": "baseline_model"}, {"source": "centralized federated learning framework", "target": "Long Short-Term Memory Network", "value": "cites"}, {"source": "decentralized federated learning framework", "target": "Long Short-Term Memory Network", "value": "cites"}, {"source": "Segment Anything", "target": "Segment Anything Model (SAM)", "value": "proposed_model"}, {"source": "Segment Anything", "target": "Segment Anything", "value": "author_of"}, {"source": "Visual Instruction Tuning", "target": "LLaVA: Large Language and Vision Assistant", "value": "proposed_model"}, {"source": "LLaVA: Large Language and Vision Assistant", "target": "Science QA", "value": "evaluated_on"}, {"source": "LLaVA: Large Language and Vision Assistant", "target": "GPT-4 generated visual instruction tuning data", "value": "evaluated_on"}, {"source": "Visual Instruction Tuning", "target": "GPT-4", "value": "cites"}, {"source": "LLaVA: Large Language and Vision Assistant", "target": "GPT-4", "value": "baseline_model"}, {"source": "Improved Baselines with Visual Instruction Tuning", "target": "LLaVA", "value": "proposed_model"}, {"source": "Improved Baselines with Visual Instruction Tuning", "target": "LLaVA", "value": "baseline_model"}, {"source": "Improved Baselines with Visual Instruction Tuning", "target": "LLaVA", "value": "cites"}, {"source": "LLaVA", "target": "CLIP-ViT-L-336px", "value": "cites"}, {"source": "LLaVA", "target": "MLP projection", "value": "cites"}, {"source": "LLaVA", "target": "academic-task-oriented VQA data", "value": "evaluated_on"}, {"source": "DepictQA-Wild", "target": "Enhancing Descriptive Image Quality Assessment With a Large-Scale Multi-Modal Dataset", "value": "proposed_model"}, {"source": "DepictQA-Wild", "target": "DQ-495K", "value": "evaluated_on"}, {"source": "DepictQA-Wild", "target": "traditional score-based methods", "value": "baseline_model"}, {"source": "DepictQA-Wild", "target": "prior VLM-based IQA models", "value": "baseline_model"}, {"source": "DepictQA-Wild", "target": "GPT-4V", "value": "baseline_model"}, {"source": "Enhancing Descriptive Image Quality Assessment With a Large-Scale Multi-Modal Dataset", "target": "Vision Language Models (VLMs)", "value": "cites"}, {"source": "Enhancing Descriptive Image Quality Assessment With a Large-Scale Multi-Modal Dataset", "target": "VLM-based Image Quality Assessment (IQA)", "value": "cites"}, {"source": "Adaptive Chain-of-Focus Reasoning via Dynamic Visual Search and Zooming for Efficient VLMs", "target": "Chain-of-Focus (CoF) method", "value": "proposed_model"}, {"source": "Adaptive Chain-of-Focus Reasoning via Dynamic Visual Search and Zooming for Efficient VLMs", "target": "Chain-of-Focus (CoF) method", "value": "author_of"}, {"source": "Chain-of-Focus (CoF) method", "target": "V* benchmark", "value": "evaluated_on"}, {"source": "Chain-of-Focus (CoF) method", "target": "V* benchmark", "value": "uses_metric"}, {"source": "Chain-of-Focus (CoF) method", "target": "Vision language models (VLMs)", "value": "baseline_model"}, {"source": "Chain-of-Focus (CoF) method", "target": "Vision language models (VLMs)", "value": "cites"}, {"source": "Chain-of-Focus (CoF) method", "target": "MM-CoF dataset", "value": "uses_metric"}, {"source": "Qwen2.5-VL model", "target": "V* benchmark", "value": "evaluated_on"}, {"source": "Qwen2.5-VL model", "target": "MM-CoF dataset", "value": "uses_metric"}, {"source": "3DThinker", "target": "Think with 3D: Geometric Imagination Grounded Spatial Reasoning from Limited Views", "value": "proposed_model"}, {"source": "3DThinker", "target": "vision-language models (VLMs)", "value": "baseline_model"}, {"source": "3DThinker", "target": "topological cognitive maps", "value": "baseline_model"}, {"source": "3DThinker", "target": "VGGT", "value": "uses_metric"}, {"source": "zhangquanchen", "target": "Think with 3D: Geometric Imagination Grounded Spatial Reasoning from Limited Views", "value": "author_of"}, {"source": "UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning", "target": "UniME-V2", "value": "proposed_model"}, {"source": "UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning", "target": "UniME-V2-Reranker", "value": "proposed_model"}, {"source": "UniME-V2", "target": "MLLM-as-a-Judge mechanism", "value": "uses_metric"}, {"source": "UniME-V2", "target": "MMEB benchmark", "value": "evaluated_on"}, {"source": "UniME-V2-Reranker", "target": "MMEB benchmark", "value": "evaluated_on"}, {"source": "OpenMMReasoner", "target": "OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe", "value": "proposed_model"}, {"source": "OpenMMReasoner", "target": "Qwen2.5-VL-7B-Instruct", "value": "baseline_model"}, {"source": "OpenMMReasoner", "target": "nine multimodal reasoning benchmarks", "value": "evaluated_on"}, {"source": "OpenMMReasoner", "target": "Qwen2.5-VL-7B-Instruct", "value": "cites"}, {"source": "OpenMMReasoner", "target": "OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe", "value": "author_of"}, {"source": "Vision-Language-Action (VLA) Models: Concepts, Progress, Applications and Challenges", "target": "Applied-AI-Research-Lab", "value": "author_of"}, {"source": "Vision-Language-Action (VLA) Models: Concepts, Progress, Applications and Challenges", "target": "over 80 VLA models", "value": "cites"}, {"source": "Vision-Language-Action (VLA) Models: Concepts, Progress, Applications and Challenges", "target": "Vision-Language-Action (VLA) models", "value": "proposed_model"}, {"source": "Vision-Language-Action (VLA) Models: Concepts, Progress, Applications and Challenges", "target": "vision-language models (VLMs)", "value": "proposed_model"}, {"source": "Vision-Language-Action (VLA) Models: Concepts, Progress, Applications and Challenges", "target": "agentic AI", "value": "proposed_model"}, {"source": "Vision-Language-Action (VLA) Models: Concepts, Progress, Applications and Challenges", "target": "socially aligned, adaptive, and general-purpose embodied agents", "value": "proposed_model"}, {"source": "Vision-Language-Action (VLA) models", "target": "autonomous vehicles", "value": "evaluated_on"}, {"source": "Vision-Language-Action (VLA) models", "target": "medical and industrial robotics", "value": "evaluated_on"}, {"source": "Vision-Language-Action (VLA) models", "target": "precision agriculture", "value": "evaluated_on"}, {"source": "Vision-Language-Action (VLA) models", "target": "humanoid robotics", "value": "evaluated_on"}, {"source": "Vision-Language-Action (VLA) models", "target": "augmented reality", "value": "evaluated_on"}, {"source": "Vision-Language-Action (VLA) models", "target": "intelligent, real-world robotics", "value": "evaluated_on"}, {"source": "Vision-Language-Action (VLA) models", "target": "artificial general intelligence", "value": "evaluated_on"}, {"source": "Vision-Language-Action (VLA) models", "target": "architectural innovations", "value": "uses_metric"}, {"source": "Vision-Language-Action (VLA) models", "target": "efficient training strategies", "value": "uses_metric"}, {"source": "Vision-Language-Action (VLA) models", "target": "real-time inference accelerations", "value": "uses_metric"}, {"source": "Vision-Language-Action (VLA) models", "target": "agentic adaptation", "value": "uses_metric"}, {"source": "Vision-Language-Action (VLA) models", "target": "cross-embodiment planning", "value": "uses_metric"}, {"source": "Vision-Language-Action (VLA) models", "target": "cross-modal learning architectures", "value": "baseline_model"}, {"source": "Vision-Language-Action (VLA) models", "target": "generalist agents", "value": "cites"}, {"source": "Vision-Language-Action (VLA) models", "target": "action planners", "value": "cites"}, {"source": "Vision-Language-Action (VLA) models", "target": "hierarchical controllers", "value": "cites"}, {"source": "Leave No Observation Behind: Real-time Correction for VLA Action Chunks", "target": "Asynchronous Action Chunk Correction (A2C2)", "value": "proposed_model"}, {"source": "Asynchronous Action Chunk Correction (A2C2)", "target": "Real Time Chunking (RTC)", "value": "baseline_model"}, {"source": "Asynchronous Action Chunk Correction (A2C2)", "target": "dynamic Kinetix task suite", "value": "evaluated_on"}, {"source": "Asynchronous Action Chunk Correction (A2C2)", "target": "LIBERO Spatial", "value": "evaluated_on"}, {"source": "Latent-CoT-Drive (LCDrive)", "target": "Latent Chain-of-Thought World Modeling for End-to-End Driving", "value": "proposed_model"}, {"source": "Latent-CoT-Drive (LCDrive)", "target": "large-scale end-to-end driving benchmark", "value": "evaluated_on"}, {"source": "Latent-CoT-Drive (LCDrive)", "target": "non-reasoning baselines", "value": "baseline_model"}, {"source": "Latent-CoT-Drive (LCDrive)", "target": "text-reasoning baselines", "value": "baseline_model"}, {"source": "Latent Chain-of-Thought World Modeling for End-to-End Driving", "target": "Vision-Language-Action (VLA) models", "value": "cites"}, {"source": "Latent Chain-of-Thought World Modeling for End-to-End Driving", "target": "chain-of-thought (CoT) reasoning", "value": "cites"}, {"source": "HyperVLA", "target": "Vision-Language-Action (VLA) models", "value": "proposed_model"}, {"source": "HyperVLA", "target": "OpenVLA", "value": "baseline_model"}, {"source": "HyperVLA", "target": "OpenVLA", "value": "cites"}, {"source": "HyperVLA", "target": "HyperVLA", "value": "author_of"}, {"source": "Token Expand-and-Merge-VLA (TEAM-VLA)", "target": "Token Expand-Merge: Training-Free Token Compression for Vision-Language-Action Models", "value": "proposed_model"}, {"source": "Token Expand-and-Merge-VLA (TEAM-VLA)", "target": "Vision-Language-Action (VLA) models", "value": "baseline_model"}, {"source": "Token Expand-and-Merge-VLA (TEAM-VLA)", "target": "LIBERO benchmark", "value": "evaluated_on"}, {"source": "TransSIL: A Silhouette Cue-Aware Image Classification Framework for Bird Ecological Monitoring Systems", "target": "TransSIL", "value": "proposed_model"}, {"source": "TransSIL", "target": "CUB200-2011", "value": "evaluated_on"}, {"source": "TransSIL", "target": "NABirds", "value": "evaluated_on"}, {"source": "TransSIL", "target": "fine-grained bird image classification (FBIC)", "value": "uses_metric"}, {"source": "TransSIL", "target": "bird ecological intelligent detection system", "value": "baseline_model"}, {"source": "CBRFormer: rendering technology-based transformer for refinement segmentation of bridge crack images", "target": "bridge crack images", "value": "evaluated_on"}, {"source": "A Fast and Compact Threshold Switch-Based Cellular Nonlinear Network Cell", "target": "threshold switch (TS) model", "value": "proposed_model"}, {"source": "A Fast and Compact Threshold Switch-Based Cellular Nonlinear Network Cell", "target": "standard isolated CNN cell", "value": "baseline_model"}, {"source": "A Fast and Compact Threshold Switch-Based Cellular Nonlinear Network Cell", "target": "image processing tasks", "value": "evaluated_on"}, {"source": "DrugCLIP", "target": "Deep contrastive learning enables genome-wide virtual screening", "value": "proposed_model"}, {"source": "DrugCLIP", "target": "norepinephrine transporter", "value": "evaluated_on"}, {"source": "DrugCLIP", "target": "thyroid hormone receptor interactor 12", "value": "evaluated_on"}, {"source": "DrugCLIP", "target": "AlphaFold2", "value": "cites"}, {"source": "We", "target": "Deep contrastive learning enables genome-wide virtual screening", "value": "author_of"}, {"source": "Deep contrastive learning enables genome-wide virtual screening", "target": "AlphaFold2", "value": "cites"}, {"source": "LLaVA-based semantic feature modulation diffusion model for underwater image enhancement", "target": "LLaVA", "value": "proposed_model"}, {"source": "LLaVA-based semantic feature modulation diffusion model for underwater image enhancement", "target": "underwater image enhancement", "value": "evaluated_on"}, {"source": "3DGS-Drag", "target": "Dragging Gaussians for Intuitive Point-Based 3D Editing", "value": "proposed_model"}, {"source": "3DGS-Drag", "target": "Dragging Gaussians for Intuitive Point-Based 3D Editing", "value": "author_of"}, {"source": "LILaC: Late Interacting in Layered Component Graph for Open-domain Multimodal Multihop Retrieval", "target": "LILaC", "value": "proposed_model"}, {"source": "LILaC: Late Interacting in Layered Component Graph for Open-domain Multimodal Multihop Retrieval", "target": "layered component graph", "value": "proposed_model"}, {"source": "LILaC: Late Interacting in Layered Component Graph for Open-domain Multimodal Multihop Retrieval", "target": "late-interaction-based subgraph retrieval method", "value": "proposed_model"}, {"source": "LILaC", "target": "five benchmarks", "value": "evaluated_on"}, {"source": "Bidirectional Normalizing Flow (BiFlow)", "target": "Bidirectional Normalizing Flow: From Data to Noise and Back", "value": "proposed_model"}, {"source": "Bidirectional Normalizing Flow (BiFlow)", "target": "ImageNet", "value": "evaluated_on"}, {"source": "Bidirectional Normalizing Flow: From Data to Noise and Back", "target": "TARFlow", "value": "cites"}, {"source": "Bidirectional Normalizing Flow: From Data to Noise and Back", "target": "Normalizing Flows (NFs)", "value": "cites"}, {"source": "One-step Latent-free Image Generation with Pixel Mean Flows", "target": "pixel MeanFlow", "value": "proposed_model"}, {"source": "One-step Latent-free Image Generation with Pixel Mean Flows", "target": "ImageNet", "value": "evaluated_on"}, {"source": "Meta Flow Maps enable scalable reward alignment", "target": "Meta Flow Maps", "value": "proposed_model"}, {"source": "Meta Flow Maps", "target": "ImageNet", "value": "evaluated_on"}, {"source": "Meta Flow Maps", "target": "Best-of-1000", "value": "baseline_model"}, {"source": "Meta Flow Maps", "target": "consistency models", "value": "cites"}, {"source": "Meta Flow Maps", "target": "flow maps", "value": "cites"}, {"source": "Accelerated Sequential Flow Matching: A Bayesian Filtering Perspective", "target": "Sequential Flow Matching", "value": "proposed_model"}, {"source": "Sequential Flow Matching", "target": "forecasting, decision-making and state estimation tasks", "value": "evaluated_on"}, {"source": "Sequential Flow Matching", "target": "Bayesian filtering", "value": "cites"}, {"source": "Sequential Flow Matching", "target": "diffusion and flow-matching models", "value": "cites"}, {"source": "Drifting Models", "target": "Generative Modeling via Drifting", "value": "proposed_model"}, {"source": "Generative Modeling via Drifting", "target": "ImageNet", "value": "evaluated_on"}, {"source": "Generative Modeling via Drifting", "target": "FID", "value": "uses_metric"}, {"source": "Generative Modeling via Drifting", "target": "diffusion models", "value": "cites"}, {"source": "Generative Modeling via Drifting", "target": "flow-based models", "value": "cites"}, {"source": "A Simple Framework for Contrastive Learning of Visual Representations", "target": "SimCLR", "value": "proposed_model"}, {"source": "SimCLR", "target": "ImageNet", "value": "evaluated_on"}, {"source": "SimCLR", "target": "ResNet-50", "value": "baseline_model"}, {"source": "SimCLR", "target": "AlexNet", "value": "baseline_model"}, {"source": "Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning", "target": "Directional Decoupling Alignment (D\u00b2-Align)", "value": "proposed_model"}, {"source": "Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning", "target": "DivGenBench", "value": "proposed_model"}, {"source": "Directional Decoupling Alignment (D\u00b2-Align)", "target": "DivGenBench", "value": "evaluated_on"}, {"source": "Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning", "target": "Reinforcement Learning from Human Feedback", "value": "cites"}, {"source": "Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning", "target": "Preference Mode Collapse (PMC)", "value": "cites"}, {"source": "ImagerySearch: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints", "target": "ImagerySearch", "value": "proposed_model"}, {"source": "ImagerySearch: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints", "target": "LDT-Bench", "value": "evaluated_on"}, {"source": "ImagerySearch: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints", "target": "VBench", "value": "evaluated_on"}, {"source": "ImagerySearch: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints", "target": "VBench", "value": "cites"}, {"source": "Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders", "target": "Representation Autoencoders (RAEs)", "value": "proposed_model"}, {"source": "Representation Autoencoders (RAEs)", "target": "ImageNet", "value": "evaluated_on"}, {"source": "Representation Autoencoders (RAEs)", "target": "FLUX VAE", "value": "baseline_model"}, {"source": "Representation Autoencoders (RAEs)", "target": "VAEs", "value": "baseline_model"}, {"source": "Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders", "target": "SigLIP-2", "value": "cites"}, {"source": "Simulating the Visual World with Artificial Intelligence: A Roadmap", "target": "video foundation models", "value": "proposed_model"}, {"source": "video foundation models", "target": "implicit world model", "value": "proposed_model"}, {"source": "video foundation models", "target": "video renderer", "value": "proposed_model"}, {"source": "world model", "target": "video generation model", "value": "proposed_model"}, {"source": "Simulating the Visual World with Artificial Intelligence: A Roadmap", "target": "robotics", "value": "evaluated_on"}, {"source": "Simulating the Visual World with Artificial Intelligence: A Roadmap", "target": "autonomous driving", "value": "evaluated_on"}, {"source": "Simulating the Visual World with Artificial Intelligence: A Roadmap", "target": "interactive gaming", "value": "evaluated_on"}, {"source": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "target": "unified design specification for world models", "value": "proposed_model"}, {"source": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "target": "World models", "value": "cites"}, {"source": "World models", "target": "visual prediction", "value": "evaluated_on"}, {"source": "World models", "target": "3D estimation", "value": "evaluated_on"}, {"source": "World models", "target": "symbol grounding", "value": "evaluated_on"}, {"source": "unified design specification for world models", "target": "interaction", "value": "uses_metric"}, {"source": "unified design specification for world models", "target": "perception", "value": "uses_metric"}, {"source": "unified design specification for world models", "target": "symbolic reasoning", "value": "uses_metric"}, {"source": "unified design specification for world models", "target": "spatial representation", "value": "uses_metric"}, {"source": "RecTok: Reconstruction Distillation along Rectified Flow", "target": "RecTok", "value": "proposed_model"}, {"source": "RecTok", "target": "Shi Qingyu", "value": "author_of"}, {"source": "RecTok", "target": "gFID-50K", "value": "evaluated_on"}, {"source": "RecTok", "target": "gFID-50K", "value": "uses_metric"}, {"source": "RecTok", "target": "visual tokenizers", "value": "baseline_model"}, {"source": "RecTok", "target": "diffusion models", "value": "cites"}, {"source": "RecTok", "target": "vision foundation models", "value": "cites"}, {"source": "RecTok", "target": "flow matching", "value": "cites"}, {"source": "RecTok", "target": "diffusion transformers", "value": "cites"}, {"source": "RecTok", "target": "VFMs", "value": "cites"}, {"source": "RePack then Refine", "target": "RePack-DiT-XL/1", "value": "proposed_model"}, {"source": "RePack then Refine", "target": "RePack module", "value": "proposed_model"}, {"source": "RePack then Refine", "target": "Latent-Guided Refiner", "value": "proposed_model"}, {"source": "RePack then Refine", "target": "Latent Diffusion Models", "value": "baseline_model"}, {"source": "RePack then Refine", "target": "ImageNet-1K", "value": "evaluated_on"}, {"source": "RePack then Refine", "target": "FID", "value": "uses_metric"}, {"source": "RePack then Refine", "target": "Vision Foundation Models", "value": "cites"}, {"source": "RePack then Refine", "target": "Diffusion Transformers", "value": "cites"}, {"source": "RePack module", "target": "Vision Foundation Models", "value": "cites"}, {"source": "Latent-Guided Refiner", "target": "RePack module", "value": "cites"}, {"source": "Diffusion Models Beat GANs on Image Synthesis", "target": "diffusion models", "value": "proposed_model"}, {"source": "Diffusion Models Beat GANs on Image Synthesis", "target": "GANs", "value": "baseline_model"}, {"source": "Diffusion Models Beat GANs on Image Synthesis", "target": "ImageNet 128\u00d7128", "value": "evaluated_on"}, {"source": "Diffusion Models Beat GANs on Image Synthesis", "target": "ImageNet 256\u00d7256", "value": "evaluated_on"}, {"source": "Diffusion Models Beat GANs on Image Synthesis", "target": "ImageNet 512\u00d7512", "value": "evaluated_on"}, {"source": "Diffusion Models Beat GANs on Image Synthesis", "target": "FID", "value": "uses_metric"}, {"source": "diffusion models", "target": "BigGAN-deep", "value": "cites"}, {"source": "diffusion models", "target": "FID", "value": "uses_metric"}, {"source": "classifier guidance", "target": "upsampling diffusion models", "value": "cites"}, {"source": "DINOv2: Learning Robust Visual Features without Supervision", "target": "ViT model (Dosovitskiy et al., 2020)", "value": "proposed_model"}, {"source": "DINOv2: Learning Robust Visual Features without Supervision", "target": "OpenCLIP (Ilharco et al., 2021)", "value": "baseline_model"}, {"source": "DINOv2: Learning Robust Visual Features without Supervision", "target": "OpenCLIP (Ilharco et al., 2021)", "value": "evaluated_on"}, {"source": "Dosovitskiy et al.", "target": "ViT model (Dosovitskiy et al., 2020)", "value": "author_of"}, {"source": "Ilharco et al.", "target": "OpenCLIP (Ilharco et al., 2021)", "value": "author_of"}, {"source": "DINOv2: Learning Robust Visual Features without Supervision", "target": "ViT model (Dosovitskiy et al., 2020)", "value": "cites"}, {"source": "DINOv2: Learning Robust Visual Features without Supervision", "target": "OpenCLIP (Ilharco et al., 2021)", "value": "cites"}, {"source": "PixelGen", "target": "PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss", "value": "proposed_model"}, {"source": "PixelGen", "target": "latent diffusion", "value": "baseline_model"}, {"source": "PixelGen", "target": "ImageNet-256", "value": "evaluated_on"}, {"source": "PixelGen", "target": "GenEval", "value": "evaluated_on"}, {"source": "PixelGen", "target": "FID", "value": "uses_metric"}, {"source": "PixelGen", "target": "LPIPS", "value": "cites"}, {"source": "PixelGen", "target": "DINO", "value": "cites"}, {"source": "Zehong-Ma", "target": "PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss", "value": "author_of"}, {"source": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "target": "GPT-4o", "value": "cites"}, {"source": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "target": "multimodal understanding models", "value": "cites"}, {"source": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "target": "image generation models", "value": "cites"}, {"source": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "target": "autoregressive-based architectures", "value": "cites"}, {"source": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "target": "diffusion-based models", "value": "cites"}, {"source": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "target": "unified frameworks", "value": "cites"}, {"source": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "target": "diffusion-based", "value": "cites"}, {"source": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "target": "autoregressive-based", "value": "cites"}, {"source": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "target": "hybrid approaches", "value": "cites"}, {"source": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "target": "datasets and benchmarks", "value": "cites"}, {"source": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "target": "GitHub", "value": "cites"}, {"source": "MentisOculi: Revealing the Limits of Reasoning with Mental Imagery", "target": "MentisOculi", "value": "proposed_model"}, {"source": "MentisOculi: Revealing the Limits of Reasoning with Mental Imagery", "target": "Frontier models", "value": "evaluated_on"}, {"source": "MentisOculi: Revealing the Limits of Reasoning with Mental Imagery", "target": "multimodal large language models (MLLMs)", "value": "evaluated_on"}, {"source": "MentisOculi: Revealing the Limits of Reasoning with Mental Imagery", "target": "unified multimodal models (UMMs)", "value": "evaluated_on"}, {"source": "MentisOculi: Revealing the Limits of Reasoning with Mental Imagery", "target": "Frontier models", "value": "cites"}, {"source": "MentisOculi: Revealing the Limits of Reasoning with Mental Imagery", "target": "multimodal large language models (MLLMs)", "value": "cites"}, {"source": "MentisOculi: Revealing the Limits of Reasoning with Mental Imagery", "target": "unified multimodal models (UMMs)", "value": "cites"}, {"source": "OpenVision 3: A Family of Unified Visual Encoder for Both Understanding and Generation", "target": "OpenVision 3", "value": "proposed_model"}, {"source": "OpenVision 3", "target": "SeedBench", "value": "uses_metric"}, {"source": "OpenVision 3", "target": "POPE", "value": "uses_metric"}, {"source": "OpenVision 3", "target": "ImageNet", "value": "uses_metric"}, {"source": "OpenVision 3", "target": "CLIP", "value": "baseline_model"}, {"source": "OpenVision 3", "target": "LLaVA-1.5", "value": "evaluated_on"}, {"source": "OpenVision 3", "target": "RAE", "value": "evaluated_on"}, {"source": "OpenVision 3", "target": "VAE", "value": "cites"}, {"source": "OpenVision 3", "target": "ViT", "value": "cites"}, {"source": "OpenVision 3", "target": "ViT-VAE", "value": "cites"}, {"source": "Distributed Representations of Words and Phrases and their Compositionality", "target": "continuous Skip-gram model", "value": "proposed_model"}, {"source": "Distributed Representations of Words and Phrases and their Compositionality", "target": "subsampling of the frequent words", "value": "proposed_model"}, {"source": "Distributed Representations of Words and Phrases and their Compositionality", "target": "negative sampling", "value": "proposed_model"}, {"source": "Distributed Representations of Words and Phrases and their Compositionality", "target": "simple method for finding phrases in text", "value": "proposed_model"}, {"source": "Distributed Representations of Words and Phrases and their Compositionality", "target": "hierarchical softmax", "value": "baseline_model"}, {"source": "GloVe: Global Vectors for Word Representation", "target": "global logbilinear regression model", "value": "proposed_model"}, {"source": "global logbilinear regression model", "target": "global matrix factorization", "value": "baseline_model"}, {"source": "global logbilinear regression model", "target": "local context window methods", "value": "baseline_model"}, {"source": "global logbilinear regression model", "target": "word analogy task", "value": "evaluated_on"}, {"source": "global logbilinear regression model", "target": "similarity tasks", "value": "evaluated_on"}, {"source": "global logbilinear regression model", "target": "named entity recognition", "value": "evaluated_on"}, {"source": "global logbilinear regression model", "target": "word-word cooccurrence matrix", "value": "uses_metric"}, {"source": "Deep Contextualized Word Representations", "target": "deep bidirectional language model", "value": "proposed_model"}, {"source": "Deep Contextualized Word Representations", "target": "question answering", "value": "evaluated_on"}, {"source": "Deep Contextualized Word Representations", "target": "textual entailment", "value": "evaluated_on"}, {"source": "Deep Contextualized Word Representations", "target": "sentiment analysis", "value": "evaluated_on"}, {"source": "We", "target": "Deep Contextualized Word Representations", "value": "author_of"}, {"source": "Relating Word Embedding Gender Biases to Gender Gaps: A Cross-Cultural Analysis", "target": "Modern models for common NLP tasks", "value": "proposed_model"}, {"source": "Relating Word Embedding Gender Biases to Gender Gaps: A Cross-Cultural Analysis", "target": "2018 Twitter data spanning 51 U.S. regions and 99 countries", "value": "evaluated_on"}, {"source": "Relating Word Embedding Gender Biases to Gender Gaps: A Cross-Cultural Analysis", "target": "18 international and 5 U.S.-based statistical gender gaps", "value": "evaluated_on"}, {"source": "SegMamba-V2", "target": "SegMamba-V2: Long-Range Sequential Modeling Mamba for General 3-D Medical Image Segmentation", "value": "proposed_model"}, {"source": "SegMamba-V2: Long-Range Sequential Modeling Mamba for General 3-D Medical Image Segmentation", "target": "ge-xing", "value": "author_of"}, {"source": "SegMamba-V2", "target": "CRC-2000", "value": "evaluated_on"}, {"source": "SegMamba-V2: Long-Range Sequential Modeling Mamba for General 3-D Medical Image Segmentation", "target": "Transformer", "value": "cites"}, {"source": "SegMamba-V2: Long-Range Sequential Modeling Mamba for General 3-D Medical Image Segmentation", "target": "Mamba", "value": "cites"}, {"source": "SegMamba-V2: Long-Range Sequential Modeling Mamba for General 3-D Medical Image Segmentation", "target": "State Space Model (SSM)", "value": "cites"}, {"source": "Generative Classifiers Avoid Shortcut Solutions", "target": "diffusion-based generative classifiers", "value": "proposed_model"}, {"source": "Generative Classifiers Avoid Shortcut Solutions", "target": "autoregressive generative classifiers", "value": "proposed_model"}, {"source": "Generative Classifiers Avoid Shortcut Solutions", "target": "five standard image and text distribution shift benchmarks", "value": "evaluated_on"}, {"source": "Generative Classifiers Avoid Shortcut Solutions", "target": "medical datasets", "value": "evaluated_on"}, {"source": "Generative Classifiers Avoid Shortcut Solutions", "target": "satellite datasets", "value": "evaluated_on"}, {"source": "Generative Classifiers Avoid Shortcut Solutions", "target": "Gaussian toy setting", "value": "evaluated_on"}, {"source": "Edge Large AI Model Agent-Empowered Cognitive Multimodal Semantic Communication", "target": "Edge Large AI Model Agent", "value": "proposed_model"}, {"source": "Edge Large AI Model Agent-Empowered Cognitive Multimodal Semantic Communication", "target": "Cognitive Multimodal Semantic Communication", "value": "proposed_model"}, {"source": "Language Models are Unsupervised Multitask Learners", "target": "GPT-2", "value": "proposed_model"}, {"source": "The Llama 3 Herd of Models", "target": "Llama 3", "value": "proposed_model"}, {"source": "The Llama 3 Herd of Models", "target": "Llama 3", "value": "evaluated_on"}, {"source": "Llama 3", "target": "GPT-4", "value": "uses_metric"}, {"source": "The Llama 3 Herd of Models", "target": "GPT-4", "value": "cites"}, {"source": "A Survey on Diffusion Language Models", "target": "VILA-Lab", "value": "author_of"}, {"source": "A Survey on Diffusion Language Models", "target": "Diffusion Language Models", "value": "cites"}, {"source": "A Survey on Diffusion Language Models", "target": "autoregressive paradigm", "value": "cites"}, {"source": "A Survey on Diffusion Language Models", "target": "masked language models", "value": "cites"}, {"source": "A Survey on Diffusion Language Models", "target": "Diffusion Language Models", "value": "proposed_model"}, {"source": "Diffusion Language Models", "target": "autoregressive paradigm", "value": "baseline_model"}, {"source": "VILA-Lab", "target": "Awesome-DLMs", "value": "author_of"}, {"source": "Training Optimal Large Diffusion Language Models", "target": "Quokka", "value": "proposed_model"}, {"source": "Quokka", "target": "Chinchilla", "value": "cites"}, {"source": "Inpainting-Guided Policy Optimization for Diffusion Large Language Models", "target": "IGPO (Inpainting Guided Policy Optimization)", "value": "proposed_model"}, {"source": "IGPO (Inpainting Guided Policy Optimization)", "target": "GRPO", "value": "baseline_model"}, {"source": "IGPO (Inpainting Guided Policy Optimization)", "target": "GSM8K", "value": "evaluated_on"}, {"source": "IGPO (Inpainting Guided Policy Optimization)", "target": "Math500", "value": "evaluated_on"}, {"source": "IGPO (Inpainting Guided Policy Optimization)", "target": "AMC", "value": "evaluated_on"}, {"source": "masked diffusion large language models (dLLMs)", "target": "autoregressive LLMs", "value": "cites"}, {"source": "IGPO (Inpainting Guided Policy Optimization)", "target": "reinforcement learning", "value": "cites"}, {"source": "IGPO (Inpainting Guided Policy Optimization)", "target": "supervised fine-tuning", "value": "cites"}, {"source": "IGPO (Inpainting Guided Policy Optimization)", "target": "entropy-based filtering", "value": "cites"}, {"source": "Encoder-Decoder Diffusion Language Models for Efficient Training and Inference", "target": "encoder-decoder architecture", "value": "proposed_model"}, {"source": "Encoder-Decoder Diffusion Language Models for Efficient Training and Inference", "target": "Efficient Encoder-Decoder Diffusion (E2D2)", "value": "proposed_model"}, {"source": "Encoder-Decoder Diffusion Language Models for Efficient Training and Inference", "target": "discrete diffusion models", "value": "baseline_model"}, {"source": "Encoder-Decoder Diffusion Language Models for Efficient Training and Inference", "target": "autoregressive approaches", "value": "baseline_model"}, {"source": "Encoder-Decoder Diffusion Language Models for Efficient Training and Inference", "target": "summarization", "value": "evaluated_on"}, {"source": "Encoder-Decoder Diffusion Language Models for Efficient Training and Inference", "target": "translation", "value": "evaluated_on"}, {"source": "Encoder-Decoder Diffusion Language Models for Efficient Training and Inference", "target": "mathematical reasoning", "value": "evaluated_on"}, {"source": "encoder-decoder architecture", "target": "block diffusion models", "value": "cites"}, {"source": "Stable-DiffCoder", "target": "Stable-DiffCoder: Pushing the Frontier of Code Diffusion Large Language Model", "value": "proposed_model"}, {"source": "Stable-DiffCoder", "target": "Seed-Coder", "value": "baseline_model"}, {"source": "Stable-DiffCoder", "target": "code benchmarks", "value": "evaluated_on"}, {"source": "Stable-DiffCoder", "target": "code benchmarks", "value": "uses_metric"}, {"source": "Stable-DiffCoder", "target": "Seed-Coder", "value": "cites"}, {"source": "Stable-DiffCoder", "target": "Stable-DiffCoder: Pushing the Frontier of Code Diffusion Large Language Model", "value": "author_of"}, {"source": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "target": "Large Language Model (LLM)-based agents", "value": "author_of"}, {"source": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "target": "graph-based agent memory", "value": "proposed_model"}, {"source": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "target": "open-sourced libraries and benchmarks", "value": "evaluated_on"}, {"source": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "target": "research papers", "value": "cites"}, {"source": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "target": "open-source data", "value": "cites"}, {"source": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "target": "projects", "value": "cites"}, {"source": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "target": "open-sourced libraries and benchmarks", "value": "uses_metric"}, {"source": "graph-based agent memory", "target": "self-evolving agent memory", "value": "baseline_model"}, {"source": "open-sourced libraries and benchmarks", "target": "self-evolving agent memory", "value": "evaluated_on"}, {"source": "https://github.com/DEEP-PolyU/Awesome-GraphMemory", "target": "research papers", "value": "cites"}, {"source": "https://github.com/DEEP-PolyU/Awesome-GraphMemory", "target": "open-source data", "value": "cites"}, {"source": "https://github.com/DEEP-PolyU/Awesome-GraphMemory", "target": "projects", "value": "cites"}, {"source": "Empirical-MCTS", "target": "Empirical-MCTS: Continuous Agent Evolution via Dual-Experience Monte Carlo Tree Search", "value": "proposed_model"}, {"source": "Empirical-MCTS", "target": "Monte Carlo Tree Search (MCTS)", "value": "baseline_model"}, {"source": "Empirical-MCTS", "target": "AIME25", "value": "evaluated_on"}, {"source": "Empirical-MCTS", "target": "ARC-AGI-2", "value": "evaluated_on"}, {"source": "Empirical-MCTS", "target": "MathArena Apex", "value": "evaluated_on"}, {"source": "Empirical-MCTS: Continuous Agent Evolution via Dual-Experience Monte Carlo Tree Search", "target": "Monte Carlo Tree Search (MCTS)", "value": "cites"}, {"source": "Empirical-MCTS: Continuous Agent Evolution via Dual-Experience Monte Carlo Tree Search", "target": "Large Language Models (LLMs)", "value": "cites"}, {"source": "Empirical-MCTS", "target": "Empirical-MCTS: Continuous Agent Evolution via Dual-Experience Monte Carlo Tree Search", "value": "author_of"}, {"source": "TAME: A Trustworthy Test-Time Evolution of Agent Memory with Systematic Benchmarking", "target": "TAME", "value": "proposed_model"}, {"source": "TAME: A Trustworthy Test-Time Evolution of Agent Memory with Systematic Benchmarking", "target": "Trust-Memevo benchmark", "value": "evaluated_on"}, {"source": "TAME: A Trustworthy Test-Time Evolution of Agent Memory with Systematic Benchmarking", "target": "Agent Memory Misevolution", "value": "cites"}, {"source": "ProcMEM: Learning Reusable Procedural Memory from Experience via Non-Parametric PPO for LLM Agents", "target": "ProcMEM", "value": "proposed_model"}, {"source": "Position: Beyond Model-Centric Prediction -- Agentic Time Series Forecasting", "target": "agentic time series forecasting (ATSF)", "value": "proposed_model"}, {"source": "agentic time series forecasting (ATSF)", "target": "Position: Beyond Model-Centric Prediction -- Agentic Time Series Forecasting", "value": "author_of"}, {"source": "agentic time series forecasting (ATSF)", "target": "workflow-based design", "value": "cites"}, {"source": "agentic time series forecasting (ATSF)", "target": "agentic reinforcement learning", "value": "cites"}, {"source": "agentic time series forecasting (ATSF)", "target": "hybrid agentic workflow paradigm", "value": "cites"}, {"source": "Training language models to follow instructions with human feedback", "target": "InstructGPT", "value": "proposed_model"}, {"source": "Training language models to follow instructions with human feedback", "target": "GPT-3", "value": "baseline_model"}, {"source": "InstructGPT", "target": "public NLP datasets", "value": "evaluated_on"}, {"source": "Training language models to follow instructions with human feedback", "target": "GPT-3", "value": "cites"}, {"source": "Training language models to follow instructions with human feedback", "target": "InstructGPT", "value": "author_of"}, {"source": "PaLM: Scaling Language Modeling with Pathways", "target": "Pathways Language Model PaLM", "value": "proposed_model"}, {"source": "Pathways Language Model PaLM", "target": "BIG-bench", "value": "evaluated_on"}, {"source": "Pathways Language Model PaLM", "target": "Transformer language model", "value": "baseline_model"}, {"source": "ReAct: Synergizing Reasoning and Acting in Language Models", "target": "ReAct", "value": "proposed_model"}, {"source": "ReAct", "target": "HotpotQA", "value": "evaluated_on"}, {"source": "ReAct", "target": "Fever", "value": "evaluated_on"}, {"source": "ReAct", "target": "ALFWorld", "value": "evaluated_on"}, {"source": "ReAct", "target": "WebShop", "value": "evaluated_on"}, {"source": "ReAct", "target": "large language models (LLMs)", "value": "cites"}, {"source": "ReAct", "target": "chain-of-thought prompting", "value": "cites"}, {"source": "ReAct", "target": "imitation and reinforcement learning methods", "value": "cites"}, {"source": "ReAct", "target": "chain-of-thought prompting", "value": "baseline_model"}, {"source": "ReAct", "target": "imitation and reinforcement learning methods", "value": "baseline_model"}, {"source": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "target": "zzli2022", "value": "author_of"}, {"source": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "target": "OpenAI's o1/o3", "value": "cites"}, {"source": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "target": "DeepSeek's R1", "value": "cites"}, {"source": "From System 1 to System 2: A Survey of Reasoning Large Language Models", "target": "Awesome-Slow-Reason-System", "value": "evaluated_on"}, {"source": "Deep Research Agents: A Systematic Examination And Roadmap", "target": "Deep Research (DR) agents", "value": "proposed_model"}, {"source": "Deep Research Agents: A Systematic Examination And Roadmap", "target": "taxonomy", "value": "proposed_model"}, {"source": "Deep Research Agents: A Systematic Examination And Roadmap", "target": "benchmarks", "value": "evaluated_on"}, {"source": "Deep Research (DR) agents", "target": "benchmarks", "value": "uses_metric"}, {"source": "Deep Research Agents: A Systematic Examination And Roadmap", "target": "Large Language Models (LLMs)", "value": "cites"}, {"source": "Deep Research Agents: A Systematic Examination And Roadmap", "target": "Model Context Protocols (MCPs)", "value": "cites"}, {"source": "Deep Research Agents: A Systematic Examination And Roadmap", "target": "repository of DR agent research", "value": "cites"}, {"source": "Table-R1: Inference-Time Scaling for Table Reasoning", "target": "Table-R1-SFT", "value": "proposed_model"}, {"source": "Table-R1: Inference-Time Scaling for Table Reasoning", "target": "Table-R1-Zero", "value": "proposed_model"}, {"source": "Table-R1: Inference-Time Scaling for Table Reasoning", "target": "GPT-4.1", "value": "baseline_model"}, {"source": "Table-R1: Inference-Time Scaling for Table Reasoning", "target": "DeepSeek-R1", "value": "baseline_model"}, {"source": "Table-R1: Inference-Time Scaling for Table Reasoning", "target": "DeepSeek-R1", "value": "cites"}, {"source": "Table-R1: Inference-Time Scaling for Table Reasoning", "target": "GRPO algorithm", "value": "cites"}, {"source": "Table-R1: Inference-Time Scaling for Table Reasoning", "target": "Table-R1: Inference-Time Scaling for Table Reasoning", "value": "author_of"}, {"source": "Mind2Report: A Cognitive Deep Research Agent for Expert-Level Commercial Report Synthesis", "target": "Mind2Report", "value": "proposed_model"}, {"source": "Mind2Report: A Cognitive Deep Research Agent for Expert-Level Commercial Report Synthesis", "target": "QRC-Eval", "value": "evaluated_on"}, {"source": "Mind2Report: A Cognitive Deep Research Agent for Expert-Level Commercial Report Synthesis", "target": "OpenAI deep research agents", "value": "baseline_model"}, {"source": "Mind2Report: A Cognitive Deep Research Agent for Expert-Level Commercial Report Synthesis", "target": "Gemini deep research agents", "value": "baseline_model"}, {"source": "Mind2Report", "target": "QRC-Eval", "value": "uses_metric"}, {"source": "PaperScout: An Autonomous Agent for Academic Paper Search with Process-Aware Sequence-Level Policy Optimization", "target": "PaperScout", "value": "proposed_model"}, {"source": "PaperScout: An Autonomous Agent for Academic Paper Search with Process-Aware Sequence-Level Policy Optimization", "target": "Proximal Sequence Policy Optimization (PSPO)", "value": "proposed_model"}, {"source": "PaperScout", "target": "synthetic and real-world benchmarks", "value": "evaluated_on"}, {"source": "PaperScout", "target": "recall", "value": "uses_metric"}, {"source": "PaperScout", "target": "workflow-driven baselines", "value": "baseline_model"}, {"source": "PaperScout", "target": "RL baselines", "value": "baseline_model"}, {"source": "GGL-Net", "target": "Gradient-Guided Learning Network for Infrared Small Target Detection", "value": "proposed_model"}, {"source": "GGL-Net", "target": "NUAA-SIRST dataset", "value": "uses_metric"}, {"source": "GGL-Net", "target": "NUDT-SIRST dataset", "value": "uses_metric"}, {"source": "GGL-Net", "target": "NUAA-SIRST dataset", "value": "evaluated_on"}, {"source": "GGL-Net", "target": "NUDT-SIRST dataset", "value": "evaluated_on"}, {"source": "GGL-Net", "target": "gradient supplementary module (GSM)", "value": "cites"}, {"source": "GGL-Net", "target": "two-way guidance fusion module (TGFM)", "value": "cites"}, {"source": "YuChuang1205", "target": "Gradient-Guided Learning Network for Infrared Small Target Detection", "value": "author_of"}, {"source": "A Retrieval-Augmented Generation Approach to Extracting Algorithmic Logic from Neural Networks", "target": "NN-RAG", "value": "proposed_model"}, {"source": "NN-RAG", "target": "LEMUR dataset", "value": "evaluated_on"}, {"source": "CenterMamba-SAM", "target": "CenterMamba encoder", "value": "proposed_model"}, {"source": "CenterMamba-SAM", "target": "memory-driven structural prompt generator", "value": "proposed_model"}, {"source": "CenterMamba-SAM", "target": "memory-augmented multi-scale decoder", "value": "proposed_model"}, {"source": "CenterMamba-SAM", "target": "brain lesion segmentation", "value": "evaluated_on"}, {"source": "CenterMamba-SAM", "target": "public benchmarks", "value": "evaluated_on"}, {"source": "IMobileTransformer", "target": "rice disease identification", "value": "proposed_model"}, {"source": "RF-DETR", "target": "RF-DETR: Neural Architecture Search for Real-Time Detection Transformers", "value": "proposed_model"}, {"source": "RF-DETR", "target": "COCO", "value": "evaluated_on"}, {"source": "RF-DETR", "target": "Roboflow100-VL", "value": "evaluated_on"}, {"source": "RF-DETR", "target": "D-FINE", "value": "baseline_model"}, {"source": "RF-DETR", "target": "GroundingDINO", "value": "baseline_model"}, {"source": "RF-DETR", "target": "vision-language model (VLM)", "value": "cites"}, {"source": "RF-DETR", "target": "DETRs", "value": "cites"}, {"source": "Non-invasive diagnosis of nutrient deficiencies in winter wheat and winter rye using UAV-based RGB images", "target": "winter wheat", "value": "evaluated_on"}, {"source": "Non-invasive diagnosis of nutrient deficiencies in winter wheat and winter rye using UAV-based RGB images", "target": "winter rye", "value": "evaluated_on"}, {"source": "Non-invasive diagnosis of nutrient deficiencies in winter wheat and winter rye using UAV-based RGB images", "target": "UAV-based RGB images", "value": "uses_metric"}, {"source": "Deep learning models for efficient geotechnical predictions: reducing training effort and data requirements with transfer learning", "target": "transfer learning", "value": "proposed_model"}, {"source": "Image quality assessment: from error visibility to structural similarity", "target": "error visibility", "value": "evaluated_on"}, {"source": "Image quality assessment: from error visibility to structural similarity", "target": "structural similarity", "value": "evaluated_on"}, {"source": "FreeOrbit4D", "target": "FreeOrbit4D: Training-Free Arbitrary Camera Redirection for Monocular Videos via Geometry-Complete 4D Reconstruction", "value": "proposed_model"}, {"source": "FreeOrbit4D", "target": "monocular video", "value": "uses_metric"}, {"source": "FreeOrbit4D", "target": "monocular video", "value": "evaluated_on"}, {"source": "FreeOrbit4D", "target": "diffusion-based methods", "value": "baseline_model"}, {"source": "FreeOrbit4D", "target": "diffusion-based methods", "value": "cites"}, {"source": "FreeOrbit4D", "target": "geometry-complete 4D proxy", "value": "uses_metric"}, {"source": "FreeOrbit4D", "target": "FreeOrbit4D: Training-Free Arbitrary Camera Redirection for Monocular Videos via Geometry-Complete 4D Reconstruction", "value": "author_of"}, {"source": "object-centric multi-view diffusion model", "target": "FreeOrbit4D: Training-Free Arbitrary Camera Redirection for Monocular Videos via Geometry-Complete 4D Reconstruction", "value": "proposed_model"}, {"source": "conditional video diffusion model", "target": "FreeOrbit4D: Training-Free Arbitrary Camera Redirection for Monocular Videos via Geometry-Complete 4D Reconstruction", "value": "proposed_model"}, {"source": "FreeOrbit4D", "target": "edit propagation", "value": "cites"}, {"source": "FreeOrbit4D", "target": "4D data generation", "value": "cites"}, {"source": "NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos", "target": "NeoVerse", "value": "proposed_model"}, {"source": "NeoVerse", "target": "standard reconstruction and generation benchmarks", "value": "evaluated_on"}, {"source": "NeoVerse", "target": "4D world modeling methods", "value": "baseline_model"}, {"source": "NeoVerse", "target": "4D world modeling methods", "value": "cites"}, {"source": "Scalable Diffusion Models with Transformers", "target": "Diffusion Transformers (DiTs)", "value": "proposed_model"}, {"source": "Diffusion Transformers (DiTs)", "target": "U-Net", "value": "baseline_model"}, {"source": "Diffusion Transformers (DiTs)", "target": "ImageNet 512x512", "value": "evaluated_on"}, {"source": "Diffusion Transformers (DiTs)", "target": "ImageNet 256x256", "value": "evaluated_on"}, {"source": "Diffusion Transformers (DiTs)", "target": "FID", "value": "uses_metric"}, {"source": "Diffusion Transformers (DiTs)", "target": "Gflops", "value": "uses_metric"}, {"source": "DiT-XL/2", "target": "ImageNet 512x512", "value": "evaluated_on"}, {"source": "DiT-XL/2", "target": "ImageNet 256x256", "value": "evaluated_on"}, {"source": "RoFormer: Enhanced Transformer with Rotary Position Embedding", "target": "RoPE", "value": "proposed_model"}, {"source": "RoFormer: Enhanced Transformer with Rotary Position Embedding", "target": "long text classification benchmark datasets", "value": "evaluated_on"}, {"source": "RoFormer: Enhanced Transformer with Rotary Position Embedding", "target": "transformer", "value": "cites"}, {"source": "RoFormer", "target": "long text classification benchmark datasets", "value": "uses_metric"}, {"source": "The Role of World Models in Shaping Autonomous Driving: A Comprehensive Survey", "target": "LMD0311", "value": "author_of"}, {"source": "The Role of World Models in Shaping Autonomous Driving: A Comprehensive Survey", "target": "Driving World Model (DWM)", "value": "cites"}, {"source": "The Role of World Models in Shaping Autonomous Driving: A Comprehensive Survey", "target": "autonomous driving (AD)", "value": "cites"}, {"source": "Driving World Model (DWM)", "target": "autonomous driving (AD)", "value": "proposed_model"}, {"source": "Driving World Model (DWM)", "target": "mainstream simulators", "value": "evaluated_on"}, {"source": "Driving World Model (DWM)", "target": "high-impact datasets", "value": "evaluated_on"}, {"source": "Driving World Model (DWM)", "target": "various metrics", "value": "uses_metric"}, {"source": "Driving World Model (DWM)", "target": "representative approaches", "value": "baseline_model"}, {"source": "representative approaches", "target": "generating tasks", "value": "evaluated_on"}, {"source": "representative approaches", "target": "driving tasks", "value": "evaluated_on"}, {"source": "current research", "target": "future directions", "value": "cites"}, {"source": "Vision meets robotics: The KITTI dataset", "target": "KITTI dataset", "value": "evaluated_on"}, {"source": "FlexMap: Generalized HD Map Construction from Flexible Camera Configurations", "target": "FlexMap", "value": "proposed_model"}, {"source": "FlexMap", "target": "HD maps", "value": "uses_metric"}, {"source": "FlexMap", "target": "autonomous driving systems", "value": "evaluated_on"}, {"source": "FlexMap", "target": "geometry-aware foundation model", "value": "baseline_model"}, {"source": "FlexMap", "target": "spatial-temporal enhancement module", "value": "author_of"}, {"source": "FlexMap", "target": "camera-aware decoder", "value": "author_of"}, {"source": "We", "target": "Universal Feed-Forward Metric 3D Reconstruction", "value": "author_of"}, {"source": "Universal Feed-Forward Metric 3D Reconstruction", "target": "MapAnything", "value": "proposed_model"}, {"source": "Seedream 4.0", "target": "diffusion transformer", "value": "proposed_model"}, {"source": "Seedream 4.0", "target": "VAE", "value": "proposed_model"}, {"source": "Seedream 4.0", "target": "text-to-image synthesis", "value": "evaluated_on"}, {"source": "Seedream 4.0", "target": "image editing", "value": "evaluated_on"}, {"source": "Seedream 4.0", "target": "Seedream 4.5", "value": "cites"}, {"source": "We", "target": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "value": "author_of"}, {"source": "Seedream 4.0", "target": "VLM model", "value": "proposed_model"}, {"source": "Seedream 4.0", "target": "adversarial distillation", "value": "proposed_model"}, {"source": "Seedream 4.0", "target": "distribution matching", "value": "proposed_model"}, {"source": "Seedream 4.0", "target": "quantization", "value": "proposed_model"}, {"source": "Seedream 4.0", "target": "speculative decoding", "value": "proposed_model"}, {"source": "Seedream 4.0", "target": "multi-image composition", "value": "evaluated_on"}, {"source": "Seedream 4.0", "target": "Volcano Engine", "value": "cites"}, {"source": "Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation", "target": "Echo-4o", "value": "proposed_model"}, {"source": "Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation", "target": "Echo-4o-Image", "value": "proposed_model"}, {"source": "Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation", "target": "GenEval++", "value": "proposed_model"}, {"source": "Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation", "target": "Imagine-Bench", "value": "proposed_model"}, {"source": "Echo-4o", "target": "Bagel", "value": "baseline_model"}, {"source": "Echo-4o", "target": "GenEval++", "value": "evaluated_on"}, {"source": "Echo-4o", "target": "Imagine-Bench", "value": "evaluated_on"}, {"source": "Echo-4o-Image", "target": "GenEval++", "value": "evaluated_on"}, {"source": "Echo-4o-Image", "target": "Imagine-Bench", "value": "evaluated_on"}, {"source": "Echo-4o-Image", "target": "GenEval++", "value": "uses_metric"}, {"source": "Echo-4o-Image", "target": "Imagine-Bench", "value": "uses_metric"}, {"source": "Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation", "target": "GPT-4o", "value": "cites"}, {"source": "Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation", "target": "Bagel", "value": "cites"}, {"source": "Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation", "target": "OmniGen2", "value": "cites"}, {"source": "Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation", "target": "BLIP3-o", "value": "cites"}, {"source": "Lumina-DiMOO", "target": "Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding", "value": "proposed_model"}, {"source": "Lumina-DiMOO", "target": "autoregressive (AR) or hybrid AR-Diffusion paradigms", "value": "baseline_model"}, {"source": "Lumina-DiMOO", "target": "multiple benchmarks", "value": "evaluated_on"}, {"source": "Lumina-DiMOO", "target": "autoregressive (AR) or hybrid AR-Diffusion paradigms", "value": "cites"}, {"source": "Lumina-DiMOO", "target": "code and checkpoints", "value": "author_of"}, {"source": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "target": "NextStep-1", "value": "proposed_model"}, {"source": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "target": "autoregressive models", "value": "baseline_model"}, {"source": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "target": "diffusion models", "value": "baseline_model"}, {"source": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "target": "vector quantization (VQ)", "value": "baseline_model"}, {"source": "NextStep-1", "target": "text-to-image generation tasks", "value": "uses_metric"}, {"source": "NextStep-1", "target": "text-to-image generation tasks", "value": "evaluated_on"}, {"source": "RoBERTa: A Robustly Optimized BERT Pretraining Approach", "target": "BERT", "value": "baseline_model"}, {"source": "RoBERTa: A Robustly Optimized BERT Pretraining Approach", "target": "GLUE", "value": "evaluated_on"}, {"source": "RoBERTa: A Robustly Optimized BERT Pretraining Approach", "target": "RACE", "value": "evaluated_on"}, {"source": "RoBERTa: A Robustly Optimized BERT Pretraining Approach", "target": "SQuAD", "value": "evaluated_on"}, {"source": "RoBERTa: A Robustly Optimized BERT Pretraining Approach", "target": "BERT", "value": "cites"}, {"source": "Devlin et al., 2019", "target": "BERT", "value": "author_of"}, {"source": "DeepSeek-R1", "target": "reinforcement learning (RL)", "value": "proposed_model"}, {"source": "DeepSeek-R1", "target": "large language models (LLMs)", "value": "baseline_model"}, {"source": "DeepSeek-R1", "target": "mathematics", "value": "evaluated_on"}, {"source": "DeepSeek-R1", "target": "coding competitions", "value": "evaluated_on"}, {"source": "DeepSeek-R1", "target": "STEM fields", "value": "evaluated_on"}, {"source": "DeepSeek-R1", "target": "reasoning patterns", "value": "uses_metric"}, {"source": "DeepSeek-R1", "target": "chain-of-thought prompting", "value": "cites"}, {"source": "DeepSeek-R1", "target": "supervised learning", "value": "cites"}, {"source": "reinforcement learning (RL)", "target": "DeepSeek-R1", "value": "author_of"}, {"source": "large language models (LLMs)", "target": "DeepSeek-R1", "value": "author_of"}, {"source": "Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning", "target": "Search-R1", "value": "proposed_model"}, {"source": "Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning", "target": "seven question-answering datasets", "value": "evaluated_on"}, {"source": "Search-R1", "target": "Qwen2.5-7B", "value": "baseline_model"}, {"source": "Search-R1", "target": "Qwen2.5-3B", "value": "baseline_model"}, {"source": "PeterGriffinJin", "target": "Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning", "value": "author_of"}, {"source": "Med-PaLM 2", "target": "Toward expert-level medical question answering with large language models", "value": "proposed_model"}, {"source": "Med-PaLM 2", "target": "Med-PaLM", "value": "baseline_model"}, {"source": "Med-PaLM 2", "target": "MedQA", "value": "evaluated_on"}, {"source": "Med-PaLM 2", "target": "MedMCQA", "value": "evaluated_on"}, {"source": "Med-PaLM 2", "target": "PubMedQA", "value": "evaluated_on"}, {"source": "Med-PaLM 2", "target": "MMLU clinical topics", "value": "evaluated_on"}, {"source": "Toward expert-level medical question answering with large language models", "target": "Med-PaLM", "value": "cites"}, {"source": "SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training", "target": "Supervised fine-tuning (SFT)", "value": "proposed_model"}, {"source": "SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training", "target": "reinforcement learning (RL)", "value": "proposed_model"}, {"source": "SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training", "target": "GeneralPoints", "value": "evaluated_on"}, {"source": "SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training", "target": "V-IRL", "value": "evaluated_on"}, {"source": "Supervised fine-tuning (SFT)", "target": "GeneralPoints", "value": "uses_metric"}, {"source": "reinforcement learning (RL)", "target": "GeneralPoints", "value": "uses_metric"}, {"source": "Supervised fine-tuning (SFT)", "target": "V-IRL", "value": "uses_metric"}, {"source": "reinforcement learning (RL)", "target": "V-IRL", "value": "uses_metric"}, {"source": "reinforcement learning (RL)", "target": "outcome-based reward", "value": "baseline_model"}, {"source": "EquiCSP", "target": "Equivariant Diffusion for Crystal Structure Prediction", "value": "proposed_model"}, {"source": "EquiCSP", "target": "Crystal Structure Prediction", "value": "evaluated_on"}, {"source": "Equivariant Diffusion for Crystal Structure Prediction", "target": "symmetry-aware deep learning models", "value": "cites"}, {"source": "Equivariant Diffusion for Crystal Structure Prediction", "target": "diffusion models", "value": "cites"}, {"source": "EquiCSP", "target": "existing models", "value": "baseline_model"}, {"source": "WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling", "target": "WorldPlay", "value": "proposed_model"}, {"source": "WorldPlay", "target": "Dual Action Representation", "value": "proposed_model"}, {"source": "WorldPlay", "target": "Reconstituted Context Memory", "value": "proposed_model"}, {"source": "WorldPlay", "target": "Context Forcing", "value": "proposed_model"}, {"source": "WorldPlay", "target": "existing techniques", "value": "evaluated_on"}, {"source": "Context Forcing", "target": "memory-aware model", "value": "proposed_model"}, {"source": "Context Forcing", "target": "teacher", "value": "cites"}, {"source": "Context Forcing", "target": "student", "value": "cites"}, {"source": "Native and Compact Structured Latents for 3D Generation", "target": "O-Voxel", "value": "proposed_model"}, {"source": "Native and Compact Structured Latents for 3D Generation", "target": "Sparse Compression VAE", "value": "proposed_model"}, {"source": "Native and Compact Structured Latents for 3D Generation", "target": "flow-matching models", "value": "proposed_model"}, {"source": "Native and Compact Structured Latents for 3D Generation", "target": "public 3D asset datasets", "value": "evaluated_on"}, {"source": "What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?", "target": "JEPA-WMs", "value": "proposed_model"}, {"source": "What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?", "target": "simulated environments", "value": "evaluated_on"}, {"source": "What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?", "target": "real-world robotic data", "value": "evaluated_on"}, {"source": "JEPA-WMs", "target": "DINO-WM", "value": "baseline_model"}, {"source": "JEPA-WMs", "target": "V-JEPA-2-AC", "value": "baseline_model"}, {"source": "Progressive Learned Image Transmission for Semantic Communication Using Hierarchical VAE", "target": "PLIT", "value": "proposed_model"}, {"source": "We", "target": "Progressive Learned Image Transmission for Semantic Communication Using Hierarchical VAE", "value": "author_of"}, {"source": "STORM: Search-Guided Generative World Models for Robotic Manipulation", "target": "STORM", "value": "proposed_model"}, {"source": "STORM: Search-Guided Generative World Models for Robotic Manipulation", "target": "Search-Guided Generative World Models", "value": "proposed_model"}, {"source": "STORM", "target": "SimplerEnv", "value": "evaluated_on"}, {"source": "STORM", "target": "Frechet Video Distance", "value": "uses_metric"}, {"source": "STORM", "target": "CogACT", "value": "baseline_model"}, {"source": "STORM", "target": "Vision-Language-Action (VLA) models", "value": "cites"}, {"source": "STORM", "target": "Monte Carlo Tree Search (MCTS)", "value": "cites"}, {"source": "Evolutionary Optimization of Model Merging Recipes", "target": "evolutionary approach", "value": "proposed_model"}, {"source": "evolutionary approach", "target": "Japanese LLM benchmarks", "value": "uses_metric"}, {"source": "evolutionary approach", "target": "Japanese LLM benchmarks", "value": "evaluated_on"}, {"source": "evolutionary approach", "target": "Japanese LLM with Math reasoning capabilities", "value": "proposed_model"}, {"source": "evolutionary approach", "target": "culturally-aware Japanese VLM", "value": "proposed_model"}, {"source": "Japanese Math LLM", "target": "Japanese LLM benchmarks", "value": "evaluated_on"}, {"source": "culturally-aware Japanese VLM", "target": "Japanese culture-specific content", "value": "evaluated_on"}, {"source": "evolutionary approach", "target": "Japanese VLMs", "value": "baseline_model"}, {"source": "evolutionary approach", "target": "model merging", "value": "cites"}, {"source": "evolutionary approach", "target": "open-source models", "value": "cites"}, {"source": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation", "target": "RNN Encoder-Decoder", "value": "proposed_model"}, {"source": "RNN Encoder-Decoder", "target": "statistical machine translation system", "value": "evaluated_on"}, {"source": "statistical machine translation system", "target": "log-linear model", "value": "uses_metric"}, {"source": "DriveMLM", "target": "DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving", "value": "proposed_model"}, {"source": "DriveMLM", "target": "Autopilot", "value": "baseline_model"}, {"source": "DriveMLM", "target": "Apollo", "value": "baseline_model"}, {"source": "DriveMLM", "target": "CARLA Town05 Long", "value": "evaluated_on"}, {"source": "DriveMLM", "target": "CARLA Town05 Long", "value": "uses_metric"}, {"source": "DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving", "target": "Large language models (LLMs)", "value": "cites"}, {"source": "DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving", "target": "Autonomous driving (AD)", "value": "cites"}, {"source": "DriveMLM", "target": "DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving", "value": "author_of"}, {"source": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "target": "multi-modal benchmarks", "value": "uses_metric"}, {"source": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "target": "large multi-modality models", "value": "evaluated_on"}, {"source": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "target": "OpenVLM Leaderboard", "value": "proposed_model"}, {"source": "VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models", "target": "PyTorch", "value": "baseline_model"}, {"source": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models", "target": "chain of thought prompting", "value": "proposed_model"}, {"source": "chain of thought prompting", "target": "GSM8K benchmark", "value": "evaluated_on"}, {"source": "chain of thought prompting", "target": "GPT-3", "value": "baseline_model"}, {"source": "Rich feature hierarchies for accurate object detection and semantic segmentation", "target": "R-CNN: Regions with CNN features", "value": "proposed_model"}, {"source": "Rich feature hierarchies for accurate object detection and semantic segmentation", "target": "PASCAL VOC dataset", "value": "evaluated_on"}, {"source": "Rich feature hierarchies for accurate object detection and semantic segmentation", "target": "ILSVRC2013 detection dataset", "value": "evaluated_on"}, {"source": "Rich feature hierarchies for accurate object detection and semantic segmentation", "target": "mean average precision (mAP)", "value": "uses_metric"}, {"source": "Rich feature hierarchies for accurate object detection and semantic segmentation", "target": "OverFeat", "value": "cites"}, {"source": "Intelligent recognition of GPR road hidden defect images based on feature fusion and attention mechanism", "target": "Multi-modal Chain and Global Attention Network (MCGA-Net)", "value": "proposed_model"}, {"source": "Intelligent recognition of GPR road hidden defect images based on feature fusion and attention mechanism", "target": "DCGAN-based data augmentation strategy", "value": "proposed_model"}, {"source": "Multi-modal Chain and Global Attention Network (MCGA-Net)", "target": "Precision", "value": "uses_metric"}, {"source": "Multi-modal Chain and Global Attention Network (MCGA-Net)", "target": "Recall", "value": "uses_metric"}, {"source": "Multi-modal Chain and Global Attention Network (MCGA-Net)", "target": "mAP@50", "value": "uses_metric"}, {"source": "Multi-modal Chain and Global Attention Network (MCGA-Net)", "target": "GPR road hidden defect images", "value": "evaluated_on"}, {"source": "Multi-modal Chain and Global Attention Network (MCGA-Net)", "target": "Ground Penetrating Radar (GPR)", "value": "cites"}, {"source": "Multi-modal Chain and Global Attention Network (MCGA-Net)", "target": "MS COCO", "value": "cites"}, {"source": "Federated Learning Architectures: A Performance Evaluation with Crop Yield Prediction Application", "target": "centralized federated learning framework", "value": "proposed_model"}, {"source": "Federated Learning Architectures: A Performance Evaluation with Crop Yield Prediction Application", "target": "decentralized federated learning framework", "value": "proposed_model"}, {"source": "centralized federated learning framework", "target": "cloud-only framework", "value": "baseline_model"}, {"source": "centralized federated learning framework", "target": "prediction accuracy", "value": "evaluated_on"}, {"source": "centralized federated learning framework", "target": "precision", "value": "evaluated_on"}, {"source": "centralized federated learning framework", "target": "recall", "value": "evaluated_on"}, {"source": "centralized federated learning framework", "target": "F1-Score", "value": "evaluated_on"}, {"source": "centralized federated learning framework", "target": "training time", "value": "evaluated_on"}, {"source": "decentralized federated learning framework", "target": "prediction accuracy", "value": "evaluated_on"}, {"source": "decentralized federated learning framework", "target": "precision", "value": "evaluated_on"}, {"source": "decentralized federated learning framework", "target": "recall", "value": "evaluated_on"}, {"source": "decentralized federated learning framework", "target": "F1-Score", "value": "evaluated_on"}, {"source": "decentralized federated learning framework", "target": "training time", "value": "evaluated_on"}, {"source": "centralized federated learning framework", "target": "prediction accuracy", "value": "uses_metric"}, {"source": "centralized federated learning framework", "target": "precision", "value": "uses_metric"}, {"source": "centralized federated learning framework", "target": "recall", "value": "uses_metric"}, {"source": "centralized federated learning framework", "target": "F1-Score", "value": "uses_metric"}, {"source": "centralized federated learning framework", "target": "training time", "value": "uses_metric"}, {"source": "decentralized federated learning framework", "target": "prediction accuracy", "value": "uses_metric"}, {"source": "decentralized federated learning framework", "target": "precision", "value": "uses_metric"}, {"source": "decentralized federated learning framework", "target": "recall", "value": "uses_metric"}, {"source": "decentralized federated learning framework", "target": "F1-Score", "value": "uses_metric"}, {"source": "decentralized federated learning framework", "target": "training time", "value": "uses_metric"}, {"source": "DepictQA-Wild", "target": "Enhancing Descriptive Image Quality Assessment with A Large-scale Multi-modal Dataset", "value": "proposed_model"}, {"source": "DepictQA-Wild", "target": "traditional score-based methods", "value": "baseline_model"}, {"source": "DepictQA-Wild", "target": "prior VLM-based IQA models", "value": "baseline_model"}, {"source": "DepictQA-Wild", "target": "GPT-4V", "value": "baseline_model"}, {"source": "DepictQA-Wild", "target": "distortion identification", "value": "evaluated_on"}, {"source": "DepictQA-Wild", "target": "instant rating", "value": "evaluated_on"}, {"source": "DepictQA-Wild", "target": "reasoning tasks", "value": "evaluated_on"}, {"source": "DepictQA-Wild", "target": "web-downloaded images", "value": "evaluated_on"}, {"source": "DepictQA-Wild", "target": "model-processed images", "value": "evaluated_on"}, {"source": "DepictQA-Wild", "target": "DQ-495K", "value": "uses_metric"}, {"source": "Enhancing Descriptive Image Quality Assessment with A Large-scale Multi-modal Dataset", "target": "Vision Language Models (VLMs)", "value": "cites"}, {"source": "Enhancing Descriptive Image Quality Assessment with A Large-scale Multi-modal Dataset", "target": "VLM-based Image Quality Assessment (IQA)", "value": "cites"}, {"source": "Deep contextualized word representations", "target": "deep bidirectional language model (biLM)", "value": "proposed_model"}, {"source": "Deep contextualized word representations", "target": "question answering", "value": "evaluated_on"}, {"source": "Deep contextualized word representations", "target": "textual entailment", "value": "evaluated_on"}, {"source": "Deep contextualized word representations", "target": "sentiment analysis", "value": "evaluated_on"}, {"source": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "target": "reinforcement learning", "value": "proposed_model"}, {"source": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "target": "supervised learning", "value": "baseline_model"}, {"source": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "target": "mathematics", "value": "evaluated_on"}, {"source": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "target": "coding competitions", "value": "evaluated_on"}, {"source": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "target": "STEM fields", "value": "evaluated_on"}, {"source": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "target": "large language models", "value": "cites"}, {"source": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "target": "chain-of-thought prompting", "value": "cites"}],
                    categories: [{"name": "Thesis"}, {"name": "Person"}, {"name": "TechArticle"}, {"name": "Dataset"}, {"name": "SoftwareApplication"}, {"name": "CreativeWork"}, {"name": "Article"}, {"name": "Report"}],
                    roam: true,
                    label: { show: true, position: 'right', formatter: '{b}' },
                    edgeLabel: { fontSize: 11, formatter: '{c}' },
                    edgeSymbol: ['none', 'arrow'], edgeSymbolSize: 10,
                    lineStyle: { color: 'source', curveness: 0.3 },
                    force: { repulsion: 1500, edgeLength: 250 },
                    emphasis: { focus: 'adjacency', lineStyle: { width: 4 } }
                }]
            };
            myChart.setOption(option);
            setTimeout(function() { myChart.resize(); }, 100);
            window.addEventListener('resize', function() { myChart.resize(); });
        }
        if (document.readyState === 'loading') {
            document.addEventListener('DOMContentLoaded', initChart);
        } else {
            initChart();
        }
    </script>
</body>
</html>